{
  "metadata": {
    "timestamp": "2025-07-09 15:02:24",
    "task_id": "b233e473",
    "total_courses": 64,
    "subjects": [
      {
        "url": "https://ocw.mit.edu/search/?l=Non-Credit",
        "name": "General"
      }
    ]
  },
  "courses": [
    {
      "course_name": "Competency-Based Education: The Why, What, and How",
      "course_description": "This course will help you develop an understanding of the characteristic elements of competency-based education (CBE) and how schools are implementing it. You will learn about CBE’s potential for closing opportunity gaps, as well as challenges and concerns. You will get a closer look at what the implementation of CBE looks and feels like for students, teachers, administrators, families, and community members. You will consider the kinds of system-wide shifts necessary to support this innovation in education.\nBy looking at research and hearing from experts and voices in schools, you will leave the course equipped to start or continue conversations about whether CBE is a good fit in your context.\nThis course is part of the Open Learning Library, which is free to use. You have the option to sign up and enroll in the course if you want to track your progress, or you can view and use all the materials without enrolling.",
      "topics": [
        "Teaching and Education",
        "Teaching and Education"
      ],
      "syllabus_content": "",
      "files": [],
      "source_url": "https://ocw.mit.edu/courses/res-cms-502-competency-based-education-the-why-what-and-how-spring-2020/",
      "course_info": "RES.CMS-502 | Non-Credit",
      "subject": "General"
    },
    {
      "course_name": "Collaborative Design and Creative Expression with Arduino Microcontrollers",
      "course_description": "This is a 9-day hands-on workshop about collaboration, design, and electronics prototyping. No previous experience with computer programming or electronics is required. Beginning students will be taught everything they need to know and advanced students will be challenged to learn new skills. Participants will learn about microcontroller programming using Arduino, collaborative software development using GitHub, solderless electronics prototyping, electronic sensors, rapid prototyping, and small team management.\nThis course is offered during the Independent Activities Period (IAP), which is a special 4-week term at MIT that runs from the first week of January until the end of the month.",
      "topics": [
        "Engineering",
        "Computer Science",
        "Electrical Engineering",
        "Robotics and Control Systems",
        "Engineering",
        "Computer Science",
        "Electrical Engineering",
        "Robotics and Control Systems"
      ],
      "syllabus_content": "Workshop Meeting Times\n\nLectures and Open Lab: 9 sessions in total, 3 hours/session\n\nOverview\n\nThis short course takes place at MIT during the 2017 IAP (Independent Activities Period).\n\nDescription\n\nThis is a 9-day hands-on workshop about collaboration, design, and electronics prototyping. No previous experience with computer programming or electronics is required. Beginning students will be taught everything they need to know and advanced students will be challenged to learn new skills. Participants will work in small teams to design and build electronics projects using open-source microprocessors. Team projects are completely open-ended and designed by participants, past projects have included: An internet-connected weather simulation station, a giant LED billboard, and a CNC drawing machine. Participants will complete three guided projects in order to learn the fundamentals and will then break into small teams to complete a one-day short project of their choosing. After the short project, participants will break into new teams that will each get $250 and four days to design, plan, and build a custom project of their choice. On the last day of the course, students will present their projects in public exhibition and have the chance to win a prize for crowd favorite. Participants will learn about microcontroller programming using Arduino, collaborative software development using GitHub, solderless electronics prototyping, electronic sensors, rapid prototyping, and small team management.\n\nGrading\n\nThere are no grades for this course.\n\nLogistics\n\nThe class size is 30 students from varying backgrounds, and the class takes place in a classroom with movable desks or tables so students can form teams.\n\nSchedule\n\nSES #\n\nTOPICS / CLASS ACTIVITIES\n\nSurvey of GitHub, Arduino, and the basics of software collaboration:\n\nAn overview of GitHub collaboration\n\nCreating and contributing to repositories\n\nAn overview of Arduino microcontrollers\n\nRecreating a guided project (roll-a-ball)\n\nThe basics of design and ideation:\n\nUsing the motors\n\nExpand, explore, and personalize the roll-a-ball example\n\nOverview of collaborative design process\n\nShort project: Form team for short project\n\nStart short project\n\nProject design and execution for short projects:\n\nCrash course in prototyping and documenting ideas\n\nShort project\n\nIdeation, pitches, team formation, and project selection for short projects:\n\nReflections from yesterday\n\nOverview of plan, team structure and expected outcomes\n\nProject ideation\n\nTeam formation\n\nGet started or refine idea\n\nPresentation of short projects\n\nProject time for long projects: Meet and create with guidance\n\nProject time for long projects: Meet and create with guidance\n\nProject time for long projects: Meet and create with guidance\n\nPresentation of long projects",
      "files": [],
      "source_url": "https://ocw.mit.edu/courses/res-3-002-collaborative-design-and-creative-expression-with-arduino-microcontrollers-january-iap-2017/",
      "course_info": "RES.3-002 | Non-Credit",
      "subject": "General"
    },
    {
      "course_name": "CITE Reports",
      "course_description": "Created in 2012 at the Massachusetts Institute of Technology, the Comprehensive Initiative on Technology Evaluation (CITE) is the first-ever program dedicated to developing methods for product evaluation in global development. CITE produces technology evaluations that provide evidence for data-driven decision-making by development workers, donors, manufacturers, suppliers, and consumers themselves. In addition, CITE evaluations lead to significant developing insights, helping us better understand development challenges.",
      "topics": [
        "Social Science",
        "Public Administration",
        "Science and Technology Policy",
        "Society",
        "The Developing World",
        "Social Science",
        "Public Administration",
        "Science and Technology Policy",
        "Society",
        "The Developing World"
      ],
      "syllabus_content": "",
      "files": [],
      "source_url": "https://ocw.mit.edu/courses/res-11-001-cite-reports-fall-2015/",
      "course_info": "RES.11-001 | Non-Credit",
      "subject": "General"
    },
    {
      "course_name": "Day of AI",
      "course_description": "This resource is to support teachers and educators to run Day of AI activities in their classrooms through curriculum packages and teacher training, all of which is available at no cost to participants.\nDeveloped by leading faculty and educators from MIT RAISE, the curriculum features up to four hours of hands-on activities that engage kids in creative discovery, discussion, and play as they learn the fundamentals of AI, investigate the societal impact of these technologies, and bring artificial intelligence to life through lessons and activities that are accessible to all, even those with no computer science or technical background.",
      "topics": [
        "Engineering",
        "Computer Science",
        "Artificial Intelligence",
        "Teaching and Education",
        "Curriculum and Teaching",
        "Engineering",
        "Computer Science",
        "Artificial Intelligence",
        "Teaching and Education",
        "Curriculum and Teaching"
      ],
      "syllabus_content": "",
      "files": [],
      "source_url": "https://ocw.mit.edu/courses/res-mas-002-day-of-ai-spring-2022/",
      "course_info": "RES.MAS-002 | Non-Credit",
      "subject": "General"
    },
    {
      "course_name": "Brave New Planet",
      "course_description": "Utopia or dystopia? It’s up to us.\nIn the 21st century, powerful technologies have been appearing at a breathtaking pace—related to the internet, artificial intelligence, genetic engineering, and more. They have amazing potential upsides, but we can’t ignore the serious risks that come with them.\nBrave New Planet is a podcast that delves deep into the most exciting and challenging scientific frontiers, helping us understand them and grapple with their implications. Dr. Eric Lander, president and founding director of the Broad Institute of MIT and Harvard, is a geneticist, molecular biologist, and mathematician who was a leader of the Human Genome Project and for eight years served as a science advisor to the White House for President Obama. He’s also the host of Brave New Planet, and he’s talked to leading researchers, journalists, doctors, policy makers, activists, and legal experts to illuminate how this generation’s choices will shape the future as never before.\nBrave New Planet is a partnership between the Broad Institute, Pushkin Industries, and the Boston Globe.",
      "topics": [
        "Energy",
        "Climate",
        "Renewables",
        "Engineering",
        "Computer Science",
        "Artificial Intelligence",
        "Humanities",
        "Philosophy",
        "Ethics",
        "Science",
        "Biology",
        "Genetics",
        "Earth Science",
        "Climate Studies",
        "Social Science",
        "Public Administration",
        "Science and Technology Policy",
        "Energy",
        "Climate",
        "Renewables",
        "Engineering",
        "Computer Science",
        "Artificial Intelligence",
        "Humanities",
        "Philosophy",
        "Ethics",
        "Science",
        "Biology",
        "Genetics",
        "Earth Science",
        "Climate Studies",
        "Social Science",
        "Public Administration",
        "Science and Technology Policy"
      ],
      "syllabus_content": "",
      "files": [],
      "source_url": "https://ocw.mit.edu/courses/res-7-003-brave-new-planet-fall-2020/",
      "course_info": "RES.7-003 | Non-Credit",
      "subject": "General"
    },
    {
      "course_name": "Design Thinking for Leading and Learning",
      "course_description": "How do we prepare K-12 students and learning communities to be as successful as possible? If future jobs require creativity, problem-solving, and communication, how do we teach these skills in meaningful ways? How do we bring together passionate school leaders to create systemic solutions to educational challenges? Come explore these questions and more in Design Thinking for Leading and Learning.\nThe course is organized into three sections that combine design thinking content with real-world education examples, as well as opportunities for learners to apply concepts in their own setting.\nThis course is part of the Open Learning Library, which is free to use. You have the option to sign up and enroll in the course if you want to track your progress, or you can view and use all the materials without enrolling.",
      "topics": [
        "Teaching and Education",
        "Education Policy",
        "Educational Technology",
        "Teaching and Education",
        "Education Policy",
        "Educational Technology"
      ],
      "syllabus_content": "",
      "files": [],
      "source_url": "https://ocw.mit.edu/courses/res-cms-155-design-thinking-for-leading-and-learning-spring-2019/",
      "course_info": "RES.CMS-155 | Non-Credit",
      "subject": "General"
    },
    {
      "course_name": "Телемосты (Telebridges) Russian Conversation Exchange Site",
      "course_description": "This open-access conversation exchange site offers topics and conversation tasks for students learning Russian and English. The goal of this pilot project is to support exchanges between students in English-speaking and Russian-speaking countries. \nThe conversation topics included are aligned with common college-level Russian language curricula, grouped by levels defined by ACTFL proficiency standards, and utilize OPI (Oral Proficiency Interview) practices. Topics include vocabulary, questions, and interactive activities that can be used in conversations as well as in individual practice.\nMaria Khotimsky (MIT) initiated this project based on conversation exchanges between SkolTech and MIT students, in collaboration with Dr. Marina Alexandrova (UT Austin) and Iringa Kogel (Davidson College).\nThe Телемосты website is published under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 (CC BY-NC-SA) International license.",
      "topics": [
        "Humanities",
        "Language",
        "Russian",
        "Humanities",
        "Language",
        "Russian"
      ],
      "syllabus_content": "",
      "files": [],
      "source_url": "https://ocw.mit.edu/courses/res-21g-601-telebridges-russian-conversation-exchange-site-fall-2021/",
      "course_info": "RES.21G-601 | Non-Credit",
      "subject": "General"
    },
    {
      "course_name": "Teaching Marguerite de Navarre's Heptaméron",
      "course_description": "This site is designed for scholars and students interested in exploring Marguerite de Navarre’s Heptaméron to help delve more deeply into this compelling writer and her texts. Resources are compiled on the site to allow easy access to information about Marguerite’s writings and her substantial influence in debates about religion and women in sixteenth-century France; these include extensive biographies, summaries, full texts, images and media, teaching resources, films, and a space to share ideas.\nThe website is published under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 (CC BY-NC-SA) International license.",
      "topics": [
        "Humanities",
        "Language",
        "French",
        "Literature",
        "International Literature",
        "Humanities",
        "Language",
        "French",
        "Literature",
        "International Literature"
      ],
      "syllabus_content": "",
      "files": [],
      "source_url": "https://ocw.mit.edu/courses/res-21g-3002-teaching-marguerite-de-navarres-heptameron-fall-2023/",
      "course_info": "RES.21G-3002 | Non-Credit",
      "subject": "General"
    },
    {
      "course_name": "Nancy's Brain Talks",
      "course_description": "Professor Nancy Kanwisher uses a brain imaging method called fMRI to study the human brain. Her website, Nancy’s Brain Talks, is a collection of short videos that explore the different scientific techniques used to study the human mind and brain. You do not need any background in the field to understand the talks.\nTopics include:\n\nWhat Kinds of Minds and Brains Do We Have?\nHow Can You Study the Human Mind and Brain?\nFace Perception\nfMRI Imaging of the Human Brain at Work\n\nThe site also includes lecture videos from Prof. Kanwisher’s undergraduate MIT course 9.13 The Human Brain. You can find a complete version of this course here on MIT OpenCourseWare.",
      "topics": [
        "Health and Medicine",
        "Sensory-Neural Systems",
        "Science",
        "Biology",
        "Neuroscience",
        "Health and Medicine",
        "Sensory-Neural Systems",
        "Science",
        "Biology",
        "Neuroscience"
      ],
      "syllabus_content": "",
      "files": [],
      "source_url": "https://ocw.mit.edu/courses/res-9-004-nancys-brain-talks-fall-2022/",
      "course_info": "RES.9-004 | Non-Credit",
      "subject": "General"
    },
    {
      "course_name": "Biology Teaching Assistant (TA) Training",
      "course_description": "The MIT Biology Department supports TAs’ teaching by providing a specialized Teaching Assistant (TA) training program in Biology Pedagogy, for which TAs can earn a training certificate. This program has been developed in response to the feedback of previous TAs, and is designed to actively meet each TA’s needs as they are teaching. It provides practical knowledge that directly relates to their teaching responsibilities each week, and provides them with the opportunity to practice different skills and techniques in a supportive environment.",
      "topics": [
        "Teaching and Education",
        "Curriculum and Teaching",
        "Teaching and Education",
        "Curriculum and Teaching"
      ],
      "syllabus_content": "Biology Pedagogy Program Overview\n\nThis semester we will be supporting your teaching by providing a specialized Teaching Assistant (TA) training program in Biology Pedagogy, for which you can earn a training certificate. This program has been developed in response to the feedback of previous TAs, and is designed to actively meet your needs as you are teaching. It will provide practical knowledge that directly relates to your teaching responsibilities each week, and you will have the opportunity to practice different skills and techniques in a supportive environment.\n\nThere are six core sessions for the training program (1hr each):\n\nOrganizing a recitation section to promote student learning\n\nKeeping students engaged\n\nCreating an inclusive classroom\n\nProviding constructive, equitable feedback\n\nHow students learn\n\nSupporting our students\n\nFor the remaining sessions, you will have the option to choose your own adventure, and must choose at least one of the following special sessions to attend:\n\nWriting effective questions\n\nMaking material relevant to motivate students\n\nTeaching students how to learn\n\nHelping students to learn the language of Biology\n\nLeveraging your teaching experience for the future\n\nThose who attend all 6 core training sessions, participate in a teaching observation session, and attend at least one \"choose your own adventure\" session, will receive a Biology Pedagogy Program Certificate from the department to acknowledge your accomplishment in completing the training program and pursuing professional development in teaching. For Biology graduate students, each pedagogy session you attend can also count toward your Professional Development requirement for the Biology graduate program.\n\nGoals & Intended Learning Outcomes\n\nGoals for TAs\n\nCommunicate\nclearly with a broad audience on a variety of topics in biology, and thoughtfully address questions which may arise in this setting.\n\nPresent\nin a way that effectively aids communication, taking into account organization of materials, use of classroom space, and physical presence (i.e. body language, facial expression, tone, etc.).\n\nCreate a respectful learning environment\nwhere students feel comfortable participating in the classroom, and teaching staff can work as a team to best serve students.\n\nFraming Discussion Slides (PDF)\n\nInstructor-TA agreement Form (PDF)\n\nIntended Learning Outcomes (ILO)\n\nILO1: Articulate strategies for recitation organization that promote student learning\n\nILO2: Describe the features of feedback that is effective and encourages a growth mindset\n\nILO3: Describe active learning strategies and explain their importance\n\nILO4: Identify how different teaching practices can be received by diverse audiences, and assess strategies that promote inclusivity\n\nILO5: Identify ways of communicating with students that promote a growth mindset and minimize stereotype threat.\n\nProgram requirements\n\nPre-semester statement of teaching goals\nYour Goals for Teaching worksheet (PDF)\n\nCompletion of 6 core pedagogy sessions\n\nCompletion of 1 special session\n\nAn instructor-led teaching observation and debrief\nBiology TA Feedback Form (PDF)\n\nCore sessions\n\nSession 1 (pre-semester) - Organizing a recitation section to promote student learning\n\nSession 2 (pre-semester) - Keeping students engaged\n\nSession 3 - Creating an inclusive classroom\n\nSession 4 - Providing constructive, equitable feedback\n\nSession 5 - How students learn\n\nSession 6 - Supporting our students\n\nSpecial sessions\n\nSession 7- Writing effective questions\n\nSession 8 - Making material relevant to motivate students\n\nSession 9 - Teaching students how to learn\n\nSession 10 - Leveraging your teaching experience for the future\n\nAcknowledgements\n\nThe course instructor would like to acknowledge the contributions of Dr. Darcy Gordon, Instructor of Blended and Online Initiatives in the MIT Biology Department, who created materials and activities used in sessions 3 & 4. In addition, the instructor would like to acknowledge the contributions of the TA Training Team, Dr. Mary Ellen Wiltrout, Director of Online & Blended Learning Initiatives in the MIT Biology Department, and MIT Biology Graduate students Alice Lydia Herneisen, Nima Jaberi-Lashkari, and Byron Lee, who created the Instructor-TA Agreement Form and the TA Feedback Form.",
      "files": [
        {
          "category": "Resource",
          "title": "RES.7-005 Biology TA Training, Session 1: Lesson Planning Worksheet",
          "type": "PDF",
          "source_url": "https://ocw.mit.edu/courses/res-7-005-biology-teaching-assistant-ta-training-fall-2021/lesson-planning-worksheet_.pdf",
          "content": "Lesson Planning Worksheet\nIncorporating Active Learning and Inclusivity into your Recitations\nCheck-in &\nOutline\n● How will you check in with your students at\nthe beginning of recitation?\n● How will you communicate your goals for the\nday? Are there any announcements to share?\n\nKnowledge\npractice\n● What difficult or important concepts from the\nlecture(s) do you want to prioritize?\n● How will you review these topics in a way that\nengages your students?\n\nSkills\npractice\n● What do students need to know how to do\nwith the material from the lecture(s)? How can\nyou give them practice with these skills?\n● Will you work on questions as a class?\nIndividually? In small groups?\n● How will you ensure everyone has a chance\nto engage with each question?\n● How will you make sure everyone is\nunderstanding?\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu/\n\nRES.7-005 Biology Teaching Assistant (TA) Training\nSummer 2020\n\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms."
        },
        {
          "category": "Resource",
          "title": "RES.7-005 Biology TA Training, Session 2: Active Learning Activities Breakout Groups",
          "type": "PDF",
          "source_url": "https://ocw.mit.edu/courses/res-7-005-biology-teaching-assistant-ta-training-fall-2021/session-2_-active-learning-activities-breakout-groups.pdf",
          "content": "Techniques from: \"Interactive Techniques\" by Kevin Yee Creative Commons BY-NC-SA.\n\nGroup 1: Intentional mistakes\nGive students a worked problem that contains some mistakes. Have students, as a class or in\nsmall groups, find mistakes and then make the corrections.\n\nPurpose (Why is this a helpful technique? What will students gain from it?):\n\nFollow-up (How will you wrap-up your conversation and make sure everyone is on board?):\n\nExample (For what types of problems/concepts would this be useful?):\n\nTechniques from: \"Interactive Techniques\" by Kevin Yee Creative Commons BY-NC-SA.\n\nGroup 2: Pro/Con Grid or Ranking alternatives\nFor a given scenario, everyone thinks up as many alternative courses of action (or explanations\nof the situation) as possible. Students list out the pros and cons for each approach, and/or rank\nthem by preference.\n\nPurpose (Why is this a helpful technique? What will students gain from it?):\n\nFollow-up (How will you wrap-up your conversation and make sure everyone is on board?):\n\nExample (For what types of problems/concepts would this be useful?):\n\nTechniques from: \"Interactive Techniques\" by Kevin Yee Creative Commons BY-NC-SA.\n\nGroup 3: Picture Prompt\nShow students a complex image with no explanation, and ask them to identify/explain it, or to\nname the processes and concepts shown. Let students explore all options before intervening.\n\nPurpose (Why is this a helpful technique? What will students gain from it?):\n\nFollow-up (How will you wrap-up your conversation and make sure everyone is on board?):\n\nExample (For what types of problems/concepts would this be useful?):\n\nTechniques from: \"Interactive Techniques\" by Kevin Yee Creative Commons BY-NC-SA.\n\nGroup 4: Blank-page review\nInstruct students to write as much as they can remember about a topic or section of the lecture\nwithin a defined period of time (3-5 min). Do this at the beginning of class, with notes away,\nencouraging students to write the whole time.\n\nPurpose (Why is this a helpful technique? What will students gain from it?):\n\nFollow-up (How will you wrap-up your conversation and make sure everyone is on board?):\n\nExample (For what types of problems/concepts would this be useful?):\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu/\n\nRES.7-005 Biology Teaching Assistant (TA) Training\nSummer 2020\n\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms."
        },
        {
          "category": "Resource",
          "title": "RES.7-005 Biology TA Training, Session 3: Inclusive Classroom Shared Document",
          "type": "PDF",
          "source_url": "https://ocw.mit.edu/courses/res-7-005-biology-teaching-assistant-ta-training-fall-2021/session-3_-inclusive-classroom-shared-document.pdf",
          "content": "Group activity\nAs a group, choose one common teaching practice and examine it by answering the reflection\nquestions on your group's page.\n\nExample teaching practices (may or may not be inclusive!):\n1. Leaving time for questions at the end class\n2. Asking a question that has many possible answers and have every student share a brief\nanswer\n3. Waiting for at least 5 students to raise their hands before you call on anyone after asking\na question\n4. Assign reporters for small groups discussion\n5. Learning students' names\n6. Giving students time to write\n7. Using think-pair-share (students have time to think about a question, then discuss it with\na partner, and finally report out on their discussion)\n8. Responding to correct answers with \"excellent job\" and \"great answer\"\n\nGroup 1 Reflection\nGroup Members:\nTeaching practice examined:\n\nWhy might I use this practice?\n\nWhat is implied about my values and expectations for students?\n\nWhich student behaviors are encouraged and which are discouraged by using this practice?\nWhich students are affected?\n\nDo you think this practice is more or less inclusive? What could be done to modify this practice\nto ensure inclusivity?\n\nGroup 2 Reflection\nGroup Members:\nTeaching practice examined:\n\nWhy might I use this practice?\n\nWhat is implied about my values and expectations for students?\n\nWhich student behaviors are encouraged and which are discouraged by using this practice?\nWhich students are affected?\n\nDo you think this practice is more or less inclusive? What could be done to modify this practice\nto ensure inclusivity?\n\nGroup 3 Reflection\nGroup Members:\nTeaching practice examined:\n\nWhy might I use this practice?\n\nWhat is implied about my values and expectations for students?\n\nWhich student behaviors are encouraged and which are discouraged by using this practice?\nWhich students are affected?\n\nDo you think this practice is more or less inclusive? What could be done to modify this practice\nto ensure inclusivity?\n\nGroup 4 Reflection\nGroup Members:\nTeaching practice examined:\n\nWhy might I use this practice?\n\nWhat is implied about my values and expectations for students?\n\nWhich student behaviors are encouraged and which are discouraged by using this practice?\nWhich students are affected?\n\nDo you think this practice is more or less inclusive? What could be done to modify this practice\nto ensure inclusivity?\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu/\n\nRES.7-005 Biology Teaching Assistant (TA) Training\nSummer 2020\n\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms."
        },
        {
          "category": "Resource",
          "title": "RES.7-005 Biology TA Training, Session 6: Supporting Our Students Scenarios",
          "type": "PDF",
          "source_url": "https://ocw.mit.edu/courses/res-7-005-biology-teaching-assistant-ta-training-fall-2021/session-6_-supporting-our-students-scenarios.pdf",
          "content": "Student scenarios:\n1. A student that does poorly on the first assignment. There is a student in your recitation\nwho fails the first major assignment. This student is an active participant in the\nclassroom, and has shown significant improvement on subsequent assignments. They\nare worried about how this first failed assignment will affect their grade.\n2. A student that does poorly on multiple assignments. A student in your recitation fails\nseveral major assignments in the course. The student tells you they are struggling in\ntheir other courses too and are having a hard time keeping up with their extracurricular\nactivities. They want to know whether they should continue in the course.\n3. A student who says that \"Biology just isn't their thing\". A student in your recitation is\nstruggling in the course but tells you they are doing well in all of their other classes. They\nare frustrated and don't understand why they are doing poorly, especially since they did\nwell in Biology in high school.\n4. A student whose behavior changes suddenly. A student who regularly attends your\nrecitation, and is typically thoughtful and engaged, appears to be disconnected during\nclass and has struggled to complete recent assignments. The assignments that they do\nturn in are only partially completed and show significant gaps in understanding.\n5. A student with repeated missing assignments. It is about half way through the semester\nand you have a student that has stopped turning in their assignments altogether. This\nstudent has never attended your recitation, and only attends class about half of the time.\n6. A student that asks tangential questions. You have a student that frequently asks\nquestions during recitation that are beyond the scope of the course. These questions\ndemonstrate that the student has an advanced understanding of the material, but it often\nconfuses other students in your section and you are finding it disruptive to the flow of\nrecitation.\n7. A student who is disrespectful of their peers. During discussion, a student asks a\nquestion that you already answered and another student chimes in with, \"And here I\nthought there was no such thing as a dumb question!\" which is met with snickering and\nrolled eyes from the rest of the class.\n8. A student who calls you in. You are going through a problem related to genetic\ninheritance and pedigrees and have been referring to the genetic donors as \"mom and\ndad\". A student approaches you after class and reveals that this language feels a bit\nexclusionary for transgender and non-binary folks, and for those with non-traditional\nfamily structures.\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu/\n\nRES.7-005 Biology Teaching Assistant (TA) Training\nSummer 2020\n\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms."
        },
        {
          "category": "Resource",
          "title": "RES.7-005 Biology TA Training, Session 7: Tips for Assessment Construction",
          "type": "PDF",
          "source_url": "https://ocw.mit.edu/courses/res-7-005-biology-teaching-assistant-ta-training-fall-2021/session-7_tips-for-assessment-construction.pdf",
          "content": "Tips for constructing assessments\nAdapted from: Teaching at Its Best: A Research-Based Resource for College Instructors by Linda B. Nilson\nMultiple choice/Select all\nAdvantages\nDisadvantages\n● Easy and quick to grade\n● Can efficiently assess remembering,\nunderstanding, application, analysis,\nevaluation, and creating\n● Useful as a diagnostic tool (wrong\nchoices can indicate misconceptions)\n● Familiar to students\n● Sometimes difficult and time-\nconsuming to construct\n● Encourages students to find the\ncorrect answer by process of\nelimination\n\n-\nWrite the correct response first, then the distractors (incorrect responses)\n-\nJuggle the elements or variables of a correct response, or substitute a correct variable\nfor one that students confuse it with to create distractors\n-\nMake all responses grammatically parallel and about the same length\n-\nMake all responses equally plausible and attractive\n-\nAddress one concept per question\n-\nStrive for clarity and conciseness\n-\nPresent the options in some logical order to resist cuing student into a pattern\n-\nUse 3-5 responses per question\n-\nIncorporate graphics where appropriate\n-\nIf you use \"all of the above\" or \"none of the above,\" use it liberally (not just when that\nanswer is correct)\n-\nInclude in the stem any words that may repeat in the response alternatives\n-\nUse familiar language but avoid lifting phrases directly from lecture (this reduces thinking\nto simple recall)\n-\nMake no, not, never, none, and except stand out by bolding or underlining\nTrue or False\nAdvantages\nDisadvantages\n● Usually easy to prepare and grade\n● Can test a lot of material in a short\ntime\n● Can tap higher levels of cognition by\nhaving students correct false\nstatements\n● Useful as a diagnostic tool if students\nhave to explain\n● High guessing factor\n● May be difficult to think of\nunequivocally true or false statements\n● Encourages instructors to test trivial\nfactual knowledge\n● Truly knowledgeable students may\nsee too many nuances, multiple\nmeanings, or conceive of exceptions\n● May contain verbal clues (never,\nalways, and every indicate false)\n\n-\nFocus each statement on a single idea\n-\nWrite positive statements (avoid negative or double negative)\n-\nAvoid verbal cues (usually, seldom, often, never, always, every)\n-\nUse only statements that are entirely true or entirely false\n-\nAvoid making true statements long and false statements short (or vice versa)\n-\nAvoid direct quotes (requiring memorization)\n-\nAdd higher level cognition by having students justify or rewrite false statements to make\nthem true\nShort Answer\nAdvantages\nDisadvantages\n● Easy to construct\n● Can assess remembering,\nunderstanding, application, analysis,\nevaluation, creating\n● Requires a command of vocabulary or\nproblem-solving skills\n● Very useful as a diagnostic tool\n● Encourages instructors to give\nstudents individual feedback\n● Time-consuming to grade\n● Difficult to standardize grading due to\nvariability across answers\n\n-\nBe very specific and concise in identifying the task that students are to perform\n-\nIdentify all the key points students should address\n-\nInstead of using what, why, or how, choose a descriptive verb that reflects what\nyou want students to do\n-\nUse familiar language from lecture, but new examples are great!\n-\nSpecify that students should show their work/thinking for full credit on problems, or if an\nillustration is required.\n-\nLeave an appropriate amount of space for the answers. In some cases you may even\nwant to specify the length of answers you are looking for.\nFill in the Blank\nAdvantages\nDisadvantages\n● Easy to prepare and grade\n● Can test a lot of material in a short\ntime\n● Assesses student's ability to\nremember (recall & vocabulary)\n● Eliminates guessing\n● Cannot assess higher levels of\ncognition\n● Highly structured and inflexible\n● Not useful as a diagnostic tool\n● May include grammatical clues\n● Difficult to construct so that the\ndesired response is unambiguous\n\n-\nUse clear wording to elicit a unique response\n-\nAvoid grammatical cues (use as/an and is/are)\n-\nOmit words from the middle or end of a statement, not the beginning\n-\nMake all fill lines the same length\n-\nUse familiar language (similar to lecture)\nAdditional tips\n-\nConsider the background of your students, and eliminate any unnecessary jargon\n-\nIf several questions on an assignment are based on a single scenario or set of\ninformation:\n-\nMinimize interlocking items (i.e. getting the first part of the question wrong leads\nto getting all later parts of the question wrong)\n-\nA longer or more complex set-up should be accompanied by a longer series of\nquestions\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu/\n\nRES.7-005 Biology Teaching Assistant (TA) Training\nSummer 2020\n\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms."
        },
        {
          "category": "Resource",
          "title": "RES.7-005 Framing Discussion Slides",
          "type": "PDF",
          "source_url": "https://ocw.mit.edu/courses/res-7-005-biology-teaching-assistant-ta-training-fall-2021/framing-discussion_edited_processed.pdf",
          "content": "Goals for TAS - Why are we here?\n\nIntroduce yourself and share something you are excited to learn about!\nIntroductions - Who are we?\n\nTA training structure - What will this look like?\nFlexible training and support. Attend trainings that are most helpful for you, and get\nin touch when you feel stuck, confused, overwhelmed, or excited!\nTake things one step at a time. Our trainings are spaced out throughout the first half\nof the semester, so that you can learn new things as you need them.\nFocused trainings that save time and stress. We will focus on practical ideas and\nactivities that you can take with you each week.\nEveryone's teaching style is different. We will provide many different ideas related to\nteaching best practices - find what works for you and your students.\n\nLet's talk about:\n●\nWhat do you want this space to look like?\n●\nWhat expectations do you have for yourself\nand your colleagues?\n●\nWhat expectations do you have for us?\nIdentifying expectations - How will we do it?\nImage (c) Katerina Limpitsouni, unDraw. All rights reserved. This content is excluded from our\nCreative Commons license. For more information, see https://ocw.mit.edu/help/faq-fair-use/.\n\nI hope that you will....\n●\nAsk questions!\n●\nEngage with activities - they are designed to help give you a leg up on\nyour TA responsibilities each week\n●\nBe respectful of fellow TAs, and thoughtful in your answers\nIdentifying expectations - How will we do it?\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu/\nRES.7-005 Biology Teaching Assistant (TA) Training\nSummer 2020\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms."
        },
        {
          "category": "Resource",
          "title": "RES.7-005 Session 1 Slides: Organizing a Recitation to Promote Student Learning",
          "type": "PDF",
          "source_url": "https://ocw.mit.edu/courses/res-7-005-biology-teaching-assistant-ta-training-fall-2021/session-1_-organizing-a-recitation-section-to-promote-student-learning_edited_processed.pdf",
          "content": "Organizing a recitation section to promote\nstudent learning\nCreating a plan for recitation\n\nGoals for today:\nAfter this session, TAs should be able to...\n1. Articulate and implement strategies for recitation organization that\npromote student learning\n\nFramework for recitation organization\n●What is the goal of recitation?\n●What material should you cover?\n●How should the material be covered?\nImage (c) Katerina Limpitsouni, unDraw. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see https://ocw.mit.edu/help/faq-fair-use/.\n\nWhat is the goal of recitation?\n\"teaching as dialogue\npresumes that teachers\nlisten and respond to their\nstudents' perspectives...\nrather than talking at\nstudents\"\nQuote from: \"Teaching as Dialogue: An Emerging Model\nof Culturally Responsive Online Pedagogy\" -APRIL\nLAWRENCE Journal of Online Learning Research\nVolume 6, Number 1, May 2020.\n(c) Association for the Advancement of Computing in\nEducation (AACE). All rights reserved. This content is\nexcluded from our Creative Commons license. For more\ninformation, see https://ocw.mit.edu/help/faq-fair-use/.\nFigure by Alexander Braile, used with permission.\n\nWhat does it look like for us to create a dialogue with\nour students?\n\nTeaching as dialogue - \"we do\"\nAsk open-ended questions\nConsider asking broad questions that have several possible responses\nPrompt deeper\nexplanations\n\"Why do you think that?\"\n\"Would you be willing to share how you got there?\"\nBring more folks into the\ndiscussion\n\"What else do folks think might be going on?\"\n\"What are some other ways of approaching this question?\"\nAcknowledge contributions\nIndicate student contribution holds value without asserting correctness.\n-\nrepeat student contributions to emphasize part of a response\n-\nask for clarification\n-\nsummarize\n-\nconnect student ideas to specific concepts from class\n\nWhat material should be covered?\nTake home message: Think about what students will need to be able to do\nto succeed in their assignments, and plan recitation to give them practice!\nIdentify difficult or\nimportant concepts\nPrepare condensed review\nand relevant problems\nIllustrations by Alexander Braile, used with permission.\n\nHow should the material be covered?\ncheck-in\nand\noutline\nprovide\nsummary\nKnowledge practice\nSkills practice\ntime\nTopic A\nTopic B\nTopic C\n\nKnowledge practice\nKnowledge\nKnowledge\nvs.\nKnowledge practice focuses on fact-based questions that...\n●\nexplore terminology\n●\nencourage recall\n●\ncheck comprehension\nIllustrations by Alexander Braile, used with permission.\n\nApplying\nand\nAnalyzing\nConcepts\nExplore\nconnections\nto other\ntopics\nCompare\nand\ncontrast\nideas\nExplore\nunfamiliar\ncontexts\nMake\npredictions\n& design\nexperiments\nEvaluate and\nmake a\njudgement\nLook at\nmultiple\nperspectives\nSkills practice\n\nBreakout groups\nINTRO\nCORE/UPPER\nLAB\n●\nSlide 1 provides some example approaches to\nrunning your recitation or laboratory section.\nThink about which approach(es) appeal to you\npersonally based on the context of your course.\n●\nSlide 2 presents you with a scenario or question\nrelevant to your recitation experience.\nTake a few minutes to brainstorm ideas individually\nand then discuss as a group. Use slide 1 as a\nresource.\n\n-\nBreak the question or problem down into parts\n-\nAsk students how they interpret the question\n-\nAsk students to describe how they would approach the question\n-\nModel the skill or approach\n-\nProvide an opportunity to reflect on the solution\nExample approaches to guiding skills practice\n(when you have a set of problems to work from)\nINTRO\n\nLet's practice!\nINTRO\nDiscuss what you can do to promote both knowledge and skills practice for\nstudents going through a question from your first recitation handout.\n[Provide an example of a problem from an Introductory Course]\n\nExample approaches for skills practice\n(when you're designing your own problems)\nCORE/UPPER\nYou don't need to design complex, exam-level questions to help students learn the skills\nneeded to succeed on their assignments! Consider the following ideas:\n●\nStudents identify several possible approaches for a particular scenario or experimental question .\nStudents can list the pros and cons for each, and/or rank them by preference.\n●\nAsk what would happen if a particular component broke, or a step was skipped in a particular process.\n●\nCreate a table where students decide if a feature is PRESENT or ABSENT in a series of scenarios\n(applies or does not apply, does or does not occur, etc.).\n●\nPractice using resources provided in class (tables, flow charts, etc.).\n●\nUse graphs or other images from the literature to test the concepts that students need to learn.\n●\nPartner with students in going through a past problem set or exam question (with faculty permission),\nfocusing on the process of problem solving & breaking it down into parts.\n\nLet's practice!\nOften, in a core or upper level course covering more advanced topics, it is our\ninclination to focus only on knowledge practice in recitation. The topics are\ncomplicated after all, and there is a lot to go over in each recitation! But if we want\nstudents to solve problems on a problem set or exam, we have to practice this\ntype of problem-based thinking with them.\nChoose one specific topic covered in your course.\n1. What are the skills needed to understand or master this topic?\n2. Write down a few ideas of how you could support skills practice for this topic.\nShare ideas as a group.\nCORE/UPPER\n\nExample approaches to a laboratory section\nLAB\nNote: Depending on the set of experiments to be performed (and the amount of down time), you may find that it is better to\ncondense the review at the beginning. You should do whatever works best for the set up of the lab, with guidance of instructors.\nKnowledge practice can help folks feel prepared to tackle the lab. To promote this TAs can:\n●\nReview important concepts and sticking points in the lab\n●\nHighlight key terminology\nSkills practice is what labs are all about! To best facilitate lab skills TAs should:\n●\nMonitor progress of laboratory experiments by walking around and asking questions\n●\nPromote independence by providing guidance and feedback (not giving away answers!)\n\nLaboratory Scenarios\nLAB\nYou are walking around the lab and...\n●\na student approaches you saying they made a mistake in the protocol and\nthey wonder how/if they can fix it.\n●\na student approaches you asking what step they should do next.\n●\na student approaches you asking if they got the correct result for a particular\nquestion in the lab assignment.\nFor each scenario, consider:\n1. What skills are needed, or can be reinforced, in each scenario?\n2. How can you help them practice these skills?\n\nTeaching tool: Lesson planning worksheet\n\n1. How will you introduce yourself to your students?\n2. How will you get to know your students?\n3. How will you share your own expectations/guidelines for recitation?\nWhat to do on the first day of teaching?\n\nExit Ticket:\nReflect on today's meeting\n+\nSomething you're taking away from today's topic on\norganizing a recitation\nΔΔ\nSomething you still have questions about\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu/\nRES.7-005 Biology Teaching Assistant (TA) Training\nSummer 2020\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms."
        },
        {
          "category": "Resource",
          "title": "RES.7-005 Session 10 Slides: Leveraging Your Teaching Experience For The Future",
          "type": "PDF",
          "source_url": "https://ocw.mit.edu/courses/res-7-005-biology-teaching-assistant-ta-training-fall-2021/session-10_-leveraging-your-teaching-experience-for-the-future_edited_processed.pdf",
          "content": "Leveraging your teaching experience for the\nfuture\nHow to market your skills as a TA across a variety of different contexts\n\nLearning Goals:\nAfter today's session you should be able to...\n1) Identify transferable skills learned in teaching\n2) Illustrate the value of these skills by describing action and impact\nImage (c) Katerina Limpitsouni, unDraw. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see https://ocw.mit.edu/help/faq-fair-use/.\n\nWhat transferable skills do TAs have?\n\nWhat transferable skills do TAs have?\n1. Communication skills\n2. Presentation and facilitation skills\n3. Organizational skills\n4. Feedback and evaluation skills\n5. Critical thinking skills\n6. Leadership and mentoring skills\n7. Management and supervision skills\n8. Creativity and innovation skills\n9. Listening and reflection skills\n10. Learning skills\n\nBrainstorming concrete examples\nBrainstorm at least two ideas related to the common interview prompts below that\ndemonstrate some of the skills you have learned as a TA. Describe the moment as\nclearly as you can and reflect on which of your strengths contributed to your success.\nShare an example of...\n-\na challenge you faced. How did you resolve it?\n-\na mistake you made. How did you handle it?\n-\na goal you set. How did you achieve it?\n-\nhow you worked on a team.\n-\nhow you were able to motivate the people you work with.\n-\nhow you worked effectively under pressure.\nImage (c) Katerina Limpitsouni, unDraw. All rights reserved. This content is excluded from our Creative Commons\nlicense. For more information, see https://ocw.mit.edu/help/faq-fair-use/.\n\nInterview and storytelling exercise\nStep 1: The interviewer invites the speaker to respond to the question,\ntaking note of any particular strengths and skills that the story highlights.\nThe interviewer may ask additional questions to help draw these out.\nStep 2: After the speaker has finished, the interviewer reflects the stories\nback to the speaker, noting particular words or phrases that helped identify\nthe speaker's strengths and skills.\nPick one prompt and share your story with a partner. Each person will have the\nopportunity to act as both speaker and interviewer.\n\nWhat themes or skills did you identify?\n\nInterview technique: STAR stories\nSituation\nAn event, project or\nchallenge you faced\nTask\nYour responsibilities\nand assignments for\nthe situation\nAction\nSteps taken to\nrelieve or rectify the\nsituation\nResult\nImpact of actions\ntaken\nIllustrations by Alexander Braile, used with permission.\n\nTell me about a time you handled a challenge. How did you\nresolve it? Skills = leadership, learning, innovation\nSituation: Students who were sick or in quarantine during the semester did not have a way\nto attend weekly problem-solving sessions (recitations) for the class.\nTask: I was asked by the course instructor to teach a hybrid recitation that would allow\nstudents to attend online and in person.\nAction: I sought out the appropriate technology and training, including learning how to use\na tablet to teach. I tested out the equipment ahead of time, and sought feedback from the\nstudents in my section to make sure they felt comfortable participating in the hybrid format.\nResult: My students appreciated my efforts to include them in the course even though they\ncould not attend in person, and I received very good evaluations from my students (Overall\nscore 6.8/7). My actions promoted both inclusion and accessibility of resources for students\nwho would otherwise have been excluded.\n\nWrite your own STAR story\nCreating a more comprehensive picture of your skills\nSituation\nAn event, project or\nchallenge you faced\nTask\nYour responsibilities\nand assignments for\nthe situation\nAction\nSteps taken to\nrelieve or rectify the\nsituation\nResult\nImpact of actions\ntaken\nIllustrations by Alexander Braile, used with permission.\n\nTurn your STAR story into a resume bullet\nResumes bullets aren't just about what you did!\nThey should communicate both action and impact.\n●\nTell your STAR story, emphasizing the result\n●\nStart with an action verb\n●\nExamples:\n○\nDeveloped comprehensive review sessions and moderated an online discussion forum to offer\nmore opportunities for questions and review.\n○\nCollaborated with a team of faculty and teaching assistants in an advanced undergraduate biology\ncourse to create a series of assessments that gauge student learning.\n\nExit Ticket:\n+ What is one thing you are taking away today's discussion?\n∆ Is there anything you still have questions about?\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu/\nRES.7-005 Biology Teaching Assistant (TA) Training\nSummer 2020\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms."
        },
        {
          "category": "Resource",
          "title": "RES.7-005 Session 2 Slides: Keeping Students Engaged",
          "type": "PDF",
          "source_url": "https://ocw.mit.edu/courses/res-7-005-biology-teaching-assistant-ta-training-fall-2021/session-2_-keeping-students-engaged_edited_processed.pdf",
          "content": "Keeping students engaged\nEngaging students in class through active learning strategies\n\nLearning Goals:\nAfter today's meeting, TAs should be able to...\n1) Describe active learning strategies and explain their importance\n2) Implement frequent and varied active learning strategies in recitation\n\nEngagement: What makes you feel engaged in a\nclassroom?\n\nHow do we promote student engagement?\nActive learning is a cognitive process\nwhich promotes analysis, synthesis,\nand evaluation of course material.\nSTUDENT-DRIVEN\nBrame, C. (2016). Active learning. Vanderbilt University Center for Teaching.\nRetrieved 11/16/2022 from https://cft.vanderbilt.edu/active-learning/. License CC-BY-\nNC.\n\nActive learning improves student outcomes by\npromoting engagement\nCarl E. Wieman (2014) Large-scale comparison of science teaching methods sends clear message. PNAS 111(23):8319-8320.\nFreeman et. al. (2014) Active learning increases student performance in science, engineering, and mathematics. PNAS 111(23):8410-8415.\nFigures (c) National Academy of Sciences. All rights reserved. This content is excluded from our Creative Commons license.\nFor more information, see https://ocw.mit.edu/help/faq-fair-use/.\n\nActive learning promotes inclusivity\nStudent outcomes are disproportionately affected among:\n●\nwomen\n●\nunderrepresented minorities\n●\nlower income students\n●\nfirst generation students\nCBE--Life Sciences Education 2014\n13:3, 478-492.\nhttps://doi.org/10.1187/cbe.13-10-0204\nLicense BY-NC-SA\n\nWhat strategies can we use to promote active\nlearning?\nActive learning strategies should be both consistent and varied\nConsistent active learning techniques can be integrated into your\neveryday teaching (frequent, in-the-moment)\nAn array of different structured active learning activities can be\nintroduced to augment student learning (periodic, planned)\n\nActive learning techniques to implement regularly\n(frequent, in-the-moment)\n●\nThink Break - Allow 30-60 seconds for students to think about the problem before you\ngo on to explain; ask them to write it down\n●\nThink-pair-share - Students (1) think individually about a topic or answer to a question,\n(2) share ideas with a partner, and (3) partners share out with the class.\n●\n\"Why do you think that?\" - Follow up all student responses (not just the incorrect\nones) with a challenge to explain their thinking\n●\nPolling - Ask all students to respond, using informal polling (thumbs up/thumbs down,\ncolored notecards) or student response system (PollEverywhere)\n\nIncorporating Active Learning techniques in your\nclassroom\nFree Write: Identify one active learning technique have used or would you like to\nuse in your class regularly. How and when would you use it?\n\nActive learning activities to add variety\n(periodic, planned)\nIn groups of 2-3, explore one new active learning activity. Discuss the following:\n●\nPurpose (Why is this a helpful technique? What will students gain from it?):\n●\nFollow-up (How will you wrap-up your conversation and make sure everyone\nis on board?):\n●\nExample (For what types of problems/concepts would this be useful?):\nRecord your thoughts and nominate a group member to share out.\n\nActive Learning Activity: Intentional Mistakes\nGive students a worked problem that contains some mistakes. Have students, as\na class or in small groups, find mistakes and then make the corrections.\nPurpose:\nFollow up:\nExample:\n\nActive Learning Activity: Pro/Con Grid or Ranking\nAlternatives\nFor a given scenario, everyone thinks up as many alternative courses of action (or\nexplanations of the situation) as possible. Students list out the pros and cons for\neach approach, and/or rank them by preference.\nPurpose:\nFollow up:\nExample:\n\nActive Learning Activity: Picture prompt\nShow students a complex image with no explanation, and ask them to\nidentify/explain it, or to name the processes and concepts shown. Let students\nexplore all options before intervening.\nPurpose:\nFollow up:\nExample:\n\nActive Learning Activity: Blank Page Review\nInstruct students to write as much as they can remember about a topic or section\nof the lecture within a defined period of time (3-5 min) . Do this at the beginning of\nclass, with notes away, encouraging students to write the whole time.\nPurpose:\nFollow up:\nExample:\n\nActive Learning in your classroom\nCreate a rough outline of a focused active learning activity based on a topic you\nwill teach during your first week.\n●\nWhat skill do you want students to have in completing this activity (learning goal)?\n●\nExplain how your activity specifically gets at this.\n●\nHow will you assess whether students have achieved your goal?\n\nExit Ticket:\n+ What are you taking away from today's session on active learning?\n∆ Is there anything you still have questions about?\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu/\nRES.7-005 Biology Teaching Assistant (TA) Training\nSummer 2020\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms."
        },
        {
          "category": "Resource",
          "title": "RES.7-005 Session 3 Slides: Creating an Inclusive Classroom",
          "type": "PDF",
          "source_url": "https://ocw.mit.edu/courses/res-7-005-biology-teaching-assistant-ta-training-fall-2021/session-3_-creating-an-inclusive-classroom_edited_processed.pdf",
          "content": "Creating an Inclusive Classroom\nUsing reflective teaching practices to foster inclusivity\n\nLearning Goals:\nAfter today's meeting, TAs should be able to...\n1) Identify how different teaching practices can be received by diverse\naudiences\n2) Assess strategies that promote inclusivity by engaging in self-\nreflection\n\nWhat does it mean to promote inclusivity in our\nclassrooms?\n\nWhat does it mean to promote inclusivity in our\nclassrooms?\nProviding equitable access to opportunities and resources for\npeople who might otherwise be excluded or marginalized\n\nIs it enough to \"treat all students equally\"?\nImages (c) USC Center for Urban Education. All rights reserved. This content is excluded from our Creative Commons license. For more information, see\nhttps://ocw.mit.edu/help/faq-fair-use/.\n\nWhat barriers exist to educational access?\nImage (c) USC Center for Urban\nEducation. All rights reserved. This\ncontent is excluded from our Creative\nCommons license. For more\ninformation, see\nhttps://ocw.mit.edu/help/faq-fair-use/.\n\nWhat does equity in education look like?\nImage (c) USC Center for Urban\nEducation. All rights reserved. This\ncontent is excluded from our\nCreative Commons license. For\nmore information, see\nhttps://ocw.mit.edu/help/faq-fair-use/.\n\nGuided Reflection:\n●\nWhy might I use this practice?\n●\nWhat is implied about my values and expectations for students?\n●\nWhich student behaviors are encouraged and which are discouraged by using\nthis practice? Which students are affected?\n●\nWhat could be done to modify this practice to ensure inclusivity?\nChoose one teaching practice that you use (or plan to use) in a specific class\ncontext and examine it by answering the reflection questions.\n(Guided Reflection process from \"Inclusive Classrooms: How to leverage identity to improve your teaching\npractice\" a workshop developed by Dr. Darcy Gordon and Dr. David Bergsman)\n\nExample Teaching Practices (may be more or less inclusive!)\n1. Leaving time for questions at the end class\n2. Asking a question that has many possible answers and have every student share\na brief answer\n3. Waiting for at least 5 students to raise their hands before you call on anyone after\nasking a question\n4. Assign reporters for small groups discussion\n5. Learning students' names\n6. Giving students time to write\n7. Using think-pair-share (students have time to think about a question, then discuss\nit with a partner, and finally report out on their discussion)\n8. Responding to correct answers with \"excellent job\" and \"great answer\"\n\nAdditional Considerations\nEvery class, every teacher, and every group of students is different. In your own\nreflection, consider how the following features may change the inclusivity of a given\nteaching strategy:\n-\nformat of the class\n-\nvirtual vs. in-person environment\n-\ngroup membership(s) of your students\n-\nyour own identity\n-\nthe scope of the course\n\nExamining inclusivity in our classrooms\nby Darcy Gordon,\nMIT Open Learning\n\nTeaching Tool: STRATEGIES FOR INCLUSIVE PARTICIPATION\nAsk Open-ended Questions: instead of asking verbal questions with only one possible answer (closed-ended questions), ask\nquestions with multiple possible answers (open-ended questions).\nThink-Pair-Share: providing an opportunity for students to first think quietly and then share their ideas with a partner can help\nstudents rehearse and build confidence to share with the whole class, increasing participation.\nTime to Write: an opportunity to write down their ideas on paper helps many students revisit what they know, formulate questions,\nand rehearse what they may want to share, increasing participation.\nWait Time: pause for 3 to 5 seconds (longer than you think!) after you ask a question before you call on anyone to speak or\nanswer the question yourself. Longer wait times will allow more students thinking time.\nMultiple Hands, Multiple Voices: after you ask a question, say that you'll wait for at least 5 students to raise their hands before\nyou call on anyone, and then really wait for 5 hands. Promote more participation this way.\nWhip: ask a question that has many possible answers and have every student share a brief answer.\nWork in Stations/Small Groups: to decrease effective class size and provide more opportunity for interaction and discussion,\nconsider organizing multiple activities as stations that small groups rotate through. (Assign Reporters for Small Groups)\nKimberly D. Tanner (2017) Structure Matters: Twenty-One Teaching Strategies to Promote Student Engagement and Cultivate Classroom Equity.\nCBE--Life Sciences Education 12(3). License BY-NC-SA\n\nExit Ticket:\n+ What are you taking away from our discussion of inclusive teaching\npractices?\n∆ Is there anything you still have questions about?\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu/\nRES.7-005 Biology Teaching Assistant (TA) Training\nSummer 2020\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms."
        },
        {
          "category": "Resource",
          "title": "RES.7-005 Session 4 Slides: Providing Effective Equitable Feedback",
          "type": "PDF",
          "source_url": "https://ocw.mit.edu/courses/res-7-005-biology-teaching-assistant-ta-training-fall-2021/session-4_-providing-effective-_-equitable-feedback_edited_processed.pdf",
          "content": "Providing effective & equitable feedback\nTools and techniques for grading\n\nLearning Goals:\nAfter today's meeting, TAs should be able to...\n1) Describe the features of feedback that is both effective and equitable\n2) Use grading tools for effective and equitable grading\n\nWhat is the point of giving students feedback?\n\nFeedback is effective when it...\n●\nis aligned to the learning goals of the assignment.\n●\nencourages students to adopt a growth mindset.\n●\ncreates a dialogue between student and teacher.\n\nFeedback is equitable when it...\n●\nuses objective criteria consistently across all submissions\n●\nis free of implicit or unconscious bias\n\nWritten by Darcy Gordon\nKey Grading Practices: Rubrics and feedback\n\nAn example\nQuestion: (2 points) Explain what a positive control is and why they are used, then\ngive an example of one you might design if you were to conduct an \"experiment\" at\nhome.\nStudent response: Positive controls help you decide if an experimental result is an\nartifact of the experimental design. Suppose you were testing if adding baking soda\nto houseplant soil increases flowering. A positive control would be a set of\nhouseplants that were given a commercial fertilizer that is demonstrated to increase\nthe number of blooms.\nAdapted from material by Darcy Gordon\n\nStudent Response: Positive controls help you decide if an experimental result is an\nartifact of the experimental design. Suppose you were testing if adding baking soda to\nhouseplant soil increases flowering. A positive control would be a set of houseplants that\nwere given a commercial fertilizer that is demonstrated to increase the number of\nblooms.\nPoint value\n(per part)\nExplanation of positive control (1pt)\nExample given (1pt)\nmissing entirely\nmissing entirely\n+0.5\na positive control is correctly defined\nthe home experiment is described\n+0.5\nwhy positive controls are used is explained\nthe positive control identified is correct\nAdapted from material by Darcy Gordon\n\nStudent Response: Positive controls help you decide if an experimental result is an\nartifact of the experimental design. Suppose you were testing if adding baking soda to\nhouseplant soil increases flowering. A positive control would be a set of houseplants that\nwere given a commercial fertilizer that is demonstrated to increase the number of\nblooms.\nExample feedback:\nA. Not quite- a positive control receives a treatment that is known to produce a result\ncomparable to what is proposed by your hypothesis.\nB. You gave an explanation of why positive controls are used and not what they are.\nC. 1.5/2 pts\nD. This is a good example of one application of a positive control, but your response is\nmissing a full explanation of what positive controls are. Remember positive controls\nprovide a comparison to a known outcome similar to that predicted by your hypothesis\n(1.5/2 pts).\nAdapted from material by Darcy Gordon\n\nWhat do you like and what is challenging about this\nprocess?\n\nWritten by Darcy Gordon\nRemedies to Grading Challenges\n\nIn your own words, provide this\nstudent with feedback on their\nresponse.\n[Student response]\n[Open-ended question prompt]\nCreating your own rubric and feedback\nWhat would your rubric look\nlike for this question?\n\nPractical tips for giving feedback more efficiently\n-\nLook only at what was said, don't try to interpret what might have\nbeen meant.\n-\nMake and stick to a rubric that aligns with the assignment goals\n- Don't focus on correcting every single little thing!\n-\nKeep track of the most common pieces of feedback and copy/paste.\n\"Piled Higher and Deeper\"\nby Jorge Cham\nwww.phdcomics.com\nUsed with permission\n\nGrading fatigue is normal!\n-\nShuffle the order of grading between questions.\n-\nTry to stay consistent in your comments throughout.\n-\nTake breaks to walk/stretch.\n-\nBe kind to yourself!\n\"Piled Higher and Deeper\"\nby Jorge Cham\nwww.phdcomics.com\nUsed with permission\n\nExit Ticket:\n+\nWhat are you taking away from today's discussion of effective\nand equitable grading?\nΔΔ\nIs there anything you still have questions about?\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu/\n\nRES.7-005 Biology Teaching Assistant (TA) Training\nSummer 2020\n\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms."
        },
        {
          "category": "Resource",
          "title": "RES.7-005 Session 5 Slides: How Students Learn",
          "type": "PDF",
          "source_url": "https://ocw.mit.edu/courses/res-7-005-biology-teaching-assistant-ta-training-fall-2021/session-5_-how-students-learn_edited_processed.pdf",
          "content": "How students learn\nUsing research in cognitive science and classroom practices to\ninform our teaching\n\nLearning Goals:\nAfter today's meeting, TAs should be able to...\n1) Connect research-based strategies for teaching to key principles of\nstudent learning\n\nWhat promotes student learning?\n\nHow do we know how students learn?\nCognitive research: how our brains acquire and use information\nResearch on the classroom practices: how teaching practice relate to student\nachievement\n\n-\nRead through the\nresearch-based strategy\nassigned to you\n-\nPresent your strategy (2-\n3 minutes) to the rest of\nthe group\nYour presentation should\naddress:\n-\nWhat does this\nstrategy teach you\nabout how students\nlearn?\n-\nAn example of how\nyou could implement\nthis strategy in your\nteaching.\nTitle and image (c) American Federation of Teachers. In: Rosenshine, B. (2012) Principles of instruction: Research-based strategies that all teachers should know. American\nEducator 36(1):12-19. All rights reserved. This content is excluded from our Creative Commons license. For more information, see https://ocw.mit.edu/help/faq-fair-use/.005\n\nStrategies from: Rosenshine, B. (2012) Principles of instruction: Research-based strategies that all teachers should know. American Educator 36(1):12-19. (c) American\nFederation of Teachers. In: All rights reserved. This content is excluded from our Creative Commons license. For more information, see https://ocw.mit.edu/help/faq-fair-use/.006\n\nExit Ticket:\n+ What stuck out to you about how students learn, or the strategies we can\nuse to meet these needs?\n∆ Is there anything you still have questions about?\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu/\nRES.7-005 Biology Teaching Assistant (TA) Training\nSummer 2020\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms."
        },
        {
          "category": "Resource",
          "title": "RES.7-005 Session 5 Slides: Shared Presentation",
          "type": "PDF",
          "source_url": "https://ocw.mit.edu/courses/res-7-005-biology-teaching-assistant-ta-training-fall-2021/session-5_-shared-presentation_edited_processed.pdf",
          "content": "-\nRead through the\nresearch-based strategy\nassigned to you\n-\nPresent your strategy (2-\n3 minutes) to the rest of\nthe group\nYour presentation should\naddress:\n-\nWhat does this\nstrategy teach you\nabout how students\nlearn?\n-\nAn example of how\nyou could implement\nthis strategy in your\nteaching.\nTitle and image (c) American Federation of Teachers. In: Rosenshine, B. (2012) Principles of instruction: Research-based strategies that all teachers should know. American\nEducator 36(1):12-19. All rights reserved. This content is excluded from our Creative Commons license. For more information, see https://ocw.mit.edu/help/faq-fair-use/.\n\n1. Begin a lesson with a short review of previous learning\n\n2. Present new material in small steps, with student\npractice after each step\n\n3. Ask a large number of questions, checking the response\nof all students\n\n4. Provide models\n\n5. Guide student practice\n\n6. Check for student understanding\n\n7. Obtain a high success\n\n8. Provide scaffolds for difficult tasks\n\n9. Require and monitor independent practice\n\n10. Engage students in weekly and monthly review\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu/\nRES.7-005 Biology Teaching Assistant (TA) Training\nSummer 2020\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms."
        },
        {
          "category": "Resource",
          "title": "RES.7-005 Session 6 Slides: Supporting Our Students",
          "type": "PDF",
          "source_url": "https://ocw.mit.edu/courses/res-7-005-biology-teaching-assistant-ta-training-fall-2021/session-6_-supporting-our-students_edited_processed.pdf",
          "content": "Supporting our students\nShowing empathy and promoting a growth mindset when students are\nstruggling\n\nLearning Goals:\nAfter today's meeting, TAs should be able to...\n1) Identify ways of communicating with students that promote a growth\nmindset and minimize stereotype threat.\n2) Describe the elements of active listening and use active listening to\nsupport students.\n\nHow have you felt most supported by a teacher\nwhen you were struggling?\n\nWhat's really going on with our students?\nApparent\nChallenges\nSelf-perception and\nInternal Pressure\nPhysical, emotional,\nand social needs\nExternal Pressures\nPast experiences\nImage by Alexander Braile, used with permission.\n\nActive listening as a way of showing empathy\n2. Listen\n3. Respond\n1. Ask\nActive\nListening\n\nWhat makes a good question?\n2. Listen\n3. Respond\n1. Ask\nActive\nListening\n\nWhat makes a good question?\nGood questions are short, open-ended, non-judgmental, and future-focused (drive\nthe student to talk about what they want moving forward).\nImage (c) unDraw. All rights reserved. This\ncontent is excluded from our Creative\nCommons license. For more information,\nsee https://ocw.mit.edu/help/faq-fair-use/.\n\nActivity: What makes a good question?\nLet's say a student says to you \"I'm worried I'm not doing well in this class. Maybe I\nshould drop it.\" What question could you ask to start off the conversation?\n\nWhat does it look like to listen?\n2. Listen\n3. Respond\n1. Ask\nActive\nListening\n\nActivity: What does listening look like?\n1. Partner A should listen to Partner B speak for 60 seconds on a topic of their\nchoosing.\n2. Partner A should not respond in any way (no sounds, movements, or facial\nexpressions) to what Partner B is saying, but should maintain eye contact as\nthey are comfortable.\n3. Partner B should speak continuously for the entire period.\n4. Switch roles.\n\nActivity: What does listening look like?\nReflect on this activity:\nSpeakers - What was it like to talk to someone who did not respond physically or\nverbally? What cues would have been comforting to see from the listener to know\nthat they were paying attention?\nListeners - How did you find yourself wanting to respond? Did you notice that you\ndid some things automatically?\n\nListening well\nSignaling your attention and receptiveness as you listen can look like...\n●\nGentle eye contact\n●\nNeutral or relaxed facial expression\n●\nOpen and inviting body language\n●\nSmall affirmations, like nodding\nImage (c) unDraw. All rights reserved. This\ncontent is excluded from our Creative\nCommons license. For more information,\nsee https://ocw.mit.edu/help/faq-fair-use/.\n\nWhat does it mean to respond?\n2. Listen\n3. Respond\n1. Ask\nActive\nListening\n\nWhat does it mean to respond?\nAcknowledge you have heard what the person has said:\n●\nRestate (\"Let me make sure I've got this right ...\")\n●\nAffirm (\"I'm sorry. That sounds really frustrating.\")\n●\nReflect (\"What I'm hearing is ...\")\n●\nInterpret (\"I've noticed that ... \")\nImage (c) unDraw. All rights reserved. This\ncontent is excluded from our Creative\nCommons license. For more information, see\nhttps://ocw.mit.edu/help/faq-fair-use/.\n\nScenarios: Responding supportively to our students\nIn groups of 2-3, pick at least one scenario that you want to discuss in depth.\nAnswer the following questions about each scenario you discuss.\n●\nHow would you respond to this student directly?\n●\nHow could you promote a growth mindset in your interactions with this\nstudent?\n●\nWhat additional resources could you refer the student to, or what resources\ncould you turn to for more information?\nPrepare to share out about at least one of the scenarios you discuss.\n\nExit Ticket:\n+ What are you taking away from today's discussion on supporting students?\n∆ Is there anything you still have questions about?\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu/\nRES.7-005 Biology Teaching Assistant (TA) Training\nSummer 2020\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms."
        },
        {
          "category": "Resource",
          "title": "RES.7-005 Session 7 Slides: Writing Effective Questions",
          "type": "PDF",
          "source_url": "https://ocw.mit.edu/courses/res-7-005-biology-teaching-assistant-ta-training-fall-2021/session-7_-writing-effective-questions_edited_processed.pdf",
          "content": "Writing effective questions for assessment\nThe art (and science) of question writing\n\nLearning Goals:\nAfter today's meeting, TAs should be able to...\n1) Understand the advantages and disadvantages of different types of\nassessment questions\n2) Create assessment questions that are clear and concise, and engage\ndifferent levels of student cognition\n\nWhat is the purpose of assessment?\n\nWhat is the purpose of assessment?\nFormative assessment\nmonitors student learning\nto provide ongoing\nfeedback\nSummative assessment\nevaluates student learning\nat the end of an\ninstructional unit\n\nDefining what do you want the student to do\nBloom's\nTaxonomy\nLevels of\ncognition\n\nEngaging different levels of cognition\nCreating\nEvaluating\nAnalyzing\nApplying\nUnderstanding\nA virus has the following components [ ______ ]. Explain what type of\nvirus this is likely to be.\nRemembering\nList components of the flu virus.\n\nEngaging different levels of cognition\nCreating\nUsing your knowledge of the influenza virus, design a test to distinguish\nbetween two variants of influenza.\nEvaluating\n[Example of process to test for the flu]. Justify why this is the best\nprocess to test for the influenza virus.\nAnalyzing\nHow would you distinguish whether the patient is infected with the\ninfluenza virus vs. another common virus?\nApplying\nWhat tests could you implement to determine if a patient is infected\nwith the influenza virus?\nUnderstanding\nA virus has the following components [ ______ ]. Explain what type of\nvirus this is likely to be.\nRemembering\nList components of the influenza virus.\n\nTypes of Questions\nWhat you want the student to do will determine the type of question you should\nask. Some common question types are:\n-\nMultiple Choice (or Select All)\n-\nTrue/False\n-\nShort Answer\n→How easy is it to prepare and grade this type of question?\n→Will it allow me to diagnose student misconceptions?\n→What level of cognition will it engage students in?\n→Are there any structural limitations/pitfalls?\n\nMultiple choice/Select all\nAdvantages\n-\nEasy and quick to grade\n-\nCan assess all levels of cognition\n-\nUseful as a diagnostic tool\n(wrong choices can indicate\nmisconceptions)\n-\nFamiliar to students\nDisadvantages\n-\nSometimes difficult and time-\nconsuming to construct\n-\nEncourages students to find the\ncorrect answer by process of\nelimination\n(c) John Wiley and Sons. From: Nilson, Linda B. 2016. Teaching at Its Best : A Research-Based\nResource for College Instructors. All rights reserved. This content is excluded from our\nCreative Commons license. For more information, see https://ocw.mit.edu/help/faq-fair-use/.\n\nRevise the multiple choice question\nVanderbilt University, Center for Teaching Writing good multiple choice questions\nby Cynthia J. Brame. License: Creative Commons BY-NC.\n\nMultiple choice pitfalls\nVanderbilt University, Center for Teaching Writing good multiple choice questions\nby Cynthia J. Brame. License: Creative Commons BY-NC.\n\nA few tips for construction\nMultiple Choice\n-\nWrite the correct response first, then the distractors (incorrect responses)\n-\nJuggle the elements or variables of a correct response, or substitute a\ncorrect variable for one that students confuse it with to create distractors\n-\nMake all responses grammatically parallel and about the same length\n(c) John Wiley and Sons. From: Nilson, Linda B. 2016. Teaching at Its Best : A Research-Based\nResource for College Instructors. All rights reserved. This content is excluded from our\nCreative Commons license. For more information, see https://ocw.mit.edu/help/faq-fair-use/.\n\nTrue or False\nAdvantages\n-\nUsually easy to prepare and grade\n-\nCan test a lot of material in a short\ntime\n-\nCan tap higher levels of cognition\nby having students correct false\nstatements\n-\nUseful as a diagnostic tool if\nstudents have to explain\nDisadvantages\n-\nHigh guessing factor\n-\nMay be difficult to think of\nunequivocally true or false statements\n-\nEncourages instructors to test trivial\nfactual knowledge\n-\nTruly knowledgeable students may\nsee too many nuances, multiple\nmeanings, or conceive of exceptions\n(c) John Wiley and Sons. From: Nilson, Linda B. 2016. Teaching at Its Best : A Research-Based\nResource for College Instructors. All rights reserved. This content is excluded from our\nCreative Commons license. For more information, see https://ocw.mit.edu/help/faq-fair-use/.\n\nRevise the True/False question\nWhen an enzyme is added to a reaction, the reaction is always spontaneous. (True/False)\nThe diagram at right shows the free energy changes that occur\nduring a chemical reaction. When a specific enzyme that\ncatalyzes this reaction is added, the reaction goes from being\nnon-spontaneous to spontaneous. (True/False)\nThe diagram at right shows the free energy changes that occur during a chemical reaction.\nWhen a specific enzyme is added that catalyzes this reaction, which of the following\nstatements are true about the reaction? Select all that apply.\nThe transition state energy level will decrease\nThe energy level of the reactants will increase\nThe energy level of the products will decrease\nThe reaction will go from being non-spontaneous to spontaneous\n\nA few tips for construction\nTrue or False\n-\nFocus each statement on a single idea\n-\nWrite positive statements (avoid negative or double negative)\n-\nAvoid verbal cues (usually, seldom, often, never, always, every)\n(c) John Wiley and Sons. From: Nilson, Linda B. 2016. Teaching at Its Best : A Research-Based\nResource for College Instructors. All rights reserved. This content is excluded from our\nCreative Commons license. For more information, see https://ocw.mit.edu/help/faq-fair-use/.\n\nShort Answer\nAdvantages\n-\nEasier to construct\n-\nCan assess all levels of cognition\n-\nRequires a command of vocab\nand problem-solving skills\n-\nVery useful as a diagnostic tool\n-\nEncourages instructors to give\nstudents individual feedback\nDisadvantages\n-\nTime-consuming to grade\n-\nDifficult to standardize grading due\nto variability across answers\n(c) John Wiley and Sons. From: Nilson, Linda B. 2016. Teaching at Its Best : A Research-Based\nResource for College Instructors. All rights reserved. This content is excluded from our\nCreative Commons license. For more information, see https://ocw.mit.edu/help/faq-fair-use/.\n\nAn example of a short answer question\nPrior knowledge:\n[Example from course that teaching assistants teach]\n\nA few tips for construction\nShort Answer\nBe very specific and concise in identifying the task that students are to perform\n-\nIdentify all the key points students should address\n-\nInstead of using what, why, or how, choose a descriptive verb that\nreflects what you want students to do\n(c) John Wiley and Sons. From: Nilson, Linda B. 2016. Teaching at Its Best : A Research-Based\nResource for College Instructors. All rights reserved. This content is excluded from our\nCreative Commons license. For more information, see https://ocw.mit.edu/help/faq-fair-use/.\n\nCreate your own question\nPick a current or upcoming topic from your course and identify a broad question\nrelated to the material (e.g. \"How do you purify a protein?\")\nOn your own, revise this question to provide more focus (5 min)\n-\nWrite a statement answering the question - \"what do I want my students to do?\"\n(Bloom's taxonomy)\n-\nUse the Tips for construction to build your question\nShare your question with a partner, and provide each other feedback. (5 min)\n-\nIs the question clear and concise?\n-\nWhat level of Bloom's taxonomy does it ask students to engage with?\n-\nAre there any ambiguities?\n\nAdditional Tips\nConsider the background of your students, and eliminate any unnecessary jargon\nPapers, news articles, images, or every day observations can prompt a good\nquestion. Some common frameworks include:\n●\nDescribe setup, interpret data, predict results, etc. of an experiment\n●\nWhat if a component broke, a step was skipped, or a mistake was made in a particular\nprocess?\nIf several questions on an assignment are based on a single scenario or set of\ninformation\n●\nMinimize interlocking items\n●\nA longer or more complex set-up = a longer series of questions (while still avoiding\nunnecessary information!)\n\nExit Ticket:\n+ What are you taking away from today's discussion of writing effective\nquestions for assessment?\n∆ Is there anything you still have questions about?\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu/\nRES.7-005 Biology Teaching Assistant (TA) Training\nSummer 2020\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms."
        }
      ],
      "source_url": "https://ocw.mit.edu/courses/res-7-005-biology-teaching-assistant-ta-training-fall-2021/",
      "course_info": "RES.7-005 | Undergraduate, Graduate, Non-Credit",
      "subject": "General"
    },
    {
      "course_name": "Leveraging Urban Mobility Disruptions to Create Better Cities",
      "course_description": "In this course, we explore how new mobility systems can be leveraged to promote equity, improve health outcomes, and increase accessibility. Lectures by transportation professors from Europe, Asia, Latin America, Africa, and the United States are supplemented with interviews with preeminent entrepreneurs, city planners, community development experts, and mobility justice advocates.\nTopics covered include land use and urban form; new mobility business models, pricing, policy, technology, and data; the importance of designing new mobility systems for equity, health, and the environment; and racial justice within the transportation field.\nThis course is part of the Open Learning Library, which is free to use. You have the option to sign up and enroll in the course if you want to track your progress, or you can view and use all the materials without enrolling.",
      "topics": [
        "Business",
        "Innovation",
        "Energy",
        "Transportation",
        "Social Science",
        "Urban Studies",
        "Transportation Planning",
        "Business",
        "Innovation",
        "Energy",
        "Transportation",
        "Social Science",
        "Urban Studies",
        "Transportation Planning"
      ],
      "syllabus_content": "",
      "files": [],
      "source_url": "https://ocw.mit.edu/courses/res-11-550-leveraging-urban-mobility-disruptions-to-create-better-cities-spring-2021/",
      "course_info": "RES.11-550 | Non-Credit",
      "subject": "General"
    },
    {
      "course_name": "Energy Needs Assessment Toolkit",
      "course_description": "Understanding the energy needs and market opportunities in the specific off-grid community or region is the first step for effectively selecting and implementing the solutions to meet a community’s energy needs. MIT D-Lab has developed the Energy Assessment Toolkit to guide organizations through the process of gathering the information needed to make informed decisions about what technologies and business models are best suited to meet the specific needs of their community through market-based initiatives. \nThis toolkit is designed for any organization that has an on­-the­-ground presence in an off­-grid community or region and has the ability to take action based on the opportunities identified. This community-­based assessment approach is not intended to replace studies that track energy access on a national level or to generate market intelligence reports for external organizations looking to expand their business or programs into new markets.",
      "topics": [
        "Energy",
        "Society",
        "The Developing World",
        "Energy",
        "Society",
        "The Developing World"
      ],
      "syllabus_content": "",
      "files": [],
      "source_url": "https://ocw.mit.edu/courses/res-ec-004-energy-needs-assessment-toolkit/",
      "course_info": "RES.EC-004 | Non-Credit",
      "subject": "General"
    },
    {
      "course_name": "Becoming a More Equitable Educator: Mindsets and Practices",
      "course_description": "Every day, teachers make thousands of decisions: what content to teach, what activities to assign, who to call on, how to respond to a student question, how to react to student behavior. These day-to-day decisions can have an enormous effect on the lives of young people, for good and ill. They can open new doors or cause lasting harm; they can make students feel seen and valued, or dampen their interest in school. In this course, we will investigate these interactions, rehearse responding to difficult scenarios, and develop a set of equity teaching mindsets and practices to support all of our learners, especially underserved students.\nWith colleagues from your school or organization and online learners around the world, you will participate in four cycles of inquiry, practice, and action, and then complete a final action project. In each cycle of inquiry, you will examine and re-examine dimensions of inequality through educator mindsets, imagine community change through documentary case studies, rehearse taking action in thorny situations through digital practice spaces, and begin to lead change through action-oriented assignments. Our early investigations will focus on relationships and interactions with individual students, and pan out to examine the effects of bias on classrooms, schools, and communities. As you complete activities with peers online, you will develop a rich set of resources and exercises to use with your students and colleagues in your local context.\nAt the end of the course, you will have a better understanding of yourself and your students, new resources to draw on for helping all students thrive, and a plan to work with your school community to advance the lifelong work of equitable teaching.\nThis course is part of the Open Learning Library, which is free to use. You have the option to sign up and enroll in the course if you want to track your progress, or you can view and use all the materials without enrolling.",
      "topics": [
        "Teaching and Education",
        "Curriculum and Teaching",
        "Educational Technology",
        "Teaching and Education",
        "Curriculum and Teaching",
        "Educational Technology"
      ],
      "syllabus_content": "",
      "files": [],
      "source_url": "https://ocw.mit.edu/courses/res-cms-503-becoming-a-more-equitable-educator-mindsets-and-practices-spring-2020/",
      "course_info": "RES.CMS-503 | Non-Credit",
      "subject": "General"
    },
    {
      "course_name": "Media Literacy in the Age of Deepfakes",
      "course_description": "Media Literacy in the Age of Deepfakes aims to equip students with the critical skills to better understand the past and contemporary threat of misinformation. Students will learn about different ways to analyze emerging forms of misinformation such as “deepfake” videos as well as how new technologies can be used to create a more just and equitable society. This module consists of three interconnected sections. We begin by defining and contextualizing some key terms related to misinformation. We then focus on the proliferation of deepfakes within our media environment. Lastly, we explore synthetic media for the civic good, including AI-enabled projects geared towards satire, investigative documentary, and public history. In Event of Moon Disaster, an award-winning deepfake art installation about the “failed” Apollo 11 moon landing, serves as a central case study.\nThis learning module also includes a suite of educator resources that consists of a syllabus, bibliography, and design prompts. We encourage teachers to draw on and adapt these resources for the purposes of their own classes.\nVisit Media Literacy in the Age of Deepfakes to access the learning module and educator resources. A sample of some of these materials can be found on OCW.\nThis course was produced by the MIT Center for Advanced Virtuality, with support from the J-WEL: Abdul Latif Jameel World Education Lab.",
      "topics": [
        "Engineering",
        "Computer Science",
        "Artificial Intelligence",
        "Fine Arts",
        "Media Studies",
        "Teaching and Education",
        "Engineering",
        "Computer Science",
        "Artificial Intelligence",
        "Fine Arts",
        "Media Studies",
        "Teaching and Education"
      ],
      "syllabus_content": "The following is an expanded course description that builds on the learning module, Media Literacy in the Age of Deepfakes. For the full syllabus, please go to the main\nlearning module website\n.\n\nResource Description\n\nThe accelerating proliferation of misinformation poses an urgent threat to American democracy. False or misleading news reports can spread faster than COVID-19, while novel \"cheapfakes,\" \"shallowfakes,\" and \"deepfakes\" challenge the very foundation of our information ecosystem. Our seminar aims to shed a clarifying light on the contemporary media landscape, and to equip students to better understand the past and contemporary impact of misinformation. Students will also learn strategies to combat the dangers posed by novel forms of misinformation as well as how emerging technologies can be used to create a more just and inclusive society.\n\nWe will begin by first situating misinformation within a longer history of hoaxes, humbug, and \"fake news.\" We will then explore the more recent forces that have shaped our fraught media ecology, which have resulted in propaganda campaigns, conspiracy theories, and the rise of deliberately deceptive deepfake videos. Lastly, our seminar will focus on media for the public good, including instances of grassroots networked advocacy as well as synthetic projects geared towards satire, investigative documentary, and community history.\n\nA series of questions will animate our discussion throughout the semester. How old is misinformation? What constitutes \"truth\" and \"fact\" in our digital age? Are there ethical or legal responsibilities of media platforms and to what extent should government regulate our information environment? What is the role of socially engaged art and journalism in society today? Our interdisciplinary course ultimately aims to cultivate a more discerning public. To this end, we will combine fine-grained close reading with conceptual interpretation, critical studies with creative practice. Scholarly articles, white papers, and news reports from a range of fields will inform our exploration.\n\nLearning Goals\n\nBy the conclusion of the module, students will be able to:\n\nDefine key concepts such as \"misinformation,\" \"deepfake,\" and \"civic media.\"\n\nUnderstand different forms of misinformation, the disruptive role they play within our information ecology, and the threat they pose to societies around the world.\n\nEmploy interdisciplinary methods to critically analyze misinformation and emerging media. In addition to learning techniques of close analysis, students will become familiar with how digital forensics, verification, and policy are all crucial to combatting misinformation.\n\nLocate, research and properly cite primary and secondary sources from a variety of institutions and online archives.\n\nRecognize the ways that synthetic media can be used for the civic good.\n\nReadings\n\nSee the\nBibliography\nas well as an example\nReading List\nfor the course.\n\nGrading\n\nActivities\n\nPercentages\n\nAttendance/Participation\n\n20%\n\nHistorical Misinformation Case Study\n\n20%\n\nGroup Presentation\n\n30%\n\nMedia for the Civic Good Essay\n\n30%\n\nAttendance\n\nBecause our discussions are so important to our learning about media, attendance at each class meeting is mandatory. Over the course of the semester, you are allowed two unexcused absences. Missing more than 50% of the classes in any three-week period before the drop date will automatically remove you from the course. Six unexcused absences will result in an F for the course.\n\nParticipation\n\nThis course is collaborative and will work well when everybody comes to class prepared to contribute. Participation itself may take a number of forms; for example, responding to questions posed in class or asking questions about a reading, film, or another student's comment. While we do not always have to agree with each other, we must always try to be respectful of different opinions.\n\nIt's natural to feel nervous about speaking publicly in any kind of class setting. I'm happy to chat to discuss strategies for participation. Public speaking is a learned skill and we'll develop this skill throughout the semester.\n\nHistorical Misinformation Case Study\n\nMisinformation is hardly new. False and deceitful media has circulated for 1000s of years. Whether it was generated for an advertising ploy or as a form of official state propaganda, misinformation has served a variety of strategic purposes. Your task will be to write a 5 page account of an historical case study of misinformation. The example must be before the year 2000 and could involve any kind of media (film, radio, newspaper, etc.). Your case study could originate from within the halls of a government institution, be manufactured by a corporation or even a private citizen. The following questions will help to guide your research: Who created this work of media and what does it communicate? Why does it make sense to characterize it as misinformation? How did it circulate and engage with people? What were some of the consequences? Newspapers from Proquest's online holdings as well as other sources we will discuss in class will aid in your research.\n\nGroup Presentation: Combatting Misinformation\n\nThere are many strategies being proposed and implemented to combat misinformation. Working in groups of three, research one of them in-depth and present on it to the class. Examples could include government regulation, tech platforms investing in content moderation, third-party watchdogs, or grassroots efforts to bolster a credible and independent press. Your 20 minute presentation should include a range of visuals and text. Describe the motivations behind a particular strategy and your assessment of its effectiveness. We will speak in class about examining different sources for your research, including tech journalism, mainstream news periodicals, and articles from scholars and public intellectuals about how to fight the threat and consequences of misinformation.\n\nEmerging Media for the Civic Good\n\nJust as we have covered how emerging media can be used to manipulate and deceive, we have also examined the civic possibilities of contemporary technology. You will write a 7 pg. paper that analyzes one particular example, devoting special attention to the following: how is a particular technology being used toward a civic outcome? What is the question or challenge that it is addressing? Can you detect qualitative or quantitative impact? Is there a larger public perception or resonance? You might select a film, such as the recent documentary, Welcome To Chechnya (David France, 2020), which uses AI to protect the identity of witnesses; or, you might select the public history project Dimensions in Testimony, which stages conversations between AI-enabled simulations of camp survivors and museumgoers.",
      "files": [],
      "source_url": "https://ocw.mit.edu/courses/res-cms-001-media-literacy-in-the-age-of-deepfakes-spring-2021/",
      "course_info": "RES.CMS-001 | Non-Credit",
      "subject": "General"
    },
    {
      "course_name": "MEG Workshop",
      "course_description": "This series helps learners understand magnetoencephalography (MEG) signals through the lens of source estimation, decoding, and connectivity: principles, pitfalls, and perspectives.\nMEG methodological approaches have grown remarkably during the 50-year history of MEG. A breadth of source estimation tools can localize brain activity even in challenging situations. Pattern analysis of brain activity can perform feats of mind reading by revealing what a person is seeing, perceiving, attending to, or remembering. Functional connectivity approaches can assess the role of large-scale brain networks in cognitive function. The aim of this workshop is to deconstruct these tools, overview the challenges and limitations, and demonstrate MEG data analysis procedures to a novice researcher.\nThis workshop was sponsored by the Center for Brains, Minds, and Machines (CBMM), a multi-institutional NSF Science and Technology Center headquartered at MIT that is dedicated to the study of intelligence—how the brain produces intelligent behavior and how we may be able to replicate intelligence in machines.",
      "topics": [
        "Health and Medicine",
        "Biomedical Signal and Image Processing",
        "Medical Imaging",
        "Science",
        "Cognitive Science",
        "Health and Medicine",
        "Biomedical Signal and Image Processing",
        "Medical Imaging",
        "Science",
        "Cognitive Science"
      ],
      "syllabus_content": "",
      "files": [],
      "source_url": "https://ocw.mit.edu/courses/res-9-007-meg-workshop-spring-2019/",
      "course_info": "RES.9-007 | Non-Credit",
      "subject": "General"
    },
    {
      "course_name": "Climate Action Hands-On: Harnessing Science with Communities to Cut Carbon",
      "course_description": "This course explores how citizen science can support community actions to combat climate change. Participants will learn about framing problems, design ways to gather data, gather some of their own field data, and consider how the results can enable action. Leaks in the natural gas system—a major source of methane emissions, and a powerful contributor to climate change—will be a particular focus.\nThe course was organized by ClimateX and Fossil Free MIT, with support from the National Science Foundation for the methane monitoring equipment. It was offered during the Independent Activities Period (IAP), which is a special 4-week January term at MIT.",
      "topics": [
        "Energy",
        "Climate",
        "Fossil Fuels",
        "Engineering",
        "Environmental Engineering",
        "Environmental Management",
        "Social Science",
        "Public Administration",
        "Environmental Policy",
        "Energy",
        "Climate",
        "Fossil Fuels",
        "Engineering",
        "Environmental Engineering",
        "Environmental Management",
        "Social Science",
        "Public Administration",
        "Environmental Policy"
      ],
      "syllabus_content": "Course Meeting Times\n\nFour sessions held across 3 weeks.\n\nLectures / discussion: 2 sessions, 2 hours / session\n\nMakerspace Hands-on: 1 session, 4 hours\n\nField Hands-on: 1 session, 2 groups, 1.5 hours / group\n\nCourse Overview\n\nPut citizen science into action to tackle climate change! This course explores approaches to applying scientific data and new technologies toward climate-related research needs, community risks, and policy actions. Natural gas leaks (a major source of methane emissions) will be a particular focus. Through in-class lectures and discussion, a \"maker\"-style activity and a data collection field trip, participants will learn about effective science-based community action and practice putting that knowledge into action themselves.\n\nPrerequisites\n\nThis non-credit course has no prerequisites. Problem solvers of all backgrounds and experience levels are welcome. Just bring a passion for changing the world for the better and an eagerness to roll up your sleeves.\n\nCalendar\n\nSES #\n\nSESSION TYPES\n\nTOPICS\n\nLecture / discussion (2 hours)\n\nIntroduction to citizen / community science networks in operation, including Public Lab; future of community science for climate action. Discuss some relevant field examples.\n\nMakerspace Hands-on (4 hours)\n\nTools to visualize & verify: A mini-hackathon on data collection and data visualization, and a hands-on introduction to the tools for live data collection of methane gas leaks. Details on the history of natural gas infrastructure nationally and in Boston area.\n\nField Hands-on (2 x 1.5 hours)\n\nMethane leak \"safari\": A field trip to collect live data on methane leaks in the natural gas infrastructure, using a van equipped for mobile GPS-linked monitoring and a handheld probe for up-close investigation.\n\nLecture / discussion (2 hours)\n\nDiscuss the ways data can inform public decision-making: Using citizen data in legal cases, and the challenges and promise of sustainability footprints. Debrief of methane leak data collected on the prior field trip.",
      "files": [
        {
          "category": "Resource",
          "title": "Community Science",
          "type": "PDF",
          "source_url": "https://ocw.mit.edu/courses/res-env-001-climate-action-hands-on-harnessing-science-with-communities-to-cut-carbon-january-iap-2017/d85fb96dd199997cfdbb9326df015a2a_MITRES_ENV_001IAP17_ses1.1.pdf",
          "content": "From Community Science\nto Community Action\n\nWhat is science for?\ncuriosity\nsolving problems\n\nWhat is the role of science in\nmodern society?\n\nand yet...\n\nScience needs to speak for\ncommunities\n\nMotivation for\ncommunity science\nCommunity empowerment,\ndata ownership\nRespond to specific needs\nIncrease public interest and\nawareness\nAccess to local knowledge\nChallenges\nData quality\nLong-term support\nChanging community needs\n\nWhat makes successful community science?\nOpen-source data and methods\nOpen communication between community members and\nscientists\nInvolvement of community from planning stages\nEncourage creativity and synthesis of tools and ideas from\ndifferent fields\n\nEarthWorks Community\nEmpowerment Project\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\nResource: Climate Action Hands-On: Harnessing Science with Communities to Cut Carbon\nDavid Damm-Luhr, Rajesh Kasturirangan, Nathan Phillips, Audrey Schulman, Britta Voss, Jeff Warren and Ory Zik\n\nThe following may not correspond to a p articular c ou rse o n MIT OpenCourseWare, but has been\nprovided by the author as an individual learning resource.\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms."
        },
        {
          "category": "Resource",
          "title": "Fixing the Carbon Footprint",
          "type": "PDF",
          "source_url": "https://ocw.mit.edu/courses/res-env-001-climate-action-hands-on-harnessing-science-with-communities-to-cut-carbon-january-iap-2017/6716a40c5a61b4e26fe1fbcf288d111f_MITRES_ENV_001IAP17_ses4.2.pdf",
          "content": "Fixing Carbon Footprint\nMIT\nFebruary 1st, 2017\nDr. Ory Zik, CEO\n\nPolicy is moving in the wrong direction\nCannot rely on the supply side to change fast enough\n(c) CNN. All rights reserved. This content is excluded from our Creative Commons\nlicense. For more information, see https://ocw.mit.edu/help/faq-fair-use/.\nGraphic depicting \"Reality\" and \"Policy\" as road signs pointing in\ndifferent directions removed due to copyright restrictions.\nJanuary 2017\n\nThe only way to achieve a low-carbon\neconomy is by activating the market\nFilmed July 2010 at TEDGlobal 2010\nJason Clay: How big brands can help save\nbiodiversity\nFilmed July 2010 at TEDGlobal 2010\nJason Clay: How big brands can help save\nbiodiversity\nInvestors\n6.9 billion consumers\n300-500 brands\nControl 70% of commodity trade\nSuppliers\nCities\nUniversities\n(c) :orld :ildlife Fund. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see https://ocw.mit.edu/help/faq-fair-use/.\nSource of original graphics: Jason Clay, WWF\n\nDeclining google searches and newspaper articles on\n'carbon footprint'. Increasing academic interest\nAcademic\npublications\nPublic interest\nCourtes\\ of 0,T 3ress. 8sed with permission.\nSource: J. M. Turner; \"\"Counting Carbon: The Politics of Carbon Footprints and Climate Governance from the Individual to the Global.\"\nGlobal Environmental Politics; Vol. 14, No. 1, 2014. DOI: 10.1162/GLEP_a_00214\n\nWhat makes a good metric?\n-\nreasoning\n- Accuracy - enable a 'race to the top' -\ndifferentiating similar products\nBy Daniel Kahneman, Nobel\nPrize Winner in Economics\nSimplicity - estimations and quantitative\n\nWhat is the carbon footprint of using one\ngallon of gasoline ?\nPhoto of person pumping gas into a car removed due to copyright restrictions.\n\n300 people estimated the carbon footprint of using\none gallon of gasoline\nSource: A. Grinstein, E. Kodra, S. Sheldon and O. Zik (manuscript)\n\n300 people estimated the carbon footprint of using\none gallon of gasoline\nEstimation error ~ X 100 to X 1,000\nSource: A. Grinstein, E. Kodra, S. Sheldon and O. Zik (manuscript)\n\nThe same results with 1000 participants\nCO2 estimation ratio in a gallon of gas\nCar weight estimation ratio\nSource: S. Chen, A. Grinstein, E. Kodra, S. Sheldon and O. Zik (manuscript)\n\n300% difference between\ncarbon footprint calculators\nusing the same data\n(c) source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see https://ocw.mit.edu/help/faq-fair-use/.\nSource: Padgett et. al. Environmental Impact Assessment Review Vol 28, 2008\n\nThe absence of quantitative reasoning leads to\nanecdotes...\nFrom Tsukayama, Hayley. \"How bad is email for the environment?\"\nWashington Post, January 25, 2017:\n0.3 gr CO2 per email\n(0.00003 gallon of gasoline)\n\nEven the best-intended fail to make progress\n(c) TimEerland. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see https://ocw.mit.edu/help/faq-fair-use/.\n-\nSustainability leader\n-\nReduces 20% of 4%...\n-\nDesigned a label in kWh\n\nHow carbon footprint works\nkg CO2-e\nMetric\nConversion factors\ne.g. kg CO2-e per kilowatt-hour\nConsumption data\ne.g. kilowatt-hour\nOn-site\nElectricity Supply chain\nWater & land\n(Scope 1)\n(Scope 2)\n(Scope 3)\n(not included)\n\nWhat need fixing\nkg CO2-e\nMetric\nConversion factors\ne.g. kg CO2-e per kilowatt-hour\nConsumption data\ne.g. kilowatt-hour\nOn-site\nElectricity Supply chain\nWater & land\n(Scope 1)\n(Scope 2)\n(Scope 3)\n(not included)\n\nCarbon footprinting is an inherently complex problem\nImage: Al Gore's TED talk (Climate Reality Project)\n(c) Climate 5ealit\\ 3roMect. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see https://ocw.mit.edu/help/faq-fair-use/.\n\nNeed to solve the reverse problem:\nGiven the output, determine the input\nScope 2 example\nDelivered\n40%\nWasted\n60%\n3uElic domain image.\nYour impact is\nYou consume\ndetermined here\nhere\n(c) source unknown. All rights reserved. This\ncontent is excluded from our Creative\nCommons license. For more information,\nsee https://ocw.mit.edu/help/faq-fair-use/.\n\n\"The best minds of my generation are thinking about\nhow to make people click ads... That sucks\"\nData Scientist Jeff Hammerbacher\n\nCarbon footprinting 2.0\nOpen source effort to generate\nscience-based conversion factors\nEP =10 kg CO2-e\n~ gallon of gas inc. refining losses\nRelatable metric\nInclude water and other\nresources\n-\nDesigned to address the challenges of carbon footprinting\n-\nA universal metric rooted in physical and behavioral science\n-\nRequires a collaborative effort\n\nUsing data science to calculate scope 2\nSource: EPA\nCourtes\\ of (. .odra, S. Sheldon, 5. 'olan, 2. =ik, license CC %<.\n-\nAnnual average (static)\n-\nMonthly and hourly (dynamic)\n-\n24 regions\n-\n138 regions\n-\nExcel\n-\nAPI release Feb. 8 2017\nSource: E. Kodra, S. Sheldon, R. Dolan, O. Zik\nEnviron. Sci. Technol., 2015, 49 (22), pp 13692-13698\n\nAdding water to carbon footprint calculations\nkilowatt-hour per kgallon\nSource: Sheldon and Zik\n-\nStep 1: Energy intensity of water\n-\nStep 2: Carbon intensity of energy\nSource: S. Sheldon and O. Zik Water Scarcity - An energy Problem; ASME 2012\n\nThe world with carbon footprint 2.0\n\nEvery household, company, school or city have a simple,\nrigorously calculated carbon budget\nA typical Monthly Budget in EP (1 EP = 10 kg CO2-e)\n200 EP\n198 EP\n105 EP\n120 EP\nSource: N. Kulatilaka and O. Zik The Sustainability Babelfish; Sustainability Science Vol. 8 (2) pp 295-300 (2013)\n\nThe climate impact of home energy control\nThe carbon footprint of a Sense device in EP @ 29 kWh\n29 kWh\n-\nHome energy control provides kWh reading\n-\nGreenometry provides the climate context through EP and its API\n-\n1EP= 10 kg CO2-e ~ 1 gallon of gasoline\nCourtes\\ of Sense /aEs. 8sed with permission.\nImage source: sense\n\nThe MPG of Tesla\n-\nTesla's dashboard Wh/mi has little climate context\n-\nBy definition: MPG = miles per EP = miles per 10 kg of CO2-e\n-\nPowered by Greenometry's API and app\nCar and dashEoard photos (c) Tesla. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see https://ocw.mit.edu/help/faq-fair-use/.\n\nBetter consumer choices\nWaste\nPegasus\nEnergy\nWater\n3.2 EP\nFlyknit Fly\nFlyknit\nFlyknit Fly\nFlyknit\nlyknit\nFlykn\nlyknit Ft F\nFlyknit\n2.7 EP\nFlyknit\n(if produced\nin Portland)\n2.1 EP\n-\nThe values are estimated for demonstration, based on Nike's LCA\n-\nRequires not only simplicity, but also accuracy - better scope 3 data\nSource of life cycle data: NIKE\nShoe photos (c) Nike. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see https://ocw.mit.edu/help/faq-fair-use/.\n\nThe dependence of solar energy on technology\nand location of manufacturing and installation\nCarbon payback time\n-\nAnalysis of climate payback time depends on: life cycle analysis, energy mix and\nmanufacturing location, energy input at installation location, radiation, efficiency etc.\n-\nThose factors are included in the backend calculation\n\n- We must engage the market\n- The market needs metrics\n- We have to fix carbon footprint\n\nThank you!\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\nResource: Climate Action Hands-On: Harnessing Science with Communities to Cut Carbon\nDavid Damm-Luhr, Rajesh Kasturirangan, Nathan Phillips, Audrey Schulman, Britta Voss, Jeff Warren and Ory Zik\nThe following may not correspond to a particular course on MIT OpenCourseWare, but has been provided by the author as an\nindividual learning resource.\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms."
        },
        {
          "category": "Resource",
          "title": "Climate Action Hands-On: Session 1.2, Natural Gas Leaks",
          "type": "PDF",
          "source_url": "https://ocw.mit.edu/courses/res-env-001-climate-action-hands-on-harnessing-science-with-communities-to-cut-carbon-january-iap-2017/a7efbad9a2f0c50961ce43baafb9432a_MITRES_ENV_001IAP17_ses1.2_gasleaks.pdf",
          "content": "Natural Gas Leaks\nHEET\n\n*+,-\".)/%.0-123+4-\n0' 123+ 454+)'6%23 789:)'\n0 ;&< 454+)'&+\",'\"=< >\"='>%\">,'\n0' ?#5&5#5+)'2= @: A+\"% #53+ 6%\"3+ 62% %+4&\">+3+=#'\n!\"\"#$%&'()-\n!\"\"#$%&'()-\n\n1('5/+$4-\n7B' C2#+=#5\"&&A'+D4&2)5E+'\n.\")# -\"%&+3 F\")'+D4&2)52= G@:7HI JA'K\"3+)'L+5E2=B M !+N O2%,'P\"5&A'!+N)B Q&& %5FR#)'%+)+%E+<B /R5)'>2=#+=# 5)'\n+D>&$<+< 6%23 2$% S%+\"#5E+ S2332=)'&5>+=)+B T2% 32%+ 5=62%3\"#52=U')++'R##4)VWW2>NB35#B+<$WR+&4W6\"XY6\"5%Y$)+W'\n!\"\"#$%&'()-\n\nHEETma.org\nHEETma.org\n1('5/+$4-\n7B' C2#+=#5\"&&A'+D4&2)5E+'\n@B' L5&& #%++)'\n\n1('5/+$4-\n7B' C2#+=#5\"&&A'+D4&2)5E+'\n@B' L5&& #%++)'\nZB' C2N+%6$& F%++=R2$)+ F\")'\n[$%=+<'\\ S;@'\n!;/ J$%=+<'\\']+#R\"=+'\n678 $'(+-0%$%)2.)-\nCR2#2)'M')2$%>+ $=,=2N=B Q&& %5FR#)'%+)+%E+<B /R5)'>2=#+=# 5)'+D>&$<+< 6%23 2$% S%+\"#5E+'\nS2332=)'&5>+=)+B T2% 32%+ 5=62%3\"#52=U )++'R##4)VWW2>NB35#B+<$WR+&4W6\"XY6\"5%Y$)+W'\n!\"\"#$%&'()-\n\n1('5/+$4-\n7B' C2#+=#5\"&&A'+D4&2)5E+'\n@B' L5&& #%++)'\nZB' C2N+%6$& F%++=R2$)+ F\")'\nHB' C\"5< 62% JA'#R+ %\"#+4\"A+%'\n!\"\"#$%&'()-\n\n9:;4-3'4425/+-:'-$%3-.%:<(%/-)%4-/+%=4-\n!\"\"#$%&'()-\n\n?=<+%&A5=F 3\"4 M (22F&+B Q&& %5FR#)'%+)+%E+<B /R5)'>2=#+=# 5)'+D>&$<+< 6%23 2$%'\nS%+\"#5E+ S2332=)'&5>+=)+B T2% 32%+ 5=62%3\"#52=U )++'R##4)VWW2>NB35#B+<$WR+&4W6\"XY6\"5%Y$)+W'\n8'\n\n?=<+%&A5=F 3\"4 M (22F&+B Q&& %5FR#)'%+)+%E+<B /R5)'>2=#+=# 5)'+D>&$<+< 6%23 2$%'\nS%+\"#5E+ S2332=)'&5>+=)+B T2% 32%+ 5=62%3\"#52=U )++'R##4)VWW2>NB35#B+<$WR+&4W6\"XY6\"5%Y$)+W'\n^'\n\n7:'\n\n77'\n\n7@'\n\n0'PC?'<\"#\"'\n0 PC?'<\"#\"\nCohasset\n?=<+%&A5=F 3\"4 M (22F&+B Q&&'%5FR#)'%+)+%E+<B /R5)'>2=#+=# 5)'+D>&$<+< 6%23 2$%'\nS%+\"#5E+ S2332=)'&5>+=)+B T2% 32%+ 5=62%3\"#52=U )++'R##4)VWW2>NB35#B+<$WR+&4W6\"XY6\"5%Y$)+W'\n\nDorchester\n?=<+%&A5=F 3\"4 M (22F&+B Q&&'%5FR#)'%+)+%E+<B /R5)'>2=#+=# 5)'+D>&$<+< 6%23 2$%'\nS%+\"#5E+ S2332=)'&5>+=)+B T2% 32%+ 5=62%3\"#52=U )++'R##4)VWW2>NB35#B+<$WR+&4W6\"XY6\"5%Y$)+W'\n7H'\n\nWorcester\n?=<+%&A5=F 3\"4 M (22F&+B Q&& %5FR#)'%+)+%E+<B /R5)'>2=#+=# 5)'+D>&$<+< 6%23 2$%'\nS%+\"#5E+ S2332=)'&5>+=)+B T2% 32%+ 5=62%3\"#52=U )++'R##4)VWW2>NB35#B+<$WR+&4W6\"XY6\"5%Y$)+W'\n7_'\n\n1$4+%Y+35##+%)'\n?=<+%&A5=F 3\"4 M (22F&+B Q&&'%5FR#)'%+)+%E+<B /R5)'>2=#+=# 5)'+D>&$<+< 6%23 2$% S%+\"#5E+ S2332=)'&5>+=)+B T2% 32%+ 5=62%3\"#52=U')++'R##4)VWW2>NB35#B+<$WR+&4W6\"XY6\"5%Y$)+W'\n1++ -+=<%5>,U']B'TBU'+#'\"&B'`T$F5#5E+ 3+#R\"=+ +35))52=)'6%23 &+\",Y4%2=+ =\"#$%\"& F\")'<5)#%5J$#52='\n5=6%\")#%$>#$%+ 5= $%J\"='+=E5%2=3+=#)B`'!\"#$%&\"'(\")*+ -&++.)$&\" @7Z'G@:79IV a7:b9B'\n\nc+%56A'\n?=<+%&A5=F 3\"4 M (22F&+B Q&& %5FR#)'%+)+%E+<B /R5)'>2=#+=# 5)'+D>&$<+< 6%23 2$% S%+\"#5E+ S2332=)'&5>+=)+B T2% 32%+ 5=62%3\"#52=U')++'R##4)VWW2>NB35#B+<$WR+&4W6\"XY6\"5%Y$)+W'\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\nResource: Climate Action Hands-On: Harnessing Science with Communities to Cut Carbon\nDavid Damm-Luhr, Rajesh Kasturirangan, Nathan Phillips, Audrey Schulman, Britta Voss, Jeff Warren and Ory Zik\nThe following may not correspond to a particular course on MIT OpenCourseWare, but has been\nprovided by the author as an individual learning resource.\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms."
        }
      ],
      "source_url": "https://ocw.mit.edu/courses/res-env-001-climate-action-hands-on-harnessing-science-with-communities-to-cut-carbon-january-iap-2017/",
      "course_info": "RES.ENV-001 | Non-Credit",
      "subject": "General"
    },
    {
      "course_name": "MIT Sloan Teaching Resources Library",
      "course_description": "Sloan’s Teaching Resources Library provides open access to case studies and management simulations for management educators and students worldwide. This collection of teaching materials and games focuses on areas in which Sloan’s innovative research and teaching are on the cutting edge, including action learning, entrepreneurship, leadership and ethics, operations management, strategy, sustainability, and system dynamics.\nFormerly known as LearningEdge, and MIT Sloan Teaching Innovation Resources (MSTIR).\nOnline Publication",
      "topics": [
        "Business",
        "Accounting",
        "Entrepreneurship",
        "Finance",
        "Leadership",
        "Management",
        "Operations Management",
        "Organizational Behavior",
        "Business",
        "Accounting",
        "Entrepreneurship",
        "Finance",
        "Leadership",
        "Management",
        "Operations Management",
        "Organizational Behavior"
      ],
      "syllabus_content": "",
      "files": [],
      "source_url": "https://ocw.mit.edu/courses/res-15-001-mit-sloan-learningedge-fall-2008/",
      "course_info": "RES.15-001 | Non-Credit",
      "subject": "General"
    },
    {
      "course_name": "Algebra I Student Notes",
      "course_description": "Algebra I is the first semester of a year-long introduction to modern algebra. Algebra is a fundamental subject, used in many advanced math courses and with applications in computer science, chemistry, etc. The focus of this class is studying groups, linear algebra, and geometry in different forms.\nThese notes, which were created by students in a recent on-campus 18.701 Algebra I class, are offered here to supplement the materials included in OCW’s version of 18.701. They have not been checked for accuracy by the instructors of that class or by other MIT faculty members.",
      "topics": [
        "Mathematics",
        "Algebra and Number Theory",
        "Mathematics",
        "Algebra and Number Theory"
      ],
      "syllabus_content": "",
      "files": [],
      "source_url": "https://ocw.mit.edu/courses/res-18-011-algebra-i-student-notes-fall-2021/",
      "course_info": "RES.18-011 | Non-Credit",
      "subject": "General"
    },
    {
      "course_name": "D-Lab Student Showcases",
      "course_description": "Student projects in D-Lab classes are defined by community partners and social ventures around the world. We don’t always know what is needed, but our community partners do, and our students have technical knowledge and skills to contribute to that work.\nEach semester, through a selection of full-semester classes, our students form into teams to work on projects framed by community partners – NGOs, local nonprofits, and social entrepreneurs. At the end of each semester, students present their work to their peers, partners, and guests.",
      "topics": [
        "Energy",
        "Engineering",
        "Health and Medicine",
        "Social Science",
        "Society",
        "Teaching and Education",
        "Energy",
        "Engineering",
        "Health and Medicine",
        "Social Science",
        "Society",
        "Teaching and Education"
      ],
      "syllabus_content": "",
      "files": [],
      "source_url": "https://ocw.mit.edu/courses/res-ec-003-d-lab-student-showcases-spring-2022/",
      "course_info": "RES.EC-003 | Non-Credit",
      "subject": "General"
    },
    {
      "course_name": "The Roosevelt Project",
      "course_description": "No description found.",
      "topics": [
        "Energy",
        "Climate",
        "Social Science",
        "Economics",
        "Public Administration",
        "Environmental Policy",
        "Public Policy",
        "Energy",
        "Climate",
        "Social Science",
        "Economics",
        "Public Administration",
        "Environmental Policy",
        "Public Policy"
      ],
      "syllabus_content": "",
      "files": [],
      "source_url": "https://ocw.mit.edu/courses/res-14-003-the-roosevelt-project-spring-2023/",
      "course_info": "RES.14-003 | Non-Credit",
      "subject": "General"
    },
    {
      "course_name": "MIT Project on Embodied Education",
      "course_description": "The MIT Project on Embodied Education aims to close the gap between the growing body of research on movement and the learning process and the pedagogical strategies that educators use, finding ways to integrate physical activity and academic instruction at all levels—for example, teaching elementary school math through yoga, middle school physics through martial arts, high school science through swimming, and college history through dance.",
      "topics": [
        "Teaching and Education",
        "Curriculum and Teaching",
        "Teaching and Education",
        "Curriculum and Teaching"
      ],
      "syllabus_content": "",
      "files": [],
      "source_url": "https://ocw.mit.edu/courses/res-sts-001-mit-project-on-embodied-education-fall-2024/",
      "course_info": "RES.STS-001 | Non-Credit",
      "subject": "General"
    },
    {
      "course_name": "Teaching La Princesse de Clèves",
      "course_description": "This website has been designed to offer strategies for teaching this seminal work to intermediate-level college students in a way that is dynamic, engaging, and perhaps most importantly highlights the connection between Madame de Lafayette’s seventeenth-century work La Princesse de Clèves and the contemporary social concerns of young people in today’s world. \nThere was a recent heated debate in France about the modern relevance of this literary text that began when Nicolas Sarkozy suggested that the study of this text was useless. His comments incited fervent discussion in French academic, artistic, and political circles. The compelling history of the text, along with its importance in contemporary French society and culture, makes the study of this work highly relevant for students.\nThe La Princesse de Clèves website is published under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 (CC BY-NC-SA) International license.",
      "topics": [
        "Humanities",
        "Language",
        "French",
        "Literature",
        "International Literature",
        "Humanities",
        "Language",
        "French",
        "Literature",
        "International Literature"
      ],
      "syllabus_content": "",
      "files": [],
      "source_url": "https://ocw.mit.edu/courses/res-21g-3001-teaching-la-princesse-de-cleves-fall-2023/",
      "course_info": "RES.21G-3001 | Non-Credit",
      "subject": "General"
    },
    {
      "course_name": "BioNook Online Biology Resources",
      "course_description": "BioNook is Whitehead Institute’s online biology resource, offering exciting learning enrichment for students, parents and teachers. Find videos, podcasts and stories on Whitehead Institute Science, as well as virtual workshop opportunities through BioNook’s After School Science Club, and ideas for nature-based activities.\nExplore free materials on biology and research—from deep explorations of how science is done, to stories following the lives of scientists, to suggestions for fun outside activities and hands-on citizen science projects.",
      "topics": [
        "Science",
        "Biology",
        "Biochemistry",
        "Cell Biology",
        "Genetics",
        "Molecular Biology",
        "Science",
        "Biology",
        "Biochemistry",
        "Cell Biology",
        "Genetics",
        "Molecular Biology"
      ],
      "syllabus_content": "",
      "files": [],
      "source_url": "https://ocw.mit.edu/courses/res-7-004-bionook-online-biology-resources-spring-2021/",
      "course_info": "RES.7-004 | Non-Credit",
      "subject": "General"
    },
    {
      "course_name": "Case Studies in Social and Ethical Responsibilities of Computing",
      "course_description": "The MIT Case Studies in Social and Ethical Responsibilities of Computing (SERC) aims to advance new efforts within and beyond MIT’s Stephen A. Schwarzman College of Computing. The specially commissioned and peer-reviewed cases are brief and intended to be effective for undergraduate instruction across a range of classes and fields of study. The series editors expect the cases will also be of interest for computing professionals, policy specialists, and general readers. All cases will be made freely available via open-access publishing, with author retained copyright, through Creative Commons licensing.\nThe Series Editors interpret “social and ethical responsibilities of computing” broadly. Some cases focus closely on particular technologies, others on trends across technological platforms. Still others examine social, historical, philosophical, legal, and cultural facets that are essential for thinking critically about present-day efforts in computing and data sciences.",
      "topics": [
        "Engineering",
        "Computer Science",
        "Humanities",
        "Philosophy",
        "Ethics",
        "Teaching and Education",
        "Curriculum and Teaching",
        "Engineering",
        "Computer Science",
        "Humanities",
        "Philosophy",
        "Ethics",
        "Teaching and Education",
        "Curriculum and Teaching"
      ],
      "syllabus_content": "",
      "files": [],
      "source_url": "https://ocw.mit.edu/courses/res-tll-007-case-studies-in-social-and-ethical-responsibilities-of-computing-fall-2021/",
      "course_info": "RES.TLL-007 | Non-Credit",
      "subject": "General"
    },
    {
      "course_name": "Sorting Truth From Fiction: Civic Online Reasoning",
      "course_description": "With educators from around the world and faculty from MIT and Stanford University, you will learn quick and effective practices for evaluating online information that you can bring back to your classroom. The Stanford History Education Group has distilled these practices from observations with professional fact-checkers from the nation’s most prestigious media outlets from across the political spectrum. Using a combination of readings, classroom practice lessons, and assignments, you will learn how to teach the critical thinking skills needed for making wise judgments about web sources.\nAt the end of the course, you will be better able to help students find reliable sources at a time when we need it most.\nThis course is part of the Open Learning Library, which is free to use. You have the option to sign up and enroll in the course if you want to track your progress, or you can view and use all the materials without enrolling.",
      "topics": [
        "Teaching and Education",
        "Teaching and Education"
      ],
      "syllabus_content": "",
      "files": [],
      "source_url": "https://ocw.mit.edu/courses/res-cms-504-sorting-truth-from-fiction-civic-online-reasoning-spring-2021/",
      "course_info": "RES.CMS-504 | Non-Credit",
      "subject": "General"
    },
    {
      "course_name": "How to Process, Analyze and Visualize Data",
      "course_description": "This course is an introduction to data cleaning, analysis and visualization. We will teach the basics of data analysis through concrete examples. You will learn how to take raw data, extract meaningful information, use statistical tools, and make visualizations.\nThis was offered as a non-credit course during the Independent Activities Period (IAP), which is a special 4-week term at MIT that runs from the first week of January until the end of the month.",
      "topics": [
        "Engineering",
        "Computer Science",
        "Data Mining",
        "Graphics and Visualization",
        "Engineering",
        "Computer Science",
        "Data Mining",
        "Graphics and Visualization"
      ],
      "syllabus_content": "Welcome! This class is an introduction to data cleaning, analysis and visualization. We will walk you through as we analyze real world datasets. Each day, we will spend the first 30 minutes introducing the day's concepts, and spend the rest of the class doing the lab exercises. We have written a daily walkthrough that you will read and program through in class, and we will be available to help.\n\nThis is our first time teaching this course, and we'll be learning as much as you. Don't hesitate to ask us to change something or improve on something. We'll be grateful.\n\nPrerequisites\n\nWe assume you have a working knowledge of Python (perhaps from\n6.01\n) and are willing to write code. Most of the code you interact with will come with an example that you can modify. Hopefully you won't need to write too much custom code--unless you're inspired to write more!\n\nWe expect you to install several development-related Python modules, and download the datasets we will be using in the class. Instructions can be found under Day 0, in the\nLectures and Labs\nsection.\n\nWhat We Will Teach\n\nWe will teach the basics of data analysis through concrete examples. All of your programming will be written in Python. The schedule is as follows:\n\nDay 0 (today): setup\n\nDay 1: An end-to-end example getting you from a dataset found online to several plots of campaign contributions.\n\nDay 2: Lots of visualization examples, and practice going from data to chart.\n\nDay 3: Statistics basics, including t-tests, linear regression, and statistical significance. We'll use campaign finance and per-county health rankings.\n\nDay 4: Text processing on a large text corpus (the Enron email dataset) using tf-idf and cosine similarity.\n\nDay 5: Scaling up to process large datasets using Hadoop/MapReduce on a larger copy of the Enron dataset.\n\nDay 6: You tell us! Get into groups or work on your own to analyze a dataset of your choosing, and tell us a story!\n\nWhat We Will Not Teach\n\nR. R is a wonderful data analysis, statistics, and plotting framework. We will not be using it because we can achieve all of our objectives in Python, and more MIT undergraduates know Python.\n\nVisualization using browser technology (canvas, svg, d3, etc) or in non-Python languages (\nProcessing\n). These tools are very interesting, and lots of visualizations on the web use these tools (such as the\nNew York Times visualizations\n), but they are out of the scope of this class. We'll teach you how to visualize data in static charts. If this is an area of interest for you, the next step will be to build interactive visualizations that the world can explore, and we can point you in the right direction with these.\n\nGitHub\n\nThe course materials can also be found\nin this GitHub repository\n, which may be updated more frequently than the OCW site.",
      "files": [
        {
          "category": "Lecture Notes",
          "title": "Day 0 Lecture Notes: Setup",
          "type": "PDF",
          "source_url": "https://ocw.mit.edu/courses/res-6-009-how-to-process-analyze-and-visualize-data-january-iap-2012/42d3a02506e3a2bbb8c1c8eb120bfe3b_MITRES_6_009IAP12_lec0.pdf",
          "content": "How to Process, Visualize,\nand Analyze Data\nEugene Wu, Adam Marcus\n\nCourse Basics\n- 5 lab days: ~30min background, 2.5h lab\n- 1 presentation madness day\n- No grades\n- No homework, unless you don't finish lab\n\nDay 6 Madness\n- After lab 4, you will have all the skills you need\n- Find your own dataset + questions\n- Tell us a story: 2 slides, 1 minute\n\nWhy is this important?\n\n(c) The Economist, O'Reilly Media, and Nature Publishing Group. All rights reserved. This content is excluded\nfrom our Creative Commons license. For more information, see http://ocw.mit.edu/fairuse.\n\n\"I keep saying that the sexy job in the\nnext 10 years will be statisticians\"\n\nHal Varian, Chief Economist Google\nStatisticians will never have a sexy job.\nData-powered storytellers will.\n\nSchedule\n\nDay 0\n- Setup\n- Optimistically, you've already done this\n\nToday\n\nDay 2: Visualizations\n\nDay 3: Statistics\n\nDay 4: Text Analysis with Kenneth Lay\nDay 5: Scaling up with\nHadoop/MapReduce\nImages of Kenneth Lay removed due to copyright restrictions.\n\nDay 6: Storytelling Madness!\nbiology\nstackoverflow\nsource code\nhealthcare\nfinance\nweb scraping\neconomics\nsociology\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\nResource: How to Process, Analyze and Visualize Data\nAdam Marcus and Eugene Wu\nThe following may not correspond to a particular course on MIT OpenCourseWare, but has been\nprovided by the author as an individual learning resource.\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
        },
        {
          "category": "Lecture Notes",
          "title": "Day 1 Lecture Notes: Let’s Play with Data!",
          "type": "PDF",
          "source_url": "https://ocw.mit.edu/courses/res-6-009-how-to-process-analyze-and-visualize-data-january-iap-2012/5798f33c524d917abe52819adb68fc5f_MITRES_6_009IAP12_lec1.pdf",
          "content": "Day 1: Let's Play with Data!\n2008 Presidential Election Donations\n\n$1,644,712,232\n\n6X\nEarth's circumference!\n\n10%\nU.S. Dept of Energy's Budget!\n\nFederal Election Commission\n(FEC)\n\n2008 Donations Dataset\nC00430470,\"P80002801\",\n\"McCain, John S\",\n\"WAHLERS, STUART E. MR.\",\n\"A.P.O.\", \"AE\", \"091280013\",\n\"U.S. MILITARY\",\"SOLDIER\",\n250, 31‐JUL‐08,\n\"\",\"X\",\n\"TRANSFER FROM MCCAIN VICTORY 2008\",\n\"SA18\",377957\n\nThis content is in the public domain, from the Federal Election Commission.\n\nTotal donations\nTime\n\nNegative Donations\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\nResource: How to Process, Analyze and Visualize Data\nAdam Marcus and Eugene Wu\nThe following may not correspond to a particular course on MIT OpenCourseWare, but has been\nprovided by the author as an individual learning resource.\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
        },
        {
          "category": "Lecture Notes",
          "title": "Day 2 Lecture Notes: Visualizations",
          "type": "PDF",
          "source_url": "https://ocw.mit.edu/courses/res-6-009-how-to-process-analyze-and-visualize-data-january-iap-2012/bcbf1667eaa64ca643e923fd884520bb_MITRES_6_009IAP12_lec2.pdf",
          "content": "Day 2: Introduction to\nVisualizations\nmatplotlib\n\nVisualization != Sexy Pictures\n\nThe Basics\nblog.okcupid.com\n\nBar Graph\nhttp://blog.okcupid.com\n(c) Humor Rainbow, Inc. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/fairuse.\n\nScatter Plot\nhttp://blog.okcupid.com\n(c) Humor Rainbow, Inc. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/fairuse.\n\nLine Graph\nhttp://blog.okcupid.com\n(c) Humor Rainbow, Inc. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/fairuse.\n\nChoropleth Plots\nhttp://blog.okcupid.com\n(c) Humor Rainbow, Inc. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/fairuse.\n\nBox Plots\n\nmatplotlib\nPython's version of Matlab plotting\n\nHow matplotlib Draws\n\nFigure object\n\nFigure\n\nSubplot object\nFigure\nDraw in here\nSubplot\nDraw in here\ne\ne\n\nfigure.add_subplot(2, 3, 1)\nrows\n3 columns\n\nfigure.add_subplot(2, 3, 1)\nrows\n3 columns\n\nfigure.add_subplot(2, 3, 1)\nrows\n3 columns\n\nfigure.add_subplot(2, 3, 1)\nrows\n3 columns\n\nCharting Library\n- subplot.bar()\n- subplot.plot()\n- subplot.scatter()\n- subplot.boxplot()\n\nLines\nFigure\nSubplot\n\nBoxes\nFigure\nSubplot\n\nPolygons\nFigure\nSubplot\n\nOverlaps\nFigure\nSubplot\n\nOverlaps\nFigure\nSubplot\n\nChoropleth Plots\nhttp://blog.okcupid.com\n(c) Humor Rainbow, Inc. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/fairuse.\n\nNo Easy Way\n\nHow Maps are Drawn\n\nHow Maps are Drawn\n\nHelper Functions\nFIPS\ndraw_county(subplot, county_id, color)\n\ndraw_state(subplot, state, color)\nunty\nFIPS\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\nResource: How to Process, Analyze and Visualize Data\nAdam Marcus and Eugene Wu\nThe following may not correspond to a particular course on MIT OpenCourseWare, but has been\nprovided by the author as an individual learning resource.\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
        },
        {
          "category": "Lecture Notes",
          "title": "Day 3 Lecture Notes: Hypothesis Testing",
          "type": "PDF",
          "source_url": "https://ocw.mit.edu/courses/res-6-009-how-to-process-analyze-and-visualize-data-january-iap-2012/19e0a9fac5ec147115bce81ba4daa68f_MITRES_6_009IAP12_lec3.pdf",
          "content": "How I learned to stop\nvisualizing and love statistics\n\nYou have a hunch\n\nVisualizations sanity check\nStatistics quantify the hunch\n(Visualizations storytelling)\n\nSomeone says:\n\"Obama got more small campaign\ncontributions than McCain\"\n\n???\n\n(c) Jhguch on Wikipedia. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/fairuse.\n\nMedian\n\n25% 75%\n\nInner Quartile Range\n\nWhiskers / Extremes\n\nOutliers\n\nBox-and-Whiskers Plot\n\n???\n\nAre they actually different?\nT-Test\n\nObama McCain\nObama McCain\nAssume\nReality\n\nObama McCain\nObama McCain\nHow likely is given ?\nHow likely is\n?\n\nObama\nMcCain\navg1\navg2\n\nObama\nMcCain\navg1\navg2\nEffect Size\n\nObama\nMcCain\navg1\navg2\nvariance 1\nvariance 2\n\nHow likely is given ?\nHow likely is\n?\navg1\navg2 2\na\nvariance 1\nvariance 2\n\nHow likely are they equal\ngiven avg/variance differences?\nProbablility p\np is low\np is high\nObama, McCain\nDon't trust\nare different\nthe difference\n(significant)\n(not significant)\nbabl\ni\n\nSignificance is binary\n- Pick a threshold: .01? .05?\n- Is p > threshold, or < threshold?\np < .05? significant\np > .05? don't trust the difference\n\navg1\navg2 2\na\nvariance 1\nvariance 2\nT-Test Signifiance\n# Samples\n\nObama: >1M\nMcCain: >1M\n+\n\nCorrelation, Linear Regression\n\nCounty Health Rankings\n- Every county in USA\n- Years of Potential Life Lost (YPLL): early morbidity\n- less is good\n- more is bad\n- Median income, % population w/ diabetes,\n% population under 18, ...\n\nWhat is correlated with early\ndeath in a community?\nBurgers\nSleep\nEducation\nExercise\n# Rappers\nYour theory here\n\ny = mx + b\nR2 (0 to 1)\np < .05?\nLine coefficients:\nCorrelation amount:\nSignificance:\n\nCorrelation != Causation\nCorrelation\nCausal Hunch\nRandomized Trial\nT-Test!\nal H\nmiz\nTes\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\nResource: How to Process, Analyze and Visualize Data\nAdam Marcus and Eugene Wu\nThe following may not correspond to a particular course on MIT OpenCourseWare, but has been\nprovided by the author as an individual learning resource.\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
        },
        {
          "category": "Lecture Notes",
          "title": "Day 5 Lecture Notes: Processing Large Datasets",
          "type": "PDF",
          "source_url": "https://ocw.mit.edu/courses/res-6-009-how-to-process-analyze-and-visualize-data-january-iap-2012/4e9970d74fb095227b692be7fd134815_MITRES_6_009IAP12_lec5.pdf",
          "content": "Scaling Up with MapReduce,\nHadoop, and Amazon\n\nTerm Frequency\nKenneth Lay\n15 MB\nEnron\n1,300 MB\nGMail\n>1,000,000,000 MB\n\nParallelism\n\n[Google logo]\n\nMapReduce Paper\n[Hadoop logo]\n\nOpen Source Project\n\nCommon Pattern\n\ndoc\ndoc\ndoc\nthe dog\ni\nate\nfruit\nshe\nate\nfruit\nthe\ndog\ni\nate\nate\nshe\nfruit\nfruit\nthe: 1\ndog: 1\ni: 1\nate: 2\nshe: 1\nfruit: 2\n\nLoop\nGroup\nSummarize\n\nWord Count\nLoop\nwords in documents\nGroup\ninstances of a word\nSummarize\ncount instances\nof a word\n\nWord Count\nCandidates\nLoop\nwords in documents\nlines in csv\nGroup\ninstances of a word\ncandidate, day\nSummarize\ncount instances\nof a word\nsum of contributions\nby candidate, day\n\nMapReduce\nLoop\nMap\nGroup\nShuffle\nSummarize\nReduce\nYou Implement\nSh\n\nAmazon Provides Compute Power\nSimple Storage Service (S3): Files\nElastic MapReduce (EMR): Computers\n\nS3 stores files\n- Create bucket (unique name)\n- Files in bucket\n- Access via amazon web console\n- Access via programmatic API\n\nAmazon Charges Us Money\n- S3: 14 cents per GB per month\n- EMR: 10 cents per machine per hour\n- 1 minute = 1 hour\n- Ask us if you use more than 200 hours\n- Excess gets charged to our credit card\n\nSlower Than You Think\nScale, not Performance\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\nResource: How to Process, Analyze and Visualize Data\nAdam Marcus and Eugene Wu\nThe following may not correspond to a particular course on MIT OpenCourseWare, but has been\nprovided by the author as an individual learning resource.\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
        },
        {
          "category": "Lecture Notes",
          "title": "Day 6 Lecture Notes: Course Recap",
          "type": "PDF",
          "source_url": "https://ocw.mit.edu/courses/res-6-009-how-to-process-analyze-and-visualize-data-january-iap-2012/9d352b3cac158c5ef71cdc7804544311_MITRES_6_009IAP12_lec6.pdf",
          "content": "Recap\nOverview\n\nRaw Data\nCleaned, Structured\nData\nExploratory Data\nAnalysis\nVerify Hunches (stats)\nData Product\nImage of Schedule A-P, showing two contributions to Obama for America.\nData includes full name, date of contribution, and contribution amount.\n\nC00420224,\"P80002983\",\"Cox, John H\",\"BROWN, CHARLENE\",\"EAGLE RIVER\",\"AK\",\"99577\",\"\",\"STUDENT\",25,01-MAR-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"KELLY, RAY\",\"HUNTSVILLE\",\"AL\",\"35801\",\"ARKTECH\",\"RETIRED\",25,25-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"CINGEL, KEITH\",\"SEVERN\",\"AL\",\"20999\",\"SANTA CLAUS\",\"SNOWMAN\",50,17-MAY-07,\"\",\"\",\"\",\"SA17A\",305408\nC00420224,\"P80002983\",\"Cox, John H\",\"DUNAWAY, JONATHON\",\"DEATSVILLE\",\"AL\",\"36022\",\"CSC\",\"TECHNICAL MANAGER\",10,18-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"TERRY, R.S. MR. SR.\",\"SHEFFIELD\",\"AL\",\"35660\",\"RETIRED\",\"\",25,18-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"CANADY, DALE\",\"PHOENIX\",\"AZ\",\"85051\",\"RETIRED\",\"\",25,11-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"LORENZ, DWIGHT\",\"SUN CITY\",\"AZ\",\"85351\",\"NONE\",\"RETIRED\",20,12-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"STEWART, MICHAEL\",\"CHANDLER\",\"AZ\",\"85224\",\"DYNAMIC ENERGY\",\"TECHNICIAN\",5,11-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"ROSENTHAL, ARNOLD\",\"CAREFREE\",\"AZ\",\"85277\",\"RETIRED\",\"\",10,11-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"VADNAIS, DOROTHY\",\"SAN DIEGO\",\"CA\",\"92116\",\"\",\"RETIRED\",10,10-JAN-\n07,\"\",\"\",\"\",\"SA17A\",288757C00420224,\"P80002983\",\"Cox, John H\",\"BROWN, CHARLENE\",\"EAGLE RIVER\",\"AK\",\"99577\",\"\",\"STUDENT\",25,01-MAR-\n07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"KELLY, RAY\",\"HUNTSVILLE\",\"AL\",\"35801\",\"ARKTECH\",\"RETIRED\",25,25-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"CINGEL, KEITH\",\"SEVERN\",\"AL\",\"20999\",\"SANTA CLAUS\",\"SNOWMAN\",50,17-MAY-07,\"\",\"\",\"\",\"SA17A\",305408\nC00420224,\"P80002983\",\"Cox, John H\",\"DUNAWAY, JONATHON\",\"DEATSVILLE\",\"AL\",\"36022\",\"CSC\",\"TECHNICAL MANAGER\",10,18-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"TERRY, R.S. MR. SR.\",\"SHEFFIELD\",\"AL\",\"35660\",\"RETIRED\",\"\",25,18-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"CANADY, DALE\",\"PHOENIX\",\"AZ\",\"85051\",\"RETIRED\",\"\",25,11-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"LORENZ, DWIGHT\",\"SUN CITY\",\"AZ\",\"85351\",\"NONE\",\"RETIRED\",20,12-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"STEWART, MICHAEL\",\"CHANDLER\",\"AZ\",\"85224\",\"DYNAMIC ENERGY\",\"TECHNICIAN\",5,11-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"ROSENTHAL, ARNOLD\",\"CAREFREE\",\"AZ\",\"85277\",\"RETIRED\",\"\",10,11-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"VADNAIS, DOROTHY\",\"SAN DIEGO\",\"CA\",\"92116\",\"\",\"RETIRED\",10,10-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"BROWN, CHARLENE\",\"EAGLE RIVER\",\"AK\",\"99577\",\"\",\"STUDENT\",25,01-MAR-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"KELLY, RAY\",\"HUNTSVILLE\",\"AL\",\"35801\",\"ARKTECH\",\"RETIRED\",25,25-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"CINGEL, KEITH\",\"SEVERN\",\"AL\",\"20999\",\"SANTA CLAUS\",\"SNOWMAN\",50,17-MAY-07,\"\",\"\",\"\",\"SA17A\",305408\nC00420224,\"P80002983\",\"Cox, John H\",\"DUNAWAY, JONATHON\",\"DEATSVILLE\",\"AL\",\"36022\",\"CSC\",\"TECHNICAL MANAGER\",10,18-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"TERRY, R.S. MR. SR.\",\"SHEFFIELD\",\"AL\",\"35660\",\"RETIRED\",\"\",25,18-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"CANADY, DALE\",\"PHOENIX\",\"AZ\",\"85051\",\"RETIRED\",\"\",25,11-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"LORENZ, DWIGHT\",\"SUN CITY\",\"AZ\",\"85351\",\"NONE\",\"RETIRED\",20,12-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"STEWART, MICHAEL\",\"CHANDLER\",\"AZ\",\"85224\",\"DYNAMIC ENERGY\",\"TECHNICIAN\",5,11-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"ROSENTHAL, ARNOLD\",\"CAREFREE\",\"AZ\",\"85277\",\"RETIRED\",\"\",10,11-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"VADNAIS, DOROTHY\",\"SAN DIEGO\",\"CA\",\"92116\",\"\",\"RETIRED\",10,10-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"BROWN, CHARLENE\",\"EAGLE RIVER\",\"AK\",\"99577\",\"\",\"STUDENT\",25,01-MAR-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"KELLY, RAY\",\"HUNTSVILLE\",\"AL\",\"35801\",\"ARKTECH\",\"RETIRED\",25,25-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"CINGEL, KEITH\",\"SEVERN\",\"AL\",\"20999\",\"SANTA CLAUS\",\"SNOWMAN\",50,17-MAY-07,\"\",\"\",\"\",\"SA17A\",305408\nC00420224,\"P80002983\",\"Cox, John H\",\"DUNAWAY, JONATHON\",\"DEATSVILLE\",\"AL\",\"36022\",\"CSC\",\"TECHNICAL MANAGER\",10,18-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"TERRY, R.S. MR. SR.\",\"SHEFFIELD\",\"AL\",\"35660\",\"RETIRED\",\"\",25,18-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"CANADY, DALE\",\"PHOENIX\",\"AZ\",\"85051\",\"RETIRED\",\"\",25,11-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"LORENZ, DWIGHT\",\"SUN CITY\",\"AZ\",\"85351\",\"NONE\",\"RETIRED\",20,12-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"STEWART, MICHAEL\",\"CHANDLER\",\"AZ\",\"85224\",\"DYNAMIC ENERGY\",\"TECHNICIAN\",5,11-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"ROSENTHAL, ARNOLD\",\"CAREFREE\",\"AZ\",\"85277\",\"RETIRED\",\"\",10,11-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"VADNAIS, DOROTHY\",\"SAN DIEGO\",\"CA\",\"92116\",\"\",\"RETIRED\",10,10-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"BROWN, CHARLENE\",\"EAGLE RIVER\",\"AK\",\"99577\",\"\",\"STUDENT\",25,01-MAR-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"KELLY, RAY\",\"HUNTSVILLE\",\"AL\",\"35801\",\"ARKTECH\",\"RETIRED\",25,25-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"CINGEL, KEITH\",\"SEVERN\",\"AL\",\"20999\",\"SANTA CLAUS\",\"SNOWMAN\",50,17-MAY-07,\"\",\"\",\"\",\"SA17A\",305408\nC00420224,\"P80002983\",\"Cox, John H\",\"DUNAWAY, JONATHON\",\"DEATSVILLE\",\"AL\",\"36022\",\"CSC\",\"TECHNICAL MANAGER\",10,18-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"TERRY, R.S. MR. SR.\",\"SHEFFIELD\",\"AL\",\"35660\",\"RETIRED\",\"\",25,18-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"CANADY, DALE\",\"PHOENIX\",\"AZ\",\"85051\",\"RETIRED\",\"\",25,11-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"LORENZ, DWIGHT\",\"SUN CITY\",\"AZ\",\"85351\",\"NONE\",\"RETIRED\",20,12-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"STEWART, MICHAEL\",\"CHANDLER\",\"AZ\",\"85224\",\"DYNAMIC ENERGY\",\"TECHNICIAN\",5,11-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"ROSENTHAL, ARNOLD\",\"CAREFREE\",\"AZ\",\"85277\",\"RETIRED\",\"\",10,11-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"VADNAIS, DOROTHY\",\"SAN DIEGO\",\"CA\",\"92116\",\"\",\"RETIRED\",10,10-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"BROWN, CHARLENE\",\"EAGLE RIVER\",\"AK\",\"99577\",\"\",\"STUDENT\",25,01-MAR-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"KELLY, RAY\",\"HUNTSVILLE\",\"AL\",\"35801\",\"ARKTECH\",\"RETIRED\",25,25-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"CINGEL, KEITH\",\"SEVERN\",\"AL\",\"20999\",\"SANTA CLAUS\",\"SNOWMAN\",50,17-MAY-07,\"\",\"\",\"\",\"SA17A\",305408\nC00420224,\"P80002983\",\"Cox, John H\",\"DUNAWAY, JONATHON\",\"DEATSVILLE\",\"AL\",\"36022\",\"CSC\",\"TECHNICAL MANAGER\",10,18-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"TERRY, R.S. MR. SR.\",\"SHEFFIELD\",\"AL\",\"35660\",\"RETIRED\",\"\",25,18-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"CANADY, DALE\",\"PHOENIX\",\"AZ\",\"85051\",\"RETIRED\",\"\",25,11-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"LORENZ, DWIGHT\",\"SUN CITY\",\"AZ\",\"85351\",\"NONE\",\"RETIRED\",20,12-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"STEWART, MICHAEL\",\"CHANDLER\",\"AZ\",\"85224\",\"DYNAMIC ENERGY\",\"TECHNICIAN\",5,11-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"ROSENTHAL, ARNOLD\",\"CAREFREE\",\"AZ\",\"85277\",\"RETIRED\",\"\",10,11-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"VADNAIS, DOROTHY\",\"SAN DIEGO\",\"CA\",\"92116\",\"\",\"RETIRED\",10,10-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"BROWN, CHARLENE\",\"EAGLE RIVER\",\"AK\",\"99577\",\"\",\"STUDENT\",25,01-MAR-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"KELLY, RAY\",\"HUNTSVILLE\",\"AL\",\"35801\",\"ARKTECH\",\"RETIRED\",25,25-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"CINGEL, KEITH\",\"SEVERN\",\"AL\",\"20999\",\"SANTA CLAUS\",\"SNOWMAN\",50,17-MAY-07,\"\",\"\",\"\",\"SA17A\",305408\nC00420224,\"P80002983\",\"Cox, John H\",\"DUNAWAY, JONATHON\",\"DEATSVILLE\",\"AL\",\"36022\",\"CSC\",\"TECHNICAL MANAGER\",10,18-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"TERRY, R.S. MR. SR.\",\"SHEFFIELD\",\"AL\",\"35660\",\"RETIRED\",\"\",25,18-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"CANADY, DALE\",\"PHOENIX\",\"AZ\",\"85051\",\"RETIRED\",\"\",25,11-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"LORENZ, DWIGHT\",\"SUN CITY\",\"AZ\",\"85351\",\"NONE\",\"RETIRED\",20,12-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"STEWART, MICHAEL\",\"CHANDLER\",\"AZ\",\"85224\",\"DYNAMIC ENERGY\",\"TECHNICIAN\",5,11-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"ROSENTHAL, ARNOLD\",\"CAREFREE\",\"AZ\",\"85277\",\"RETIRED\",\"\",10,11-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"VADNAIS, DOROTHY\",\"SAN DIEGO\",\"CA\",\"92116\",\"\",\"RETIRED\",10,10-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nRaw Data\nCleaned, Structured\nData\nExploratory Data\nAnalysis\nVerify Hunches (stats)\nData Product\n\nC00420224,\"P80002983\",\"Cox, John H\",\"BROWN, CHARLENE\",\"EAGLE RIVER\",\"AK\",\"99577\",\"\",\"STUDENT\",25,01-MAR-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"KELLY, RAY\",\"HUNTSVILLE\",\"AL\",\"35801\",\"ARKTECH\",\"RETIRED\",25,25-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"CINGEL, KEITH\",\"SEVERN\",\"AL\",\"20999\",\"SANTA CLAUS\",\"SNOWMAN\",50,17-MAY-07,\"\",\"\",\"\",\"SA17A\",305408\nC00420224,\"P80002983\",\"Cox, John H\",\"DUNAWAY, JONATHON\",\"DEATSVILLE\",\"AL\",\"36022\",\"CSC\",\"TECHNICAL MANAGER\",10,18-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"TERRY, R.S. MR. SR.\",\"SHEFFIELD\",\"AL\",\"35660\",\"RETIRED\",\"\",25,18-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"CANADY, DALE\",\"PHOENIX\",\"AZ\",\"85051\",\"RETIRED\",\"\",25,11-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"LORENZ, DWIGHT\",\"SUN CITY\",\"AZ\",\"85351\",\"NONE\",\"RETIRED\",20,12-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"STEWART, MICHAEL\",\"CHANDLER\",\"AZ\",\"85224\",\"DYNAMIC ENERGY\",\"TECHNICIAN\",5,11-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"ROSENTHAL, ARNOLD\",\"CAREFREE\",\"AZ\",\"85277\",\"RETIRED\",\"\",10,11-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"VADNAIS, DOROTHY\",\"SAN DIEGO\",\"CA\",\"92116\",\"\",\"RETIRED\",10,10-JAN-\n07,\"\",\"\",\"\",\"SA17A\",288757C00420224,\"P80002983\",\"Cox, John H\",\"BROWN, CHARLENE\",\"EAGLE RIVER\",\"AK\",\"99577\",\"\",\"STUDENT\",25,01-MAR-\n07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"KELLY, RAY\",\"HUNTSVILLE\",\"AL\",\"35801\",\"ARKTECH\",\"RETIRED\",25,25-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"CINGEL, KEITH\",\"SEVERN\",\"AL\",\"20999\",\"SANTA CLAUS\",\"SNOWMAN\",50,17-MAY-07,\"\",\"\",\"\",\"SA17A\",305408\nC00420224,\"P80002983\",\"Cox, John H\",\"DUNAWAY, JONATHON\",\"DEATSVILLE\",\"AL\",\"36022\",\"CSC\",\"TECHNICAL MANAGER\",10,18-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"TERRY, R.S. MR. SR.\",\"SHEFFIELD\",\"AL\",\"35660\",\"RETIRED\",\"\",25,18-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"CANADY, DALE\",\"PHOENIX\",\"AZ\",\"85051\",\"RETIRED\",\"\",25,11-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"LORENZ, DWIGHT\",\"SUN CITY\",\"AZ\",\"85351\",\"NONE\",\"RETIRED\",20,12-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"STEWART, MICHAEL\",\"CHANDLER\",\"AZ\",\"85224\",\"DYNAMIC ENERGY\",\"TECHNICIAN\",5,11-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"ROSENTHAL, ARNOLD\",\"CAREFREE\",\"AZ\",\"85277\",\"RETIRED\",\"\",10,11-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"VADNAIS, DOROTHY\",\"SAN DIEGO\",\"CA\",\"92116\",\"\",\"RETIRED\",10,10-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"BROWN, CHARLENE\",\"EAGLE RIVER\",\"AK\",\"99577\",\"\",\"STUDENT\",25,01-MAR-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"KELLY, RAY\",\"HUNTSVILLE\",\"AL\",\"35801\",\"ARKTECH\",\"RETIRED\",25,25-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"CINGEL, KEITH\",\"SEVERN\",\"AL\",\"20999\",\"SANTA CLAUS\",\"SNOWMAN\",50,17-MAY-07,\"\",\"\",\"\",\"SA17A\",305408\nC00420224,\"P80002983\",\"Cox, John H\",\"DUNAWAY, JONATHON\",\"DEATSVILLE\",\"AL\",\"36022\",\"CSC\",\"TECHNICAL MANAGER\",10,18-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"TERRY, R.S. MR. SR.\",\"SHEFFIELD\",\"AL\",\"35660\",\"RETIRED\",\"\",25,18-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"CANADY, DALE\",\"PHOENIX\",\"AZ\",\"85051\",\"RETIRED\",\"\",25,11-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"LORENZ, DWIGHT\",\"SUN CITY\",\"AZ\",\"85351\",\"NONE\",\"RETIRED\",20,12-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"STEWART, MICHAEL\",\"CHANDLER\",\"AZ\",\"85224\",\"DYNAMIC ENERGY\",\"TECHNICIAN\",5,11-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"ROSENTHAL, ARNOLD\",\"CAREFREE\",\"AZ\",\"85277\",\"RETIRED\",\"\",10,11-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"VADNAIS, DOROTHY\",\"SAN DIEGO\",\"CA\",\"92116\",\"\",\"RETIRED\",10,10-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"BROWN, CHARLENE\",\"EAGLE RIVER\",\"AK\",\"99577\",\"\",\"STUDENT\",25,01-MAR-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"KELLY, RAY\",\"HUNTSVILLE\",\"AL\",\"35801\",\"ARKTECH\",\"RETIRED\",25,25-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"CINGEL, KEITH\",\"SEVERN\",\"AL\",\"20999\",\"SANTA CLAUS\",\"SNOWMAN\",50,17-MAY-07,\"\",\"\",\"\",\"SA17A\",305408\nC00420224,\"P80002983\",\"Cox, John H\",\"DUNAWAY, JONATHON\",\"DEATSVILLE\",\"AL\",\"36022\",\"CSC\",\"TECHNICAL MANAGER\",10,18-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"TERRY, R.S. MR. SR.\",\"SHEFFIELD\",\"AL\",\"35660\",\"RETIRED\",\"\",25,18-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"CANADY, DALE\",\"PHOENIX\",\"AZ\",\"85051\",\"RETIRED\",\"\",25,11-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"LORENZ, DWIGHT\",\"SUN CITY\",\"AZ\",\"85351\",\"NONE\",\"RETIRED\",20,12-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"STEWART, MICHAEL\",\"CHANDLER\",\"AZ\",\"85224\",\"DYNAMIC ENERGY\",\"TECHNICIAN\",5,11-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"ROSENTHAL, ARNOLD\",\"CAREFREE\",\"AZ\",\"85277\",\"RETIRED\",\"\",10,11-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"VADNAIS, DOROTHY\",\"SAN DIEGO\",\"CA\",\"92116\",\"\",\"RETIRED\",10,10-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"BROWN, CHARLENE\",\"EAGLE RIVER\",\"AK\",\"99577\",\"\",\"STUDENT\",25,01-MAR-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"KELLY, RAY\",\"HUNTSVILLE\",\"AL\",\"35801\",\"ARKTECH\",\"RETIRED\",25,25-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"CINGEL, KEITH\",\"SEVERN\",\"AL\",\"20999\",\"SANTA CLAUS\",\"SNOWMAN\",50,17-MAY-07,\"\",\"\",\"\",\"SA17A\",305408\nC00420224,\"P80002983\",\"Cox, John H\",\"DUNAWAY, JONATHON\",\"DEATSVILLE\",\"AL\",\"36022\",\"CSC\",\"TECHNICAL MANAGER\",10,18-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"TERRY, R.S. MR. SR.\",\"SHEFFIELD\",\"AL\",\"35660\",\"RETIRED\",\"\",25,18-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"CANADY, DALE\",\"PHOENIX\",\"AZ\",\"85051\",\"RETIRED\",\"\",25,11-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"LORENZ, DWIGHT\",\"SUN CITY\",\"AZ\",\"85351\",\"NONE\",\"RETIRED\",20,12-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"STEWART, MICHAEL\",\"CHANDLER\",\"AZ\",\"85224\",\"DYNAMIC ENERGY\",\"TECHNICIAN\",5,11-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"ROSENTHAL, ARNOLD\",\"CAREFREE\",\"AZ\",\"85277\",\"RETIRED\",\"\",10,11-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"VADNAIS, DOROTHY\",\"SAN DIEGO\",\"CA\",\"92116\",\"\",\"RETIRED\",10,10-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"BROWN, CHARLENE\",\"EAGLE RIVER\",\"AK\",\"99577\",\"\",\"STUDENT\",25,01-MAR-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"KELLY, RAY\",\"HUNTSVILLE\",\"AL\",\"35801\",\"ARKTECH\",\"RETIRED\",25,25-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"CINGEL, KEITH\",\"SEVERN\",\"AL\",\"20999\",\"SANTA CLAUS\",\"SNOWMAN\",50,17-MAY-07,\"\",\"\",\"\",\"SA17A\",305408\nC00420224,\"P80002983\",\"Cox, John H\",\"DUNAWAY, JONATHON\",\"DEATSVILLE\",\"AL\",\"36022\",\"CSC\",\"TECHNICAL MANAGER\",10,18-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"TERRY, R.S. MR. SR.\",\"SHEFFIELD\",\"AL\",\"35660\",\"RETIRED\",\"\",25,18-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"CANADY, DALE\",\"PHOENIX\",\"AZ\",\"85051\",\"RETIRED\",\"\",25,11-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"LORENZ, DWIGHT\",\"SUN CITY\",\"AZ\",\"85351\",\"NONE\",\"RETIRED\",20,12-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"STEWART, MICHAEL\",\"CHANDLER\",\"AZ\",\"85224\",\"DYNAMIC ENERGY\",\"TECHNICIAN\",5,11-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"ROSENTHAL, ARNOLD\",\"CAREFREE\",\"AZ\",\"85277\",\"RETIRED\",\"\",10,11-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"VADNAIS, DOROTHY\",\"SAN DIEGO\",\"CA\",\"92116\",\"\",\"RETIRED\",10,10-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"BROWN, CHARLENE\",\"EAGLE RIVER\",\"AK\",\"99577\",\"\",\"STUDENT\",25,01-MAR-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"KELLY, RAY\",\"HUNTSVILLE\",\"AL\",\"35801\",\"ARKTECH\",\"RETIRED\",25,25-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"CINGEL, KEITH\",\"SEVERN\",\"AL\",\"20999\",\"SANTA CLAUS\",\"SNOWMAN\",50,17-MAY-07,\"\",\"\",\"\",\"SA17A\",305408\nC00420224,\"P80002983\",\"Cox, John H\",\"DUNAWAY, JONATHON\",\"DEATSVILLE\",\"AL\",\"36022\",\"CSC\",\"TECHNICAL MANAGER\",10,18-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"TERRY, R.S. MR. SR.\",\"SHEFFIELD\",\"AL\",\"35660\",\"RETIRED\",\"\",25,18-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"CANADY, DALE\",\"PHOENIX\",\"AZ\",\"85051\",\"RETIRED\",\"\",25,11-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"LORENZ, DWIGHT\",\"SUN CITY\",\"AZ\",\"85351\",\"NONE\",\"RETIRED\",20,12-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"STEWART, MICHAEL\",\"CHANDLER\",\"AZ\",\"85224\",\"DYNAMIC ENERGY\",\"TECHNICIAN\",5,11-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"ROSENTHAL, ARNOLD\",\"CAREFREE\",\"AZ\",\"85277\",\"RETIRED\",\"\",10,11-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"VADNAIS, DOROTHY\",\"SAN DIEGO\",\"CA\",\"92116\",\"\",\"RETIRED\",10,10-JAN-07,\"\",\"\",\"\",\"SA17A\",288757\nRaw Data\nCleaned, Structured\nData\nExploratory Data\nAnalysis\nVerify Hunches (stats)\nData Product\n\"SANTA CLAUS\",\"SNOWMAN\",\n\nRaw Data\nCleaned, Structured\nData\nExploratory Data\nAnalysis\nVerify Hunches (stats)\nData Product\n\nT-test\n\nCreate a model\n(linear regression)\nRaw Data\nCleaned, Structured\nData\nExploratory Data\nAnalysis\nVerify Hunches (stats)\nData Product\n\nT-test\n\nCreate a model\n(linear regression)\nSignificance\nRaw Data\nCleaned, Structured\nData\nExploratory Data\nAnalysis\nVerify Hunches (stats)\nData Product\n\nT-test\n\nCreate a model\n(linear regression)\nSignificance\nRaw Data\nCleaned, Structured\nData\nExploratory Data\nAnalysis\nVerify Hunches (stats)\nData Product\n\nRaw Data\nCleaned, Structured\nData\nExploratory Data\nAnalysis\nVerify Hunches (stats)\nData Product\n\nRaw Data\nCleaned, Structured\nData\nExploratory Data\nAnalysis\nVerify Hunches (stats)\nData Product\n(c) New York Times, FlowingData. All rights reserved. This content is excluded from our\nCreative Commons license. For more information, see http://ocw.mit.edu/fairuse.\n\nRaw Data\nCleaned, Structured\nData\nExploratory Data\nAnalysis\nVerify Hunches (stats)\nData Product\nImages removed due to copyright restrictions: suggested\nmovies on Netflix, Facebook search, LinkedIn logo.\n\nRaw Data\nCleaned, Structured\nData\nExploratory Data\nAnalysis\nVerify Hunches (stats)\nData Product\nContext\n\nYesterday and today, 3 companies kindly\ncame to talk about their technologies. I\npersonally found it awesome as well\nbecause it gives context to the stuff we've\nbeen teaching and learning.\n\nRaw Data\nCleaned, Structured\nData\nExploratory Data\nAnalysis\nVerify Hunches (stats)\nData Product\nSimilar\n\nWhat struck me was how similar their\nprocesses are to what we've done in\nthis class, but on a different dataset,\nor different scale, etc.\n\nPipeline\n- Crazy raw data\n- Cleaned, structured data\n- Exploratory data analysis\n- Verify Hunches\n- Data Product (tm hammer@cloudera)\n\n- Different companies fit into different subsets of the\npipeline\n- locu is the first segment (100% accuracy)\n- visible measures is full pipeline, at huge scale\n- Hadapt makes exploratory and verifying faster\n\nRaw Data\nCleaned, Structured\nData\nExploratory Data\nAnalysis\nVerify Hunches (stats)\nData Product\nhttp://locu.com/\n\n[logo removed due to copyright\nrestrictions]\n\nRaw Data\nCleaned, Structured\nData\nExploratory Data\nAnalysis\nVerify Hunches (stats)\nData Product\nhttp://www.visiblemeasures\n.com/\n\nGoogle analytics.\nTakes structured apache logs (access logs) and\nanalyzes them to see how many people are viewing\na particular internet video ad.\n\nRaw Data\nCleaned, Structured\nData\nExploratory Data\nAnalysis\nVerify Hunches (stats)\nData Product\nhttp://www.vertica.com/\n\n[logo removed due to copyright restrictions]\n\nRaw Data\nCleaned, Structured\nData\nExploratory Data\nAnalysis\nVerify Hunches (stats)\nData Product\nhttp://www.hadapt.com/\n\nHadapt doesn't actively perform data analysis etc.\nInstead, they create platforms that help other\ncompanies (like visiblemeasures) perform their\ndata analysis faster.\n\nYou'll find companies focused on every part of this\npipeline. It's what makes companies \"smarter\".\n\n- Visible Measures\n- Locu\n\n- Gave us context about what companies that\nare centered around data analytics are doing\n- A lot of them are very similar to what we did,\nat a huge scale.\n\nRaw Data\nClean\nData\nExplore\nVerify\nData\nProduct\n- Getting data\n- Visualization\n- Statistics\n- Machine Learning\n- Graph Analysis\n- Text Analysis\n- Databases\n- \"Big Data\"\n\nGetting Data\n- Surveys\n- Web Crawling/Scraping\n- https://scraperwiki.com\n- http://nutch.apache.org\n- Sensors\nRaw Data\nClean\nData\nExplore\nVerify\nData\nProduct\n\nVisualizations\n- Interactive Visualizations\n- HTML5/CSS/JavaScript\n- Tools\n- processingjs, d3, prefuse\n- Blogs\n- http://flowingdata.com\n- http://infosthetics.com\n\n- Harvard http://cs171.org\n- MIT 6.831\n\nRaw Data\nClean\nData\nExplore\nVerify\nData\nProduct\n\nStatistics\n- Are they different?\n- T-Tests, ANOVA\n- Bayesian Statistics\n- Correlation\n- Regressions\n- Linear\n- Non-Linear\n\n- 16.470j\n- http://statistics.mit.edu\nRaw Data\nClean\nData\nExplore\nVerify\nData\nProduct\n\nMachine Learning\n- Classification\n- Clustering\n\n- http://www.ml-class.org\n- MIT 6.867\n- Python scikit-learn (sklearn)\nRaw Data\nClean\nData\nExplore\nVerify\nData\nProduct\n\nGraph Analysis\nRaw Data\nClean\nData\nExplore\nVerify\nData\nProduct\n- Examples:\n- web pages, friend graph, twitter\n- Metrics\n- Centrality\n- Cohesion\n- \"Importance\" (page rank)\n\n- Social Network Analysis\n- Web data mining MIT Course\n- Sep Kamvar Fall 2012\n-\nhttp://www.stats.ox.ac.uk/~snijders/sna_course.htm\n\nText Analysis\nRaw Data\nClean\nData\nExplore\nVerify\nData\nProduct\n- Natural Language Processing\n- Parsing sentences\n- Extracting the grammar/structure\n\n- Similarity measures\n- Cosine Similarity\n- Jaccard\n\n- Identifying Entities\n- Opencalais\n\n- MIT 6.864/6.863J\n\nDatabases\nRaw Data\nClean\nData\nExplore\nVerify\nData\nProduct\n- SQL Implements a lot of what we did\n- Filtering\n- Joining\n- Grouping\n- Summarizing\n- Specialized system to do this\n- SQL databases, Hive, Pig\n\n- MIT 6.830\n- http://db-class.org\n\n\"Big Data\"\nRaw Data\nClean\nData\nExplore\nVerify\nData\nProduct\n- How to process on 1000+ machines?\n- Problems\n- Managing\n- Machines fail all the time\n- Network problems\n- Data out-of-sync (consistency)\n\n- Distributed Systems\n- MIT 6.824 (6.830 a bit)\n\nBerkeley Also Has a Class!\nhttp://datascienc.es\n\nThank You!\ngit pull\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\nResource: How to Process, Analyze and Visualize Data\nAdam Marcus and Eugene Wu\nThe following may not correspond to a particular course on MIT OpenCourseWare, but has been\nprovided by the author as an individual learning resource.\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
        },
        {
          "category": "Syllabus",
          "title": "Day 0 Syllabus and Setup",
          "type": "PDF",
          "source_url": "https://ocw.mit.edu/courses/res-6-009-how-to-process-analyze-and-visualize-data-january-iap-2012/b34a71a318b78cae5720e5f6625a75b1_MITRES_6_009IAP12_setup.pdf",
          "content": "Syllabus and Setup\nWelcome!\nThis class is an introduction to data cleaning, analysis and visualization. We will walk you through as\nwe analyze real world datasets. Each day, we will spend the first 30 minutes introducing the day's\nconcepts, and the rest of the class will be exercises. We have written a daily walkthrough that you will\nread and program through in class, and we will be available to help.\nThis is our first time teaching this course, and we'll be learning as much as you. Don't hesitate to ask\nus to change something or improve on something. We'll be grateful.\nPrereqs\nWe assume you have a working knowledge of python (6.01) and are willing to write code. Most of the\ncode you interact with will come with an example that you can modify. Hopefully little specialized\ncode will be generated except for programs you're inspired to write!\nWhat we will teach\nWe will teach the basics of data analysis through concrete examples. All of your programming will be\nwritten in python. The schedule is as follows:\n● Day 0 (today): setup\n● Day 1: An end-to-end example getting you from a dataset found online to several plots of\ncampaign contributions.\n● Day 2: Lots of visualization examples, and practice going from data to chart.\n● Day 3: Statistics basics, including T-Tests, Linear Regression, and statistical significance.\nWe'll use campaign finance and per-county health rankings.\n● Day 4: Text processing on a large text corpus (the Enron email dataset) using tf-idf and cosine\nsimilarity.\n● Day 5: Scaling up to process large datasets using Hadoop/MapReduce on a larger copy of the\nEnron dataset.\n● Day 6: You tell us! Get into groups or work on your own to analyze a dataset of your choosing,\n\nand tell us a story!\nWhat we will not teach\n● R. R is a wonderful data analysis, statistics, and plotting framework. We will not be using it\nbecause we can achieve all of our objectives in Python, and more MIT undergraduates know\nPython.\n● Visualization using browser technology (canvas, svg, d3, etc) or in non python languages\n(Processing). These tools are very interesting, and lots of visualizations on the web use these\ntools (e.g., nytimes visualizations), however they are out of the scope of this class. We'll teach\nyou how to visualize data in static charts. If this is an area of interest for you, the next step will\nbe to build interactive visualizations that the world can explore, and we can point you in the\nright direction with these.\nProgramming Environment (Important!)\nBefore the class, please set up the environment. You will need to install some software, packages,\nand download some datasets to get started.\nWe assume that you are developing in a unix-like environment and are familiar with the common\ncommands (e.g., less, man). If you are a windows user, we assume you are using cygwin but are on\nyour own.\nTools and Libraries\nIn this class, you will need to install a number of tools. The major ones are:\n● python 2.7\nH Python is usually installed in Mac OSX and major unix distributions. Type python --\nversion to make sure it is the right version\n● easy_install\nH python package manager.\n● pip\nH Makes installing python packages really easy. Requires easy_install.\nH Either install it by typing sudo easy_install pip or download the tar.gz file at the\n\nlink above, untar it, go into the newly created directory, and type sudo python setup.\npy install.\n● git\nH git is a version control system. Using it, you can check out our code and examples.\nH If everything is working, check the dataiap sourcecode into a directory called dataiap\nusing git clone git://github.com/dataiap/dataiap.git dataiap\nH We'll be updating the repository periodically. To get the latest copy, go to the dataiap\ndirectory and type git pull.\nWe will also require a number of python modules:\n● numpy 1.6.x: numerical processing module.\nH PIP users can type sudo pip install numpy\n● scipy 0.10: scientific computing module.\nH Ubuntu users can type sudo apt-get install python-scipy\nH PIP users can type sudo pip install scipy\nH Even if PIP works, at least on MacOS you might have to install Fortran. We strongly\nrecommend reading and following the installation instructions.\nH Unfortunately, scipy installation might not work from PIP, and you may have to compile\nit from source (see \"Obtaining and Building NumPy and SciPy\"). Try something akin to\n■ git clone https://github.com/scipy/scipy.git\n■ cd scipy\n■ python setup.py build\n■ python setup.py install\n● matplotlib 1.1.0\nH PIP users can type sudo pip install matplotlib\nH Note: If compiling from source, matplot lib requires a number of other libraries: (libpng,\nfreetype 2)\nH Some MacOS users might run into issues and should just download the binary.\n● dateutil\nH PIP users can type sudo pip install python-dateutil\n● pyparsing\nH PIP users can type sudo pip install pyparsing\n● mrjob: This is a MapReduce package that we will use it in day 5.\n\nH PIP users can type sudo pip install mrjob\nH If compiling from source, it requires boto (try sudo pip install boto).\nFor convenience, Enthought provides numpy, scipy, matplotlib in a single installable package. Many\nstudents that had trouble installing these modules separately were able to install Enthought.\ndataiap/ Directory Structure\nThe repository contains the contents of the full course. We will be using\n● dayX/: files containing the lecture for day X\n● datasets/: the datasets we will be using should live here\n● resources/: contains python scripts that you will eventually run\nH util/: contains python modules we have written that you will use in this course.\nH inst/: instructor python files. Used to setup and test the labs. Please don't view during\nthe course.\nDatasets\nWe will be working with several datasets in this course. Most of them have been added to the git\nrepository.\nThe presidential contributions dataset is fairly large. We will use it on the first day, so please\ndownload it from ftp://ftp.fec.gov/FEC/Presidential_Map/2008/P00000001/P00000001-ALL.zip.\nThe datasets we will use are\n● 2008 Presidential Campaign Contributions\nH The linked file contains all of the 2008 campaign contributions to each presidential\ncandidate. You can look at the 2012 campaign for various primary candidates as well,\nbut we'll work with 2008 since it's complete.\nH unzip into dataiap/datasets/pres_campaign/\n● 2011 County Health Rankings\nH The dataset contains per-county health and morbidity statistics.\nH The necessary data should already be uncompressed in dataiap/datasets/\ncounty_health_rankings/additional_measures_cleaned.csv\ndataiap/datasets/county_health_rankings/ypll.csv\n\n● The Enron email dataset\nH This is the complete set of emails on the enron email server that was released during\nthe scandal. Don't download the dataset as it's huge. We have included subsets of the\ndatasets in the git repository.\n■ dataiap/datasets/emails/kenneth.zip contains a subset of Kenneth Lay's\nemails that you will analyze in day 4.\n■ dataiap/datasets/emails/kenneth_json.zip contains a JSON-encoded\nsubset of Kenneth Lay's emails that you will analyze in day 5.\nH We will upload a JSON encoded version of the full dataset to amazon's S3.\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\nResource: How to Process, Analyze and Visualize Data\nAdam Marcus and Eugene Wu\nThe following may not correspond to a particular course on MIT OpenCourseWare, but has been\nprovided by the author as an individual learning resource.\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
        },
        {
          "category": "Resource",
          "title": "Day 1 Lab Handout",
          "type": "PDF",
          "source_url": "https://ocw.mit.edu/courses/res-6-009-how-to-process-analyze-and-visualize-data-january-iap-2012/0cf5cabdadcec52777c5f5020341a6c6_MITRES_6_009IAP12_lab1.pdf",
          "content": "Day 1: Let's play with some data!\nToday we will analyze the presidential campaign contributions dataset. We will go through the full process of downloading\na new dataset, the initial steps of understanding the data, visualizing it, coming up with hypotheses, and exploring\nthe dataset. Hopefully, you'll learn something new about presidential elections.\nA lot of other organizations have analyzed the data:\n● The FEC is the organization that published the dataset, but also offers basic summaries of the data.\n● Pitch Interactive has some pretty sweet visualizations of the data.\n● More from Pitch Interactive\n● Donor Occupations\nThese visualizations are beautiful but high level overviews, which tend to hide interesting details. We have our\nown questions, and we'll answer some of them today. We'll provide the commands and code to initially explore the\ndata, and ask you to further analyze the data in the exercises.\nFirst Steps\nWe assume that you have already downloaded the dataset. We need to first unzip the file and rename it to\nsomething meaningful:\n> unzip P00000001-ALL.zip\n> mv P00000001-ALL.txt donations.txt\nLets see how much data we are dealing with. The word count (wc) command will tell us the number of lines in this file:\n> wc -l donations.txt\nLet's take a quick look at the file. head prints the first N lines in a file.\n> head -n3 donations.txt cmte_id,cand_id,cand_nm,contbr_nm,contbr_city,contbr_st,\ncontbr_zip,contbr_employer,contbr_occupation,contb_receipt_amt,contb_receipt_dt,receipt_desc,\nmemo_cd,memo_text,form_tp,file_num\nC00420224,\"P80002983\",\"Cox, John H\",\"BROWN, CHARLENE\",\"EAGLE RIVER\",\"AK\",\"99577\",\"\",\"STUDENT\",25,01-\nMAR-07,\"\",\"\",\"\",\"SA17A\",288757\nC00420224,\"P80002983\",\"Cox, John H\",\"KELLY, RAY\",\"HUNTSVILLE\",\"AL\",\"35801\",\"ARKTECH\",\"RETIRED\",25,25-\nJAN-07,\"\",\"\",\"\",\"SA17A\",288757\nOn line 1 we see the names of each field in the file, and the data starts from line 2. It's in a format called CSV, or\ncomma-separated values, where each row contains a new set of field values separated by commas.\nIf we take a look at the file format description on the fec.gov website, it specifies that\nThe text file is comma delimited and uses double-quotation marks as the text qualifier.\n\nThe file contains information about the candidate, the donor's city, state, zip code, employer and occupation information,\nas well as the amount donated. In addition it contains the date of the donation,\nLet's write a script to read and print each donation's date, amount and candidate. Python comes with a csv module\nthat helps read CSV files.\nimport csv,sys,datetime\nreader = csv.DictReader(open(sys.argv[1], 'r'))\nfor row in reader:\nname = row['cand_nm']\ndatestr = row['contb_receipt_dt']\namount = row['contb_receipt_amt']\nprint ','.join([name, datestr, amount])\nDictReader assumes that the first line are the names of the fields, and creates a dictionary for each row of\nfieldname->value pairs. Copy the above code into a file (say exercise1.py) in the same directory as donations.\ntxt, and run python exercise1.py donations.txt. This will make donations.txt be the first argument to\nthe program (sys.argv[1]), which will be read and printed line by line. We'll only print the name, date, and amount of\nthe contribution for now.\nIntroducing matplotlib\nWe will be using matplotlib in the rest of the course, and work with it extensively in day 2. The following code is a\ncrash course on how to graph a line in matplotlib.\n# pyplot is the plotting module\nimport matplotlib.pyplot as plt\nimport random\n# generate the data\nxs = range(10) # 0...9\nys1 = range(10) # 0...9\nys2 = [random.randint(0, 20) for i in range(10)] # 10 random numbers from 0-19\n# create a 10-inch x 5-inch figure\nfig = plt.figure(figsize=(10,5))\n# draw a line graph\nplt.plot(xs, ys1, label='line 1')\nplt.plot(xs, ys2, label='line 2')\n# create the legend\nplt.legend(loc='upper center', ncol = 4)\n# finally, render and store the figure in an image\nplt.savefig('twolines.png', format='png')\n\nplt.plot() takes a list of x and a list of y values, and draws a line between every pair of (x,y) points. The line is drawn\non the most recently created figure.\nplt.legend() draws the legend in the figure. There are a bunch of other common chart objects like x-axis labels\nthat matplotlib supports.\nIn the final line, plt.savefig() saves the figure to a file called twolines.png in the directory we ran the script. Try it\nout! You should see something like\nSampling The Data\nThe dataset is quite large, and processing the full dataset can be pretty slow. It is often useful to sample the dataset and\ntry things out on the sample before doing a complete analysis of all of the data. The following is a script that samples\nthe donations dataset. It will print 1 out of every 1000 donations (or roughly 5000 total donations):\nimport sys\nwith file(sys.argv[1], 'r') as f:\ni = 0\nfor line in f:\nif i % 1000 == 0:\nprint line[:-1]\ni += 1\nThe line print line[:-1] prints the entire line except its last character to the screen. Why skip the last\ncharacter? Because each line ends in a carriage return, and print will add one for us. We don't want a space\nbetween each line!\nThis script will print every thousandth line of whatever file you pass in as an argument to the screen. To create a new\nfile, use the > standard output rediretor.\npython exercise3.py donations.txt > donations_sampled.txt\nWe will be analyzing Obama vs McCain data, so you can modify this code to create a file that only contains donations\nfor McCain and Obama. That way later analysis will run faster.\nPlotting The Data\n\nWe learned how to iterate and extract data from the dataset, and how to plot lines, so we will now combine the two to\nplot Obama's campaign contributions by date. We will compute the total amount of donations for each day, and\nuse matplotlib to create the charts.\nfrom collections import defaultdict\nimport matplotlib.pyplot as plt\nimport csv, sys, datetime\nreader = csv.DictReader(open(sys.argv[1], 'r'))\nobamadonations = defaultdict(lambda:0)\nfor row in reader:\nname = row['cand_nm']\ndatestr = row['contb_receipt_dt']\namount = float(row['contb_receipt_amt'])\ndate = datetime.datetime.strptime(datestr, '%d-%b-%y')\nif 'Obama' in name:\nobamadonations[date] += amount\n# dictionaries\nsorted_by_date = sorted(obamadonations.items(), key=lambda (key,val): key)\nxs,ys = zip(*sorted_by_date)\nplt.plot(xs, ys, label='line 1')\nplt.legend(loc='upper center', ncol = 4)\nplt.savefig('/tmp/test.png', format='png')\nA few notes about the code\n● defaultdict is a convenience dictionary. When we use a regular dictionary, it throws an error when we access a key\nthat doesn't exist:\n>>> d = {}\n>>> d['foo']\nTraceback (most recent call last):\nFile \"<stdin>\", line 1, in <module>\nKeyError: 'foo'\nWe provide defaultdict a function to call and return if the key doesn't exist. This is nice because we can assume\na default value. It is otherwise used as a normal python dictionary:\n>>> d = collections.defaultdict(lambda:0)\n>>> d['foo']\n>>> d['bar'] += 1\n● We parse the dates using the datetime module's strptime function. The string %d-%b-%y is called a date format string.\n● In the loop that reads the data, we record the total donation amount for each date.\n\n●Finally, we need to sort the data in obamadonations by the date (the key). sorted(l, key=f) returns a sorted copy of\nl and calls f to extract the key to use for comparison.\n●zip(*pairs) then unzips the list of pairs into two lists.\nYou should see something like this:\nGreat! It's interesting to see a spike in donations on August 2008 -- does it relate to the democratic party\nnomination speech he gave on August 28th? At this point a reporter may try to understand some of the spikes in the graph.\nBut wait! There's a really weird dip in his donations in the lower right corner. How does someone give\nnegative donations? The next part will investigate this further.\nThe Case of the Negative Donation\nThe first thing we should do is look at some of the data where the donation amount is negative and see if there's\nanything interesting. We can modify our existing code.\nimport csv,sys,datetime\nreader = csv.DictReader(open(sys.argv[1], 'r'))\nfor row in reader:\nname = row['cand_nm']\ndatestr = row['contb_receipt_dt']\namount = float(row['contb_receipt_amt'])\nif amount < 0:\nline = '\\t'.join(row.values())\nprint line\nNote that we cast amount into a float. The CSV module returns strings, so its our job to cast the data into the proper type.\nIf you scan through the output, you'll see data such as:\nC00430470 DARIEN RETIRED McCain, John S SA17A P80002801 068202003 VAN MUNCHING, LEO MR.\n\nJR. 02-AUG-07 CT X REATTRIBUTION TO SPOUSE 315387 REATTRIBUTION TO SPOUSE -2300\nC00430470 LOS ANGELES EXECUTIVE McCain, John S SA17A P80002801 900492125 A.E.G.\nLEIWEKE, TIMOTHY J. MR. 30-APR-08 CA X REFUND; REDESIGNATION REQUESTED 364146 REFUND;\nREDESIGNATION REQUESTED -2300\nLots of text, but \"REDESIGNATION TO GENERAL\" and \"REATTRIBUTION TO SPOUSE\" pop out as pretty strange.\nIt turns out that \"redesignations\" and \"reattributions\" are perfectly normal. If a donation by person A is excessive, the\npart that exceeds the limits can be \"reattributed\" to person B, meaning that person B donated the rest to the\ncampaign. Alternatively, the excess amount can be redesignated to another campaign in the same party. So a donation\nto Obama could be redesignated to a poor democrat in Nebraska.\nWhat's fishy is \"REATTRIBUTION TO SPOUSE.\" A quick google search gives a potential theory: that this is a tactic to\nhide campaign contributions from CEOs. A CEO will donate money, which will be reattributed (refunded) to the\nCEO's spouse. Then the humble spouse will turn around and donate the money to the candidate. In this way, it's hard for\na casual browser to notice that the candidate is backed by a company's CEOs.\nExercise 1: Plot Obama vs. McCain\nSo far we have only plotted Obama's campaign donations. Modify the script to also plot McCain's donations on the\nsame chart. It should look something like:\nWhoa whoa whoa, what was McCain up to March 2008? That's a whole lot of negative donations! We'll deal with that in\na few exercises.\nExercise 2: Cumulative Graphs\nWord on the street says that Obama's donations eclipsed McCain's donations. Let's see if that's true. Plot the\ncumulative donations (for a given date, plot the total donations up to that date). It should look something like:\n\nExercise 3: Understand \"Reattribution to Spouse\"\nLet's now filter the contributions to only see the cumulative \"reattribution to spouse\" donations. Which candidate do\nthe dark, hooded CEOs prefer?\nYou will need to find the name of the field that contains the \"reattribution\" text, and filter on that field. Depending on\nhow you filter it, you may get different results. Try out a few ways to see what happens.\nExercise 4: Pause and Think\nIt's time for a reality check. If you saw the graph in the previous exercise, you would think \"That's a lot of\nnegative donations! This candidate is really sneaky.\" Don't believe that just yet. Re-plot the ratio between\neach candidate's cumulative \"reattribution to spouse\" donations and that candidate's cumulative overall donations.\nThat changes our offenders quite a bit.\nKey Lesson: don't automatically trust charts in the wild. It's easy to make a chart say\nwhatever you want by selectively leaving out data!\nDone!\nCongrats! You are now a data sleuth. To recap the process we just went through we:\n1. Took a quick look at the data using head to get a sense of what we're dealing with. We also figured out the format of\nthe data. This is usually important, because the fields are otherwise somewhat non-sensical!\n2. Create a quick, initial visualization of some of the data fields and see if there are interesting trends.\n3. Listen to your hunch, and form a hypothesis around it\n4. Figure out why the trend exists\n5. Filter the dataset to the \"interesting portion\" and go to step 2\nTomorrow, we will dive deeper into matplotlib's visualization facilities, and further analyze the data using\ndifferent visualizations.\n\nRelated Datasets\nIf you are interested more campaign finance data, you can also download the campaign expense data from the\nsame website, if you click the \"expenditures\" tab in the right table.\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\nResource: How to Process, Analyze and Visualize Data\nAdam Marcus and Eugene Wu\nThe following may not correspond to a particular course on MIT OpenCourseWare, but has been\nprovided by the author as an individual learning resource.\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
        },
        {
          "category": "Resource",
          "title": "Day 2 Lab Handout",
          "type": "PDF",
          "source_url": "https://ocw.mit.edu/courses/res-6-009-how-to-process-analyze-and-visualize-data-january-iap-2012/30d5bbd6d59d6edac96d214ff773f274_MITRES_6_009IAP12_lab2.pdf",
          "content": "Overview\nToday, we will do more with\n.\nbar graphs\nline graphs\nbox plots (will be useful tomorrow)\nscatter plots\nchoropleth plots (map plots)\nWe will also learn to\ncreate figures with multiple sub-figures (called subplots)\ncustomize labels, colors, error bars etc.\nIn the exercises, we will use this to further visualize and analyze the campaign donations data.\nis quite powerful, and is intended to emulate matlab 's visualization facilities. We will give you a basic understanding of how plotting works, which\nshould be enough for a majority of the charts that you will want to create.\nPlotting Large Datasets\nThe dataset that we are working with is fairly large for a single computer, and it can take a long time to process the whole dataset, especially if you will process\nit repeatedly during the labs.\nUse the sampling technique we discussed in yesterday' s lab! You can change the sampling frequency (\nyesterday) to change the size of the sample. Use\nas a starting point, but realize the graphs we show are with sampling set to (all rows are included).\nIntroduction\nVisualizations are used to succinctly and visually describe different parts or different interpretations of your data. They give the reader, who is not necessarily an\nexpert in the dataset, an intuition of trends or relationships.\nI typically use visualizations for two purposes:\n1. Exploring: Quickly viewing the dataset to spot outliers and trends and form hypotheses.\n2. Storytelling: Illustrating a piece of data that I 've cleaned, and processed in order to make a point.\nFigure and Subplots\nThe package we will be using is\n. It provides a lot of shorthands and defaults (we used some of them yesterday when making line charts),\nbut today we will do things the \"right way\".\nA\nis the area that we will draw in. We can specify that it is 50 inches wide and 30 inches tall.\nimport matplotlib.pyplot as p\nlt\nfig = plt.figure(figsize=(50, 30))\nIt is common to create multiple subfigures or\nin a single figure.\ntells the figure to treat the area as a nrows\nx ncols grid, and return an Axes object that represents the i' th grid cell. You will then create your chart by calling methods on object. It helps me to think of an\nAxes object as a subplot.\nsubplot1 = fig.add_subplot(2, 3\n, 1)\nsubplot2 = fig.add_subplot(2, 3\n, 2)\nFor example, the above code creates a figure with the following layout. The black box is the area of the figure, while each blue box is a subplot in a 2x3 grid.\nThe number in a blue box is the subplot 's index.\n\nIt 's important to mention that\ndoes not actually create a grid, it just finds the area in an imaginary grid where a\nshould be and return an\nobject that represents the area. Thus it is possible to do draw on overlapping\n. Be careful!\nfig.add_subplot(2, 3, 1)\nfig.add_subplot(2, 1, 1)\nWhen you read matplotlib code on the internet, you will often see a shorthand for creating subplots when the subplot index, number of rows, and number of\ncolumns are all less than 10.\nreturns the z' th subplot in a x by y grid. So\nreturns the first subplot in a 2x3\ngrid.\nHow Drawing Works\nThe functions that we will be using to create charts are simply convenience functions that draw and scale points, lines, and polygons at x,y coordinates.\nWhenever we call a plotting method, it will return a set of objects that have been added to the subplot. For example, when we use the\nmethod to create\na bar graph,\nwill draw rectangles for each bar, and return a list of\nobjects so that we can manipulate them later (e.g., in an\nanimation).\nAs you use\n, keep in mind that:\nMany of the plotting functions will ask you to specify things similar to x,y coordinates / offsets.\nWhen you call a drawing function, it won' t rearrange the layout of what was drawn before. It simply draws the pixels on top of what has been drawn\nbefore.\nYou are ultimately adding points, lines and polygons on top of one another.\nLet 's get to drawing graphs! By the end of this tutorial, you will have experience creating bar charts, line charts, box plots, scatter plots, and choropleths (map\nplots). We will walk you through how to create a figure similar to\n\nThis figure creates subplots in a 3x2 grid, so let 's first setup the figure and generate two sets of data. Both sets have the same x values, but different y values.\nThink \"obama\" and \"mccain\" from yesterday :)\nimport matplotlib.pyplot as p\nlt\nimport random\nrandom.seed(0)\nfig = plt.figure(figsize=(50, 30))\nN = 100\nxs = range(N)\ny1 = [random.randint(0, 50) for i in xs]\ny2 = range(N)\nBar Plots documentation\nBar plots are typically used when you have categories of data that you want to compare. The\nfunction is:\nThe bar plot function either takes a single left and height value, which will be used to draw a rectangle whose left edge is at\n, and is\ntall:\nsubplot.bar(10, 30) # left edge at 10, and the height is 30.\nor you can pass a list of lefts values and a list of height values, and it will draw bars for each pair of left,height value. For example, the following will create three\nbars at the x coordinates 10, 20 and 30. The bars will be 5, 8, 2 units tall.\nsubplot.bar([10, 20, 30], [5, 8, 2])\nwill automatically scale the x and y axes so that the figure looks good. While the numbers along the x and y axes depend on the values of\nand\n, the sizes of the bars just depend on their relative values. That 's why we' ve used the word \"unit\" instead of \"pixel\".\nThe\nkeyword argument sets width of the bars It can be a single value, which sets the width of all of the bars, or a list that specifies the list of each bar.\nSet it relative to the differences of the\nvalues. For example, the code above sets each bar 10 units apart (\n), so I would set\n.\nThe\nkeyword argument specifies the bottom edge of the bars.\nsubplot.bar([10, 20, 30], [\n5, 8\n, 2], width=[5,5,5], b\nottom=[5, 10, 15])\n\nWhat if you want to draw 2 sets of bars? We simply call\nmultiple times. However, we would need to set the\nargument appropriately. If\nwe used the same\nlist for all the calls, then the bars would be drawn on top of each other.\nWhat if we want to shift the second set of bars by\nunits? One way to do this is to turn\ninto a\nlist. Numpy arrays let us perform math\noperations (e.g.,\n) on every element in the array, and\nmethods also accept\nlists. So\nadds\nto every\nelement in\n, which serves to shift the second set of bars to the right by\nunits. The following code should reproduce the first subplot in the figure.\nimport numpy as n\np\nleft = np.arange(len(xs))\nwidth = 0.25\nsubplot = fig.add_subplot(3,2,1)\nsubplot.bar(left, ys, width=width)\nsubplot.bar(left+width, ys2, w\nidth=width, bottom=ys)\nYou can further customize your bar charts using the following popular keyword arguments:\n: set color to a hex value (\"#ffffff\"), a common color name (\"green\"), or a shade of grey (\"0.8\").\n: the width of the bar 's border. set it to to remove the border.\n: set the color of the bar 's border.\n: give a set of bars a name. Later, we will teach you how to create legends that will display the labels.\nFor example, the following would draw a set of red bars:\nsubplot.bar(left, ys, color='red')\nLine Plots documentation\nLine plots are typically used when graphing data with two continuous dimensions. In addition, drawing the line implies that we can extrapolate values between\nadjacent points on the line. This is a key difference between line plots and scatter plots.\nThe\ncommand draws a line graph. It takes a list of x values and y values, and draws a line between every adjacent pair of points. Try it out using the data\nin the previous section.\nis a convenient shorthand for:\nsubplot.plot(xs1, ys1)\nsubplot.plot(xs2, ys2)\n...\nTo reproduce the line graph, we can simply write\nsubplot = fig.add_subplot(322)\nsubplot.plot(xs, y\ns1, xs, ys2)\nYou can also customize the lines using the keyword arguments:\n: same as\nfor bar graphs'\n: specify the marker to draw at each point. I commonly use\nor '\n. Set it to\nto not draw markers. The\ndocumentation has a full list of the available markers.\n: give a line a name. I usually call\nfor each line if I want to give each one a name.\nBox Plots documentation\nBoxplots are used to summarize and compare groups of numerical data. Each box summarizes a set of numbers and depicts 5 parameters:\n\nNOTE The words we are about to use might seem foreign to you. We will teach boxplots in depth tomorrow. We are just introducing how to draw box plots\ntoday, and will use them a whole lot tomorrow.\nThe smallest number\nThe lower quartile\nThe median\nThe upper quartile\nThe largest observation\nwill automatically compute these values, and also ignore numbers that it thinks are outliers. Don' t worry about when and why they are used\n-- we will discuss that tomorrow. Just know that one box summarizes a set of numbers.\nUnlike the other charts, you can't draw each box individually. The\nvariable is either a list of numbers, in which case it will compute and draw a single box:\nsubplot.boxplot(range(10))\nor\ncan be a list of lists. In which case, it will compute and draw a box for each list. The following code reproduces the box plot shown earlier. We create\nsets of data (\n,\n,\n) and create a box for each set.\nsubplot = fig.add_subplot(323)\nboxdata1 = [random.randint(0, 20) for i in xrange(10)]\nboxdata2 = [random.randint(20,40) for i in xrange(10)]\nboxdata3 = [random.randint(40,60) for i in xrange(10)]\ndata = [boxdata1, boxdata2, boxdata3]\nsubplot.boxplot(data)\nYou can customize your box plots with the following keyword arguments\n: By default, the boxes are drawn vertically. You can draw them horizontally by setting\n: Like\nin bar charts, this sets the width of each box\nScatter Plots documentation\nScatter plots are used to graph data along two continuous dimensions. In contrast to line graphs, each point is independent.\nThis method will draw a single point if you give it a single x,y pair\nsubplot.scatter(10, 10)\nor you can give it a list of x and a list of y values\nsubplot.scatter([0, 1, 2], [9, 3, 10])\nI 've included the commonly used keyword arguments\n: sets the size of each point to 20 pixels.\n: sets the color of each point to blue\n: each point will be drawn as a circle. The documentation lists large number of other markers\n: the alpha (transparency) value of the points. Between and .\n: sets the width of the line around the point to 4 pixels. I usually set it to .\nChoropleths/Maps\nCartography is a very involved process and there is an enormous number of ways to draw the 3D world in 2D. Unfortunately, we couldn' t find any native\nfacilities to easily draw US states and counties. It 's a bit of a pain to get it working, so we 've written some wrappers that you can call to draw\ncolored state and counties in a\n. We' ll describe the api, and briefly explain how we went about the process at the end.\nThe API is defined in\n. You can import the methods using the following code:\nimport sys\n# this a\ndds the resources/util/ folder i\nnto your p\nython path\n# you may need t\no edit t\nhis so t\nhat the path i\ns correct\nsys.path.append('resources/util/')\nfrom map_util import *\n: draws the county with the specified\ncounty code. Most datasets that contain per-county data\nwill include the fips code. If you don' t include a\n, we will randomly pick a nice shade of blue for you.\n\n: draws the state with the full state name as specified by the official USPS state names. If you\ndon' t include\n, we will pick a shade of blue for you.\n: retrieve the full state name from its abbreviation. The method is case insensitive, so\nis the same as\n.\nWe also included a list of all fips county codes and state names in\nand\n. We will use\nthem to reproduce the map charts.\nimport json\n# Map of C\nounties\n#\nsubplot = fig.add_subplot(325)\n# data i\ns a list o\nf strings that c\nontain f\nips values\ndata = json.load(file('../datasets/geo/id-counties.json'))\nfor fips i\nn data:\ndraw_county(subplot, fips)\n# Map of S\ntates\n#\nsubplot = fig.add_subplot(326)\ndata = json.load(file('../datasets/geo/id-states.json'))\nfor state in d\nata:\ndraw_state(subplot, state)\nThe files are in JSON format, so we call\n, which parses the files into python lists. The rest of the code simply iterates through the fips ' and\nstates, and draws them.\nThe gritty details (advanced)\nThe process of drawing maps yourself requires a number of steps:\n1. Download shape files. A shape file specifies the lat, lon positions that describe the border of an area (e.g., county, zip code, state).\n2. Parse the shape files. They come in all types of formats. We downloaded the shape files that D3 uses. It comes in the GeoJS format, which is nice\nbecause\ncan parse it for us.\nRemember how we mentioned that there lots of ways to draw the world in 2D. Our shape files use the Albers Equal Area Projection, which is also\nused by the US Census Bureau.\n3. Once we have the shapes, we need to draw polygons in the subplot. Thankfully\nfills in the region defined by the list of x,y\npoints.\n4. Our methods actually take any keyword argument that\naccepts. So take a look at its documentation if you want to further customize\nyour maps.\nCustomizing Subplots\nWe only touched a small part of what\ncan do. Here are some additional ways that you can customize subplots.\nKeyword Arguments\n: list of floats that specify x-axis error bars.\n: list of floats that specify y-axis error bars\nAdditional Charting Methods\n: plots a log-log line graph\n: plots the x-axis in log scale\n: plots the y-axis in log scale\n: draws a filled polygon with vertices at\n.\n: write\nat coordinates\n.\nSubplot Customization\n: clear everything that has been drawn on the subplot.\n- add a legend. You can specify where to place it using\n, and the number of columns in the\nlegend.\n: Set the subplot title.\n: Set the x-axis label\n: Draws x-axis tick marks at the points specified by\n. Otherwise\nwill draw reasonable tick marks.\n: Draw x-axis tick labels using the\nlist.\n: Sets the x-axis scaling.\nis\nor\n.\n\nFor Obama, that 's donations between\n. For McCain, that' s between\nExercise 2: More line graphs\n: Set the x-axis limits\n: Set the y-axis limits\nColor\nThis document provides a good summary of what to think about when choosing colors.\nColor Brewer 2 is a fantastic tool for picking colors for a map. We used it to pick the default colors for the choropleth library.\nExercise 1: Histograms\nWe will use yesterday 's Obama vs McCain dataset and visualize it using different chart types.\nMany people say that Obama was able to attract votes from \"the common man\", and had far more smaller contributions that his competitors. Let 's plot a\nhistogram of each candidate' s contribution amounts in $100 increments to see if this is the case. A histogram breaks a data range (donation amounts, in this\ncase) into fixed size buckets (100 in this case), and counts the number of items that fall into each bucket. Plot both candidates on the same graph. You' ll want to\nuse a bar chart.\nYou'll find that it 's difficult to read the previous chart because the donation amounts vary from -$1 Million to $8 Million, while the majority of the donations are\nless than 2000. One method is to ignore the outliers and focus on the majority of the data points. Let 's only print histogram buckets within 3 standard deviations\nof the overall average donation.\nNow create a cumulative line graph of Obama and McCain' s donations. The x-axis should be the donation amount, and the y-axis should be the cumulative\ndonations up to that amount.\nWe can see that even though Obama and McCain have some very large contributions, the vast majority of their total donations were from small contributors.\nAlso, not only did Obama get more donations, he also received larger donations.\nOnly after we' ve verified that the small donations were the major contributors, is it safe to zoom in on the graph! Use the ranges in the previous exercise.\n\nExercise 3: Scatter plots\nScatter plot of re-attribution by spouses for all candidates. Find all re-attribution by spouses data points for each candidate and plot them on a scatter plot. The\nx-axis is the donation date and the y-axis is the donation amount.\nIt seems to be concentrated in a small group of Republican candidates.\nAt this point, we' ve only scratched the surface of one dimension (reattributions) of this interesting dataset. You could continue our investigation by correlating\nprofessions with candidates, visualize donations by geography, or see if there are any more suspicious and interesting data points.\nFor example, which professions and companies are using this \"re-attribution to spouse\" trick?\nAlso, the 2012 campaign contributions are also available on the website, so you could use your analysis on the current election!\nExercise 4\nNow create a figure where each subgraph plots the total amount of per-state donations to a candidate. Thus, if there are 5 candidates (for example), there\nwould be 5 subplots.\nThe tricky part is mapping the donation amount to a color. Here' s some sample code to pick a shade of blue depending on the value of a donation between 0\nand MAXDONATION. The bigger index means a darker shade.\n# this c\nreates a\nn array of g\nrey colors f\nrom white to b\nlack\ncolors = ['0','1','2','3','4','5','6','7','8','9','a', 'b', '\nc', 'd', '\ne', 'f']\ncolors = map(lambda s\n: '#%s' % (s*6), c\nolors)\ncolors.sort(reverse=True)\n# a\nssume MAXDONATION was defined\n# a\nssume curdonation is t\nhe d\nonation to p\nick a color for\nratio = (curdonation/float(MAXDONATION))\ncolor_idx = int( r\natio * (\nlen(colors) - 1) )\n\ncolors[color_idx]\nUsing this, you should be able to create something like the following:\n\nYou'll notice that if you plot more candidates, they are very difficult to see because their donations are eclipsed by Obama' s. One way is to use a log scale\ninstead of a linear scale when mapping donations\nHere 's some sample code for computing a log\n\nimport math\nmath.log(100) # log of 100\nNow you have hands on experience with the most popular python plotting library!\nis far more power than what we have covered. To cover the\ngeneral process of using visualizations:\n\nAlways start by looking at your data with the simplest visualizations possible. For most datasets, a scatter plot or line graph is sufficient.\nFirst view a summary of the whole dataset so that you know which subsets are worth visualizing in more detail, and how significant the details really are.\nPlot your interesting data along a bunch of different dimensions.\nStare at your data, try to identify trends, outliers and other interesting regions and form hypotheses.\nUse statistics to see if your hypotheses were correct (tomorrow 's lecture)\nRepeat\nDomain specific visualizations\nWe only covered a small number of core visualizations in this lab. There are lots of other types of visualizations specialized for different domains. A few of them\nare listed below.\nGene Expression Matrix\nGene expression matrixes can be used to show correlations between genes and properties of patients. Here is one:\nNetwork Graphs\nPlotting graphs of social networks is a topic unto itself, and isn't well supported in\n. There are other libraries for drawing them, but we unfortunately\ndon' t have the time to talk about it in this class. If you' re interested, one useful network graphing library is NetworkX. Here' s an example of a network graph\noverlayed on a map:\n(c) NetworkX Developers. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/fairuse.\n(c) Source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see http://ocw.mit.edu/fairuse.\nTreeMaps\nA Treemap helps summarize relative proportions of a whole. Here' s a treemap of financial markets. You can make treemaps in matplotlib.\n\nImage from Wikipedia, in the public domain.\nOther visualization tools\nSome other visualization tools. A few are in python, and many are in other languages like javascript or java.\nhttp://orange.biolab.si/features.html: visualization and machine learning package for python\nProcessing: a fantastic java-based visualization language.\nProcessingJs: Processing ported to javascript\nd3: A javascript based visualization library that makes drawing on\nmuch much easier.\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\nResource: How to Process, Analyze and Visualize Data\nAdam Marcus and Eugene Wu\nThe following may not correspond to a particular course on MIT OpenCourseWare, but has been\nprovided by the author as an individual learning resource.\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
        },
        {
          "category": "Resource",
          "title": "Day 3 Lab Part A Handout",
          "type": "PDF",
          "source_url": "https://ocw.mit.edu/courses/res-6-009-how-to-process-analyze-and-visualize-data-january-iap-2012/5a85b1b2482129e6633ca47a06cc59d5_MITRES_6_009IAP12_lab3a.pdf",
          "content": "So far, weʹve plotted and visualized data in various ways. Today, weʹll see how to statistically back up some of the\nobservations weʹve made in looking at our data. Statistics is a tool that helps separate newsmaking data‐backed stories from\none‐off anecdotes. Usually, both kinds of stories start with a hunch, and statistics helps us quantify the evidence backing\nthat hunch.\nWhenever you have a hunch (a hypothesis in statistician‐speak), the first thing to do is to look at some summary statistics\n(e.g., averages), and explore the data graphically as we did yesterday. If the visualizations seem to support your hunch, you\nwill move into hypothesis‐testing mode.\nTwo Running Examples\nFor our first set of tests, weʹre going to use two running examples: campaign spending and a fun comparison of two townsʹ\ncitizensʹ heights. Here are the two scenarios:\nOne thing thatʹs been claimed about the 2008 election is that President Obama raised smaller quantities from a larger\ngroup of donors than Senator McCain, who raised a smaller number of large contributions. Statistical techniques will\nhelp us determine how true this statement is.\nImagine two towns that only differ in that one of the towns had ʺsomething in the waterʺ the year a bunch of kids\nwere born. Did that something in the water affect the height of these kids? (Note: This situation is unrealistic. Itʹs\nnever the case that the only difference between two communities is the one you want to measure, but itʹs a nice goal!)\nWeʹll use statistics to determine whether the two communities have meaninfully different heights.\nComparing Averages\nLetʹs start by comparing a simple statistic, to see if in the data we observe thereʹs any difference. Weʹll start by comparing the\naverage heights of the two towns. (As an aside: it would help if you wrote and ran your code in dataiap/day3/ today, since\nseveral modules like ols.py are available in that directory).\nimport numpy\ntown1_heights = [5, 6, 7, 6, 7.1, 6, 4]\ntown2_heights = [5.5, 6.5, 7, 6, 7.1, 6]\ntown1_mean = numpy.mean(town1_heights)\ntown2_mean = numpy.mean(town2_heights)\nprint \"Town 1 avg. height\", town1_mean\nprint \"Town 2 avg. height\", town2_mean\nprint \"Effect size: \", abs(town1_mean ‐ town2_mean)\nIt looks like town 2ʹs average height (6.35 feet) is higher than town 1 (5.87 feet) by a difference of .479 feet. This difference is\ncalled the effect size . Town 2 certainly looks taller than Town 1!\nExercise Compute the average campaign contribution for the Obama and McCain campaigns from the dataset in day 1.\nWhatʹs the effect size? We have an average contribution of $423 for McCain and $192 for Obama, for an effect size of $231.\nMcCain appears, on average, to have more giving donors.\nBefore we fire up the presses on either of these stories, letʹs look at the data in more depth.\nGraph The Data\nIf you finished yesterdayʹs histogram exercise, then feel free to skip down to the box plot section\nThe effect size in both of our examples seems large. It would be nice to more than just compare averages. Letʹs try to look at\n\na histogram of the distributions. We created a histogram of the two campaigns contributions, binned by $100 increments.\nimport matplotlib.pyplot as plt\nfrom collections import Counter\nincrement = 1\nwidth= .25\ntown1_bucketted = map(lambda ammt: ammt ‐ ammt%increment, town1_heights)\ntown2_bucketted = map(lambda ammt: ammt ‐ ammt%increment + width, town2_heights)\ntown1_hist = Counter(town1_bucketted)\ntown2_hist = Counter(town2_bucketted)\nminamount = min(min(town1_heights), min(town2_heights))\nmaxamount = max(max(town1_heights), max(town2_heights))\nbuckets = range(int(minamount), int(maxamount)+1, increment)\nfig = plt.figure()\nsub = fig.add_subplot(111)\nsub.bar(town1_hist.keys(), town1_hist.values(), color='b', width=width, label=\"town 1\")\nsub.bar(town2_hist.keys(), town2_hist.values(), color='r', width=width, label=\"town 2\")\nsub.legend()\nplt.savefig('figures/town_histograms.png', format='png')\nThis results in a histogram that looks like this:\nNot bad! The buckets are all exactly the same size except for one person of height between 4 and 5 feet in town 1.\nExercise Build a histogram for the Obama and McCain campaigns. This is challenging, because there are a large number of\noutliers that make the histograms difficult to compare. Add the line\n\nsub.set_xlim((‐20000, 20000))\nbefore displaying the plot in order to set the x‐values of the histogram to cut off donations larger than $20,000 or smaller\nthan ‐$20,000 (refunds). With bar widths of 50 and increments of $100, your histogram will look something like this:\nOuch! I canʹt make heads or tails of that. It seems like Obama has a larger number of small donations, but there isnʹt a lot of\ngranularity at that scale. For large datasets, a histogram might have too much information on it to be helpful. Luckily,\ndescriptive statisticians have a more concise visualization. Itʹs called a box‐and‐whisker plot! The code for it is quite simple\nas well:\nimport matplotlib.pyplot as plt\nfig = plt.figure()\nsub = fig.add_subplot(111)\nsub.boxplot([town1_heights, town2_heights], whis=1)\nsub.set_xticklabels((\"Town 1\", \"Town 2\"))\nsub.set_title(\"Town 1 vs. Town 2 Heights\")\nplt.savefig('figures/town_boxplots.png', format='png')\nHereʹs what we see:\n\nLetʹs interpret this plot. We show town 1 on the left and town 2 on the right. Each town is represented by a box with a red\nline and whiskers.\nThe red line in the box represents the median , or 50th percentile value of the distribution. If we sort the dataset, 50%\nof the values will be below this line, and 50% will be above it.\nThe bottom edge of the box represents the 25th percentile (the value larger than 25% of your dataset), and the top\nedge represents the 75th percentile (the value larger than 75% of your dataset). The difference between the 75th and\n25th percentile is called the inner quartile range (IQR) .\nThe whiskers represent the ʺextremesʺ of our dataset: the largest value weʹre willing to consider in our dataset before\ncalling it an outlier. In our case, we set whis=1 , requesting that we show whiskers the most extreme value at a\ndistance of at most 1x the IQR from the bottom and top edges of the box plot.\nIf normal distributions are your thing, this image might help you interpret the box‐and‐whiskers plot.\nLike in the histogram, we see that the townsʹ height distributions donʹt look all that different from one‐another. Generally, if\nthe boxes of each distribution overlap, and you havenʹt taken something on the order of a buttload (metric units) of\nmeasurements, you should doubt the differenes in distribution averages. It looks like a single height measurement for town\n1 is pretty far away from the others, and you should investigate such measurements as potential outliers.\nExercise Build a box‐and‐whiskers plot of the McCain and Obama campaign contributions. Again, outliers make this a\ndifficult task. With whis=1 , and by setting the y range of the plots like so\nsub.set_ylim((‐250, 1250))\nwe got the following plot\n\nObama is on the left, and McCain on the right. Real data sure is more confusing than fake data! Obamaʹs box plot is a lot\ntighter than McCains, who has a larger spread of donation sizes. Both of Obamaʹs whiskers are visible on this chart, whereas\nonly the top whisker of McCainʹs plot is visible. Another feature we havenʹt seen before is the stream of blue dots after each\nof the whiskers on each of Obama and McCainʹs plots. These represent potential outliers , or values that are extreme and\ndo not represent the majority of the dataset.\nIt was easy to say that the histograms and box plots for the town heights overlapped heavily. So while the effect size for\ntown heights was pretty large, the distributions donʹt actually look all that different from one‐another.\nThe campaign plots are a bit harder to discern. The histogram told us virtually nothing. The box plot showed us that\nObamaʹs donations seemed more concentrated on the smaller end, whereas McCains seemed to span a larger range. There\nwas overlap between the boxes in the plot, but we donʹt really have a sense for just how much overlap or similarity there is\nbetween these distributions. In the next section, weʹll quantify the difference using statistics!\nRun a Statistical Test\nWe have two population height averages. We know that they are different, but charts show that overall the two towns look\nsimilar. We have two campaign contribution averages that are also different, but with a murkier story after looking at our\nbox‐and‐whisker plots. How will we definitively say whether the differences we observe are meaningful?\nIn statistics, what we are asking is whether differences we observed are reliable indicators of some trend, or just happened\nby lucky chance. For example, we might simply have measured particularly short members of town 1 and tall members of\ntown 2. Statistical significance is a measure of the probability that, for whatever reason, we stumbled upon the results we\ndid by chance.\nThere are several tests for statistical significance, each applying to a different question. Our question is: ʺIs the difference\nbetween the average height of people in town 1 and town 2 statistically significant?ʺ We ask a similar question about the\ndifference in average campaign contributions. The test that answers this question is the T‐Test. There are several flavors of\nT‐Test and we will discuss these soon, but for now weʹll focus on Welchʹs T‐Test.\n\nimport welchttest\nprint \"Welch's T‐Test p‐value:\", welchttest.ttest(town1_heights, town2_heights)\nThe Welchʹs T‐Test emitted a p‐value of .349 . A p‐value is the probability that the effect size of .479 feet between town 1 and\ntown 2 happened by chance. In this case, thereʹs 34.9% chance that weʹve arrived at our effect size by chance.\nWhatʹs a good cutoff for p‐values to know whether we should trust the effect size weʹre seeing? Two popular values are .05\nor .01: if there is less than a 5% or 1% chance that we arrived at our answer by chance, weʹre willing to say that we have a\nstatistically significant result.\nSo in our case, our result is not significant. Had we taken more measurements, or if the differences in heights were farther\napart, we might have reached significance. But, given our current results, letʹs not jump to conclusions. After all, it was just\nfood coloring in the water!\nExercise Run Welchʹs T‐test on the campaign data. Is the effect size between McCain and Obama significant? By our\nmeasurements, the p‐value reported is within rounding error of 0. Thatʹs significant by anyoneʹs measure: thereʹs a\nnear‐nonexistant chance weʹre seeing this difference between the candidates by some random fluke in the universe. Time to\nwrite an article!\nCan You Have a Very Significant Result?\nNo. There is no such thing as ʺveryʺ or ʺalmostʺ significant. Remember: the effect size is the interesting observation, and itʹs\nup to you what makes for an impressive effect size depending on the situation. You can have small effects, large effects, and\neverything in between. Significance testing tells us whether to believe that the observations we made happened by anything\nmore than random chance. While people disagree about whether a p‐value of .05 or .01 is required, they all agree that\nsignificance is a binary value.\nStrictly speaking, youʹve learned about T‐Tests at this point. If you are pressed for time, read Putting it all Together below\nand move on to the next section. For the overachievers in our midst, thereʹs lots of important information to follow, and you\ncan instead keep reading until the end.\nTypes of T‐Test\nThe T‐Test has two major flavors: paired and unpaired.\nSometimes your datasets are paired (also called dependent ). For example, you may be measuring the performance of the\nsame set of students on an exam before and after teaching them the course content. To use a paired T‐Test, you have to be\nable to measure an item twice, usually before and after some treatment. This is the ideal condition: by having before and\nafter measurements of a treatment, you control for other potential differences in the items you mentioned, like performance\nbetween students.\nOther times, you are measuring the difference between two sets of measured data, but the individual measurements in each\ndataset are unpaired (sometimes called independent ). This was the case in our tests: different people contributed to each\ncampaign, and different people live in town 1 and 2. With unpaired datasets, we lose the ability to control for differences\nbetween individuals, so weʹll likely need more data to achieve statistical significance.\nUnpaired datasets come in all flavors. Depending on whether the sizes of the sets are equal or unequal, and depending on\nwhether the variances of both sets are equal, you will run different versionf of an unpaired T‐Test. In our case, we made no\nassumptions about the sizes of our datasets, and no assumptions on their variances, either. So we went with an unpaired,\nunequal size, unequal variance test. Thatʹs Welchʹs T‐Test.\nAs with all life decisions, if you want more details, check out the Wikipedia article on T‐Tests. There are implementations of\npaired T‐Tests and unpaired ones in scipy. The unequal variance case is not available in scipy, which is why we included\nwelchsttest.py. Enjoy it!\n\nT‐Test Assumptions we Broke:(\nWeʹve managed to sound like smartypantses that do all the right things until this moment, but now we have to admit we\nbroke a few rules. The math behind T‐Tests makes assumptions about the datasets that makes it easier to achieve statistical\nsignificance if those assumptions are true. The big assumption is that the data we used came from a normal distribution.\nThe first thing we should have done is check whether or not our data is actually normal. Luckily, the fine scipy folks have\nimplemented the Shapiro‐Wilk test test for normality. This test calculates a p‐value, that, if low enough (usually < 0.05), tells\nus there is a low chance the distribution is normal.\nimport scipy.stats\nprint \"Town 1 Shapiro‐Wilks p‐value\", scipy.stats.shapiro(town1_heights)[1]\nWith a p‐value of .380, we donʹt have enough evidence that our town heights are not normally distributed, so itʹs probably\nfine to run Welchʹs T‐Test\nExercise Test the campaign contribution datasets for normality. We found them to not be normal (p = .003 for Obama and\n.014 for McCain), which means we likely broke the normality assumption of Welchʹs T‐Test. The statistics police are going to\nbe paying us a visit.\nThis turns out to be OK for two reasons: T‐Tests are resilient to breaking of the normality assumption, and, if youʹre really\nserious about your statistics, there are nonparametric equivalents that donʹt make normality assumptions. They are more\nconservative since they canʹt make assumptions about the data, and thus likely require a larger sample size to reach\nsignificance. If youʹre alright with that, feel free to run the Mann‐Whitney U nonparametric version of the T‐Test, which has\na wonderful name.\nimport scipy.stats\nprint \"Mann‐Whitney U p‐value\", scipy.stats.mannwhitneyu(town1_heights, town2_heights)[1]\nRemember: we donʹt need to run the Mann‐Whitney U test on our town data, since it didnʹt exhibit non‐normalcy. And\nbesides, the p‐value is .254. Thatʹs still not significant. This makes sense: our less conservative Welchʹs test was unable to give\nus significance, so we donʹt expect a more conservative test to magically find significance.\nExercise since we shouldnʹt be using Welchʹs T‐Test on the campaign contribution data, run the Mann‐Whitney U test on\nthe data. Is the difference between the Obama and McCain contributions still significant?\nWe got a p‐value of about 0, so you will still find the result to be statistically significant. A+ for you!\nPutting it All Together\nSo far, weʹve learned the steps to test a hypothesis:\nCompute summary statistics, like averages or medians, and see if these numbers match your intuition.\nLook at the distribution histograms or summary visualizations like box plots to understand whether your hypothesis\nappears to be backed up by the data\nIf itʹs not immediately clear your hypothesis was wrong, test it using the appropriate statistical test to 1) quantify the\neffect size, and 2) ensure the data you observed couldnʹt have happened by chance.\nThereʹs a lot more to statistics than T‐Tests, which compare two datasetsʹ averages. Next, weʹll cover correlation between\ntwo datasets using linear regression.\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\nResource: How to Process, Analyze and Visualize Data\nAdam Marcus and Eugene Wu\nThe following may not correspond to a particular course on MIT OpenCourseWare, but has been\nprovided by the author as an individual learning resource.\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
        },
        {
          "category": "Resource",
          "title": "Day 3 Lab Part B Handout",
          "type": "PDF",
          "source_url": "https://ocw.mit.edu/courses/res-6-009-how-to-process-analyze-and-visualize-data-january-iap-2012/7efe00f12b11fefc7374e366957f63b0_MITRES_6_009IAP12_lab3b.pdf",
          "content": "We hear about correlations every day. Various health outcomes are correlated with socioeconomic status. Iodine\nsupplementation in infants is correlated with higher IQ. Models are everywhere as well. An object falling for t seconds\nmoves .5gt^2 meters. You can calculate correlation and build approximate models using several techniques, but the simplest\nand most popular technique by far is linear regression . Letʹs see how it works!\nCounty Health Rankings\nFor our examples, weʹll use the County Health Rankings. Specifically, weʹll be looking at two datasets in this example: Years\nof Potential Life Lost and Additional Measures.\nYears of potential life lost (YPLL) is an early mortality measure. It measures, across 100,000 people, the total number of\nyears below the age of 75 that a 100,000‐person group loses. For example, if a person dies at age 73, they contribute 2 years\nto this sum. If they die at age 77, they contribute 0 years to the sum. The YPLL for each 100,000 people, averaged across\ncounties in the United States is between 8000 and 9000 depending on the year. The file ypll.csv contains per‐county YPLLs\nfor the United States in 2011.\nThe additional measures (found in additional_measures_cleaned.csv ) contains all sorts of fun measures per county, ranging\nfrom the percentage of people in the county with Diabetes to the population of the county.\nWeʹre going to see which of the additional measures correlate strongly with our mortality measure, and build predictive\nmodels for county mortality rates given these additional measures.\nLoading the Rankings\nThe two .csv files weʹve given you (ypll.csv and additional_measures_cleaned.csv) went through quote a bit of scrubbing\nalready. You can read our notes on the process if youʹre interested.\nWe need to perform some data cleaning and filtering when loading the data. There is a column called ʺUnreliableʺ that will\nbe marked if we shouldnʹt trust the YPLL data. We want to ignore those. Also, some of the rows wonʹt contain data for\nsome of the additional measures. For example, Yakutat, Alaska doesnʹt have a value for % child illiteracy. We want to skip\nthose rows. Finally, there is a row per state that summarizes the stateʹs statistics. It has an empty value for the ʺcountyʺ\ncolumn and we want to ignore those rows since we are doing a county‐by‐county analysis. Hereʹs a function, read_csv , that\nwill read the desired columns from one of the csv files.\nimport csv\ndef read_csv(file_name, cols, check_reliable):\nreader = csv.DictReader(open(file_name, 'rU'))\nrows = {} # map \"statename__countyname\" to the column names in cols\nfor row in reader:\nif check_reliable and row['Unreliable'] == \"x\": # discard unreliable data\ncontinue\nif row['County'] == \"\": # ignore the first entry for each state\ncontinue\nrname = \"%s__%s\" % (row['State'], row['County'])\ntry: # if a row[col] is empty, float(row[col]) throws an exception\nrows[rname] = [float(row[col]) for col in cols]\nexcept:\npass\nreturn rows\nThe function takes as input the csv filename, an array of column names to extract, and whether or not it should check and\ndiscard unreliable data. It returns a dictionary mapping each state/county to the values of the columns specified in cols . It\nhandles all of the dirty data: data marked unreliable, state‐only data, and missing columns.\nWhen we call read_csv multiple times with different csv files, a row that is dropped in one csv file may be kept in another.\n\nWe need to do what database folks call a join between the dict objects returned from read_csv so that only the counties\npresent in both dictionaries will be considered.\nWe wrote a function called get_arrs that retrieves data from the YPLL and Additional Measures datasets. It takes the\narguments dependent_cols , which is a list of column names to extract from ypll.csv , and independent_cols , which is a list of\ncolumn names to extract from additional_measures_cleaned.csv . This function performs the join for you.\nimport numpy\ndef get_arrs(dependent_cols, independent_cols):\nypll = read_csv(\"../datasets/county_health_rankings/ypll.csv\", dependent_cols, True)\nmeasures = read_csv(\"../datasets/county_health_rankings/additional_measures_cleaned.csv\", independent_cols, False)\nypll_arr = []\nmeasures_arr = []\nfor key, value in ypll.iteritems():\nif key in measures: # join ypll and measures if county is in both\nypll_arr.append(value[0])\nmeasures_arr.append(measures[key])\nreturn (numpy.array(ypll_arr), numpy.array(measures_arr))\nWe return numpy arrays (matrices) with rows corresponding to counties and columns corresponding to the columns we\nread from the spreadsheet. We can finally call the get_arrs function to load the desired columns from each file.\ndependent_cols = [\"YPLL Rate\"]\nindependent_cols = [\"Population\", \"< 18\", \"65 and over\", \"African American\",\n\"Female\", \"Rural\", \"%Diabetes\" , \"HIV rate\",\n\"Physical Inactivity\" , \"mental health provider rate\",\n\"median household income\", \"% high housing costs\",\n\"% Free lunch\", \"% child Illiteracy\", \"% Drive Alone\"]\nypll_arr, measures_arr = get_arrs(dependent_cols, independent_cols)\nprint ypll_arr.shape\nprint measures_arr[:,6].shape\nexit()\nPhew. That sucked. Letʹs look at the data!\nLook at a Scatterplot\nLike we did during hypothesis testing, our first step is to look at the data to identify correlations. The best visualization to\nidentify correlations is a scatterplot, since that shows us the relationship between two potentially related variables like ypll\nand % diabetes.\nLetʹs start by looking at scatterplots of ypll versus three potentially correlated variables: % of a community that has diabetes,\n% of the community under the age of 18, and median income.\nimport matplotlib.pyplot as plt\nfig = plt.figure(figsize=(6, 8))\nsubplot = fig.add_subplot(311)\nsubplot.scatter(measures_arr[:,6], ypll_arr, color=\"#1f77b4\") # :,6 means all rows of \"diabetes\"\nsubplot.set_title(\"ypll vs. % of population with diabetes\")\nsubplot = fig.add_subplot(312)\nsubplot.scatter(measures_arr[:,1], ypll_arr, color=\"#1f77b4\") # 1 = age\nsubplot.set_title(\"ypll vs. % population less than 18 years of age\")\nsubplot = fig.add_subplot(313)\nsubplot.scatter(measures_arr[:,10], ypll_arr, color=\"#1f77b4\") # 10 = income\nsubplot.set_title(\"ypll vs. median household income\")\n\nplt.savefig('figures/three‐scatters.png', format='png')\nwhatʹs measures_arr[:,6] ? Thatʹs a numpy supported syntax to extract a subset of a matrix. The first argument specifies\nwhich rows to extract. It can be a number (like 3), a python slice ( :3 means the rows from 0 to 3, while 3:5 means 3 to 5), or\n: , which means all of the rows. The second argument specifies which columns to extract. In this case it is 6 , which is the\n7ʹth column (remember, itʹs 0 indexed).\nYour plots should look something like this:\nWe picked these three examples because they show visual evidence of three forms of correlation:\nIn the first plot, we can see that when the percentage of people in a county with diabetes is higher, so is the mortality\nrate (YPLL)‐‐‐evidence of a positive correlation.\nThe second plot looks like a blob. Itʹs hard to see a relationship between mortality and the fraction of people under the\nage of 18 in a community.\nThe final plot shows evidence of negative correlation. Counties with higher median incomes appear to have lower\nmortality rates.\nExercise Look at scatter plots of other variables vs. YPLL. We found the percent of children eligible for school lunch to be\n\nalarmingly correlated with YPLL!\nYour First Regression\nItʹs time we turn the intuition from our scatterplots into math! Weʹll do this using the ols module, which stands for ordinary\nleast squares regression. Letʹs run a regression for YPLL vs. % Diabetes.\nimport ols\nmodel = ols.ols(ypll_arr, measures_arr[:,6], \"YPLL Rate\", [\"% Diabetes\"]) # 6 = diabetes\nmodel.summary()\nthe ols script in dataiap/day3/ implement a method called ols() that takes four arguments:\n1. a 1‐dimensional numpy array containing the values of the dependent variable (e.g., YPLL)\n2. a 2‐dimensional numpy array where each row contains the values of an independent variable. In this case the only\nindependent variable is ʺ% Diabetesʺ, so the matrix has the same shape as ypll_arr.\n3. The label for the first argument\n4. A list of labels for each row in the second argument\nAs you can see, running the regression is simple, but interpreting the output is tougher. Hereʹs the output of model.summary()\nfor the YPLL vs. % Diabetes regression:\n======================================================================\nDependent Variable: YPLL Rate\nMethod: Least Squares\nDate:\nFri, 23 Dec 2011\nTime:\n13:48:11\n# obs:\n# variables:\n======================================================================\nvariable\ncoefficient\nstd. Error\nt‐statistic\nprob.\n======================================================================\nconst\n585.126403\n169.746288\n3.447064\n0.000577\n%Diabetes\n782.976320\n16.290678\n48.062846\n0.000000\n======================================================================\nModels stats\nResidual stats\n======================================================================\nR‐squared\n0.511405\nDurbin‐Watson stat\n1.951279\nAdjusted R‐squared\n0.511184\nOmnibus stat\n271.354997\nF‐statistic\n2310.037134\nProb(Omnibus stat)\n0.000000\nProb (F‐statistic)\n0.000000\nJB stat\n559.729657\nLog likelihood\n‐19502.794993\nProb(JB)\n0.000000\nAIC criterion\n17.659389\nSkew\n0.752881\nBIC criterion\n17.664550\nKurtosis\n4.952933\n======================================================================\nLetʹs interpret this:\nFirst, letʹs verify the statistical significance, to make sure nothing happened by chance, and that the regression is\nmeaningful. In this case, Prob (F‐statistic) , which is under Models stats , is something very close to 0, which is less\nthan .05 or .01. That is: we have statistical significance, and we an safely interpret the rest of the data.\nThe coefficients (called betas ) help us understand what line best fits the data, in case we want to build a predictive\nmodel. In this case const is 585.13, and %Diabetes has a coefficient of 782.98. Thus, the line (y = mx + b) that best\npredicts YPLL from %Diabetes is: YPLL = (782.98 * %Diabetes) + 585.13.\nTo understand how well the line/model weʹve built from the data helps predict the data, we look at R‐squared . This\nvalue ranges from 0 (none of the change in YPLL is predicted by the above equation) to 1 (100% of the change in\nYPLL is predicted by the above equation). In our case, 51% of the changes YPLL can be predicted by a linear equation\non %Diabetes. Thatʹs a reasonably strong correlation.\n\nPutting this all together, weʹve just discovered that, without knowing the YPLL of a community, we can take data on the\npercentage of people affected by diabetes, and roughly reconstruct 51% of the YPLLʹs characteristics.\nIf you want to use the information in your regression to do more than print a large table, you can access the data\nindividually\nprint \"p‐value\", model.Fpv\nprint \"coefficients\", model.b\nprint \"R‐squared and adjusted R‐squared:\", model.R2, model.R2adj\nTo better visualize the model weʹve built, we can also plot the line weʹve calculated through the scatterplot we built before\nfig = plt.figure(figsize=(6, 4))\nsubplot = fig.add_subplot(111)\nsubplot.scatter(measures_arr[:,6], ypll_arr, color=\"#1f77b4\") # 6 = diabetes\nsubplot.set_title(\"ypll vs. % of population with diabetes\")\ndef best_fit(m, b, x): # calculates y = mx + b\nreturn m*x + b\nline_ys = [best_fit(model.b[1], model.b[0], x) for x in measures_arr[:,6]]\nsubplot.plot(measures_arr[:, 6], line_ys, color=\"#ff7f0e\")\nplt.savefig('figures/scatter‐line.png', format='png')\nThat should result in a plot that looks something like\nWe can see that our line slopes upward (the beta coefficient in front of the %Diabetes term is positive) indicating a positive\ncorrelation.\nExercise Run the correlations for percentage of population under 18 years of age and median household income.\nWe got statistically significant results for all of these tests. Median household income is negatively correlated (the slope beta\nis ‐.13), and explains a good portion of YPLL (R‐squared is .48). Remember that we saw a blob in the scatterplot for\npercentage of population under 18. The regression backs this up: the R‐squared of .005 suggests little predictive power of\nYPLL.\n\nExercise Plot the lines calculated from the regression for each of these independent variables. Do they fit the models?\nExercise Run the correlation for % of children eligible for school lunches. Is it significant? Positively or negatively\ncorrelated? How does this R‐squared value compare to the ones we just calculated?\nExplaining R‐squared\nR‐squared roughly tells us how well the linear model (the line) we get from a linear regression explains the independent\nvariable.\nR‐squared values have several interpretations, but one of them is as the square of a value called the Pearson Correlation\nCoefficient. That last link has a useful picture of the correlation coefficient that shows you the value of R for different kinds\nof data.\nSquaring R makes it always positive and changes its asymptotic properties, but the same trends (being near 0 or near 1) still\napply.\nRunning Multiple Variables\nSo far, weʹve been able to explain about 50% of the variance in YPLL using our additional measures data. Can we do better?\nWhat if we combine information from multiple measures? Thatʹs called a multiple regression, and we already have all the\ntools we need to do it! Letʹs combine household income, %Diabetes, and percentage of the population under 18 into one\nregression.\ndependent_cols = [\"YPLL Rate\"]\nindependent_cols = [\"< 18\", \"%Diabetes\" , \"median household income\"]\nypll_arr, measures_arr = get_arrs(dependent_cols, independent_cols)\nmodel = ols.ols(ypll_arr, measures_arr, \"YPLL Rate\", independent_cols)\nprint \"p‐value\", model.Fpv\nprint \"coefficients\", model.b\nprint \"R‐squared and adjusted R‐squared:\", model.R2, model.R2adj\nWe got the following output:\np‐value 1.11022302463e‐16\ncoefficients [\n4.11471809e+03\n1.30775027e+02\n5.16355557e+02 ‐ 8.76770577e‐02]\nR‐squared and adjusted R‐squared: 0.583249144589 0.582809842914\nSo weʹre still significant, and can read the rest of the output. A read of the beta coefficients suggests the best linear\ncombination of all of these variables is YPLL = 4115 + 131(% under 18) + 516(% Diabetes) ‐ 877*(median household income)\n.\nBecause there are multiple independent variables in this regression, we should look at the adjusted R‐squared value, which\nis .583. This value penalizes you for needlessly adding variables to the regression that donʹt give you more information about\nYPLL. Anyway, check out that R‐squared‐‐‐nice! Thatʹs larger than the R‐squared value for any one of the regressions we\nran on their own! We can explain more of YPLL with these variables.\nExercise Try combining other variables. Whatʹs the largest adjusted R‐squared you can achieve? We can reach .715 by an\nexcessive use of variables. Can you replicate that?\nEliminate Free Lunches, Save the Planet\nAt some point in performing a regression and testing for a correlation, you will be tempted to come up with solutions to\nproblems the regression has not identified. For example, we noticed that the percentage of children eligible for free lunch is\npretty strongly correlated with the morbidity rate in a community. How can we use this knowledge to lower the morbidity\nrate?\n\nALERT, ALERT, ALERT!!! The question at the end of the last paragraph jumped from a question of correlation to a\nquestion of causation.\nIt would be far‐fetched to think that increasing or decreasing the number of children eligible for school lunches would\nincrease or decrease the morbidity rate in any significant way. What the correlation likely means is that there is a third\nvariable, such as available healthcare, nutrition options, or overall prosperity of a community that is correlated with both\nschool lunch eligibility and the morbidity rate. Thatʹs a variable policymakers might have control over, and if we somehow\nimproved outcomes on that third variable, weʹd see both school lunch eligibility and the morbidity rate go down.\nRemember: correlation means two variables move together, not that one moves the other.\nWeʹve hit the point that if youʹre stressed for time, you can jump ahead to the closing remarks. Realize, however, that thereʹs\nstill mind‐blowing stuff ahead, and if you have time you should read it!\nNonlinearity\nIs finding a bunch of independent variables and performing linear regression against some dependent variable the best we\ncan do to model our data? Nope! Linear regression gives us the best line to fit through the data, but there are cases where\nthe interaction between two variables is nonlinear. In these cases, the scatterplots we built before matter quite a bit!\nTake gravity for example. Say we measured the distance an object fell in a certain amount of time, and had a bit of noise to\nour measurement. Below, weʹll simulate that activity by generating the time‐distance relationship that we learned in high\nschool (displacement = .5gt^2). Imagine we record the displacement of a ball as we drop it, storing the time and\ndisplacement measurements in timings and displacements .\ntimings = range(1, 100)\ndisplacements = [4.9*t*t for t in timings]\nA scatterplot of the data looks like a parabola, which wonʹt fit lines very well! We can transform this data by squaring the\ntime values.\nsq_timings = [t*t for t in timings]\nfig = plt.figure()\nsubplot = fig.add_subplot(211)\nsubplot.scatter(timings, displacements, color=\"#1f77b4\")\nsubplot.set_title(\"original measurements (parabola)\")\nsubplot = fig.add_subplot(212)\nsubplot.scatter(sq_timings, displacements, color=\"#1f77b4\")\nsubplot.set_title(\"squared time measurements (line)\")\nplt.savefig('figures/parabola‐linearized.png', format='png')\nHere are scatterplots of the original and transformed datasets. You can see that squaring the time values turned the plot\ninto a more linear one.\n\nExercise Perform a linear regression on the original and transformed data. Are they all significant? Whatʹs the R‐squared\nvalue of each? Which model would you prefer? Does the coefficient of the transformed value mean anything to you?\nFor those keeping score at home, we got R‐squared of .939 and 1.00 for the unadjusted and adjusted timings, which means\nwe were able to perfectly match the data after transformation. Note that in the case of the squared timings, the equation we\nend up with is displacement = 4.9 * time^2 (the coefficient was 4.9), which is the exact formula we had for gravity.\nAwesome!\nExercise Can you improve the R‐squared values by transformation in the county health rankings? Try taking the log of the\npopulation, a common technique for making data that is bunched up spread out more. To understand what the log\ntransform did, take a look at a scatterplot.\nLog‐transforming population got us from R‐squared = .026 to R‐squared = .097.\nLinear regression, scatterplots, and variable transformation can get you a long way. But sometimes, you just canʹt figure out\nthe right transformation to perform even though thereʹs a visible relationship in the data. In those cases, more complex\ntechnques like nonlinear least squares can fit all sorts of nonlinear functions to the data.\nWhere to go from here\nToday youʹve swallowed quite a bit. You learned about significance testing to support or reject high‐likelihood meaningful\nhypotheses. You learned about the T‐Test to help you compare two communities on whom youʹve measured data. You then\nlearned about regression and correlation, for identifying variables that change together. From here, there are several\ndirections to grow.\nA more general form of the T‐Test is an ANOVA, where you can identify differences among more than two groups,\nand control for known differences between items in each dataset.\n\nThe T‐Test is one of many tests of statistical significance.\nThe concept of statistical significance testing comes from a frequentist view of the world. Another view is the Bayesian\napproach, if mathematical controversy is your thing.\nLogistic regression, and more generally classification, can take a bunch of independent variables and map them onto\nbinary values. For example, you could take all of the additional measures for an individual and predict whether they\nwill die before the age of 75.\nMachine learning and data mining are fields that assume statistical significance (you collect boatloads of data) and\ndevelop algorithms to classify, cluster, and otherwise find patterns in the underlying datasets.\n\nMIT OpenCourseWare\nhttp://ocw.mit.edu\nResource: How to Process, Analyze and Visualize Data\nAdam Marcus and Eugene Wu\nThe following may not correspond to a particular course on MIT OpenCourseWare, but has been\nprovided by the author as an individual learning resource.\nFor information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms."
        }
      ],
      "source_url": "https://ocw.mit.edu/courses/res-6-009-how-to-process-analyze-and-visualize-data-january-iap-2012/",
      "course_info": "RES.6-009 | Non-Credit",
      "subject": "General"
    },
    {
      "course_name": "MIT Climate Portal",
      "course_description": "To inform and empower the public on the complex issue of climate change, the Massachusetts Institute of Technology has created a Climate Portal, an online home for timely, science-based information about the causes and consequences of climate change—and what can be done to address it. Whether you are new to climate change or ready for a deeper exploration, the MIT Climate Portal offers a virtual place to ground your knowledge and ask your questions of experts. It also highlights MIT’s latest climate change research and initiatives for action.\nThe MIT Climate Portal is managed by the MIT Environmental Solutions Initiative, with support from the MIT Office of the Vice President for Research.",
      "topics": [
        "Energy",
        "Science",
        "Earth Science",
        "Climate Studies",
        "Social Science",
        "Public Administration",
        "Science and Technology Policy",
        "Energy",
        "Science",
        "Earth Science",
        "Climate Studies",
        "Social Science",
        "Public Administration",
        "Science and Technology Policy"
      ],
      "syllabus_content": "",
      "files": [],
      "source_url": "https://ocw.mit.edu/courses/res-env-004-mit-climate-portal-fall-2020/",
      "course_info": "RES.ENV-004 | Non-Credit",
      "subject": "General"
    },
    {
      "course_name": "Topics in Fourier Analysis",
      "course_description": "The goal of these lectures is to provide an introduction to Fourier analysis. The first topic is Fourier series, in particular, the Gibbs phenomenon and the dependence of their convergence properties on the suitability method used. The second topic is the Fourier transform, first the L¹ theory and then, using Hermite functions, the L² theory. The third topic is L. Schwartz’s theory of tempered distributions. The fourth topic is the theory of weak convergence of probability measures and application to a derivation of the Lévy-Khinchine formula for the Fourier transform of infinitely divisible probability measures. The final topic is the elementary theory of singular integral operators, starting with the Hilbert transform and then using the method of rations to prove the Lᵖ boundedness of even Calderòn-Zygmund kernels.",
      "topics": [
        "Mathematics",
        "Mathematical Analysis",
        "Mathematics",
        "Mathematical Analysis"
      ],
      "syllabus_content": "",
      "files": [
        {
          "category": "Lecture Notes",
          "title": "RES.18-015 S24 Full Lecture Notes: Topics in Fourier Analysis",
          "type": "PDF",
          "source_url": "https://ocw.mit.edu/courses/res-18-015-topics-in-fourier-analysis-spring-2024/mitres_18_015_s24_full_lec.pdf",
          "content": "TOPICS IN FOURIER ANALYSIS\nDANIEL W. STROOCK\n0. Introduction\nThis is a set of notes that I wrote for a course that I intended to but did not give\nat MIT during the spring semester of 2024. It covers a number of topics related to\nthe theory and application of Fourier analysis.\nI begin in §1 by proving the L2-convergence of Fourier followed by elementary\nresults about pointwise convergence for sufficiently smooth periodic functions. In\n§2 I discuss what goes wrong in the absence of periodicity, and in §3 I apply Fourier\nseries to compute the Riemann ζ at odd integers using the Bernoulli polynomials,\nwhich I also use to develop the Euler-Maclauren series. After comparing summa-\nbility methods in §4, I give a brief introduction in §5 to the summability results of\nDirichlet, Feij er, and Lebesgue.\nIn section §6 I introduce the L1-Fourier transform, followed in §7 by the compu-\ntation of the Fourier transforms of the Gauss and Poisson kernels and the derivation\nand application of the Poisson summation formula. The L1 version of the Fourier\ninversion formula is proved in §8. In §§9-11 I make preparations for my treatment\nin §12 of the L2-Fourier transform via Hermite functions. By the end of §12, I have\ncovered the key results in that theory: Parseval's identity and the Fourier inversion\nformula.\nIn §13 I introduce the test function space on which Laurent Schwartz based his\ntheory of tempered distributions. As was the case in my treatment of the L2-Fourier\ntransform, Hermite functions play a central role here. In §14 I give the definition of\nand do a few computations with tempered distributions, and in §15 I show how to\nextend continuous operations on the test function space as continuous operations\non tempered distributions.\nIn §§1-15 I have restricted my results to the one dimensional setting, and it is only\nin §16 that I describe what has to be done to extend those results to more than one\ndimension. Once I have done so, in §17 I introduce the weak topology on the space\nof Borel probability on RN, and in §18 I show that there is an intimate relationship\nbetween that topology and Fourier analysis. The results in §18 are combined with\nthose in §14 to derive in §19 the L evy-Khinchine formula for infinitely divisible\nprobability measures.\nThe rest of these notes is devoted to the theory of singular integral operators.\nAfter a brief attempt in §20 to provide motivation, in §21 I derive the Lp bound-\nedness of the Hilbert transform when p is an even integer, and in §22 I prove the\nRiesz-Thorin interpolation theory in order the extend that result to all p ∈(1, inf).\nFinally, in §23 I use Calder`on and Zygmund's method of rotations to prove Lp\nboundedness of odd Calder`on-Zygmund kernels.\nIn so far as possible, I have tried to avoid the use of unfamiliar results, but I\nam well aware that what is familiar to some may be unfamiliar to others. At a\n\nDANIEL W. STROOCK\nminimum, the reader is expected to had a rigorous course in Lebesgue integration\ntheory. In addition, I have assumed some comfort with the ideas of elementary func-\ntional analysis, especially Hilbert spaces. Other than that, the only prerequisites\nare an interest in mathematics and a willingness to do computations.\n1. Basic Theory of Fourier Series\nSet em(x) = eı2πmx for m ∈Z and x ∈R, and observe that {em : m ∈Z} is an\northonormal family in L2(λ[0,1); C).1 Even though it involves an abuse of notation,\nwe will use (φ, em)L2(λ[0,1);C) to denote\nR\n[0,1) φ(y)e-m(y) dy for φ ∈L1(λ[0,1); C).\nGiven a function φ : [0, 1) -→C, define its periodic extension φ : R -→C\nby φ(x) = φx -⌊x⌋, where ⌊x⌋= max{n ∈Z : x ≥n}. Notice that if φ ∈\nL1(λ[0,1); C), then\nZ\n[0,1)\nφ(x) dx =\nZ\n[a,a+1)\nφ(x) dx for all a ∈R.\nSimilarly,\nZ\n[0,1)\nφ(-x) dx =\nZ\n[0,1)\nφ(x) dx.\nFor bounded, continuous functions φ and ψ on [0, 1), define\nφ ∗ψ(x) =\nZ\n[0,1)\nφ(x -y)ψ(y) dy,\nand use the preceding to check that\nφ ∗ψ(x) =\nZ\n[-x,-x+1]\nφ(y) ψ(x -y) dy = ψ ∗φ(x).\nFinally, by the continuous version of Minkowski's inequality,2\n∥φ ∗ψ∥Lp(λ[0,1);C) ≤∥φ∥Lp(λ[0,1);C)∥ψ∥L1(λ[0,1);C) ∧∥ψ∥Lp(λ[0,1);C)∥φ∥L1(λ[0,1);C)\nfor any p ∈[1, inf).\nHence, for each p ∈[1, inf), (φ, ψ) ⇝φ ∗ψ has a unique\ncontinuous extension as a map bilinear map from L1(λ[0,1); C) × Lp(λ[0,1); C) into\nLp(λ[0,1); C), and\n(1.1)\n∥φ ∗ψ∥Lp(λ[0,1);C) ≤∥φ∥L1(λ[0,1);C)∥ψ∥Lp(λ[0,1);C)\ncontinues to hold.\nTheorem 1.1. If φ ∈Lpλ[0,1]; C for some p ∈[1, inf), then\nlim\nr↗1\nφ -\nX\nm∈Z\nr|m|φ, em\n\nL2(λ[0,1);C)em\n\nLp(λ[0,1];C)\n= 0,\nand, if φ ∈C[0, 1]; C satisfies φ(0) = φ(1), then3\nlim\nr↗1\nφ -\nX\nm∈Z\nr|m|φ, em\n\nL2(λ[0,1);C)em\n\nu\n= 0.\n1For a measure space (E, F, μ) and p ∈[1, inf], Lp(μ; C) is the associated Lebesgue space. For\na Borel measurable subset S ⊆RN, λS is the Lebesgue's measure resticted to S.\n2If φ ∈Lp(μ; C), then ∥φ∥Lp(μ;C) is its Lp-norm.\n3∥· ∥u is the uniform (i.e., supremum norm).\n\nTOPICS IN FOURIER ANALYSIS\nProof. Define\npr(x) =\nX\nm∈Z\nr|m|em(x) for r ∈[0, 1) and x ∈[0, 1).\nClearly\nR 1\n0 pr(x) dx = 1, pr(-x) = pr(x), and epr is continuous. In addition,\npr(x) =\n1 -re1(x)+\nre-1(x)\n1 -re-1(x) =\n1 -r2\n|1 -re1(x)|2 =\n1 -r2\n1 -2r cos 2πx + r2 for r ∈[0, 1),\nand so pr ≥0.\nObviously,\nX\nm∈Z\nr|m|φ, em\n\nL2(λ[0,1);C)em(x) = pr ∗φ(x) =\nZ\n[0,1)\npr(y) φ(x + y) dy\nsince pr is even. Now suppose that φ ∈C[0, 1] : C with φ(0) = φ(1). Then, since\nlimr↗1\nR 1\nδ pr(y) dy = 0 for each δ ∈(0, 1), it is easy to check that\nlim\nr↗1 sup\nx∈[0,1]\n\nZ 1\nφ(x + y) dy -f(x)\n≤ωφ(δ),\nwhere ωφ is the modulus of continuity of φ. Thus the second part of the theorem\nhas been proved.\nTo prove the first part, let φ ∈Lp(λ[0,1); C), and choose choose a sequence {φk :\nk ≥1} ⊆C[0, 1]; C which satisfy φk(0) = φk(1) and ∥φ -φk∥Lp(λ[0,1];C) -→0 as\nk →inf. Then, for each k,\n∥pr ∗φ -φ∥Lp(λ[0,1];C)\n≤∥pr ∗(φ -φk)∥Lp(λ[0,1];C) + ∥pr ∗φk -φk∥Lp(λ[0,1];C) + ∥φk -φ∥Lp(λ[0,1];C),\nand so, by (1.1), for all k.\nlim\nr↗1 ∥pr ∗φ -φ∥Lp(λ[0,1];C) ≤2∥φk -φ∥Lp(λ[0,1];C).\nFinally, let k →inf.\n□\nTheorem 1.2. {em : m ∈Z} is an orthonormal basis in L2(λ[0,1); C), and so, for\neach φ ∈L2(λ[0,1); C),\n(1.2)\nX\nm∈Z\n(φ, em)L2(λ[0,1);C)em ≡lim\nn→inf\nX\n|m|≤n\n(φ, em)L2(λ[0,1);C) = φ,\nwhere the convergence is in L2(λ[0,1); C). In addition, for all φ, ψ ∈L2(λ[0,1); C),\n(φ, ψ)L2(λ[0,1);C) =\nX\nm∈Z\n(φ, em)L2(λ[0,1);C)(ψ, em)L2(λ[0,1);C).\nProof. It suffices to check the first statement, and to do so all we need to know is\nthat (φ, em)L2(λ[0,1);C) = 0 for all m ∈Z implies φ = 0 for a set of φ's which is dense\nin L2(λ[0,1); C). But, by Theorem 1.1, we know this for continuous φ's satisfying\nφ(0) = φ(1), and these are dense in L2(λ[0,1); C).\n□\nEquation (1.2) is known as Parseval's identity for Fourier series.\nDefine the partial sum Snφ = P\n|m|≤n(φ, em)L2(λ[0,1);C)em.\n\nDANIEL W. STROOCK\nCorollary 1.3. If φ ∈C([0, 1]; C) and\nX\nm=0\n(φ, em)L2(λ[0,1);C)\n< inf,\nthen the series\nX\nm∈Z\n(φ, em)L2(λ[0,1);C)em(x)\nis uniformly absolutely convergent to φ. In fact,\nSn(φ) -φ\n\nu ≤\nX\n|m|>n\n(φ, em)L2(λ[0,1);C)\n.\nProof. That the series if uniformly absolutely convergent is obvious. To see that\nit must be converging to φ, let ψ be uniform limit of {Snφ : n ≥0}. Then ψ is\ncontinuous and, because φ is the L2(λ[0,1); C) limit of this series, ψ = φ λ[0,1]-almost\neverywhere, which, since both are continues, means that they are equal everywhere.\nGiven these statements, the final estimate is trivial.\n□\nLemma 1.4. Let l≥1 and assume that φ ∈Cl([0, 1]; C) satisfies φ(k)(0) = φ(k)(1)\nfor 0 ≤k ≤l-1. Then\n(φ, em)L2(λ[0,1);C) =\n\nı\n2πm\nlφ(l), em\n\nL2(λ[0,1);C) for m = 0.\nProof. Clearly it suffices that prove the result when l= 1. To do so, use integration\nby parts and the condition φ(0) = φ(1) to check that\nZ 1\nφ(y)e-m(y) dy =\n-ı2πm\nZ 1\nφ′(y)e-m(y) dy.\n□\nAs a consequence of Lemma 1.4, we see that if φ ∈C1([0, 1]; C) satisfies φ(0) =\nφ(1), then\nX\n|m|>n\n(φ, em)L2(λ[0,1);C)\n≤\nX\n|m|>n\n(φ′, em)L2(λ[0,1);C)\n\n2π|m|\n≤1\n2π\n\nX\nm>n\nm-2\n! 1\n∥φ′∥L2(λ[0,1);C) ≤\n∥φ′∥L2(λ[0,1);C)\nπ(2n)\n.\nHence, by Corollary 1.3,\n∥Snφ -φ∥u ≤∥φ′∥u\nπ(2n)\n2 .\nExercise 1.1. Prove the Riemann-Lebesgue lemma, which is the statement that\nlimn→inf(φ, en)L2(λ[0,1);C) = 0 for all φ ∈L1(λ[0,1); C).\nExercise 1.2. Let φ be a Lipschitz continuous function satisfying φ(0) = φ(1),\nand show that\nSnφ -φ∥u ≤∥φ∥Lip\nπ(2n)\n2 .\nHint: Introduce the functions φk = p 1\nk ∗φ.\n\nTOPICS IN FOURIER ANALYSIS\n2. Gibbs Phenomenon\nHere we will examine what can be said for a φ ∈C([0, 1]; C) that is not periodic.\nFor example, consider the function φ(x) = x for x ∈[0, 1]. Clearly\n(φ, em)L2(λ[0,1);C) =\nı\n2πm for m = 0,\nand so\nSn(x) = 1\n2 -1\nπ\nn\nX\nm=1\nsin 2πmx\nm\n,\nwhere Sn ≡Snφ. Now set\nΦm(x) =\nm\nX\nk=1\nsin 2πkx.\nThen Φm(x) is the imaginary part of\nm\nX\nk=1\nek(x) = e1(x)1 -em(x)\n1 -e1(x) =\ne1(x) -em+1(x)1 -e-1(x)\n2(1 -cos 2πx)\n= e1(x) -1 -em+1 + em(x)\n2(1 -cos 2πx)\n,\nwhich is\nsin 2πx -sin 2π(m + 1)x + sin 2πmx\n2(1 -cos 2πx)\n.\nAfter using some of trigonometric identities, one sees that\n(2.1)\nΦm(x) = cos πx sin2 πmx\nsin πx\n+ sin πmx cos πmx.\nIn particular, |Φm(x)| ≤3 1\nx ∨\n1-x\n.\nSumming by parts, one sees that\nSn(x) = 1\n2 -Φn(x)\nπn\n-\nn-1\nX\nm=1\nΦm(x)\nπm(m + 1),\nwhich means that\n(2.2)\nSn(x) -x\n≤ 1\nx ∨\n1-x\nπn.\nIn particular, Sn(x) is converging to x uniformly on compact subsets of (0, 1).\nTo see what happens for x near to 0, consider x =\nk\n2n for k ≥1, and observe\nthat\nn\nX\nm=1\nsin πkm\nn\nm\n= 1\nn\nn\nX\nm=1\nsin πkm\nn\nm\nn\n-→\nZ\n[0,1]\nsin πkx\nx\ndx -→\nZ\n[0,πk]\nsin x\nx\ndx.\nHence, since (cf. (7.11) in §7)\nlim\nR→inf\nZ\n[0,R]\nsin x\nx\ndx = π\n2 ,\n\nDANIEL W. STROOCK\nSn\nk\n2n\n= -1\nπ lim\nR→inf\nZ\n[πk,R]\nsin x\nx\ndx\n= (-1)k+1\nπ2k\n-1\nπ\nZ\n[πk,inf)\ncos x\nx2\ndx = (-1)k+1\nπ2k\n+ 2\nπ\nZ\n[πk,inf)\nsin x\nx3\ndx\nas n →inf. Therefore\nSn\nk\n2n\n= (-1)k+1\nπ2k\n\n1 -ak\nπk\n\n+ εn(k),\nwhere\nak = (-1)k2(πk)2\nZ inf\nπk\nsin x\nx3\ndx ∈(-1, 1)\nand limn→infεn(k) = 0. This shows that, for large n, Sn\nk\n2n\nis at least\n2π2k if k is\nodd and at most -\n2π2k if k is even. This sort of oscillatory behavior is known as\nGibbs's phenomenon, although Gibbs seems not to have been the first to discover\nit.\nExercise 2.1. By considering Sn\nand using equations (2.1) and (2.2), show\nthat\nπ = 8\ninf\nX\nl=0\n(4l+ 1)(4l+ 3).\nExercise 2.2. Show that if φ ∈C1[0, 1]; C then,\nsup\nx∈[n-1\n2 ,1-n-1\n2 ]\nSnφ(x) -φ(x)\n≤\n8∥φ′∥L2(λ[0,1);C)\nπn\n.\n3. Bernoulli Polynomials\nTheorem 3.1. Define {bl: l≥0} ⊆R inductively by\nb0 = 1 and bl+1 =\nl\nX\nk=0\n(-1)kbl-k\n(k + 2)! ,\nand set\n(3.1)\nBl(x) =\nl\nX\nk=0\n(-1)kbl-k\nk!\nxk for l≥0.\nThen {Bl: l≥0} are the one and only functions satisfying\n(3.2)\nB0 = 1, B′\nl+1 = -Blfor l≥0, and Bl(1) = Bl(0) for l≥2.\nProof. To see that there is at most one set of functions satisfying (3.2), let {Dl:\nl≥0} be the set of differences between two solutions, and set l= inf{l: Dl= 0}.\nThen l≥1, and, if l< inf, then Dlis a constant a and there is a b ∈R such that\nDl+1(x) = -ax + b. But -a + b = Dl+1(1) = Dl+1(0) = b, and therefore a = 0.\nSince this would mean that Dl= -D′\nl+1 = 0, no such lcan exist.\n\nTOPICS IN FOURIER ANALYSIS\nBy definition, B0 = 1, and it is easy to check that B′\nl+1 = -Bl. To verify the\nperiodicity property, note that\nBl+2(1) -Bl+2(0) =\nl+2\nX\nk=1\n(-1)kbl+2-k\nk!\n= -bl+1 +\nl+2\nX\nk=2\n(-1)kbl+2-k\nk!\n= -bl+1 +\nl\nX\nk=0\n(-1)kbl-k\n(k + 2)!\n= 0.\n□\nThe functions {Bl: l≥0} in (3.1) are known as Bernoulli polynomials.\nTheorem 3.2. For l≥2 and x ∈[0, 1],\n(3.3)\nBl(x) = -ıl\n(2π)l\nX\nn=0\nen(x)\nnl\n.\nIn particular, b2l+1 = 0 and\n(3.4)\nζ(2l) ≡\ninf\nX\nm=1\nm2l= (-1)l+122l-1π2lb2l\nfor l≥1.\nProof. First observe that, for l≥1,\nBl, e0\n\nL2(λ[0,1];C) = -\nZ 1\nB′\nl+1(x) dx = Bl+1(0) -Bl+1(1) = 0\nand, for l≥2 and n = 0,\nBl, en\n\nL2(λ[0,1];C) =\nı\n2πn\nBl-1, en\n\nL2(λ[0,1];C)\nand therefore\nA2πn\nı\nal-1 Bl, en\n\nL2(λ[0,1];C) = B1, en\n\nL2(λ[0,1];C) =\nZ 1\n2 -xe-n(x) dx = -ı\n2πn.\nHence\nBl, en\n\nL2(λ[0,1];C) =\n-ıl\n(2πn)l\nfor l≥2 and n = 0, which completes the proof of (3.3). Finally, because bl= Bl(0),\nit is clear from (3.3) that b2l+1 = 0 and that (3.4) holds.\n□\nBesides (3.4), the Bernoulli polynomials play a critical role in what is known as\nthe Euler-Maclauren formula:\n(3.5)\nZ n\nf(x) dx -\nn\nX\nm=1\nf(m)\n= -\nl\nX\nk=1\nbk\nf (k-1)(n) -f k-1(0) +\nZ n\nBl(x)f (l)(x) dx\nfor l≥1,\n\nDANIEL W. STROOCK\nwhere Blis the periodic extension of Bl↾[0, 1) to R. To prove (3.5), first note that\nZ n\nf(x) dx -\nn\nX\nm=1\nf(m) =\nn\nX\nm=1\nZ m\nm-1\nf(x) -f(m) dx\n= -\nn\nX\nm=1\nZ m\nm-1\nx -(m -1)f ′(x) dx\n=\nn\nX\nm=1\nA\n-b1\nf(m) -f(m -1) +\nZ m\nm-1\nB1\nx -(m -1)f ′(x) dx\na\n= -b1\nf(n) -f(0) +\nZ n\nB1(x)f ′(x) dx.\nHence, (3.5) holds when l= 1. Next observe that for any l≥1,\nZ n\nBl(x) = n\nZ 1\nBl(x) dx = nBl+1(1) -Bl+1(0) = 0,\nand therefore\nZ n\nBl(x)f (l)(x) dx =\nn\nX\nm=1\nZ m\nm-1\nBl\nx -(m -1)f (l)(x) -f (l)(m) dx\n=\nn\nX\nm=1\nA\n-bl+1\nf (l)(m) -f (l)(m -1) +\nZ m\nm-1\nBl+1\nx -(m -1)f (l+1)(x) dx\na\n= -bl+1\nf (l)(n) -f(0) +\nZ n\nBl+1(x)f (l+1)(x) dx.\nTherefore, (3.5) for limplies (3.5) for l+ 1.\nTheorem 3.3. If l≥1 and φ ∈Cl[0, 1]; C, then\n(3.6)\nZ 1\nφ(x) -1\nn\nn\nX\nm=1\nφ m\nn\n\n= -\nl\nX\nk=1\nbk\nnk\nφ(k-1)(1) -φ(k-1)(0) + 1\nnl\nZ 1\nBl(nx)φ(l)(x) dx,\n.\nProof. Take f(x) = φ x\nn\n, apply (3.5) to f, and make a simple change of variables.\n□\nBy Schwarz's inequality,\n\nZ 1\nBl(nx)φ(l)(x) dx\n≤\nCZ 1\nBl(nx)2 dx\na 1\n∥φ(l)∥L2(λ[0,1];C),\nand\nZ 1\nBl(nx)2 dx = 1\nn\nZ n\nBl(x)2 dx = ∥Bl∥2\nL2(λR;C).\nFurther, by (1.2) and (3.3),\n∥Bl∥2\nL2(λR;C) =\n(2π)2l\nX\nn=0\nn2l.\n\nTOPICS IN FOURIER ANALYSIS\nHence, by (3.6),\n(3.7)\n\nZ 1\nφ(x) dx -1\nn\nn\nX\nm=1\nφ m\nn\n+\nl\nX\nk=1\nbk\nnk\nφ(k-1)(1) -φ(k-1)(0)\n\n≤\np\n2ζ(2l)\n(2πn)l∥φ(l)∥L2(λ[0,1];C).\nFrom (3.7) one sees that if, for some n ≥1,\n(3.8)\nlim\nl→inf\n∥φ(l)∥L2(λ[0,1];C)\n(2πn)l\n= 0,\nthen\nZ 1\nφ(x) dx -1\nn\nn\nX\nm=1\nφ m\nn\n= -lim\nl→inf\nl\nX\nk=1\nbk\nnk\nφ(k-1)(1) -φ(k-1)(0).\nIn particular, if φ ∈Cinf[0, 1]; C and φ(k) is periodic for all k ≥0, then (3.8)\nimplies that\nZ 1\nφ(x) dx = 1\nn\nn\nX\nm=1\nφ m\nn\n,\na result that has a much simpler derivation (cf. Exercise 3.1 below).\nMore generally, because\nφ(k-1)(1) -φ(k-1)(0)\n≤∥φ(k)∥L2(λ[0,1];C) and |bk| ≤\n(2π)k ,\ninf\nX\nk=1\n∥φ(k)∥L2(λ[0,1];C)\n(2πn)k\n< inf\nimplies that\n(3.9)\nZ 1\nφ(x) dx -1\nn\nn\nX\nm=1\nφ m\nn\n= -\ninf\nX\nk=1\nbk\nnk\nφ(k-1)(1) -φ(k-1)(0),\nwhere the series is absolutely convergent.\nExercise 3.1. Suppose that φ and all its derivatives are periodic on [0, 1], and\nshow that\nlim\nl→inf\n∥φ(l)∥L2(λ[0,1];C)\n(2πn)l\n= 0 ⇐⇒φ, em\n\nL2(λ[0,1];C) = 0 if |m| ≥n\n⇐⇒φ =\nX\n|m|<n\nφ, em\n\nL2(λ[0,1];C)em.\nNext, show that\nn\nn\nX\nj=1\nem\nj\nn\n= 0\nfor 1 ≤|m| < n, and thereby arrive at the conclusion reached above.\n\nDANIEL W. STROOCK\n4. Comparing Summability Methods\nIn preparation for the following section, we will review here basic definitions and\nresults for different notions of convergence of a series.\nGiven a sequence {am : m ≥1} ⊆C, set\nSn =\nn\nX\nm=1\nam and An = 1\nn\nn\nX\nm=1\nSm,\nand when limn→inf|am|\nm ≤1, set\nA(r) =\ninf\nX\nm=1\namrm-1 for r ∈[0, 1).\nThe Sn's are called the partial sums of the corresponding series, the An's are its\nC esaro means, and r ⇝A(r) is its Abel function. The series is said to be summable\nto s ∈C if s = limn→infSn, it is C esaro summable to s ∈C if limn→infAn = s, and\nit is Abel summable to s ∈C if s = limr↗1 A(r)\nHere we will show that\nsummable to s =⇒C esaro summable to s =⇒\nlim\nm→inf\nam\nm = 0 and Abel summable to s.\nThe Exercise 4.1 below outlines a proof that neither implication can be reversed.\nThe first implication is trivial. To prove the second, assume C esaro summability,\nand note that\nan\nn = An -An-1 + An-1\nn\n-→0.\nNext, write\nam =\n\nA1\nif m = 1\n2A2 -A1\nif m = 2\nmAm -2(m -1)Am-1 + (m -2)Am-2\nif m ≥3,\nand therefore\nA(r) =\ninf\nX\nm=1\nmrm-1Am -2\ninf\nX\nm=2\n(m -1)rm-1Am-1 +\ninf\nX\nm=3\n(m -2)rm-1Am-2\n=\ninf\nX\nm=1\n(rm-1 -2rm + rm+1)mAm = (1 -r)2\ninf\nX\nm=1\nmrm-1Am.\nNow observe that\nn\nX\nm=1\nmrm-1 = ∂r\nn\nX\nm=0\nrm = ∂r\n1 -rn\n1 -r = 1 -rn -n(1 -r)rn-1\n(1 -r)2\n.\nHence,\n(1 -r)2\nn\nX\nmrm-1 ≤1 -rn and (1 -r)2\ninf\nX\nmrm-1 = 1.\n\nTOPICS IN FOURIER ANALYSIS\nAssume that An -→s, and, given ε > 0, choose n so that |Am -s| ≤ε for m > n.\nThen\nA(r) -s\n= (1 -r)2\n\ninf\nX\nm=1\nmrm-1(Am -s)\n≤(1 -r)2\nn\nX\nm=1\nmrm-1|Am -s| + ε\n≤(1 -rn) max\n1≤m≤n |Am -s| + ε,\nand therefore limr↗1 |A(r) -s| ≤ε.\nExercise 4.1. Show that\n(i) the series for {(-1)m-1 : m ≥1} is C esaro summable to 1\n2 but not summable,\n(ii) the series for {(-1)m-1m : m ≥1} is Abel summable to 1\n4 but not C esaro\nsummable. In fact, show that A2n = 0 and A2n+1 =\nn+1\n2n+1 -→1\n2.\n5. Some Refinements\nIn this section we will apply the notions of summability discussed in the previous\nsection to Fourier series. Observe that we have already considered Abel summability\nin §1.\nTo examine further when the series is summable, introduce the function\nDn(x) =\nX\n|m|≤n\nem(x) for x ∈R.\nThen Dn, which is often called the Dirichlet kernel, is an even, periodic function\nwith period 1,\nR 1\n0 Dn(x) dx = 1, and Snφ = Dn ∗φ. In addition\nDn(x) = e-n(x)\n2n\nX\nm=0\nem(x) = e-n(x)1 -e2n+1(x)\n1 -e1(x)\n= e-ıπ(2n+1)x -eıπ(2n+1)x\ne-ıπx -eıπx\n= sin π(2n + 1)x\nsin πx\n.\nHence,\nSnφ(x) -φ(x) =\nZ\n[0,1]\nφ(x + y) -φ(x)\nsin πy\nsin π(2n + 1)y dy.\nNow suppose that φ is an R-valued function for which φ(0) = φ(1), and assume\nthat φ ∈Cα[0, 1]; C) 4 is H older continuous of order α ∈(0, 1). Set\nψ(y) = eıπy φ(x + y) -φ(x)\nsin πy\n.\nThen ψ ∈L1(λ[0,1); C) and Snφ(x) -φ(x) is the imaginary part of\nZ\n[0,1]\nψ(y)e-2n+1(y) dt = ψ, e2n-1\n\nL2(λ[0,1);C),\nand so, by the Riemann-Lebesgue lemma (cf. Exercise 1.1), Snφ(x) -→φ(x) as\nn →inf. The preceding shows that if φ ∈Cα[0, 1]; C satisfies φ(0) = φ(1), then\nSnφ -→φ pointwise, but it does not provide a rate of convergence or even say if\nthe convergence is uniform.\n4Cα(E; C) space of C-valued functions on a metric space E which are uniformly H older con-\ntinuous of order α ∈(0, 1).\n\nDANIEL W. STROOCK\nC esaro summability of Fourier series was initiated by Fej er. Obviously,\nn\nn-1\nX\nm=0\nSmφ = Fn ∗φ,\nwhere\nFn(x) ≡1\nn\nn-1\nX\nm=0\nDn(x).\nThe function Fn is called the Fej er kernel, and it is clear that Fn is a continuous,\neven function of period 1 for which\nR\n[0,1] Fn(x) dx = 1. In addition, nFn(x) sin πx\nis the imaginary part of\neıπx\nn-1\nX\nm=0\ne2m(x) = eıπx 1 -eıπ2nx\n1 -eı2πx = ı(1 -eı2πnx)\n2 sin πx\n,\nand so\n(5.1)\nFn(x) = 1 -cos 2πnx\n2n sin2 πx\n= 1\nn\nAsin πnx\nsin πx\na2\n.\nProceeding as in the proof of Theorem 1.1, one sees that\nFn ∗φ(x) -φ(x) =\nZ\n[0,1]\nFn(y) φ(x + y) -φ(x) dx -→0\nuniformly if φ is continuous and satisfies φ(1) = φ(0). Equivalently,\nlim\nn→inf\n\nn\nn-1\nX\nm=0\nSmφ -φ\n\nu\n= 0.\nIt turns out that one can do much better.\nTheorem 5.1. Let φ : [-1\n2, 1\n2] -→C be a measurable function, let x ∈-1\n2, 1\n, and\nassume that there is a C ∈(0, inf) and α ∈(0, 1] such that | φ(x+y)-φ(x)| ≤C|y|α\nfor y ∈-1\n2, 1\n. For n ≥5\n(5.2)\nFn ∗φ(x) -φ(x)\n≤C\n(\n(1+α)nα + 4(n1-α-41-α)\nπ2(1-α)n\n+ 1-2-(1+α)\n2α(1+α)n\nif α ∈(0, 1)\n16n +\n4 log n\nπ2n(1-α)\nif α = 1.\nHence\nlim\nn→infnα|Fn ∗φ(x) -φ(x)\n≤\n1 + α +\nπ2(1 -α)\nif α ∈(0, 1)\nand\nlim\nn→inf\nn\nlog n|Fn ∗φ(x) -φ(x)\n≤4\nπ2\nif α = 1.\nProof. Without loss in generality, I will assume that C = 1.\nThe proof turns on the estimates\n(5.3)\nFn(y) ≤\n\nn\nfor all y ∈-1\n2, 1\n\nπ2ny2\nwhen |y| ∈0, 1\n\nn\nwhen |y| ∈ 1\n4, 1\n\nTOPICS IN FOURIER ANALYSIS\nThat Fn(y) ≤n is clear from the fact that ∥Dm∥u ≤1 and therefore that nFn(y) ≤\n2 Pn-1\nm=1 m + n = n2.\nTo see second inequality, note that cos πt ≥2-1\n2 when\n|y| ∈0, 1\nand therefore that\n| sin πy| =\nZ π|y|\ncos t dt ≥2-1\n2 π|y|.\nAs for Fn(y) ≤2\nn when |y| ∈ 1\n4, 1\n, simply remember that | sin πy| ≥2-1\n2 for such\ny's.\nAssume that α ∈(0, 1). Because\nR 1\n-1\n2 Fn(y) = 1\nFn ∗φ(x) -φ(x)\n≤\nZ\n-1\nFn(y)\nφ(x + y) -φ(x)\ndy\n≤n\nZ\nn\n|y|α dy +\nπ2n\nZ\nn\n|y|α-2 dy + 2\nn\nZ\n4 ≤|y|≤1\n|y|α dy\n≤\n(1 + α)nα + 4(n1-α -41-α)\nπ2(1 -α)n\n+ 1 -2-(1+α)\n2α(1 + α)n .\nIf α = 1, the top line in (5.2) holds for all α ∈(0, 1), and therefore one need\nonly examine what happens as α ↗1. Clearly\n(1+α)nα ↘1\nn and 1-2-(1+α)\n2α(1+α)n ↘\n16n\nas α ↗1. To handle the remaining term, note that it can be written as\n42-α\nπ2n\nn\n1-α -1\n1 -α\nwhich decreases to 4 log n\nπ2n\nas α ↗1.\n□\nOne could of course have derived the estimate when α = 1 directly by the same\nargument as was used when α < 1. However, the derivation given has the advantage\nthat it shows the estimates get stronger for all n ≥5, not just asymptotically, as α\nincreases.\nObviously, results like those in Theorem 5.1 turn on the continuity properties of\nφ, properties that a generic element of L1(λ[0,1); C) will not possess. Nonetheless,\nLebesgue showed that every locally λR-integrable φ does have a continuity property\nat almost everywhere point. Namely, he showed that\nlim\nr↘0\nr\nZ r\n| φ(x ± t) -φ(x)| dt = 0\nfor λR-almost every x ∈R,\nand he used this fact to prove the following theorem.\nTheorem 5.2. If φ ∈ L1λ[-1\n2 , 1\n2 ]; C, then\nlim\nn→infFn ∗φ(x) = φ(x) for λ[-1\n2 , 1\n2 ]-almost every x ∈[0, 1].\nProof. Set φx(y) = | φ(x + y) -φ(x)| and\nΦx(y) = 1\n|y|\nZ |y|\nφx(sgn(y)t) dt.\nBy Lebesgue's theorem, lim|y|↘0 Φx(y) = 0 for λ[-1\n2 , 1\n2 ]-almost every x ∈-1\n2, 1\n.\n\nDANIEL W. STROOCK\nLet x be such a point. Then\nFn ∗φ(x) -φ(x)\n≤\nZ 0\n-1\nFn(y)φx(y) dy +\nZ\nFn(y)φx(y) dy.\nWe will show only that limn→inf\nR 1\n0 Fn(y)φx(y) dy = 0 because the proof that\nlimn→inf\nR 0\n-1\n2 Fn(y)φx(y) dy = 0 is essentially the same.\nUsing our estimates for Fn in (5.3), one has\nZ\nFn(y)φx(y) dy =\nZ\nn\nFn(y)φx(y) dy +\nZ\nn\nFn(y)φx(y) dy\n≤n\nZ\nn\nφx(y) dy + 2\nn\nZ\nn\nφx(y)\ny2\ndy.\nSince\nn\nZ\nn\nφx(y) dy = Φx\nn\n,\nthe first term tends to 0. As for the second, use integration by parts to see that it\nis dominated by\n4Φx\n\nn\n+ 4\nn\nZ\nn\nΦx(y)\ny2\ndy.\nFinally, given ε > 0, choose δ ∈0, 1\nso that Φx(y) ≤ε for 0 ≤y ≤δ. Then, for\nn > 1\nδ ,\nn\nZ\nn\nΦx(y)\ny2\ndy ≤ε\nn\nZ δ\nn\ny2 dy + 1\nn\nZ\nδ\nΦx(y)\ny2\ndy ≤2ε + ∥Φx∥u\nδn\n,\nand so\nlim\nn→inf\nZ\nFn(y)φx(y) dy ≤4ε.\n□\nTheorem 5.2 is a stark contrast to a famous example produced in 1926 by Kol-\nmogorov5 of a function in L1λ[-1\n2 , 1\n2 ]; C for which {Snφ(x) : n ≥0} diverges\nat every x. It is also interesting to compare it to more recent results by L. Car-\nleson and R. Hunt.\nNamely, Carleson showed that Snφ -→φ (a.e.,λ[-1\n2 , 1\n2 ]) if\nφ ∈L2λ[-1\n2 , 1\n2 ]; C, and Hunt showed that the same is true for φ ∈Lpλ[-1\n2 , 1\n2 ]; C\nfor p ∈(1, inf).\nExercise 5.1. Show that\nlim\nn→inf\nnα\nZ\n-1\nFn(y)|y|α dy > 0 for α ∈(0, 1)\nand that\nlim\nn→inf\nn\nlog n\nZ\n-1\nFn(y)|y| dy > 0.\n5A.N. Kolmogorov, Une s erie de Fourier-Lebesgue divergente partout, C.R. 183 (1926),\npp. 1327-1328.\n\nTOPICS IN FOURIER ANALYSIS\nHence the rates given Theorem 5.1 are optimal.\nHint: If 0 ≤m ≤n -1, show that\nFn(y) ≥\n2π2ny2 if 4m + 1\nn4\n≤y ≤2m + 1\n2n\n.\n6. The L1 Fourier Transform\nBy an easy rescaling argument, one knows that, for any L ∈Z+ and f ∈\nC1([-L, L]; C) satisfying f(-L) = f(L),\nf(x) = 1\n2L\nX\nm∈Z\nZ L\n-L\neı 2πm(y-x)\n2L\nf(y) dy = lim\nR→inf\nZ L\n-L\nN\n2L\nX\n|m|≤R\neı 2πm(y-x)\n2L\ne\nf(y) dx.\nNow suppose that f ∈C1\nc (R; C). Then\nf(x) = lim\nL→inflim\nR→inf\nZ L\n-L\nN\n2L\nX\n|m|≤R\neı 2πm(y-x)\n2L\ne\nf(y) dy.\nThus, if one can justify reversing the order in which the limits are taken, one would\nhave that\nf(x) = lim\nR→inf\nZ CZ R\n-R\neıξ2π(x-y) dξ\na\nf(y) dy\n= lim\nR→inf\n2π\nZ 2πR\n-2πR\ne-ıξx\nAZ\neıξyf(y) dy\na\ndξ.\nIn other words, there is reason to hope that, under suitable conditions on f,\n(6.1)\nf(x) = 1\n2π\nZ\ne-ıξx ˆf(ξ) dξ where ˆf(ξ) ≡\nZ\neıξyf(y) dy.\nThe function ˆf is called the Fourier transform of f, and our primary goal here\nwill be to find out in what sense (6.1) is true, first when f ∈L1(λR; C) and then\nwhen f ∈L2(λR; C). However, we will begin with some computations involving ˆf\nthat don't require our knowing when (6.1) holds.\n7. Computations and Applications of L1 Fourier Transforms\nIf f ∈L1(λR; C), then it is clear that ˆf is continuous and that\n(7.1)\n∥ˆf∥u ≤∥f∥L1(λR;C).\nLemma 7.1. If f ∈C1(R, C) ∩L1(λR; C) and f ′ ∈L1(λR; C), then\n(7.2)\n\"\nf ′(ξ) = -ıξ ˆf(ξ).\nProof. If f has compact support, then (7.2) is an easy application of integration by\nparts. To prove it under the given conditions, choose a function η ∈CinfR; [0, 1]\nfor which η(y) = 1 when y ∈[-1, 1] and η(y) = 0 when y /∈[-2, 2], and set\nfn(y) = η y\nn\nf(y). Then fn -→f and f ′\nn -→f ′ in L1(λR; C) and so\n\"\nf ′(ξ) = lim\nn→inf\nc\nf ′n(ξ) = -ıξ lim\nn→inf\nc\nfn(ξ) = -ıξ ˆf(ξ).\n□\n\nDANIEL W. STROOCK\nAs a consequence of Lemma 7.1, it is easy to prove the Riemann-Lebesgue lemma\nin this context. Namely, (7.2) makes it clear for compactly support f ∈C1(R; C),\nand (7.1) makes it clear that the set of f's for which it is holds is closed in L1(λR; C).\nWe next turn to the computation of ˆf in two important cases.\nSet gt(x) = (2πt)-1\n2 e-x2\nfor (t, x) ∈(0, inf) × R, and check that ∂tgt(x) =\n2∂2\nxgt(x). Hence, for any ζ ∈C, integration by parts leads to\n∂t\nZ\neζxgt(x) dx = 1\nZ\neζx∂2\nxgt(x) dx = ζ2\nZ\neζxgt(x) dx.\nSince\nZ\neζxgt(x) dx =\nZ\net\n2 ζxg1(x) dx -→1\nas t ↘0,\nZ\neζxgt(x) dx = e\ntζ2\n2 .\nIn particular\n(7.3)\n\"\ngt(ξ) = e-ξ2\nEquivalently, \"\ngt = 2π\nt\n2 g 1\nt and so\n(7.4)\nbgt)∧= 2πgt.\nSet py(x) = 1\nπ\ny\nx2+y2 for (y, x) ∈(0, inf) × R, and note that\nZ\npy(x) dx =\nZ\np1(x) dx = 1 for all y > 0.\nIn addition, because py(x) is the real part of\nı\nπz with z = x + ıy, (x, y) ⇝py(x) is\nharmonic. Thus, ∂2\nxpy = -∂2\nypy, and so, by (7.2),\n∂2\ny \"\npy(ξ) = ξ2 \"\npy(ξ).\nThus, for each ξ,\n'\npy(ξ) = a(ξ)eyξ + b(ξ)e-yξ,\nwhere, since \"\npy(0) = 1, a(ξ) + b(ξ) = 1. Because |'\npy(ξ)| ≤1, ξ ≥0 =⇒a(ξ) =\n0 & b(ξ) = 1 and ξ < 0 =⇒a(ξ) = 1 & b(ξ) = 0. Hence\n(7.5)\n\"\npy(ξ) = e-y|ξ|.\nHere is an interesting application of equations (7.3) and (7.5). Since\nξ2 + y2 =\nZ inf\ne-t(ξ2+y2) dx =\nZ inf\ne-ty2\"\ng2t(ξ) dt\nand \"\ng2t\n∧= 2πg2t,\nπ\ny e-y|x| = 2π\nZ inf\ne-ty2g2t(x) dt = π\nZ inf\nt-1\n2 e-ty2e-x2\n4t dt.\nThus, for x, y ∈(0, inf),\n(7.6)\nZ inf\nt-1\n2 e-ty2e-x2\nt dt = π\n2 e-2yx\ny\n,\na computation which can also be done using a somewhat tricky change of variables.\n\nTOPICS IN FOURIER ANALYSIS\nTheorem 7.2. (Poisson Sum) Let f ∈L1(λR; C) ∩C(R; C), and assume that\nX\nn∈Z\nC\nsup\nx∈[0,1]\n|f(x + n)| + | ˆf(2πn)|\na\n< inf.\nThen\n(7.7)\nX\nn∈Z\nf(n) =\nX\nn∈Z\nˆf(2πn).\nProof. Define f(x) = P\nn∈Z f(x + n). Then f is a continuous periodic function\nwith period 1, and\nf, em\n\nL2(λ[0,1];C) =\nX\nn∈Z\nZ 1\ne-ı2πmxf(x + n) dx =\nZ\ne-ı2πmxf(x) dx = ˆf(-2πm).\nThus, P\nm∈Z\n( f, em)L2(λ[0,1];C)\n< inf, and therefore\nf(x) =\nX\nm∈Z\nˆf(-2πm)em(x) =\nX\nm∈Z\nˆf(2πm)e-m(x),\nwhere the convergence of the series is absolute and uniform. By taking x = 0, (7.7)\nfollows.\n□\nEquation (7.7) is known as the Poisson summation formula. Among its many\napplications is the following.\nWhen f = py, (7.7) says that\ny\nπ\nX\nn∈Z\ny2 + n2 =\nX\nn∈Z\ne-2πy|n| = 1 + e-2πy\n1 -e-2πy = coth πy,\nand so\n(7.8)\nX\nn∈Z\ny2 + n2 = π coth πy\ny\nfor y > 0.\nA famous application of (7.8) is Euler's product formula:\n(7.9)\nsin πx = πx\ninf\nY\nm=1\nA\n1 -x2\nm2\na\n.\nTo prove it, first observe that\nx2 + m2 = 1\n2x∂x logx2 + m2 = 1\n2x∂x log\nA\n1 + x2\nm2\na\nfor m = 0\nand that π coth πy = ∂y log(sinh πy). Hence, by (7.8)\nx∂x log\ninf\nY\nn=1\nA\n1 + x2\nn2\na\n+ 1\nx2 = 1\nx∂x log(sinh πx),\nwhich means that\n∂x log\ninf\nY\nn=1\nA\n1 + x2\nn2\na\n= ∂x log(x-1 sinh πx).\n\nDANIEL W. STROOCK\nIntegrating both sides from 0 to x, one gets\nlog x\ninf\nY\nn=1\nA\n1 + x2\nn2\na\n= log(sinh πx) -log π = log sinh πx\nπx\n,\nwhich means that\n(7.10)\nsinh πx = πx\ninf\nY\nn=1\nA\n1 + x2\nn2\na\nfrom which (7.9) follows by analytic continuation.\nAnother application of (7.5) is a proof6 that\n(7.11)\nlim\nR→inf\nZ R\n-R\nsin ξx\nx\ndx = sgn(ξ)π\nfor ξ = 0.\nWe begin with the more or less trivial observation that\nZ R\n-R\nsin ξx\nx\ndx = sgn(ξ)\nZ R\n-R\nsin |ξ|x\nx\ndx = sgn(ξ)\nZ |ξ|R\n-|ξ|R\nsin x\nx\ndx.\nThus, what we have to show is that\nlim\nR→inf\nZ R\n-R\nsin x\nx\ndx = π.\n(∗)\nThe first step in the proof (∗), is to show that if\ngR(ξ, y) ≡\nZ R\n-R\nx sin ξx\nx2 + y2 dx -→πe-yξ\nfor ξ > 0,\n(∗∗)\nthen (∗) holds. Indeed,\n\nZ R\n-R\nsin ξx\nx\ndx -gR(ξ, y)\n≤2y2\n\nZ inf\n| sin ξx|\nx(x2 + y2) dx\na\n≤ξπy,\nand so (∗∗) implies (∗).\nThe next step is to show that for each y > 0 there exists a continuous ξ ∈\n(0, inf) 7-→g(ξ, y) ∈C such that gR(ξ, y) -→g(ξ, y) uniformly for ξ compact\nsubsets of (0, inf). To this end, note that\ngR(ξ, y) = 2\nZ R\nx sin ξx\nx2 + y2 dx = 2\nξ\nC\n-R cos ξR\nR2 + y2 + 2\nZ R\n(y2 -x2) cos ξx\n(x2 + y2)2\ndx\na\n-→4\nξ\nZ inf\n(y2 -x2) cos ξx\n(x2 + y2)2\ndx\nuniformly for ξ in compacts subsets of (0, inf).\nThe final step is the identify g(ξ, y) as πe-yξ. For this purpose, observe that\ngR(ξ, y) = -ı\nZ R\n-R\nxeıξx\nx2 + y2 dx = ∂ξfR(ξ, y)\nwhere\nfR(ξ, y) = -π\ny\nZ R\n-R\npy(x)eıξx dx -→-π\ny e-yξ.\n6The most commonly given proof is based on contour integration and Cauchy's theorem.\n\nTOPICS IN FOURIER ANALYSIS\nHence\nfR(η) -fR(ξ) =\nZ η\nξ\ngR(t, y) dt,\nand therefore\nπ\ny\ne-yξ -e-yη =\nZ η\nξ\ng(t, y) dt,\nfrom which g(ξ, y) = πe-yξ follows easily.\nExercise 7.1. Show that if f ∈L1(λR; C) and ft(x) = t-1ft-1x), then ˆft(ξ) =\nˆf(tξ).\nExercise 7.2. Show that if f ∈C2(R; C) ∩L1(λR; C) and both f ′ and f ′′ are in\nL1(λR; C), then ˆf ∈L1(λR; C).\nExercise 7.3. Using cosh t = 1+ t2\n2 +O(t4) and sinh t = t+ t3\n6 +O(t5), prove from\n(7.8) that Pinf\nn=1\nn2 = π2\n6 .\nExercise 7.4. Show that\nX\nn∈Z\ne-πn2\nt\n= t\n2 X\nn∈Z\ne-πtn2,\na formula that plays an important role in the theory of Theta functions.\n8. The L1 Fourier Inversion Formula\nHere we will see to what extent (6.1) can be justified, and the idea is to use the\nfact that we already know (cf. (7.4)) that it holds for gt. With this in mind, we\nhave, by Fubini's theorem,\n2πgt ∗f(x) = 2π\nZ\ngt(y)f(x -y) dy = 2π\nZ\ngt(y)f(x + y) dy\n=\nZ\n(bgt)∧(y)f(x + y) dy =\nZ\n\"\ngt(ξ)\nAZ\neıξyf(x + y) dy\na\ndξ =\nZ\ne-tξ2\n2 e-ıξx ˆf(ξ) dξ,\nand so\ngt ∗f(x) = 1\n2π\nZ\ne-tξ2\n2 e-ıξx ˆf(ξ) dξ.\nLet f ∈L1(λR; C). If f is continuous at x, then limt↘0 gt ∗f(x) = f(x), and so\n(8.1)\nf(x) = 1\n2π lim\nt↘0\nZ\ne-tξ2\n2 e-ıξx ˆf(ξ) dξ\nif f is continuous at x.\nIn particular\n(8.2)\nf(x) = 1\n2π\nZ\ne-ıξx ˆf(ξ) dξ\nif ˆf ∈L1(λR; C).\nMore generally, for any f ∈L1(λR; C), gt ∗f -→f in L1(λR; C), and so\n(8.3)\n2π\nZ\ne-tξ2\n2 e-ıξx ˆf(ξ) dξ -→f(x) in L1(λR; C),\nwhich can be thought of the Abel version of (6.1). As an immediate consequence,\nwe know that f = 0 ⇐⇒ˆf = 0.\n\nDANIEL W. STROOCK\nExercise 8.1. Show that if f ∈C2(R; C) ∩L1(λR; C) and both f ′ and f ′′ are in\nL1(λR; C), then ˆf ∈L1(λR; C) and therefore f = (2π)-1 R\ne-ıξx ˆf(ξ) dξ.\nExercise 8.2. Using Exercise 8.1, give another proof that \"\npt(ξ) = e-t|ξ|.\nExercise 8.3. There is nothing sacrosanct about gt in producing formulas like\n(8.1) and (8.3).\nIndeed, give a ρ ∈CR, [0, inf) for which\nR\nρ(x) dx = 1, set\nρt(x) = t-1ρ(t-1x). Then it is well known that, as t ↘0, ρt ∗f(x) -→f(x)\nif f ∈L1(λR; C) is continuous at x and that ρt ∗f -→f in L1(λR; C) for any\nf ∈L1(λR; C). Now suppose that ρ ∈C2R, [0, inf) and that ρ′ and ρ′′ are in\nL1(λR; C), and show that\n2π\nZ\ne-ıξxˆρ(tξ) ˆf(ξ) dξ -→f(x)\nif f ∈L1(λR; C) is continuous at x\nand\n2π\nZ\nˆe-ıξxˆρ(tξ) ˆf(ξ) dξ -→f(x) in L1(λR; C) for any f ∈L1(λR; C).\n9. The Ornstein-Uhlenbeck Semigroup\nSet gt(x) = (2πt)-1\n2 e-x2\n2t , and note that\n(9.1)\nZ\ngs(x -ξ)gt(ξ -y) dξ = gs+t(y -x) and ∂tgt(x) = 1\n2∂2\nxgt(x).\nFor (t, x, y) ∈(0, inf) × R × R, define\n(9.2)\np(t, x, y) = g1-e-ty -e-t\n2 x\n= 2π(1 -e-t)-1\n2 exp\nC\n-(y -e-t\n2 x)2\n2(1 -e-t)\na\n= e\nt\n2 get-1\nx -e\nt\n2 y.\nFrom the first part of (9.1) and the third equality in (9.2), we see that\nZ\np(s, x, ξ)p(t, ξ, y) dξ = e\nt\nZ\ng1-e-sξ -e-s\n2 yget-1\nξ -e\nt\n2 x dξ\n= e\nt\n2 get-e-se\nt\n2 y -e-s\n2 x = p(s + t, x, y).\nHence p(t, x, y) satisfies the Chapman-Kolmogorov equation\n(9.3)\np(s + t, x, y) =\nZ\np(s, x, ξ)p(t, ξ, y) dξ.\nIn addition, using the second part of (9.1), one sees that\n(9.4)\n∂tp(t, x, y) = Lxp(t, x, y) where Lx = 1\n∂2\nx -x∂x\n.\nNext define\n(9.5)\nPtφ(x) =\nZ\nφ(y)p(t, x, y) dy\nfor φ ∈C(R; C) with at most exponential growth at inf, and use (9.3) to see that\n{Pt : t > 0} is a semigroup (i.e., Ps+t = Ps *Pt). In addition, use (9.4) to show\nthat\n(9.6)\n∂tPtφ = LPtφ.\n\nTOPICS IN FOURIER ANALYSIS\nAfter making the change of variable y →e\nt\n2 y, one sees that another expression for\nPtφ is\n(9.7)\nPtφ(x) =\nZ\nφe-t\n2 yget-1(y -x dy =\nZ\ng1(y)φ(1 -e-t)\n2 y + x dy,\nfrom which it is easy to see that Ptφ -→φ uniformly on compact subsets as t ↘0.\nFurther, if p ∈[1, inf), then, by Minkowski's inequality,\n∥Ptf∥Lp(λR;C) ≤\nZ\ng1(y)\nAZ f(1 -e-t)\n2 y + xp dx\na 1\np\ndy = ∥f∥Lp(λR;C),\nand, as t ↘0,\n∥Ptf -f∥Lp(λR;C) ≤\nZ\ng1(y)\nAZ f(1 -e-t)\n2 y + x -f(x)\np dy\na 1\np\ndx -→0\nsince\n2∥f∥Lp(λR;C) ≥\nAZ f(1 -e-t)\n2 y + x -f(x)\np dx\na 1\np\n-→0.\nTherefore we know that\n(9.8)\n∥Ptf∥Lp(λR;C) ≤∥f∥Lp(λR;C) and lim\nt↘0 ∥Ptf -f∥Lp(λR;C) = 0.\nIn particular, we have now shown that {Pt : t > 0} is a continuous contraction\nsemigroup, known as the Ornstein-Uhlenbeck semigroup, on Lp(λR; C) for each\np ∈[1, inf).\nAlthough {Pt : t > 0} is a continuous semigroup on the Lebesgue spaces\nLp(λR; C), these are not the Lebesgue spaces on which it acts most naturally. In-\nstead, one should consider its action on the spaces Lp(γ; C), where γ is the standard\nGauss measure γ(dx) = (2π)-1\n2 e-x2\n2 λR(dx). The reason why is that\ne-x2\n2 p(t, x, y) = p(t, y, x)e-y2\n2 ,\nwhich means that\n(9.9)\nφ, Ptψ\nL2(γ;C) = Ptφ, ψ\nL2(γ;C).\nHence, since Pt1 = 1, Z\nPtφ dγ = φ, Pt1\nL2(γ;C) =\nZ\nφ dγ.\nAt the same time, by Jensen's inequality, |Ptφ|p ≤Pt|φ|P , and so,\nZ\n|Ptφ|p dγ ≤\nZ\nPt|φ|p dγ =\nZ\n|φ|p dγ.\nThus,\n(9.10)\n∥Ptφ∥Lp(γ;C) ≤∥φ∥Lp(γ;C) for all p ∈[1, inf).\nIn addition, if φ ∈Cb(R; C), then ∥Ptφ∥u ≤∥φ∥u and Ptφ -→φ pointwise as\nt ↘0, and therefore, for each p ∈[1, inf), ∥Ptφ -φ∥Lp(γ;C) -→0 as t ↘0. Finally,\nif φ ∈Lp(R; C), then there exists a sequence {φn : n ≥1} ⊆Cb(R; C) such that\nlimn→inf∥fn -f∥Lp(γ;C) = 0, and\n∥Ptφ -φ∥Lp(γ;C) ≤∥Pt(φ -φn)∥Lp(γ;C) + ∥Ptφn -φn∥Lp(γ;C) + ∥φn -φ∥Lp(γ;C)\n≤2∥φn -φ∥Lp(γ;C) + ∥Ptφn -φn∥Lp(γ;C).\n\nDANIEL W. STROOCK\nThus, after first letting t ↘0 and then n →inf, we see that\n(9.11)\nlim\nt↘0 ∥Ptφ -φ∥Lp(γ;C) = 0 for all p ∈[1, inf).\nSummarizing, {Pt : t > 0} is a continuous contraction semigroup on Cb(R; C)\nand on Lp(γ; C) for each p ∈[1, inf), and Pt is self-adjoint on L2(γ; C).\nExercise 9.1. Show that\n(9.12)\nφ -(φ, 1)L2(γ;C)\nL2(γ;C) ≤∥φ′∥2\nL2(γ;C) for φ ∈C1\nb(R; C)\nand that\n(9.13)\nPtφ -(φ, 1)L2(γ;C)\nL2(γ;C) ≤e-tφ -(φ, 1)L2(γ;C)\nL2(γ;C)\nfor φ ∈L2(γ; C). The inequality in (9.12) is the Poincar e inequality for γ.\nHint: Note that if suffices to handle φ ∈C2\nb(R; C) for which (φ, 1)L2(γ;C) = 0.\nNext, given such a φ, show that\n(Ptφ)′ = e-t\n2 Ptφ′ and -∂t∥Ptφ∥2\nL2(γ;C) = ∥(Ptφ)′∥2\nL2(γ;C).\nUse these to show that\n-∂t∥Ptφ∥2\nL2(γ;C) =\n(Ptφ)′2\nL2(γ;C) ≤e-t∥φ′∥2\nL2(γ;C).\n10. Hermite Polynomials\nDefine Hn(x) = (-1)ne\ns2\n2 ∂n\nxe-x2\n2 . Then Hn is an nth order monic polynomial\nknown as the nth Hermite polynomial. Define the operator A+ = x1-∂x, and note\nthat A+Hn = Hn+1, for which reason it is called the raising operator. Using this,\ncheck that Hn(-x) = (-1)nHn(x).\nNext note that if φ, ψ ∈C1(R; C) which together with their derivatives have at\nmost exponential growth, then\n(10.1)\nA+φ, ψ\nL2(γ;C) = φ, ∂ψ\nL2(γ;C).\nHence, if 0 ≤m ≤n, then\nHn, Hm\n\nL2(γ;C) = H0, ∂nHm\n\nL2(γ;C) =\n(r)\nm!\nif n = m\nif n > m.\nNext, observe that if n ≥1, then ∂Hn ∈span{Hm : 0 ≤m < n}, and so\n∂Hn =\nn-1\nX\nm=0\n∂Hn, Hm\n\nL2(γ;C)Hm\nm!\n=\nn-1\nX\nm=0\nHn, Hm+1\n\nL2(γ;C)Hm\nm!\n=\nHn, Hn\n\nL2(γ;C)Hn-1\n(n -1)!\n.\nHence ∂Hn = nHn-1, and for this reason A-≡∂is called the lowering operator.\nTheorem 10.1. ∥Hm∥L2(γ;C) = (m!)\n2 and {Hm : m ≥0} is an orthogonal basis\nin L2(γ; C). Equivalently, if Hm =\nHm\n√\nm!, then { Hm : m ≥0} is an orthonormal\nbasis in L2(γ; C).\n\nTOPICS IN FOURIER ANALYSIS\nProof. All that we need to show is that if φ ∈L2(γ; C) and (φ, Hm)L2(γ;C) = 0 for\nall m ≥0, then φ = 0. To this end, use Taylor's theorem for e-x2\n2 to see that, for\nall ζ ∈C,\n(10.2)\neζx-ζ2\n2 =\ninf\nX\nm=0\nζm\nm! Hm(x),\nwhere the series converges uniformly on compact subsets of C×R, and, by calulation\nabove, in L2(γ; C) uniformly for ζ in compact subsets of C. Now suppose that\nφ ∈L2(γ; C), and set ψ(x) = e-s2\n2 φ(x). Then\n∥ψ∥L1(λR,C) =\nZ\nR\ne-x2\n4 e-x2\n4 |φ(x)| ds ≤(2π)\n2 ∥φ∥L2(γ;C),\nand\ne\nξ2\n2 ˆψ(ξ) = (2π)\nZ\nR\neıξx-(ıξ)2\n2 φ(x)γ(dx) = (2π)\ninf\nX\nm=0\n(ıξ)m(φ, Hm)L2(γ;C)\nm!\n.\nHence ˆψ and therefore φ vanish if (φ, Hm)L2(γ;C) = 0 for all m ≥0.\n□\nObserve that L = -A+A-\n, and therefore, by (10.1)\nLφ, ψ\nL2(γ;C) = -1\nφ′, ψ′\nL2(γ;C) = φ, Lψ\nL2(γ;C)\nfor φ, ψ ∈C2(R; C) which together with their derivatives have at most exponential\ngrowth. Thus, by (9.6) and (9.9),\nLPtφ, ψ\nL2(γ;C) = ∂t\nPtφ, ψ\nL2(γ;C) = ∂t\nφ, Ptψ\nL2(γ;C)\n= φ, LPtψ\nL2(γ;C) = PtLφ, ψ\nL2(γ;C),\nand therefore LPt = PtL. In particular, because -2LHn = nA+Hn-1 = nHn,\n∂tPtHn = LPtHn = PtLHn = -n\n2 PtHn,\nand so, because limt↘0 PtHn = Hn,\n(10.3)\nPtHn = e-nt\n2 Hn.\nExercise 10.1. Using (10.3), give another proof of (9.13), and, using A+Hm =\nHm+1, give another proof of (9.12).\n11. Hermite Functions\nDefine T : L2(γ; C) -→L2(λR; C) so that Tφ(x) = π-1\n4 e-x2\n2 φ(2\n2 x), and check\nthat\n∥Tφ∥L2(λR;C) = ∥φ∥L2(γ;C) and T -1f(x) = π\n4 e\nx2\n4 f(2-1\n2 x).\nThus T is an isometric isomorphism from L2(γ; C) onto L2(λR; C).\nSet hm = THm and hm = hm = T Hm. Then, because { Hm : m ≥0} is an\northonormal basis in L2(γ; C), { hm : m ≥0} is an orthonormal bases in L2(λR; C).\nAssuming that φ ∈C1(R; C), it easy to show that\nTA±φ = a±Tφ where a± = 2-1\n2 (x1 ∓∂x)\nand therefore that\n(11.1)\na+hm = hm+1 and a-hm = mhm-1.\n\nDANIEL W. STROOCK\nTheorem 11.1. For all m ≥0, \"\nhm = (2π)\n2 ımhm.\nProof. Certainly c\nh0 = (2π)\n2 h0. Assuming that \"\nhm = (2π)\n2 ımhm, use integration\nby parts to see that\n'\nhm+1(ξ) = 2-1\nZ\neıξxa+hm(x) dx = 2-1\nZ\nxeıξxhm(x) dx + 2-1\n2 ıξbhm(ξ)\n= 2-1\n2 -ı(\"\nhm)′(ξ) + ıξbhm(ξ) = (2π)\n2 ım+1a+hm(ξ) = (2π)\n2 ım+1hm+1(ξ).\n□\nCorollary 11.2. For all m ≥0,\n(11.2)\n∥ hm∥L1(λR;C) ≤(2π)\n2 (m + 1)\n2 , ∥ hm∥u ≤(m + 1)\n2 and\n∥x hm∥u ∨∥∂ hm∥u ≤2m + 3\n2.\nProof. Since ∥ h0∥L1(λR;C) = 2\n2 π\n4 , ∥ h0∥u ≤π-1\n4 , and\nπ\n4 ( h0)′\nu = sup\nx≥0\nxe-x2\n2 = e-1\n2 ,\nthere is nothing to do when m = 0.\nNow assume that m ≥1. Using the facts that xhm(x) -h′\nm = 2\n2 hm+1 and\nxhm + h′\nm = 2\n2 mhm-1, one sees that\n(11.3)\nx hm(x) = m\n2 hm-1(x) + (m + 1)\n2 hm+1(x)\n( hm)′(x) = m\n2 hm-1(x) -(m + 1)\n2 hm+1(x)\n.\nHence,\nZ\nx2 hm(x)2 dx = m + 1\n2,\nand so\nZ\n(1 + x2) hm(x)2 dx = m + 3\n2,\nwhich, by Schwarz's inequality, means that\n∥ hm∥L1(λR;C) =\nZ\n(1 + x2)-1\n2 (1 + x2)\n2 hm(x)2 dx ≤π\n2 m + 3\n2 ≤(2π)\n2 (m + 1)\n2 .\nBecause ( hm)∧= (2π)\n2 ım hm,\n∥ hm∥u = (2π)-1\n2 ( hm)∧\nu ≤(2π)-1\n2 ∥ hm∥L1(λR;C) ≤(m + 1)\n2 .\nTo complete the proof, use the second part of (11.3) plus the preceding to see\nthat\n∂ hm\n\nu ≤m\n2 ∥ hm-1∥u + (m + 1)\n2 ∥ hm+1∥u\n\n≤m + (m + 1)\n2 (m + 2)\n2 ≤2m + 3\n2.\nThe same argument, only this time using the first part of (11.3), proves the same\nestimate for ∥x hm∥u.\n□\n\nTOPICS IN FOURIER ANALYSIS\nThe kernel which plays the role for the Hermite functions that the Ornstein-\nUhlenbeck kernel (cf. (9.2)) p(t, x, y) plays for the Hermite polynomial is\n(11.4)\nq(t, x, y) = 2\n2 e-t\n2 e-x2\n2 p2t, 2\n2 x, 2\n2 y)e\ny2\n= (2π sinh t)-1\n2 exp\nA\n-\nx2\n2 tanh t +\nxy\nsinh t -\ny2\n2 tanh t\na\n.\nObserve that q(t, x, · ) ∈Lp(λR; C) for all p ∈[1, inf] and that\ne\nt\nZ\nq(t, x, y)f(y) dy = e-x2\nZ\np(2t, 2\n2 x, y)e\ny2\n4 f2-1\n2 y dy = TP2tT -1f(x).\nHence, the operator Qt given by\nQtf(x) =\nZ\nq(t, x, y)f(y) dy\nis well defined on L2(λR; C) and is equal to e-t\n2 TP2tT -1. In particular, by (9.10),\ne\nt\n2 ∥Qtf∥L2(λR;C) = ∥P2tT -1f∥L2(γ;C) ≤∥T -1f∥L2(γ;C) = ∥f∥L2(λR;C),\nand, by (9.11)\ne\nt\n2 Qtf -f\n\nL2(λR;C) =\nT(P2tT -1f -T -1f)\n\nL2(λR;C)\n=\nP2tT -1f -T -1f\n\nL2(γ;C) -→0 as t ↘0.\nHence\n∥Qtf∥L2(λR;C) ≤e-t\n2 ∥f∥L2(λR;C) and lim\nt↘0 ∥Qtf -f∥L2(λR;C) = 0.\nIn addition, by (10.3), Qthm = e-t\n2 TP2tHm = e-(m+ 1\n2 )thm.\nTheorem 11.3. If f ∈L1(λR; C) ∪L2(λR; C), then\nZ\nq(t, x, y)f(y) dy = e-1\ninf\nX\nm=0\ne-mt(f, hm)L2(λR;C) hm for t > 0,\nwhere the convergence of the series is absolute uniformly for x ∈R.\nProof. First observe that, by the estimates in Corollary 11.2, the series is absolutely\nconvergent uniformly in x ∈R and that both sides are continuous as functions of\nf ∈L1(R; C) or of f ∈L2(λR; C). In particular, it suffices to prove the equality\nwhen f ∈Cc(R; C).\nGiven f ∈Cc(R; C), set fn = Pn\nm=0(f, hm)L2(λR;C) hm. Then\nZ\nq(t, x, y)fn(y) dy = e-t\nn\nX\nm=0\ne-mt(f, hm)L2(λR;C) hm(x).\nBecause q(t, x, · ) ∈L2(λR; C) and fn -→f in L2(λR; C), the left hand side con-\nverges to\nR\nq(t, x, y)f(y) dy.\n□\nExercise 11.1. Define the Mehler kernel M(θ, x, y) for (θ, x, y) ∈(0, 1) × R × R\nby\nM(θ, x, y) = 2π(1 -θ2)-1\n2 exp\nA\n-θ2x2 -2θxy + θ2y2\n2(1 -θ2)\na\n,\n\nDANIEL W. STROOCK\nand show that\nM(θ, x, y) = 1 -θ2-1\ninf\nX\nm=0\nθm Hm(x)Hm(y)\nm!\n,\nwhere the series converges uniformly for (x, y) in compact subsets. This famous\nequation is known as Mehler's formula.\n12. The Fourier Transform for L2(λR; C)\nThe basic goal here is to extend the Fourier transform on L1(R; C) ∩L2(λR; C)\nas a bounded operation on L2(λR; C) into L2(λR; C). We will then examine some\nof the fundamental properties of this extension.\nLemma 12.1. If f ∈L1(R; C), then\n(12.1)\ne-ξ2 tanh t\n(2π cosh t)\nZ\ne\nıξx\ncosh t e-x2 tanh t\nf(x) dx\n= e-t\ninf\nX\nm=0\n(ıe-t)m(f, hm)L2(λR;C) hm(ξ)\nfor (t, ξ) ∈(0, inf) × R.\nProof. Since both sides of (12.1) are continuous functions of f ∈L1(R; C), we may\nand will assume that f ∈Cc(R; C).\nSet D = {ζ ∈C : |ζ| < 1 & ζ /∈(-1, 0]}, and define α±(ζ) = 1\nζ ∓ζ for ζ ∈D.\nNext, for fixed ξ ∈R and all ζ ∈D, define\nΦ(ζ) = 2πα+(ζ)-1\n2 e\n-\nα-(ζ)\n2α+(ζ) ξ2 Z\ne\nξx\nα+(ζ) e\n-\nα-(ζ)\n2α+(ζ) x2\nf(x) dx\nand\nΨ(ζ) = ζ\ninf\nX\nm=0\nζm(f, hm)L2(λR;C) hm(ξ),\nand observe that both Φ and Ψ are analytic functions on D. Furthermore, since\nα+(e-t) = sinh t and α-(e-t) = cosh t, Lemma 11.3 says that Φ = Ψ on (0, 1), and\ntherefore, by analytic continuation, Φ = Ψ on D. In particular, Φıe-t = Ψıe-t.\nFinally, because α+\nıe-t =\ncosh t\nı\nand α-\nıe-t =\nsinh t\nı\n, one sees that the left\nhand and right sides of (12.1) equal, respectively ı\n2 Φıe-t and ı\n2 Ψıe-t.\n□\nTheorem 12.2. If f ∈L1(R; C) ∩L2(R; C), then\n(12.2)\nˆf = (2π)\ninf\nX\nm=0\nım(f, hm)L2(λR;C) hm\nalmost everywhere.\nProof. Because f ∈L1(R; C), the left hand side of (12.1) tends pointwise to\n(2π)-1\n2 ˆf as t ↘0, and because f ∈L2(λR; C), the right hand side tends in\nL2(λR; C) to the series on the right hand side of (12.2).\n□\n\nTOPICS IN FOURIER ANALYSIS\nAs a consequence of Theorem 12.2, we know that ∥ˆf∥L2(λR;C) = (2π)\n2 ∥f∥L2(λR;C)\nfor f ∈L1(λR; C)∩L2(λR; C). Hence the map f ∈L1(λR; C)∩L2(λR; C) ⇝ˆf admits\na unique continuous extension as a linear map with norm (2π)\n2 from L2(λR; C) into\nL2(λR; C), and (12.2) continuous to hold for this extension.\nDefine f(x) = f(-x), and observe that hm = (-1)mhm, ( f, g)L2(λR;C) = (f, g)L2(λR;C),\nand ˆf = \" f. In addition, by Fubini's theorem,\nˆφ, hm\n\nL2(λR;C) =\nZ Z\neıξxφ(x) hm(ξ) dxdξ =\nZ\nφ(x)b hm(x) dx = (2π)\n2 ım(φ, hm)L2(λR;C),\nand so, for f, g ∈L2(λR; C),\nˆf, ˆg\nL2(λR;C) =\ninf\nX\nm=0\nˆf, hm\n\nL2(λR;C)\nˆg, hm\n\nL2(λR;C)\n= 2π\ninf\nX\nm=0\nf, hm\n\nL2(λR;C)\ng, hm\n\nL2(λR;C) = 2π(f, g)L2(λR;C),\nwhich means that Parseval's identity\n(12.3)\nˆf, ˆg)L2(λR;C) = 2πf, g\nL2(λR;C)\nholds. Finally, set ˇf = ˆf, ( ˆf, g)L2(λR;C) = (f, ˇg)L2(λR;C) and therefore, by (12.3),\nthat\n( ˆf)∨, g\nL2(λR;C) = ˆf, ˆg\nL2(λR;C) = 2π(f, g)L2(λR;C).\nSimilarly, ( ˇf)∧, g\nL2(λR;C) = 2πf, g\nL2(λR;C), and so we have proved the Fourier\ninversion formula\n(12.4)\nˆf∨= 2πf = ( ˇf)∧.\nIt is important to keep in mind that ˆf is not given by a Lebesgue integral\nfor f ∈L2(λR; C) unless f ∈L1(λR; C) as well.\nOn the other hand, because\nfR ≡1[-R,R]f ∈L1(λR; C) ∩L2(λR; C) and fR -→f in L2(λR; C),\nˆf(ξ) = lim\nR→inf\nZ R\n-R\neıξxf(x) dx,\nwhere the convergence is in L2(λR; C).\nExercise 12.1. Define Ff(ξ) = ˆf(2πξ), and show that F is an orthogonal operator\non L2(λR; C). Further, show that if F∗is the adjoint of F, then equals F-1f =\nF∗f = (Ff)∪= F f.\n13. Schwartz Test Functions\nIn this section we will study a space of functions introduced by Laurent Schwartz7\nand used by him to construct the class of distributions discussed in the next section.\nThe function space alluded to above is denoted by S (R; C) and consists of\nfunctions φ ∈Cinf(R; C) with the property that x ⇝xk∂lφ(x) is bounded for all\nk, l∈N. Obviously, S (R; C) is a vector space. In addition, it is closed under\n7There are many books in which Schwartz's theory is presented, but his own original treatment\nin Th eorie des distributions, I published in 1950 by Hermann, Paris remains one of the best\naccounts.\n\nDANIEL W. STROOCK\ndifferentiation as well as products with smooth functions which, together with all\ntheir derivatives, have at most polynomial growth (i.e., grow no faster than some\npower of (1 + x2)). Thus the Hermite functions are all in S (R; C). Finally, since,\nfor φ ∈S (R; C),\nZ\n|φ(x)|p dx ≤∥(1 + x2)φ∥p\nu\nZ\n(1 + x2)-p dx,\nS (R; C) ⊆T\np∈[1,inf] Lp(λR; C).\nThere is an obvious notion of convergence for sequences in S (R; C). Namely,\ndefine the norms\n∥φ∥(k,l)\nu\n= ∥xk∂lφ∥u\nfor k, l∈N, and say that φj -→φ in S (R; C) if limn→inf∥φj -φ∥(k,l)\nu\n= 0 for all\nk, l∈N. The corresponding topology is the one for which G is open if and only if\nfor each φ ∈G there an m ∈N and r > 0 such that\nψ : ∥ψ -φ∥(m)\nu\n< r ⊆G,\nwhere\n∥· ∥(m)\nu\n≡max\nk,l∈N\nk+l≤m\n∥· ∥(j,l)\nu\n.\nWe will now develop a more convenient description of the topology on S (R; C),\none that shows that S (R; C) shares many properties with Hilbert spaces. Define\nthe operator H on S (R; C) into itself by\nHφ = x2φ -∂2φ.\nSince (cf. (11.1)) H = (2a+a-+ 1),\n(13.1)\nH hk = μk hk\nwhere μk = 2k + 1,\nand so we can define operators Hs for any s ∈R by\nHsφ =\ninf\nX\nm=0\nμs\nm(φ, hm)L2(λR;C) hm.\nFor each m ≥0, set\nS (m)(R; C) =\n(\nφ ∈L2(λR; C) :\ninf\nX\nk=1\nμm\nk\n(φ, hk)L2(λR;C)\n2 < inf\n)\n,\nand define\n(φ, ψ)S (m)(R;C) =\ninf\nX\nk=0\nμm\nk (φ, hk)L2(λR;C)( hk, ψ)L2(λR;C) = φ, Hmψ\nL2(λR;C)\n∥φ∥S (m)(R;C) = (φ, φ)\nS (m)(R;C) = φ, Hmφ 1\n2 .\nClearly S (m)(R; C) is a vector space for which (φ, ψ)S (m)(R;C) is an inner prod-\nuct. Below we will show below that it is a separable Hilbert space.\nLemma 13.1. For each m ≥0,\n∥xφ∥S (m)(R;C) ∨∥∂φ∥S (m)(R;C) ≤3m∥φ∥S (m+1)(R;C).\n\nTOPICS IN FOURIER ANALYSIS\nProof. By the first part of (11.3),\n∥xφ∥2\nS (m)(R;C) =\ninf\nX\nk=0\nμm\nk |(xφ, hk)L2(λR;C)|2\n=\ninf\nX\nk=1\nkμm\nk |(φ, hk-1)L2(λR;C)|2 +\ninf\nX\nk=0\n(k + 1)μm\nk |(φ, hk+1)L2(λR;C)|2\n= μm\n1 |(φ, h0)L2(λR;C)|2 +\ninf\nX\nk=1\n(k + 1)μm\nk+1 + kμm\nk-1\n|(φ, hk)L2(λR;C)|2\n≤3mμm+1\nm|(φ, h0)L2(λ[0,1);C)|2 +\ninf\nX\nk=1\n2m(k + 1) + kμm\nk |(φ, hk)L2(λR;C)|2\n≤3m∥φ∥S (m+1)(R;C).\nUsing the second part of (11.3) and the same argument, one can show that ∥∂φ∥S (m)(R;C)\n≤3m∥φ∥S (m+1)(R;C).\n□\nTheorem 13.2. For each m ∈N, S (R; C) is a dense subset of S (m)(R; C). In\naddition, for each m ≥0, there exists a Km ∈(0, inf) such that\n(13.2)\n∥φ∥S (m)(R;C) ≤Km∥φ∥(m+1)\nu\nand\n(13.3)\n∥φ∥(m)\nu\n≤Km∥φ∥S (m+3)(R;C).\nfor all φ ∈S (R; C). Thus φn -→φ in S (R; C) if and only if\nlim\nn→inf∥φn -φ∥S (m)(R;C) = 0\nfor all m ∈N. In particular, for each φ ∈S (R; C),\nn\nX\nk=0\n(φ, hk)L2(λR;C) hk -→φ in S (R; C) as n →inf.\nProof. Since H ↾S (R; C) is a symmetric operator, (13.1) implies that\nμm\nk (φ, hk)L2(λR;C) = (φ, Hm hk)L2(λR;C) = (Hmφ, hk)L2(λR;C),\nfor all φ ∈S (R; C) and m ≥0, from which it is clear that S (R; C) ⊆S (m)(R; C)\nfor all m ≥0. Moreover, since, for each φ ∈S (m)(R; C),\nS (R; C) ∋\nn\nX\nk=0\n(φ, hk)L2(λR;C) hk -→φ in S (m)(R; C) as n →inf,\nS (R; C) is dense in S (m)(R; C).\nNext observe that there exist constants c(m)\nj,l∈R such that\nx2 -∂2mφ =\nX\nk,l∈N\nk+l≤2m\nc(m)\nj.lxk∂lφ,\nand use integration by parts to see that\nφ, xk∂lφ\nL2(λR;C) = (-1)l′∂l′(xk′φ), xk-k′∂l-l′φ\nL2(λR;C),\n\nDANIEL W. STROOCK\nwhere\nk′ =\n(r) k\nif k is even\nk-1\nif k is odd\nand\nl′ =\n(r) l\nif lis even\nl+1\nif lis odd.\nHence there exist constants b(m)\n(k1,l1),(k2,l2) ∈R such that\nφ, Hmφ\nL2(λR;C) ≤\nX\n(k1,l1),(j2,l2)∈N2\n(k1+l1)∨(j2+l2)≤m\nb(m)\n(k1,l1),(k2,l2)\nxk1∂l1φ, xk2∂l2φ\nL2(λR;C)\n\n≤\nX\n(k1,l1),(k2,l2)∈N2\n(k1+l1)∨(k2+l2)≤m\n|b(m)\n(k1,l1),(k2,l2)|\nxk1∂l1φ\n\nL2(λR;C)\nxk2∂l2φ\n\nL2(λR;C).\nFinally, observe that\n∥xk∂lφ∥2\nL2(λR;C) =\nZ\n(1 + x2)-1(1 + x2)\n2 xk∂lφ(x)\n2 dx\n≤π∥xk∂lφ∥2\nu + ∥xk+1∂lφ∥2\nu\n,\nand combine this with the preceding to arrive at (13.2).\nTo prove (13.3), begin by making repeated application of Lemma 13.1 to show\nthat\n∥xk∂lφ∥S (3)(R;C) ≤3\nm(m+1)\n∥φ∥S (k+l+3)(R;C) if k + l≤m.\nThus, if we show that there is a K ∈(0, inf) such that\n∥φ∥u ≤K∥φ∥S (3)(R;C),\n(∗)\nthen\n∥xk∂lφ∥u ≤K∥xk∂lφ∥S (3)(R;C) ≤K∥φ∥S (k+l+3)(R;C),\nin which case we would know that ∥φ∥(m)\nu\n≤3\nm(m+1)\nK∥φ∥S (m+3)(R;C). To prove\n(∗), use the estimate in (11.2) to see that\n∥φ∥u ≤\ninf\nX\nk=0\n|(φ, hk)L2(λR;C)|∥ hk∥u\n≤\ninf\nX\nk=0\n(k + 1)\n2 |(φ, hk)L2(λR;C)| =\ninf\nX\nk=0\nAk + 1\nμ3\nk\na 1\nμ\nk |(φ, hk)L2(λR;C)|\n≤\ninf\nX\nk=0\nk + 1\nμ3\nk\n! 1\n2 inf\nX\nk=0\nμ3\nk|(φ, hk)L2(λR;C)|2\n! 1\n= K∥φ∥S (3)(R;C).\nwhere K =\nPinf\nk=0\nk+1\nμ3\nk\n2 .\n□\nAs a consequence of Theorem 13.2, we know that\nρS (φ, ψ) ≡\ninf\nX\nm=0\n2m+1\n∥φ -ψ∥S (m)(R;C)\n1 + ∥φ -ψ∥S (m)(R;C)\nis a metric for the topology on S (R; C). In addition, S (R; C) = Tinf\nm=0 S (m)(R; C),\nand so we can learn about properties of S (R; C) by understanding those of the\nS (m)(R; C)'s.\n\nTOPICS IN FOURIER ANALYSIS\nFor each m ≥0, let s(m)(N; C) be the space of functions s : N -→C such that\n∥s∥s(m)(N;C) ≡\ninf\nX\nk=0\nμm\nk |s(k)|2\n! 1\n< inf,\nand define\n(s, t)s(m)(N;C) =\ninf\nX\nk=0\nμm\nk s(k)t(k) for s, t ∈s(m)(N; C),\nClearly each s(m)(N; C) is a vector space with inner product (s, t)s(m)(N;C). Finally,\nset s(N; C) = Tinf\nm=0 s(m)(N; C), and turn s(N; C) into a metric space with metric\nρs(s, t) ≡\ninf\nX\nm=0\n2m+1\n∥t -s∥s(m)(N;C)\n1 + ∥t -s∥s(m)(N;C)\n.\nThe following corollary is essentially a reformulation of the results in Theorem\n13.2. It is the analogue for S (R; C) of the fact that every separable Hilbert space\nis isomorphic to l2(N; C).\nCorollary 13.3. Define the map S : L2(λR; C) -→l2(N; C) by\n[S(φ)](k) = (φ, hk)L2(λR;C).\nThen, for each m ≥0, S ↾S (m)(R; C) is an isometric isomorphism from S (m)(R; C)\nonto s(m)(N; C), and so S ↾S (R; C) is isometric homeomorphism from S (R; C)\nonto s(N; C).\nCorollary 13.3 means that any topological property of s(m)(N; C) or s(N; C) is a\nproperty of S (m)(R; C) or S (R; C), and the following lemma facilitates the study\nof such properties.\nLemma 13.4. Let {αk : k ≥0} ⊆(0, inf), and define the measure ν on N by\nν({k}) = αk. Then L2(ν; C) is a separable Hilbert space. In addition, a set B ⊆\nL2(ν; C) is relatively compact if and only if B is bounded and tight in the sense that\nlim\nK→infsup\ns∈B\nX\nk>K\nαk|s(k)|2 = 0.\nProof. Since the L2-space for any measure on a countably generated σ-algebra is a\nseparable Hilbert space, L2(ν; C) is a separable Hilbert space.\nSince L2(ν; C) is complete, to prove that a bounded, tight subset B is relatively\ncompact it suffices to show that B is totally bounded (i.e., for every r > 0 there is\na finite cover of B by balls of radius r with centers in B). To that end, let r > 0\nbe given, and choose K so that\nsup\ns∈B\nX\nk>K\nαk|s(k)|2 < r2\n4 .\nNext, note that s(0), . . . , s(K) : s ∈B is a bounded subset of CK+1 and\ntherefore totally bounded there. Hence there exists a finite set {sj : 1 ≤j ≤J} ⊆B\nsuch that, for each s ∈B,\nmin\n1≤j≤J\nK\nX\nk=0\nαk|s(k) -sj(k)|2 < r2\n2 ,\n\nDANIEL W. STROOCK\nwhich means that, for each s ∈B there exists a 1 ≤j ≤J such that\n∥s -sj∥2\nL2(ν;C) =\nK\nX\nk=0\nαk|s(k) -sj(k)|2 +\nX\nk>K\nαk|s(k) -sj(k)|2 ≤r2.\nFinally, suppose that B is relatively compact. Certainly it is bounded. To see\nthat it must be tight, suppose it were not. Then there would exist an ε > 0 such\nthat, for each K ∈N,\nsup\ns∈B\nX\nk>K\nαk|s(k)|2 > ε.\nThus we could find a sequence {sK : K ≥0} ⊆B with the property that\nP\nk>K αk|sK(k)|2 ≥ε, and, because B is relatively compact, we could choose it\nto be a sequence which converges to some t ∈L2(ν; C). But this would mean that\nX\nk>K\nαk|t(k)|2 ≥\nX\nk>K\nαk|sK(k)|2 -∥t -sK∥2\nL2(ν;C) ≥ε\nfor sufficient large K, and that would mean the t can't be in L2(ν; C).\n□\nSay that B ⊆S (R; C) is bounded in S (R; C) if\nsup\nφ∈B\n∥φ∥S (m)(R;C) < inffor each m ≥0.\nTheorem 13.5. S (m)(R; C) is a separable Hilbert space for each m ≥0, and\nS (R; C) is a complete separable metric space. Moreover, a subset B ⊆S (R; C) is\nrelatively compact if and only if it is bounded in S (R; C).\nProof. By Lemma 13.4 applied with αk = μm\nk , we know that each of the spaces\ns(m)(N; C) is a separable Hilbert space, and therefore, by Corollary 13.3, so is each\nS (m)(R; C).\nThus, since S (R; C) is dense in every S (m)(R; C), we can use a\ndiagonalization argument to find a sequence {φn : n ≥1} ⊆S (R; C) which is\ndense in S (m)(R; C) for all m ≥0. Since this means that\ninf\nn≥1 ∥φ -φn∥S (m)(R;C) = 0 for all φ ∈S (R; C) and m ≥0,\nit follows that\ninf\nn≥1 ρS (R;C)(φ, φn) = 0 for all φ ∈S (R; C).\nThat is, {φn : n ≥1} is dense in S (R; C), and so S (R; C) is separable.\nTo see that S (R; C) is complete, first use Lemma 13.4 and Corollary 13.3 to see\nthat each S (m)(R; C) is complete. Now suppose that {φn : n ≥1} ⊆S (R; C)\nis ρS (R;C)-Cauchy convergent. Then it is ∥· ∥S (m)(R;C)-Cauchy convergent for each\nm ≥0, and therefore it is convergent in each S (m)(R; C) to some element of\nS (m)(R; C). But if φn -→φ in S (m+1)(R; C), then φn -→φ in S (m)(R; C), and\nso there is a unique φ ∈Tinf\nm=0 S (m)(R; C) to which {φn : n ≥1} converges in\nS (m)(R; C) for all m ≥0. Therefore φ ∈S (R; C) and limn→infρS (φ, φn) = 0.\nFinally, suppose that B ⊆S (R; C) is relatively compact in S (R; C). Because\nB is then relatively compact in each S (m)(R; C) and therefore bounded there, it is\na bounded subset of S (R; C). Conversely, if B is bounded in S (R; C), in order to\nshow that it is relatively compact in S (R; C) we need only show that it is totally\nbounded there. To that end, first observe that it is bounded in each S (m)(R; C).\n\nTOPICS IN FOURIER ANALYSIS\nThus, by Lemma 13.4 and Corollary 13.3, we will know that it is relatively compact\nin S (m)(R; C) if\nlim\nK→infsup\nφ∈B\nX\nk>K\nμm\nk |(φ, hk)L2(λR;C)|2 = 0.\n(∗)\nBut\nX\nk>K\nμm\nk |(φ, hk)L2(λR;C)|2 ≤\nμK+1\n∥φ∥2\nS (m+1)(R;C),\nand so, since B is bounded in S (m+1)(R; C), (∗) holds. To complete the proof that\nB ρS -totally bounded, let r > 0 be given, and choose m so that 2-m < r\n2. Next,\nusing the fact that B is relatively compact in S (m)(R; C), choose {φj : 1 ≤j ≤\nJ} ⊆B so that\nsup\nφ∈B\nmin\n1≤j≤J ∥φ -φj∥S (m)(R;C) < r\n2,\nand conclude that\nB ⊆\nJ[\nj=1\nφ : ρS (R;C)(φ, φj) < r .\n□\nThe assertion in the following is one of the many virtues possessed by S (R; C).\nTheorem 13.6. The map φ ⇝ˆφ is an isomorphism from S (R; C) onto itself,\nand, for each m ≥0, ∥ˆφ∥S (m)(R;C) = (2π)\n2 ∥φ∥S (m)(R;C).\nProof. We already know that the Fourier transform is an isomorphism of L2(λR; C)\nonto L2(λR; C). In addition, by Theorem 12.2,\n( ˆφ, hk)L2(λR;C) = (2π)\n2 (-ı)k(φ, hk)L2(λR;C),\nand so\n∥ˆφ∥2\nS (m)(R;C) = 2π\ninf\nX\nk=0\nμm\nk |(φ, hk)L2(λR;C)|2 = 2π∥φ∥2\nS (m)(R;C).\n□\nExercise 13.1. Show that for each (m, n) ∈N2 there is a Cn,m ∈(0, inf) such that\nCn,m\nmax\nk,l∈N\nk+l≤m\n∥xk∂lφ∥S (n)(R;C) ≤∥φ∥S (n+m)(R;C) ≤Cn,m max\nk,l∈N\nk+l≤m\n∥xk∂lφ∥S (n)(R;C).\nHint: In proving the upper bound, consider using the equation\nan\n+φ, hk+n\n\nL2(λR;C) =\nA(k + n)!\nk!\na 1\n2 φ, hk\n\nL2(λR;C).\n.\n\nDANIEL W. STROOCK\nExercise 13.2. Let {φn : n ≥1} be a bounded sequence in S (R; C) such that\nlimn→infφn(x) exists for each x ∈R. Show that there is a φ ∈S (R; C) such that\nφn -→φ in S (R; C).\nHint: Use Theorem 13.5.\nExercise 13.3. This exercise deals with the relationship between various function\nspaces.\n(i) Show that Cinf\nc (R; C) is a dense subset of S (R; C)\n(ii) Set\nC0(R; C) =\nß\nf ∈C(R; C) :\nlim\n|x|→inff(x) = 0\nTM\n.\nShow that C0(R; C) with the uniform norm is a Banach space in which both Cinf\nc\nand S (R; C) are dense subsets.\nExercise 13.4. For x ∈R and φ ∈S (R; C), define τxφ(y) = φ(x + y). Show\nthat τxφ ∈S (R; C) and that ∥τxφ∥(m)\nu\n≤2m(|x| ∨1)m∥φ∥(m)\nu\nfor all m ≥0. In\naddition, show that\n∥τx2φ -τx1φ∥(m)\nu\n≤2m|x1| ∨|x2| ∨1)m∥φ∥(m+1)\nu\n|x2 -x1|.\nHint: To prove the first estimate, check that\n|yk∂lτxφ(y)| ≤\n(r)\n(2|x|)m(∂lφ)(x + y)\n\nif |y| ≤2|x|\n2m(x + y)k(∂lφ)(x + y)\n\nif |y| ≥2|x|.\nTo prove the second estimate, assume that x1 ≤x2, note that\nτx2φ -τx1φ =\nZ x2\nx1\nτtφ′ dt,\nand therefore that\n∥τx2φ -τx1φ∥(m)\nu\n≤\nZ x2\nx1\n∥τtφ′∥(m)\nu\ndt.\nFinally, apply the first estimate.\n14. Tempered Distributions\nSchwartz developed the theory of distribution in order to provide a mathemati-\ncally rigorous way to describe the sort of generalized functions that appear in the\nwork by Boole and Heaviside in connection with applications of the Laplace trans-\nform to ordinary differential equations, and those that were somewhat later intro-\nduced by Sobolev for applications to partial differential equations. What Schwartz\nrealized is that generalized functions should be thought of in terms of their action\n(i.e., their L2(λR; C) inner product with) on smooth functions rather than their\nvalue (which won't exist in general) at points.\nTo make that idea mathematically precise, he said a generalized function, which\nhe called a distribution, should be a continuous linear functional on a topologi-\ncal vector space of smooth functions. One of the spaces Schwartz considered is\nCinf\nc (R; C), but the appropriate topology on that space is rather cumbersome (for\ninstance, elements don't have countable neighborhood bases). A second, and much\nmore tractable, choice is S (R; C). Because elements of S (R; C) need not have com-\npact support, an element of its dual space must satisfy restricted growth conditions\nand is therefore called a tempered distribution.\n\nTOPICS IN FOURIER ANALYSIS\nRecall that the dual space X∗of a topological vector space X over C is the\nspace of continuous, C-valued linear functions on X. When, like S (R; C), all the\nelements of X have a countable neighborhood basis, a linear function Λ on X is\nan element of X∗if Λxn -→Λx whenever xn -→x in X. Because we want to\nthink of elements of S (R; C)∗as generalized functions which act via their L2-inner\nproduct with elements of S (R; C), we will use letters like u to denote elements of\nS (R; C)∗and write their action on φ ∈S (R; C) as ⟨φ, u⟩.\nLemma 14.1. For each u ∈S (R; C)∗there is an m ≥0 and a C ∈(0, inf) such\nthat\n|⟨φ, u⟩| ≤C∥φ∥S (m)(R;C) for all φ ∈S (R; C).\nProof. Because sets of the form ∥φ∥S (m)(R;C) ≤r form a neighborhood basis\nfor 0 in S (R; C), there is an m ≥0 and r > 0 such that |⟨φ, u⟩| ≤1 when\n∥φ∥S (m)(R;C) ≤r. Hence |⟨φ, u⟩| ≤r-1∥φ∥S (m)(R;C).\n□\nSimple as it is, Lemma 14.1 has many consequences. For example, it allows us\nto say that\n(14.1)\n⟨φ, u⟩=\ninf\nX\nk=0\n(φ, hk)L2(λR;C)⟨ hk, u⟩,\nwhere the series is absolutely convergent. Indeed, if |⟨φ, u⟩| ≤C∥φ∥S (m)(R;C), then\n|⟨ hk, u⟩| ≤Cμm\nk , and so, since |(φ, hk)L2(λR;C)| = μ-n\nk |(Hnφ, hk)L2(λR;C)| for all\nn ≥0, the series Pinf\nk=0(φ, hk)L2(λR;C)⟨ hk, u⟩is absolutely convergent. Hence, if\nφn = Pn\nk=0(φ, hk)L2(λR;C), then φn -→φ in S (R; C) and therefore\n⟨φ, u⟩= lim\nn→inf⟨φn, u⟩= lim\nn→inf\nn\nX\nk=0\n(φ, hk)L2(λR;C)⟨ hk, u⟩\n=\ninf\nX\nk=0\n(φ, hk)L2(λR;C)⟨ hk, u⟩.\nObviously, given a measurable function f : R -→C with at most polynomial\ngrowth, one can think of it as the element fλR of S (R; C)∗given by ⟨φ, fλR⟩=\nR\nφ f dλR, and in this way S (R; C) can be thought of as a subset of S (R; C)∗.\nAlthough the distribution corresponding to f is fλR, it is conventional to denote\nit by f instead, and we will adopt this convention.\nWe will need to know that S (R; C) is dense in S (R; C)∗. To see that it is, let\nu ∈S (R; C)∗, and set\nψn =\nn\nX\nk=0\n⟨ hk, u⟩ hk.\nClearly ψn ∈S (R; C), and, for each φ ∈S (R; C),\n(φ, ψn)L2(λR;C) =\nn\nX\nk=0\n(φ, hk)L2(λR;C)(ψn, hk)L2(λR;C)\n=\nn\nX\nk=0\n(φ, hk)L2(λR;C)⟨ hk, u⟩-→\ninf\nX\nk=0\n(φ, hk)L2(λR;C)⟨ hk, u⟩= ⟨φ, u⟩.\nThe importance of this density result is that it tells us how to extend contin-\nuous operators like Hs as continuous operators on S (R; C)∗.\nNamely, because\n\nDANIEL W. STROOCK\n(φ, Hsψ)L2(λR;C) = (Hsφ, ψ)L2(λR;C) for φ, ψ ∈S (R; C) and S (R; C) is dense in\nS (R; C)∗, the one and only continuous extension of Hs to S (R; C)∗is given by\n(14.2)\n⟨φ, Hsu⟩≡⟨Hsφ, u⟩.\nSince S (R; C) can be written as the intersection of the spaces S (m)(R; C),\nS (R; C)∗must be able to be written as the union of the spaces S (m)(R; C)\n∗. Of\ncourse, because S (m)(R; C) is a Hilbert space, Riesz's theorem provides an isomor-\nphism between S (m)(R; C)\n∗and S (m)(R; C). However, in order to be consistent\nwith the idea that ⟨φ, u⟩is a generalization of the L2 inner product, this is not the\nway we will think about S (m)(R; C)\n∗. Instead, we want to identify S (m)(R; C)\n∗\nas the Hilbert space\nS (-m)(R; C) =\n(\nu ∈S (R; C)∗:\ninf\nX\nk=0\nμ-m\nk\n|⟨ hk, u⟩|2 < inf\n)\nwith inner product\n(u, v)S (-m)(R;C) =\ninf\nX\nk=0\nμ-m\nk\n⟨ hk, u⟩⟨ hk, v⟩.\nRecall that if X is a Banach space and Λ ∈X∗, then ∥Λ∥X∗= sup{|Λ(x)| :\n∥x∥X = 1}. Thus\n∥u∥S (m)(R;C)∗= sup{|⟨φ, u⟩| : ∥φ∥S (m)(R;C) = 1}.\nTheorem 14.2. For each m ≥0, S (-m)(R; C) is a separable Hilbert space in\nwhich S (R; C) is a dense subset, and\nu ∈S (-m)(R; C) ⇐⇒H-m\n2 u ∈L2(λR; C) & |H-m\n2 u∥L2(λR;C) = ∥u∥S (-m)(R;C)\n⇐⇒u ∈S (m)(R; C)\n∗.\nMoreover, if u ∈S (-m)(R; C), then ∥u∥S (m)(R;C)∗= ∥u∥S (-m)(R;C) and therefore\n(14.3)\n|⟨φ, u⟩| ≤∥φ∥S (m)(R;C)∥u∥S (-m)(R;C).\nProof. That S (-m)(R; C) is a seperable Hilbert space follows from Lemma 13.4.\nNext, let u ∈S (-m)(R; C) and set un = Pn\nk=0 ⟨ hk, u⟩ hk. Then un ∈S (R; C) and\n∥u -un∥2\nS (-m)(R;C) =\nX\nk>n\nμ-m\nk\n⟨ hk, u⟩\n2 -→0.\nHence S (R; C) is dense in S (-m)(R; C).\nIf u ∈S (-m)(R; C), then\n|⟨φ, H-m\n2 u⟩| =\n\ninf\nX\nk=0\nμ\n-m\nk\n(φ, hk)L2(λR;C)⟨ hk, u⟩\n≤∥φ∥L2(λR;C)∥u∥S (-m)(R;C),\nand so H-m\n2 u ∈L2(λR; C) and ∥H-m\n2 u∥L2(λR;C) ≤∥u∥S (-m)(R;C). Conversely, if\nH-m\n2 u ∈L2(λR; C), then\n∥u∥2\nS (-m)(R;C) =\ninf\nX\nk=0\nμ-m\nk\n|⟨ hk, u⟩|2 =\ninf\nX\nk=0\n|⟨ hk, H-m\n2 u⟩|2 = ∥H-m\n2 u∥L2(λR;C).\n\nTOPICS IN FOURIER ANALYSIS\nTo prove the second equivalence, first suppose that u ∈S (m)(R; C)\n∗. Then,\nsince ∥H-m\n2 φ∥S (m)(R;C) = ∥φ∥L2(λR;C),\n|⟨φ, H-m\n2 u⟩| = |⟨H-m\n2 φ, u⟩|\n≤∥H-m\n2 φ∥S (m)(R;C)∥u∥S (m)(R;C)∗= ∥u∥S (m)(R;C)∗∥φ∥L2(λR;C),\nand so H-m\n2 u ∈L2(λR; C) and ∥u∥S (-m)(R;C) ≤∥u∥S (m)(R;C)∗.\nConversely, if\nu ∈S (-m)(R; C), set f = H-m\n2 u, then\n|⟨φ, u⟩| = |(H\nm\n2 φ, f)L2(λR;C)|\n≤∥H\nm\n2 φ∥L2(λR;C)∥f∥L2(λR;C) = ∥u∥S (-m)(R;C)∥φ∥S (m)(R;C),\nand so u ∈S (m)(R; C)\n∗and ∥u∥S (m)(R;C)∗≤∥u∥S (-m)(R;C).\n□\nBy combining Lemma 14.1 and Theorem 14.2, we know that\nS (R; C)∗=\ninf\n[\nm=0\nS (-m)(R; C).\nTheorem 14.3. If u ∈S (-m)(R; C) is non-negative in the sense that ⟨φ, u⟩≥0\nwhenever φ ∈S (R; C) is non-negative, then there exists a Borel measure μ on R\nsuch that\nZ\n(1 + x2)-m+2\nμ(dx) < infand ⟨φ, μ⟩=\nZ\nφ dμ.\nConversely, if μ is a Borel measure on R satisfying\nZ\n(1 + x2)-m\n2 μ(dx) < inf\nand u ∈S (R; C)∗is defined by ⟨φ, u⟩=\nR\nφ dμ, then u ∈S (-m-3)(R; C).\nProof. Assume that u ∈S (-m)(R; C) is non-negative. Choose η ∈CinfR; [0, 1]\nso that η = 1 on [-1, 1] and η = 0 off [-2, 2], set ηR(x) = η x\nR\nfor R ≥\n1, and define uR ∈S (R; C)∗by ⟨φ, uR⟩= ⟨ηRφ, u⟩.\nGiven an R-valued φ ∈\nS (R; C), ∥φ∥uηR ± φηR ≥0, and therefore |⟨φ, uR⟩| ≤∥φ∥u⟨ηR, u⟩. Thus there is\na unique extension of φ ⇝⟨φ, uR⟩as a continuous, non-negative linear functional on\nC[-2R; 2R], R, which, by the Riesz representation theorem, means that there is a\nfinite Borel measure μR on R such that ⟨φ, uR⟩=\nR\nφ dμR. In particular, μR(R) =\n⟨ηR, u⟩≤∥ηR∥S (m)(R;C)∥u∥S (-m)(R;C). Since ∥ηR∥2\nS (m)(R;C) = ηR, HmηR\n\nL2(λR;C)\nand HmηR is a linear combinations of terms of the form\nxk\nRlη(l) x\nR\n, where 0 ≤\nk + l≤2m, there exists a C < infsuch that\nAZ\nηR(x)HmηR(x) dx\na 1\n≤CRm+ 1\n2 ,\nand so μR(R) ≤C∥u∥S (-m)(R;C)Rm+ 1\n2 .\nNote that R ≤R′\n=⇒\nμR′ ↾[-R, R] = μR ↾[-R, R], and therefore there\nis a Borel measure μ on R such that μ ↾[-R, R] = μR ↾[-R, R] for all R ≥1.\n\nDANIEL W. STROOCK\nFurthermore\nZ\n(1 + x2)-m+2\nμ(dx) =\ninf\nX\nn=-inf\nZ\n[n,n+1]\n(1 + |x|2)-m+2\nμn(dx)\n≤2C∥u∥S (-m)(R;C)\ninf\nX\nn=0\n(n + 1)m+ 1\n(1 + n2)\nm+2\n= 2\nm+2\n2 C∥u∥S (-m)(R;C)\ninf\nX\nn=0\n(1 + n)-3\n2 < inf.\nFinally,\n⟨φ, u⟩= lim\nR→inf⟨ηRφ, u⟩= lim\nR→inf\nZ\nηRφ dμ =\nZ\nφ dμ.\nConversely, suppose that μ is a Borel measure on R and that\nC ≡\nZ\n(1 + x2)-m\n2 dμ(dx) < inf.\nClearly φ ⇝\nR\nφ dμ determines a distribution u. In fact, by (13.3),\n|⟨φ, u⟩| ≤C∥(1 + x2)\nm\n2 φ∥u ≤C∥(1 + |x|)mφ∥u ≤CKm∥φ∥S (m+3)(R;C),\nand therefore u ∈S (-m-3)(R; C).\n□\nAs a consequence of Theorem 14.3, we know that for any measurable f : R -→C\nfor which there exists an m ∈Z such that\nZ\n(1 + x2)-m\n2 |f(x)| dx < inf,\nthere is a distribution f ∈S (-m-3)(R; C) such that\n⟨φ, f⟩=\nZ\nφ(x) f(x) dx.\nThe following generalizes the preceding observation.\nTheorem 14.4. Let μ be a Borel measure on R, and assume that\nMμ ≡\nZ\n(1 + x2)-m\n2 μ(dx) < inf.\nIf f ∈Lp(μ; C), then there is a distribution fμ given by\nφ ∈S (R; C) 7-→\nZ\nφ f dμ ∈C.\nMoreover, if mp = minn : m ≤2p′n}, where p′ is the H older conjugate of p, then\nfμ ∈S (-mp-3)(R; C) and\n∥fμ∥S (-mp-3)(R;C) ≤KmpM\np′\nμ ∥f∥Lp(μ;C).\nProof. By H older's inequality,\n\nZ\nφ f dμ\n≤∥f∥Lp(μ;C)∥φ∥Lp′(μ;C).\nAt the same time,\n∥φ∥Lp′(μ;C) ≤\nAZ\n(1 + x2)-m\n2 (1 + x2)\nm\n2 |φ(x)|p′ μ(dx)\na 1\np′\n≤M\np′\nμ\n(1 + x2)\nm\n2p′ φ\n\nu ≤KmpM\np′\nμ ∥φ∥S (mp+3)(R;C).\n\nTOPICS IN FOURIER ANALYSIS\nHence,\n|⟨φ, fμ⟩| ≤KmpM\np′\nμ ∥f∥Lp(μ;C)∥φ∥S (mp+3)(R;C).\n□\nLoosely related to the preceding is the following theorem of Schwartz. Given\na u ∈S (R; C)∗, its support is the smallest closed set F such that ⟨φ, u⟩= 0 for\nall φ that are 0 on F ∁. Equivalently, ⟨φ1, u⟩= ⟨φ2, u⟩if φ1 = φ2 on an open set\ncontaining F.\nTheorem 14.5. If u ∈S (-n+1)(R; C), then u is supported on {0} if and only if\nthere exist {a0, . . . , an} ⊆C for which\n⟨φ, u⟩=\nn\nX\nm=0\nam∂mφ(0)\nfor all φ ∈S (R; C). .\nProof. The sufficiency statement is trivial. To prove the necessity assertion, first\nnote that, by Theorem 13.2, there is a C ∈[0, inf) such that |⟨φ, u⟩| ≤C∥φ∥(n)\nu .\nNext, choose η ∈CinfR; [0, 1] so that η = 1 on [-1, 1] and η = 0 off of [-2, 2], and\ndefine ηr(x) = η x\nr\nfor r ∈(0, 1]. Because 0 is the support of u, ⟨φ, u⟩= ⟨ηrφ, u⟩\nfor all r ∈(0, 1]. In particular, this means that\n|⟨φ, u⟩| ≤C\nn\nX\nl=0\n∥ηφ(l)∥u\nfor some other C < inf.\nWe will now show that ⟨φ, u⟩= 0 if φ(x) = xn+1η(x)ψ(x) for some ψ ∈\nCinf(R; C).\nTo this end, set φr(x) = xn+1ηr(x)ψ(x), and note ⟨φ, u⟩= ⟨φr, u⟩\nfor all r ∈(0, 1]. Next observe that ∂lφr is a linear combination of terms of the\nform\nxn+1-ir-jη(j) x\nr\nψ(k)(x) = xn+1-i-j x\nr\nj\nη(j) x\nr\nψ(k)(x)\nwhere i + j + k = l. Since\nxn+1-i-j x\nr\nj\nη(j) x\nr\nψ(k)(x)\n≤(2r)n+1-i-j∥xjη(j)∥u∥ψ(k)∥u,\nlimr↘0 ∥φ(l)\nr ∥u = 0 for l≤n, and so\n⟨φ, u⟩= lim\nr↘0⟨φr, u⟩= 0.\nNow let φ ∈S (R; C) and use Taylor's theorem to write\nφ(x) =\nn\nX\nm=0\nφ(m)(0)\nm!\nxm + xn+1\nn!\nZ 1\n(1 -t)nφ(n+1)(tx) dt.\nSet ψ(x) = 1\nn!\nR 1\n0 (1-t)nφ(n+1)(tx) dt, and apply the preceding to see that ⟨xn+1ηψ, u⟩=\n0 and therefore that\n⟨φ, u⟩= ⟨ηφ, u⟩=\nn\nX\nm=0\nφ(m)(0)\nm!\n⟨xmη, u⟩.\nHence we can take am = ⟨xmη,u⟩\nm!\n.\n□\n\nDANIEL W. STROOCK\nThe next result characterizes distributions u ∈S (R; C)∗which satisfy the min-\nimum principle\n(14.4)\n⟨φ, u⟩≥0 if φ ∈S (R; R) and φ(0) = min{φ(x) : x ∈R}\nand are quasi-local in the sense that\n(14.5)\nlim\nR→inf⟨φR, u⟩= 0 for all φ ∈S (R; C),\nwhere φR(x) = φ x\nR\n.\nIn preparation for the proof of the characterization, I have to introduce the\nfollowing partition of unity for R \\ {0}. Choose ψ ∈CinfR; [0, 1] so that ψ has\ncompact support in (0, 2) \\ 0, 1\nand ψ(y) = 1 when 1\n2 ≤|y| ≤1, and set ψm(y) =\nψ(2my) for m ∈Z. Then, if y ∈R and 2-m-1 ≤|y| ≤2-m, ψm(y) = 1 and ψn(y) =\n0 unless -m -2 ≤n ≤-m + 1. Hence, if Ψ(y) = P\nm∈Z ψm(y) for y ∈R \\ {0},\nthen Ψ is a smooth function with values in [1, 4]; and therefore, for each m ∈Z, the\nfunction χm given by χm(0) = 0 and χm(y) = ψm(y)\nΨ(y) for y ∈R \\ {0} is a smooth,\n[0, 1]-valued function that vanishes off of (0, 2-m+1) \\ (0, 2-m-2). In addition, for\neach y ∈R \\ {0}, P\nm∈Z χm(y) = 1 and χm(y) = 0 unless 2-m-2 ≤|y| ≤2-m+1.\nLemma 14.6. If u ∈S (R; R) satisfies (14.4) and (14.5), then there exists a unique\nBorel measure M on R such that M({0}) = 0,\nR\ny2\n1+y2 M(dy) < inf, and\n⟨φ, u⟩=\nZ\nφ(y) M(dy)\nif φ, φ′, and φ′′ vanish at 0.\nProof. Referring to the partition of unity described above, define Λmφ = ⟨χmφ, u⟩\nfor φ ∈Cinf(0, 2-m+1) \\ (0, 2-m-2); R, where\nχmφ(y) =\n(r)\nχm(y)φ(y)\nif 2-m-2 ≤|y| ≤2-m+1\notherwise.\nClearly Λm is linear. In addition, if φ ≥0, then χmφ ≥0 = χmφ(0), and so, by\n(14.4), Λmφ ≥0. Similarly, for any φ ∈Cinf(0, 2-m+1)\\(0, 2-m-2); R, ∥φ∥uχm ±\nχmφ ≥0 = ∥φ∥uχm ± χmφ(0), and therefore |Λmφ| ≤Km∥φ∥u, where Km =\n⟨χm, u⟩. Hence, Λm admits a unique extension as a continuous linear functional\non C(0, 2-m+1) \\ (0, 2-m-2); R that is non-negativity preserving and has norm\nKm; and so, by the Riesz representation theorem, we know that there is a unique\nnon-negative Borel measure Mm on R such that Mm is supported on (0, 2-m+1) \\\n(0, 2-m-2), Km = Mm(R), and ⟨χmφ, u⟩=\nR\nR φ(y) Mm(dy) for all φ ∈S (R; R).\nNow define the Borel measure M on R by M = P\nm∈Z Mm. Clearly, M({0}) = 0.\nIn addition, if φ ∈Cinf\nc\nR \\ {0}; R, then there is an n ∈Z such that χmφ ≡0\nunless |m| ≤n. Thus,\n⟨φ, u⟩=\nn\nX\nm=-n\nA(χmφ) =\nn\nX\nm=-n\nZ\nR\nφ(y) Mm(dy)\n=\nZ\nRN\n\nn\nX\nm=-n\nχm(y)φ(y)\n!\nM(dy) =\nZ\nRN φ(y) M(dy),\n\nTOPICS IN FOURIER ANALYSIS\nand therefore\n(14.6)\n⟨φ, u⟩=\nZ\nR\nφ(y) M(dy)\nfor φ ∈Cinf\nc\nR \\ {0}; R.\nBefore taking the next step, observe that, as an application of (14.4), if φ1, φ2 ∈\nS (R; R), then\nφ1 ≤φ2 and φ1(0) = φ2(0) =⇒⟨φ1, u⟩≤⟨φ2, u⟩.\n(∗)\nIndeed, this reduces to the observation that φ2 -φ1 ≥0 = (φ2 -φ1)(0).\nWith these preparations, we can show that, for any φ ∈S (R; C),\nφ ≥0 = φ(0) =⇒\nZ\nR\nφ(y) M(dy) ≤⟨φ, u⟩.\n(∗∗)\nTo check this, apply (∗) to φn = Pn\nm=-n χmφ and φ, and use (14.6) together with\nthe monotone convergence theorem to conclude that\nZ\nR\nφ(y) M(dy) = lim\nn→inf\nZ\nR\nφn(y) M(dy) = lim\nn→inf⟨φn, u⟩≤⟨φ, u⟩.\nNow let η ∈CinfR; [0, 1] satisfy η = 0 on [-1, 1] and η = 0 off (-2, 2), and set\nηR(y) = η(R-1y) for R > 0. By (∗∗) with φ(y) = |y|2η(y) we know that\nZ\nR\n|y|2η(y) M(dy) ≤⟨φ, u⟩< inf.\nAt the same time, by (14.6), for R ≥2,\nZ\nRN\nηR(y) -η(y) M(dy) = ⟨(ηR -η), u⟩= ⟨ηR, u⟩-⟨η, u⟩\nand therefore, by (14.5) and Fatou's Lemma,\nZ\nR\n1 -η(y) M(dy) ≤-⟨η, u⟩< inf.\nHence, we have proved that\n(14.7)\nZ\nR\ny2\n1 + y2 M(dy) < inf.\nWe are now in a position to show that (14.6) continues to hold for any φ ∈\nS (R; R) that vanishes along with its first and second order derivatives at 0. To\nthis end, first suppose that φ vanishes in a neighborhood of 0.\nThen, for each\nR > 0, (14.6) applies to ηRφ, and so\nZ\nR\nηR(y)φ(y) M(dy) = ⟨ηRφ, u⟩= ⟨φ, u⟩+ ⟨(1 -ηR)φ, u⟩.\nSince φ is M-integrable and (1 -ηR)φ -→0 in S (R; R) as R →inf, Lebesgue's\ndominated convergence theorem implies that,\n⟨φ, u⟩= lim\nR→inf\nZ\nR\nηR(y)φ(y) M(dy) =\nZ\nR\nφ(y) M(dy).\n\nDANIEL W. STROOCK\nWe still have to replace the assumption that φ vanishes in a neighborhood of 0\nby the assumption that it vanishes to second order there. For this purpose, first\nnote that, by (14.7), φ is certainly M-integrable, and therefore\nZ\nRN φ(y) M(dy) = lim\nr↘0⟨(1 -ηr)φ, u⟩= ⟨φ, u⟩-lim\nr↘0⟨ηrφ, u⟩.\nBy our assumptions about φ at 0, we can find a C < infsuch that |ηrφ(y)| ≤\nCry2η(y) for all r ∈(0, 1]. Hence, by (∗) and the M-integrability of y2η(y), there\nis a C′ < infsuch that ⟨ηrφ, u⟩≤C′r for small r > 0, and therefore ⟨ηrφ, u⟩-→0\nas r ↘0.\n□\nTheorem 14.7. If u ∈S (R; R) satisfies (14.4) and (14.5), then there exist an\na ≥0, a b ∈R, and Borel measure M on R such that M({0}) = 0, (14.7) holds,\nand\n⟨φ, u⟩= a\n2φ′′(0) + bφ′(0) +\nZ φ(y) -φ(0) -1[0,1](y)φ′(0)yM(dy).\nIn fact, M is determined by\n⟨φ, u⟩=\nZ\nφ(y) M(dy) if φ ∈Cinf\nc\nR \\ {0},\nand, for any η ∈CinfR; [0, 1] which is 1 on [-1, 1] and 0 off (-2, 2)\na = ⟨y2η2, u⟩-\nZ\ny2η(y)2 M(dy)\nand\nb = ⟨yη, y⟩-\nZ\nyη(y) -1[0,1](y) M(dy).\nProof. Let η be as in the statement, set ηR(x) = η x\nR\nfor R > 0, and define\nψR(y) = φ(y) -φ(0)ηR(y) -φ′(0)yη(y) -1\n2φ′′(0)y2η(y)2.\nThen ψ ∈S (R; C) and vanishes to second order at 0, and so, by Lemma 14.6,\n⟨ψR, u⟩=\nR\nψ(y) M(dy). Hence,\n⟨φ, u⟩= φ(0)⟨ηR, u⟩+ φ′(0)⟨yη, u⟩+ 1\n2φ′′(0)⟨y2η2, u⟩\n+\nZ φ(y) -φ(0)ηR(y) -φ′(0)yη(y) -1\n2φ′′(0)y2η(y)2M(dy),\nand so\n⟨φ, u⟩= φ(0)\nA\n⟨ηR, u⟩+\nZ 1 -ηR(y) M(dy)\na\n+ φ′(0)⟨yη, u⟩-1\n2φ′′(0)\nA\n⟨y2η2, u⟩-\nZ\ny2η(y)2 M(dy)\na\n+\nZ φ(y) -φ(0) -φ′(0)yη(y)M(dy).\nBy (14.5) and the Lebesgue dominated convergence theorem, as R →infboth\n⟨ηR, u⟩and\nR\n(1 -ηR) dM tend to 0. Finally, because yη(y) -1[-1.1](y) vanishes\non [-1, 1] and is therefore M-integrable, we can replace φ′(0)⟨yη, u⟩by\nφ′(0)\n\n⟨yη, u⟩-\nZ\nyη(y) -1[-1,1](y)\nM(dy)\n\nTOPICS IN FOURIER ANALYSIS\nand\nR φ(y) -φ(0) -φ′(0)yη(y)M(dy) by\nZ φ(y) -φ(0) -φ′(0)y1[-1,1](y)M(dy).\n□\nExercise 14.1. Let f ∈C1\nb(R; C), set u = f(|x|), and show that u′ = sgn(x)f ′(|x|).\nNext assume that f ∈C2\nb(R; C), and show that u′′ = f ′(0)δ0 + f ′′(|x|).\n15. Extending Continuous Operators on S (R; C) to S (R; C)∗\nThe extension that we made of the operators Hs to S (R; C)∗is a special case\nof the fact that many continuous linear maps of S (R; C) into S (R; C)∗determine\na unique continuous extension as a continuous map from S (R; C)∗itself. The key\nto making such an extension is contained in the following theorem.\nTheorem 15.1. Let A be a continuous map of S (R; C) into S (R; C)∗, and assume\nthat there is a continuous operator A∗on S (R; C) such that\nA∗φ, ψ\nL2(λR;C) = φ, Aψ\nL2(λR;C) for all φ, ψ ∈S (R; C).\nIf Au is defined for u ∈S (R; C)∗by\n(15.1)\n⟨φ, Au⟩= ⟨A∗φ, u⟩for φ ∈S (R; C),\nthen u ⇝Au is the unique extension of A as a continuous operator on S (R; C)∗.\nProof. Because A∗maps S (R; C) continuously into itself, for each m ≥0 there\nexists an n ≥0 and C < infsuch that ∥A∗φ∥S (m)(R;C) ≤C∥φ∥S (n)(R;C), and\ntherefore, if u ∈S (-m)(R; C), then\n|⟨φ, Au⟩| = |⟨A∗φ, u⟩| ≤∥A∗φ∥S (m)(R;C)∥u∥S (-m)(R;C) ≤C∥φ∥S (n)(R;C)∥u∥S (-m)(R;C).\nHence ∥Au∥S (-n)(R;C) ≤C∥u∥S (-m)(R;C), and so A maps S (-m)(R; C) continu-\nously into S (-n)(R; C).\nFurthermore, since S (R; C) is dense in S (R; C)∗and\n⟨φ, Aψ⟩= A∗φ, ψ\nL2(λR;C) for ψ ∈S (R; C), A is the one and only continuous\nextension to S (R; C)∗of A ↾S (R; C).\n□\nIf A : S (R; C) -→S (R; C)∗is a continuous map, we will say that a continuous\noperator A∗on S (R; C) is its adjoint if (A∗φ, ψ)L2(λR;C) = ⟨φ, Aψ⟩for all φ, ψ ∈\nS (R; C).\nGiven a continuous operator A on S (R; C)∗and m, n ∈Z\n∥A∥S (n)(R;C)→S (R;C)(m) = sup|Au∥S (m)(R;C) : ∥u∥S (n)(R;C) = 1 .\nThe argument given in the proof of Theorem 15.1 shows that, for m, n ∈N,\n(15.2)\n∥A∥S (-m)(R;C)→S (-n)(R;C) = ∥A∗∥S (n)(R;C)→S (m)(R;C).\nAmong the simplest maps to which Theorem 15.1 applies are φ ⇝xkφ and\nφ ⇝∂lφ. Indeed, the first of these is its own adjoint, and the adjoint of ∂lis (-∂)l.\nBy Lemma 13.1, the extensions of these maps take, respectively, S (-m)(R; C) into\nS (-m-k)(R; C) and S (-m)(R; C) into S (-m-l)(R; C).\nThe Fourier transform is a particularly important operator on S (R; C)∗, and its\nadjoint is given by φ ∈S (R; C) 7-→ˇφ ∈S (R; C). Hence\n⟨φ, u⟩= ⟨ˇφ, u⟩,\n\nDANIEL W. STROOCK\nand, since ∥ˇφ∥S (m)(R;C) = (2π)\n2 ∥φ∥S (m)(R;C) for all m ≥0, (15.2) says that\n∥ˆu∥S (-m)(R;C) = (2π)\n2 ∥u∥S (-m)(R;C) for all m ≥0. In addition, since both sides of\nthe equation ⟨ˆφ, ˆu⟩= 2π⟨φ, u⟩are continuous functions of u ∈S (R; C)∗and, by\n(12.3), the equation holds when u ∈S (R; C),\n⟨ˆφ, ˆu⟩= (2π)⟨φ, u⟩.\nThe same continuity argument shows that\nc\n∂u = -ıξˆu, c\nxu = ı∂ˆu\nand that the Fourier inversion formula\n(ˆu)∨= 2πu = (ˇu)∧\nholds.\nComputing most Fourier transforms of functions is hard, and computing them\nof distributions can be even harder. Among those that are easy are those of xkδa,\n∂lδa and f ∈L1(λR; C) ∪L2(λR; C) when thought of as a tempered distribution.\nIndeed,\n⟨φ, ˆδa⟩= ˇφ(a) =\nZ\ne-ıaxφ(x) dx = ⟨φ, ea⟩,\nwhere ea(x) = eıax,\nHence, '\n∂lδa = (-ıξ)lea. To compute ˆf when f is thought of as a distribution, note\nthat\n⟨ˇφ, f⟩=\nZ\nf(ξ)\nAZ\ne-ıξxφ(x) dx\na\ndξ =\nZ\nφ(x) ˆf(x) dx = ⟨φ, ˆf⟩,\nand therefore, when f ∈L1(λR; C) is thought of as a distribution, its Fourier\ntransform is the distribution determined by the function ˆf ∈Cb(R; C).\nWhen\nf ∈L2(λR; C), one uses the fact that, as R →inf, 1[-R,R]f -→f in S (R; C)∗and\ntherefore bf = ˆf where ˆf = limR→infc\nfR is the L2-Fourier transform of f. Similarly,\nwhen μ is a finite Borel measure on R, ˆμ as a distribution is equal to the function\nˆμ given by\n(15.3)\nˆμ(ξ) =\nZ\neıξx μ(dx).\nTrickier is the computation of the Fourier transform of distributions like log |x|.\nOne way to do so is to observe that ∂log |x| = 1\nx and first compute d\nx-1. For that\npurpose, set fy(x) =\nx\nx2+y2 for y > 0, and observe that, as y ↘0, fy -→x-1 and\ntherefore \"\nfy -→d\nx-1 in S (R; C)∗. Next observe that observe that, by (7.11),\n\"\nfy(ξ) = lim\nR→inf\nZ R\n-R\nxeıξx\nx2 + y2 dx = ı lim\nR→inf\nZ R\n-R\nx sin x\nx2 + y2 dx = ıπsgn(ξ)e-y|ξ|.\nHence\n(15.4)\nd\nx-1 = ıπsgn.\nKnowing (15.4) one might expect that one can use c\n∂u = -ıξˆu to compute ÷\nlog |x|.\nHowever to do so it is necessary to confront a technical difficulty. Namely, ıπsgn(ξ)\n-ıξ\n=\n-π\n|ξ|, and |ξ|-1 is not a distribution. On the other hand,\nφ ⇝\nZ φ(ξ) -φ(0)e-ξ2\n|ξ|\ndξ\n\nTOPICS IN FOURIER ANALYSIS\nis a distribution. Thus, to overcome the problem, set u = log |x| and write\n⟨φ, ˆu⟩= ⟨φ -φ(0)\"\ng1, ˆu⟩+ φ(0)⟨\"\ng1, ˆu⟩.\nand note that ⟨\"\ng1, ˆu⟩= 2π\nR\ng1(x) log |x| dx. At the same time,\n⟨φ -φ(0)\"\ng1, ˆu⟩=\n*\nφ -φ(0)e-ξ2\nıξ\n, -ıξˆu\n+\n=\n*\nφ -φ(0)e-ξ2\nıξ\n, c\n∂u\n+\n= -π\n*\nφ -φ(0)e-ξ2\n|ξ|\n, λR\n+\n.\nHence\n⟨φ, ÷\nlog |x|⟩= -π\nZ φ(ξ) -φ(0)e-ξ2\n|ξ|\ndξ + 2πφ(0)\nZ\ng1(x) log |x| dx.\nNext, consider a differential operator L = PJ\nj=0 aj∂j where {a0, . . . , aJ} ⊆\nCinf(R; C) and all the aj's and their derivatives have at most polynomial growth. If\nL∗φ ≡\nJ\nX\nj=0\n(-1)j∂j(ajφ),\nthen it is clear that (L∗φ, ψ)L2(λR;C) = (φ, Lφ)L2(λR;C). To see that L∗is a contin-\nuous operator on S (R; C), we need the following lemma.\nLemma 15.2. Let f ∈Cinf(R; R), and assume that for each m ≥0 there exists an\nkm ≥0 such that\nFm ≡max\n1≤j≤m sup\nx∈R\n|∂jf(x)|\n|x|km ∨1 < inf.\nThen, for each m ≥0, there is a Cm < infsuch that\n∥φf∥S (m)(R;C) ≤CmFm∥φ∥S (m+km)(R;C).\nProof. By Exercise 13.1 with n = 0, it is sufficient for us to show that for each\nk, l∈N with k + l≤m, there is a ck,lsuch that\n∥xk∂l(φf)∥L2(λR;C) ≤ck,lFm∥φ∥S (m+km)(R;C).\nTo this end, remember that\n∂l(φf) =\nl\nX\nj=0\nC\nl\nj\na\n∂jφ∂l-jf,\nand\n∥xk∂jφ∂l-jf∥L2(λR;C) ≤Fm\n(1 + |x|km)xk∂jφ∥L2(λR;C)\n≤2 · 3m+kmFm∥φ∥S (m+km)(R;C)∥.\n□\nUsing Lemma 15.2, it easy to check that L∗is a continuous operator on S (R; C),\nand therefore L extends as a continuous operator on S (R; C)∗.\nAnother important operation is convolution. That is, given ψ ∈S (R; C), con-\nsider the operator Cψ on S (R; C) given by Cψη = η ∗ψ. Because '\nη ∗ψ = ˆη ˆψ,\n\nDANIEL W. STROOCK\nLemma 15.2 guarantees that Cψ maps S (m)(R; C) continuously into itself for all\nm ≥0. In addition,\n⟨φ, ψ ∗η⟩=\nZZ\nφ(x) ψ(x -y) η(y) dxdy =\nZZ\nφ(x + y) ψ(x) η(y) dxdy = ⟨C∗\nψφ, η⟩\nwhere\nC∗\nψφ(y) =\nZ\nφ(x + y) ψ(x) dx.\nSince '\nC∗\nψφ(ξ) = ˆφ( ψ)∨, Lemma 15.2 again guarantees that, for all m ≥0, C∗\nψ maps\nS (m)(R; C) continuously into itself, and so Cψ has a unique continuous extension\nto S (R; C)∗, and this extention is a continuous map of S (m)(R; C) into itself for\nall m ∈Z.\nIn order to gain a better understanding of Cψ, we need to use the translation maps\nτx : S (R; C) -→S (R; C) defined in Exercise 13.4, and define ψ ∗u(x) = ⟨τ-xψ, u⟩\nfor u ∈S (R; C)∗and x ∈R.\nTheorem 15.3. For ψ ∈S (R; C) and u ∈S (R; C)∗, ψ∗u is a continuous function\nwith at most polynomial growth, and Cψu = ψ ∗u. In addition, '\nψ ∗u = ˆψˆu, and\nψ ∗u = (2π)-1( ˆψˆu)∨.\nProof. By Exercise 13.4, x ⇝τ-xψ is a continuous map of S (R; C) into itself and\ntherefore that ψ ∗u ∈C(R; C). Also, the estimates given in that Exercise and\nLemma 13.1 show that\n|ψ ∗u(x)| ≤2mKm(|x| ∨1)m∥ψ∥S (m+3)(R;C)∥u∥S (-m-3)(R;C),\nand therefore ψ ∗u has at most polynomial growth.\nTuring to the proof that Cψu = ψ ∗u, suppose that u ∈S (-m)(R; C) and set\nun = Pn\nk=0 ⟨ hk, u⟩ hk. Then un ∈S (R; C) and un -→u in S (-m)(R; C). Since\nCψun = ψ∗un, we will know that Cψu = ψ∗u once we show that that ψ∗un -→ψ∗u\nin S (R; C)∗. To that end, note that, by Theorem 13.2 and that Exercise 13.4,\n|ψ ∗(un -u)(x)| ≤∥τ-xψ∥S (m)(R;C)∥un -u∥S (-m)(R;C)\n≤Km∥τ-xψ∥(m+1)\nu\n∥un -u∥S (-m)(R;C)\n≤2(m+1)Km(|x| ∨1)m+1∥ψ∥(m+1)\nu\n∥un -u∥S (-m)(R;C),\nand so ψ ∗un -→ψ ∗u in S (R; C)∗.\nFinally, since '\nψ ∗u = ˆψˆu and ψ ∗u = (2π)-1 ˆψˆu∨when u ∈S (R; C), the\nS (R; C)∗-continuity of u ⇝ψ ∗u guarantees that these continue to hold for all\nu ∈S (R; C)∗.\n□\nA simple, but typical, application of these results is to the ordinary differential\nequation λu -u′′ = μ, where λ > 0 and μ is a finite Borel measure on R. The\nsolution u to this equation describes the electric potential along a wire produced by\na charge distribution μ when the wire has resistance that is a linear function of the\npotential. To solve this equation, assume that u ∈S (R; C)∗, and take the Fourier\ntransform of both sides. Then λˆu + ξ2ˆu = ˆμ, and so ˆu =\nˆμ\nλ+ξ2 . Next observe (cf.\n(7.5)) that\nλ+ξ2 = \"\nGλ, where\nGλ(x) =\n2λ\n2 e-λ\n2 |x|.\n\nTOPICS IN FOURIER ANALYSIS\nEven though Gλ /∈S (R; C), it and the function x ⇝Gλ ∗μ(x) ≡\nR\nGλ(x-y) μ(dy)\nare elements of L1(λR; C) and therefore of S (R; C)∗.\nIn addition, by Fubini's\ntheorem, ÷\nGλ ∗μ = \"\nGλˆμ, and so\nu(x) =\n2λ\nZ\ne-λ\n2 |x-y| μ(dy).\nIt is an instructive exercise to check that this u is a solution. To this end, first\nuse Exercise 14.1 to see that u′ is the function\nu′(x) = λ\nZ\nsgn(y -x)e-λ\n2 |x-y| dy.\nThus\n⟨φ, u′′⟩= -⟨φ′, u′⟩=\nZ\nφ′(x)\nA1\nZ\nsgn(x -y)e-λ\n2 |x-y|φ′(y) μ(dy)\na\ndx\n=\nZ A1\nZ\nsgn(x -y)e-λ\n2 |x-y|φ′(x) dx\na\nμ(dy).\nNext note that\nZ\nsgn(x -y)e-λ\n2 |x-y|φ′(x) dx =\nZ inf\ny\neλ\n2 (y-x)φ′(x) dx -\nZ y\n-inf\neλ\n2 (x-y)φ′(x) dx\n= -φ(y) + λ\nZ inf\ny\neλ\n2 (y-x) dx -φ(y) + λ\nZ y\n-inf\neλ\n2 (x-y) dx = -2φ(y) + 2λu(y),\nand therefore ⟨φ, u′′⟩= -⟨φ, μ⟩+ λ⟨φ, u⟩, which means that λu -u′′ = μ.\nExercise 15.1. This exercise deals with the special case when an element of\nS (R; C)∗is given by a Borel measure μ.\n(i) Show that ψ ∗μ equals the function\nx ∈R 7-→\nZ\nψ(x -y) μ(dy) ∈C.\n(ii) If μ is finite, show that ˆμ equals the function\nξ ∈R 7-→ˆμ(ξ) ≡\nZ\neıξx μ(dx) ∈C\nand that ˆμ ∈Cb(R; C) with norm ∥ˆu∥u = μ(R).\n(iii) If\nR\n(1 + x2)\nm\n2 μ(dx) < inffor some m ≥0, show that ˆμ ∈Cm\nb (R; C) and that\n∥∂kˆμ∥u ≤\nZ\n|x|k μ(dx) for 0 ≤k ≤m.\n(iv) Assume that\nR\n|x|k μ(dx) < inffor all k ∈N, and show that ψ ∗μ is an element\nof S (R; C) for all ψ ∈S (R; C).\nHint: Show that '\nψ ∗μ is an element of S (R; C).\n\nDANIEL W. STROOCK\n16. Moving to RN\nWith essentially no new ideas and the introduction of only slightly uglier nota-\ntion, we will transfer most of the contents of §§7-15 to RN.\nIf f ∈L1(RN; C), its Fourier transform is the function\nˆf(ξ) =\nZ\neı(ξ,x)RN f(x) dx,\nand, using exactly the same arguments as we did when N = 1, one can easily show\nthat ∥ˆf∥u ≤∥f∥L1(λRN ;C), ˆf is continuous and that, if f ∈C1(RN; C) ∩L1(λRN ; C)\nand f ′ ∈L1(λRN ; C), then '\n∂xjf(ξ) = -ıξj ˆf(ξ) for 1 ≤j ≤N, from which it follows\nthat ˆf(ξ) -→0 as |ξ| →inf.\nTo develop an inversion formula, one introduces the functions\ngt(x) = (2πt)-N\n2 e-|x|2\n2t ,\nuses Fubini's theorem to check that \"\ngt(ξ) = e-t|ξ|2\n2 , and proceeds as before to see\nfirst that\nZ\ngt(x -y)f(y) dy = (2π)-N\nZ\ne-t|ξ|2\n2 e-ı(ξ,x)RN ˆf(ξ) dξ,\nand then that, as t ↘0,\n(2π)-N\nZ\ne-t|ξ|2\n2 e-ı(ξ,x)RN ˆf(ξ) dx converges to\n(r)\nf\nin L1(λRN ; C)\nf(x)\nif f is continuous at x.\nThe normalized Hermite functions on RN are indexed by m = (m1, . . . , mN) ∈\nNN and defined by\nhm(x) = hn1(x1) · · · hnN (xN).\nBy standard results about products of Hilbert spaces, one knows that they form an\northonormal basis in L2(λRN ; C). In addition, if\nH = |x|2 -∆=\nN\nX\nj=1\nx2\nj -∂2\nxj\n,\nthen\nH hm = μm hm where μm =\nN\nX\nj=1\nμmj\nand\n( hm)∧= ı∥m∥1(2π)\nN\n2 hm where ∥m∥1 =\nN\nX\nj=1\nmj.\nFinally, the estimates in (11.2) can be used to show that\n(16.1)\n∥ hm∥L1(λRN ;C) ≤\nN\nN\nY\nj=1\n2π(mj + 1)\ne 1\n, ∥ hm∥u ≤\nN\nN\nY\nj=1\n(mj + 1)\ne 1\nand\n∥xj hm∥u ∨∥∂xj hm∥u ≤2N\nN\nY\nj=1\n(mj + 1).\n\nTOPICS IN FOURIER ANALYSIS\nThe Schwartz test function space S (RN; C) for RN is defined as the space of\nφ ∈Cinf(RN; C) with the property that ∥xk\ni ∂l\nxjφ∥u < inffor all 1 ≤i, j ≤N and\nk, l∈N. Again one introduces the operators\nHsφ =\nX\nk∈NN\nμs\nk(φ, hk)L2(λRN ;C) hk\nand defines the norms\n∥φ∥(m)\nu\n=\nmax\n1≤i,j≤N\nk+l≤m\n∥xi∂xjφ∥u\nand\n∥φ∥S (R;C)(m)(RN;C) =\nX\nk∈NN\nμm\nk |(φ, hk)L2(λRN ;C)|2,\nand the spaces\nS (m)(RN; C) = {φ ∈Cinf(RN; C) : ∥φ∥S (R;C)(m) < inf}.\nClearly, if φ ∈S (m)(R; C), then ∥φ∥S (R;C)(m) = ∥H\nm\n2 φ∥L2(λRN ;C).\nUsing the estimates in (16.1) and the reasoning in Lemma 13.1 and Theorem\n13.2, one sees that, for each m there is a Km ∈(0, inf) such that\n∥φ∥S (m)(RN;C) ≤Km∥φ∥(m+N)\nu\nand\n∥φ∥(m)\nu\n≤Km∥φ∥S (m+3N)(RN;C).\nHence, S (RN; C) = Tinf\nm=0 S (m)(RN; C) and S (RN; C)\n∗can be identified as the\nunion Sinf\nm=0 S (-m)(RN; C) where S (-m)(RN; C) is the analog for N ≥2 of\nS (-m)(R; C) for N = 1. Further, the obvious analogs of Theorems 14.3 and 14.5\nhold. In proving the analogs of Theorems 14.5 and 14.7, one needs to use the RN\nversion of Taylor's theorem which says that\nφ(x) =\nn\nX\nm=0\nX\n∥k∥1=m\n∂kφ(0)\nk!\nxk + 1\nn!\nX\n∥k∥1=n+1\nC\nn + 1\nk\na\nxk\nZ 1\n(1 -t)n∂kφ(tx) dt,\nwhere k! = QN\nj=1 kj, xk = QN\nj=1 xkj\nj , ∂k = QN\nj=1 ∂kj\nxj , and n+1\nk\nis the multinomial\ncoefficient (n+1)!\nk!\n.\nOnce one has the preceding, it should be clear how to extend a continuous map\nA : S (RN; C) -→S (RN; C)\n∗to continuous operators on S (RN; C)\n∗if A admits\nan adjoint A∗which is a continuous operator on S (RN; C). In particular, both the\nFourier transform and convolution have such extensions.\nThe extension of the Fourier transform to L2(λRN ; C) can be done as follows.\nFirst note that if φ ∈S (RN; C), then\nφ, hm\n\nL2(λRN ;C) = μ-n\nm\nHnφ, hm\n\nL2(λRN ;C),\nand therefore, using the first estimate in (16.1), one see that\nφn ≡\nX\n∥m∥1≤n\n(φ, hm)L2(λRN ;C) hm -→φ\nin L1(λRN ; C) as well as L2(λRN ; C). Thus, ∥ˆφn -ˆφ∥u -→0, and so\nˆφ = (2π)\nN\ninf\nX\nm=0\nı∥m∥1(φ, hm)L2(λRN ;C) hm\n\nDANIEL W. STROOCK\nfor φ ∈S (R; C). Next suppose that f ∈L1(λRN ; C) ∩L2(λRN ; C), and set\nφn =\nX\n∥m∥1≤n\n(f, hm)L2(λRN ;C) hm ∈S (RN; C).\nThen φn -→f in L2(λRN ; C), and so, by Fatou's lemma, one sees that ∥ˆf∥L2(λRN ;C) ≤\n(2π)\nN\n2 ∥f∥L2(λRN ;C). Hence the Fourier transform on L1(λRN ; C) ∩L2(λRN ; C) ad-\nmits a unique extension as a continuous operator on L2(λRN ; C). In particular, for\nall f ∈L2(λRN ; C),\nˆf(ξ) = lim\nR→inf\nZ\n|x|≤R\neı(ξ,x)RN f(x) dx,\nwhere the convergence is in L2(λRN ; C). Also\nˆf = (2π)\nN\nX\nm∈NN\nı∥m∥1f, hm\n\nL2(λRN ;C) hm,\nand so the Parseval identity\n( ˆf, ˆg)L2(λRN ;C) = (2π)N(f, g)L2(λRN ;C)\nholds for all f, g ∈L2(λRN ; C), from which the Fourier inversion formula ( ˆf)∨=\n(2π)Nf = ( ˇf)∨follows in the same way that it did when N = 1.\nFinally, by\nthe same argument used when N = 1, one can show that '\n∂xjf = -ıξjˆh if f ∈\nL2(λRN ; C) ∩C1(RN; C) and ∂xjf ∈L2(λRN ; C).\nTo demonstrate the use these considerations, consider again the example dis-\ncussed at the end of §15, only now its analog λu -∆u = μ in RN, where λ > 0\nand μ is a finite Borel measure on RN. Just as before, the Fourier transform of this\nequation lead to the conclusion that ˆu =\nˆμ\nλ+|ξ|2 . To find the function Gλ of which\n(λ + |ξ|2)-1 is the Fourier transform, note that\nλ + |ξ|2 =\nZ inf\ne-t(λ+|ξ|2) dt =\nZ inf\ne-λt\"\ng2t(ξ) dt,\nfrom which it follows that\nGλ(x) =\nZ inf\ne-λtg2t(x) dt = (4π)-1\nZ inf\nt-N\n2 e-λt-|x|2\n4 dt.\nThe function Gλ is a Bessel function, and a more explicit expression for it is easy\nto obtain only when N is odd. For example, when N = 1, we already knew that\nGλ(x) =\n2λ-1\n2 e-λ\n2 |x|, and when N = 3, after differentiating (7.6) with respect to\nx, one sees that\nGλ(x) = e-λ\n2 |x|\n2π|x| .\nIn any case, Gλ ∈L1(λR; C), and it is clear that if a solution u ∈S (RN; C)\n∗exists,\nthen it is the function\nx ⇝Gλ ∗μ(x) ≡\nZ\nGλ(x -y) μ(dy).\n(∗)\nAlso, if the function Gλ ∗μ is an element of S (RN; C)\n∗, for instance if\nZ\n(1 + |x|2)-m\nAZ\nGλ(x -y) μ(dy)\na\ndx < inf,\n\nTOPICS IN FOURIER ANALYSIS\nthen the function in (∗) determines the u ∈S (RN; C)\n∗which is the one and only\nsolution in S (RN; C)\n∗.\nThe Poisson problem ∆u = -μ is a closely related to the preceding, but are two\nreasons why this problem is more difficult than the preceding one. The first reason\nis that, if one exists, then there is more than one solution. Indeed, if u is a solution\nand ∆v = 0, then u + v is again a solution. A v satisfying ∆v = 0 is said to be\nharmonic, and there are lots of them. To see this, observe that ∆v = 0 ⇐⇒|ξ|2ˆv =\nand that |ξ|2ˆv = 0 implies that {0} is the support of ˆv, which by Theorem 14.5\nmeans that it is a linear combination of δ0 and its derivatives and therefore that v\nmust be a polynomial. 14.5 means that ˆv is a linear combination of derivatives of δ0\nand therefore that v is a polynomial. Thus, v ∈S (R; C)∗is harmonic harmonic if\nand only if v = ax + b. When N ≥2, there are harmonic polynomials of all orders.\nFor example, the real part of any complex polynomial will be a harmonic element\nof S (R2; C).\nThe second difficulty is that when N ∈{1, 2},\n|ξ|2 /∈S (RN; C)\n∗, and there-\nfore\nˆμ\n|ξ|2 is not the Fourier transform of the convolution of u with an element of\nL1(λR; C). Nonetheless, when N = 1 and\nR\n|y| μ(dy) < inf, one can check by hand\nthat if G(1)\n0 (x) = x-, then u = G(1)\n∗μ is an element of S (R; C)∗which satisfies\n∆u = -μ. When N = 2, one can use Green's formula and the divergence theorem\nto show that\nZ\n∆φ(x) log |x -y| dx = 2πφ(y)\nfor φ ∈S (R; C), and therefore, if G(2)\n0 (y) ≡-1\n2π log |y| and there is an m ≥0 for\nwhich\nZ\n(1 + |x|2)-m\nAZ G(2)\n0 (x -y)\nμ(dy)\na\ndx < inf,\nthen the function\nx ⇝\nZ\nG(2)\n0 (x -y) μ(dy)\ndetermines a solution u ∈S (R; C)(R2; C)∗.\nWhen N ≥3, one should look for the tempered distribution of which |ξ|-2 is\nthe Fourier transform. To that end, observe that\n|ξ|2 =\nZ inf\ne-t|ξ|2 dt =\nZ inf\n\"\ng2t(ξ) dt,\nand so |ξ|-2 is the Fourier transform of\nG0(x) = (4π)-N\nZ inf\nt-N\n2 e-|x|2\n4t dt =\n4π\nN\n2 |x|N-2\nZ inf\nt\nN\n2 -2e-t dt =\nΓ N-2\n\n4π\nN\n2 |x|N-2 ,\nwhere Γ is Euler's gamma function. Because Γ N\n= N-2\n2 Γ N-2\nand\n2π\nN\nΓN\nis\nthe area ωN-1 of the unit sphere SN-1 in RN, we have that\nG(N)\n(x) =\n(N -2)ωN-1|x|N-2 .\nThus, if the function\nx ⇝\nZ\nG(N)\n(x -y) μ(dy)\n\nDANIEL W. STROOCK\ndetermines a u ∈S (RN; C)\n∗, then u is a solution.\nThe function G(N)\nis called the Green's function for the Laplacian in RN.\nExercise 16.1. Show that if f is an entire function on C (i.e., an analytic function\nthere), then, as a function on R2 it is tempered distribution if and only if it is a\npolynomial. Conclude that if an entire function is not a polynomial, then it grows\nat infinity faster that any power of z.\n17. Convergence of Probability Measures\nDefine M1(RN) to be the set of Borel probability measures on RN.\nClearly\nM1(RN) is a convex subset of S (RN; C)∗, but it is a subset that possesses prop-\nerties that are not shared by most other elements of S (RN; C)\n∗, and the topology\nof S (RN; C)\n∗does not take full advantage of those properties. There are three\nstronger topologies that recommend themselves. Namely: the uniform topology,\nwhich is the one for which8\n∥μ -ν∥var ≡sup|⟨φ, μ -ν⟩| : φ a Borel measurable function with ∥φ∥u = 1\nis the metric; the strong for which sets of the form\nS(μ, r; φ1, . . . , φn) = ν : |⟨φm, ν -μ⟩| < r for 1 ≤m ≤n ,\nwhere φm's are bounded Borel measurable R-valued functions on RN, are a neigh-\nborhood basis for μ; and the weak for which sets of the S(μ, r; φ1, . . . , φn) are a\nneighborhood basis for μ, only now with the restriction that φm's must be contin-\nuous as well as bounded.\nObviously, the strength of the uniform topology is greater than that of the strong\ntopology, which is stronger than the weak topology, which, at first sight (cf. Exercise\n17.1), looks stronger than the one which M1(RN) inherits as a subset of S (RN; C)\n∗.\nEach of them has its virtues and flaws. The uniform topology admits a metric and\nis the strong topology on the dual space of the Banach space C0(RN; R) with\nthe uniform topology; the strong topology is not separable and points don't have\ncountable neighborhood bases; as we will show below, the weak topology is both\nseparable and admits a metric. In addition, convergence of measures in the weak\ntopology is intimately related to the convergence of their Fourier transforms.\nIn what follows, we will study some of the properties and applications of the\nweak topology.\nLemma 17.1. The sets S(μ, r; φ1, . . . , φn) with φ1, . . . , φn ∈Cinf\nc (RN; R) are a\nneighborhood basis at μ for the weak topology.\nProof. We begin by showing if that φ ∈Cinf\nb (R; C) with ∥φ∥u = 1 and r > 0, then\nthere exist φ1, φ2 ∈Cinf\nc (RN; C) such that\nν : |⟨φ1, ν -μ⟩| ∨|⟨φ2, ν -μ⟩| < r\n⊆{ν : |⟨φ, ν -μ⟩| < r}.\nTo this end, choose R > 0 so that μB(0, R) > 1 -r\n4, and take η ∈Cinf(RN; R)\nso that η = 1 on B(0, R) and η = 0 off B(0, R + 1). Then\n|⟨φ, ν -μ⟩| ≤|⟨ηφ, ν -μ⟩| + |⟨(1 -η)φ, ν -μ⟩|\n8We will continue to use ⟨φ, μ⟩to denote the integral with respect to μ of a function φ, even\nif φ /∈S (RN; C). Also, ⟨φ, ν -μ⟩≡⟨φ, ν⟩-⟨φ, μ⟩.\n\nTOPICS IN FOURIER ANALYSIS\nand\n|⟨(1 -η)φ, ν -μ⟩| ≤⟨1 -η, μ⟩+ ⟨1 -η, ν⟩\n≤2⟨1 -η, μ⟩+ |⟨1 -η, ν -μ⟩| = 2⟨1 -η, μ⟩+ |⟨η, ν -μ⟩|.\nThus\n|⟨(1 -η)φ, ν -μ⟩| ≤|⟨ηφ, ν -μ⟩| + 2μB(0, R)∁ + |⟨η, ν -μ⟩|,\nand so\nν : |⟨ηφ, ν -μ⟩| ∨|⟨η, ν -μ⟩| < r\n⊆{ν : |⟨φ, ν -μ⟩| < r}.\nIn view of the preceding, it suffices to show that if φ ∈Cc(RN; C) with ∥φ∥u = 1\nand r > 0, then there exists a ψ ∈Cinf\nc (RN; C) such\n|⟨ψ, ν -μ⟩| < r\n3 =⇒|⟨φ, ν -μ⟩| < r.\nTo this end, simply choose ψ ∈Cinf\nc (RN; C) so that ∥φ -ψ∥u < r\n3, and check that\nthis ψ will serve.\n□\nAs Lemma 17.1 makes clear, what we are calling the weak topology on M1(RN)\nis what a functional analyst would call the weak* topology on the dual space\nC0(RN; R)∗of the Banach space C0(RN; R) (the space of continuous functions that\ntend to 0 at infinity) with the uniform norm. Indeed, the Riesz representation theo-\nrem allows one to identify C0(RN; R) with the space of finite signed Borel measures\non RN, and so M1(RN) can be thought of as a convex subset of the unit ball in\nC0(RN; R)∗, in which case Lemma 17.1 shows that the weak topology on M1(RN) is\nthe topology M1(RN) inherits as a subset from the weak* topology on C0(RN; R)∗.\nTheorem 17.2. The weak topology on M1(RN) is a separable, metric topology.\nProof. Let {φk : k ≥1} be a dense subset of Cc(RN; R), and define\nρ(μ, ν) =\ninf\nX\nk=1\n|⟨φk, ν -μ⟩|\n2k(1 + |⟨φk, ν -μ⟩|).\nUsing Lemma 17.1, it is easy to check that φ is a metric for the weak topology on\nM1(RN).\nTo prove separability, define D to be the set of measures Pn\nm=1 amδxm, where\nn ≥1, the am's are non-negative rational numbers whose sum is 1, and the xm's\nare elements of RN with rational coordinates. Clearly D is countable. Therefore\nit suffices to show that, for each μ ∈M1(RN), each cellection {φ1, . . . , φl} ⊆\nCb(RN; R), and ε > 0, there is a ν ∈D such that max1≤k≤l|⟨φk, ν -μ⟩| < ε.\nFurther, we need do so only for φk's and a μ which are supported on a ball B(0, R).\nGiven such φk's and μ, choose r > 0 so that max1≤k≤l|φk(y) -φk(x)| <\nε\n2 if\n|y -x| < r. Next, cover B(0, R) with balls B(xm, r), where 1 ≤m ≤n, each\nxm ∈B(0, R) and has rational coordinates, and define A1 = B(x1, r) and Am =\nB(xm, r)\\Sm-1\nk=1 Ak for 2 ≤m ≤n. Finally, choose non-negative, rational numbers\na1, . . . , an so that\nmax\n1≤k≤l∥φk∥u\nn\nX\nm=1\n|am -μ(Am)| < ε\n\nDANIEL W. STROOCK\nand Pn\nm=1 am = 1, and take ν = Pn\nm=1 amδxm. Then, for 1 ≤k ≤l,\n|⟨φk, μ -ν⟩| ≤\nn\nX\nm=1\nZ\nAm\n|φk(x) -φk(xm)| dμ + ∥φk∥u\nX\nm=1\n|μ(Am) -am| < ε.\n□\nWe will use the notation μn\nw\n-→μ to mean that μn -→in the weak topology on\nM1(RN).\nTheorem 17.3. Given {μn : n ≥1}∪{μ} ⊆M1(RN), the following are equivalent:\n(i) μn\nw\n-→μ.\n(ii) |⟨φ, μn -μ⟩| -→0 for all φ ∈Cinf\nc (RN; R).\n(iii) For all closed sets F ⊆RN, limn→infμn(F) ≤μ(F).\n(iv) For all open sets G ⊆RN, limn→infμn(G) ≥μ(G).\n(v) For all upper continuous functions f : RN -→R that are bounded above,\nlimn→inf⟨f, μn⟩≤⟨f, μ⟩.\n(vi) For all lower continuous functions f : RN -→R that are bounded below,\nlimn→inf⟨f, μn⟩≥⟨f, μ⟩.\nFinally, if Γ ∈B and its boundary ∂Γ has μ-measure 0, then μn\nw\n-→μ\n=⇒\nμ(Γ) = limn→infμn(Γ).\nProof. We already proved in Lemma 17.1 the equivalence of (i) and (ii), and the\nequivalence of (iii) and (iv) as well as that of (v) and (vi) is obvious. In addition,\nit is clear that (v) together with (vi) implies (i). Thus, we need only check that (i)\nimplies (iii) and that (iv) implies (vi).\nAssume that μn\nw\n-→μ. Given a closed set F, define φk(x) = 1 -\nA\n|x-F |\n1+|x-F |\na 1\nk .\nThen φk ∈CRN; [0, 1] and φk ↘1F as k →inf. Hence, for all k,\n⟨φk, μ⟩= lim\nn→inf⟨φk, μn⟩≥lim\nn→infμn(F),\nand so μ(F) = limk→inf⟨φk, μ⟩≥limn→infμn(F). Thus (i) =⇒(iii).\nIn proving that (iv) implies (vi), it suffices to handle f's which are positive as\nwell as lower semicontinuous. Given such an f, define\nfk =\ninf\nX\nj=1\nj ∧4k\n2k\n1Ij,k *f = 1\n2k\n4k\nX\nj=1\n1Jj,k *f,\nwhere\nIj,k =\nA j\n2k , j + 1\n2k\no\nand Jj,k =\nA j\n2k , inf\na\n.\nThen 0 ≤fk ↗f as k →inf. In addition, because f is lower semicontinuous, the\nsets Gj,k = {x : f(x) ∈Jj,k} are open. Hence, if (iv) holds, then, for all k,\n⟨fk, μ⟩≤lim\nn→inf\n⟨fk, μn⟩≤lim\nn→inf\n⟨f, μn⟩,\nand so\n⟨f, μ⟩= lim\nk→inf⟨fk, μ⟩≤lim\nn→inf\n⟨f, μn⟩.\n\nTOPICS IN FOURIER ANALYSIS\nTo prove the concluding assertion, assume μn\nw\n-→μ and that μ(∂Γ) = 0. Set\nG =\n*\nΓ and F = Γ. Then\nμ(Γ) = μ(G) ≤lim\nn→inf\nμn(G) ≤lim\nn→inf\nμn(Γ)\nand\nμ(Γ) = μ(F) ≥lim\nn→infμn(F) ≥lim\nn→infμn(Γ),\nand so μ(Γ) = limn→infμn(Γ).\n□\nAnother useful fact about weak convergence is the following.\nTheorem 17.4. Assume that μn\nw\n-→μ, let ψ ∈CRN; [0, inf) be an element of\nL1(μ; R) as well as of Tinf\nn=1 L1(μn; R). Then ⟨ψ, μ⟩≤limn→inf⟨ψ, μn⟩. In addition,\nif {φn : n ≥1} ⊆C(RN; R), |φn| ≤ψ for all n ≥1, and ⟨ψ, μn⟩-→⟨ψ, μ⟩, then\n⟨φn, μn⟩-→⟨φ, μ⟩if φn -→φ uniformly on compact subsets.\nProof. Clearly,\n⟨ψ ∧R, μ⟩= lim\nn→inf⟨ψ ∧R, μn⟩≤lim\nn→inf\n⟨ψ, μn⟩\nfor all R > 0, and so ⟨ψ, μ⟩≤limn→inf⟨ψ, μn⟩.\nNow suppose that ⟨ψ, μn⟩-→⟨ψ, μ⟩, that |φn| ≤ψ, and that φn -→φ uni-\nformly on compact subsets. Clearly\n|⟨φn, μn⟩-⟨φ, μ⟩| ≤|⟨φn -φ, μn⟩| + |⟨φ, μ -μn⟩|.\nFor each R > 0, choose ηR ∈CinfRN; [0, 1] so that ηR = 1 on B(0, R) and ηR = 0\noff B(0, R + 1). Then, for each R > 0,\nlim\nn→inf|⟨φn -φ, μn⟩|\n≤lim\nn→inf\nsup\n|x|≤R+1\n|φn(x) -φ(x)|⟨ηR, μn⟩+ lim\nn→inf|⟨(1 -ηR)(φn -φ), μn⟩|\n≤2 lim\nn→inf⟨(1 -ηR)ψ, μn⟩= 2⟨(1 -ηR)ψ, μ⟩,\nand, by Lebesgue's dominated convergence theorem, the last expression tends to 0\nas R →inf. Similarly, for all R > 0,\nlim\nn→inf|⟨φ, μn -μ⟩|\n≤lim\nn→inf|⟨ηRφ, μn -μ⟩| + lim\nn→inf⟨(1 -ηR)ψ, μn⟩+ ⟨(1 -ηR)ψ, μ⟩≤2⟨(1 -ηR)ψ, μ⟩,\nand so limn→inf|⟨φ, μn -μ⟩| = 0.\n□\nWe will next investigate when a subset of M1(RN) is relatively compact. Because\nthe unit ball in the dual space of a Banach is compact in the weak* topology, a\ncareless functional analyst might think that M1(RN) is itself compact. However,\nalthough M1(RN) is closed in the strong topology on C0(RN; R)∗, it is not closed\nin the weak* topology. Indeed, the sequence {δn : n ≥1} ⊆M1(R) is weak*\nconvergent to the measure whose total mass is 0, which is not an element of M1(R).\nAs this example indicates, in order for the weak* limit of a sequence {μn : n ≥1}\n⊆M1(RN) to be in M1(RN), one needs to know that the mass of the μn's is not\n\nDANIEL W. STROOCK\nescaping to infinity. With that in mind, we will say that a subset A of M1(RN) is\ntight if, for each ε ∈(0, 1), there exists an R ∈[0, inf) such that\ninf\nμ∈A μB(0, R) ≥1 -ε.\nTheorem 17.5. A subset A ⊆M1(RN) is relatively compact in the weak topology\nif and only if it is tight.\nProof. Assume that A is tight, and let {μn : n ≥1} ⊆A. As pointed out above,\nthere is a subsequence of {μn : n ≥1} which is weak* convergent in C0(RN; R)∗\nto a ν ∈C0(RN; R)∗which is a non-negative measure with total mass less than or\nequal to 1, and so, without loss in generality, we will assume that {μn : n ≥1} is\nweak* convergent to ν. In order to check that ν(RN) = 1, for any ε ∈(0, 1) choose\nR so that infn≥1 μn\nB(0, R) ≥1 -ε, and choose η ∈CRN; [0, 1] so that η = 1\non B(0, R) and η = 0 off B(0, R + 1). Then\nν(RN) ≥νB(0, R + 1) ≥⟨η, ν⟩= lim\nn→inf⟨η, μn⟩≥lim\nn→infμn\nB(0, R) ≥1 -ε,\nand so ν(RN) must be 1.\nConversely, suppose that A ⊆M1(RN) is relatively compact in the weak topol-\nogy. If A were not tight, then there would exist a θ ∈[0, 1) and, for each n ≥1, a\nμn ∈A such that μn\nB(0, n) ≤θ, and, because A is relatively compact, we could\nassume that μn\nw\n-→μ for some μ ∈M1(RN). But if ηm ∈CRN; [0, 1] equals 1 on\nB(0, m) and 0 off of B(0, m + 1), that would mean that, for all m ≥1,\nμB(0, m) ≤⟨ηm, μ⟩= lim\nn→inf⟨ηm, μn⟩≤lim\nn→inf\nμn\nB(0, n) ≤θ,\nand so μ(RN) would have to be less than or equal to θ < 1.\n□\nExercise 17.1. Show that μn\nw\n-→μ if and only if μn -→μ in S (RN; C)\n∗.\n18. The Fourier Transform for M1(RN)\nIn many applications, it is important to know the relationship between the weak\nconvergence of measures and convergence of their Fourier transforms, which are\noften called characteristic functions in the probability literature.\nTheorem 18.1. Given {μn : n ≥1} ∪{μ} ⊆M1(RN), μn\nw\n-→μ if and only if\nˆμn(ξ) -→ˆμ(ξ) for each ξ ∈RN. In fact, if μn\nw\n-→μ, then ˆμn -→ˆμ uniformly on\ncompact subsets.\nProof. Suppose that ˆμn -→ˆμ pointwise. Then, by Parseval's identity and Lebesgue's\ndominated convergence theorem, for each φ ∈S (RN; C),\n(2π)N⟨φ, μn⟩=\nZ\nˆφ(ξ)ˆμn(-ξ) dξ -→\nZ\nˆφ(ξ)ˆμ(-ξ) dξ = (2π)N⟨φ, μ⟩,\nand so, by Theorem 17.3, μn\nw\n-→μ.\nNow suppose that μn\nw\n-→μ and that ξn -→ξ in RN. Then the functions φn(x) =\neı(ξn,x)RN converge uniformly on compact subsets to the function φ(x) = eı(ξ,x),\nand therefore, by Theorem 17.4, ˆμn(ξn) -→ˆμ(ξ). Hence ˆμn -→μ uniformly on\ncompact subsets.\n□\n\nTOPICS IN FOURIER ANALYSIS\nUndoubtedly the most famous application of Theorem 18.1 is to the derivation\nof the Central Limit Theorem in probability theory.\nThe C.L.T. states that if\n{Xn : n ≥1} is a sequence of RN-valued, mutually independent, uniformly square\nintegrable random variables on some probability space (Ω, F, P) have the properties\nthat their expected value is 0 and\nlim\nn→inf\nn\nn\nX\nm=1\nE(ξ, Xm)2\nRN\n= |ξ|2\nfor all ξ ∈RN, then the distribution σn of\nPn\nm=1 Xm\nn\nconverges weakly to γN, where γ(dx) = (2π)-1\n2 e-x2\n2 dx is the standard Gaussian\nmeasure on R. To phrase this in analytic terms, let μm be the distribution of Xm.\nThen the distribution of Pn\nm=1 Xm is the measure μ1 ∗· · · ∗μn, and so\nˆσn(ξ) =\nn\nY\nm=1\nˆμm\nξ\nn\n\nis the Fourier transform of the distribution σn of\nn\nPn\nm=1 Xm. Next note that,\nby Taylor's theorem,\nˆμm\nξ\nn\n) = 1 +\nı\nn\nZ\n(ξ, x)RN μm(dx) -\n2n\nZ\n(ξ, x)2 μm(dx) + om( 1\nn),\nwhere, because the Xm's are uniformly square integrable,\nlim\nn→infn sup\nm≥1\nom\nn\n= 0.\nHence, because the Xm have expected value 0 and\nlim\nn→inf\nn\nn\nX\nm=1\nZ\n(ξ, x)2\nRN μm(dx) = |ξ|2,\none can use | log(1 -t) -t| ≤t2 for |t| ≤1\n2 to check that\nˆσn(ξ) =\nn\nY\nm=1\nA\n1 -1\n2n\nZ\n(ξ, x)2\nRN μm(dx) + om\nn\na\n-→e-|ξ|2\n= \"\nγN(ξ).\nIn spite of Theorem 18.1, it is not true that a sequence of probability measures\nconverges weakly just because their Fourier transform converge pointwise.\nThe\nreason why is that if the sequence converges weakly, then it is relatively compact\nand therefore must be tight. The following theorem of P. L evy shows how one can\nuse Fourier transforms to test for tightness.\nTheorem 18.2. (L evy's Continuity Theorem) If A ⊆M1(RN), then A is tight\nif and only if for each ε > 0 there exists an r > 0 such that\n(18.1)\nsup\nμ∈A\n|ξ|≤r\n1 -ˆμ(ξ)\n≤ε.\nHence, {μn : n ≥1} ⊆M1(RN) is weakly convergent in M1(RN) if and only if ˆμn\nconverges uniformly in a neighborhood of 0, in which case there is a μ ∈M1(RN)\nto which {μn : n ≥1} is converging weakly.\n\nDANIEL W. STROOCK\nProof. Assume that A is tight and therefore relatively compact. To see that (18.1)\nhold, suppose it did not.\nThen there would be an ε > 0 such that, for each\nn ≥1,\n1 -ˆμn(ξn)\n≥ε for some μn ∈A and ξn ∈B0, 1\nn\n.\nBecause A is\nrelatively compact, we could choose these μn so that they converge weakly to some\nμ ∈M1(RN), in which case there would exist an m ≥1 for which\n|1 -ˆμ(ξ)| ∨\nˆμn(ξ) -ˆμ(ξ)\n< ε\nwhen n ≥m and |ξ| ≤1\nn, which would mean that ε ≤\n1 -ˆμn(ξn)| < ε.\nNow assume that (18.1) holds. To show that A must be tight, begin by observing\nthat\n|1 -ˆμ(ξ)| ≥\nZ 1 -cos(ξ, y)RN μ(dy).\nTherefore, if 9 e ∈SN-1, for all r > 0,\nr\nZ r\n1 -ˆμ(te)\ndt ≥\nZ\nRN\\{0}\nC\n1 -sinr(e, y)RN\nr(e, y)RN\na\nμ(dy).\nNow set\ns(t) = inf\nß\n1 -sin τ\nτ\n: τ ≥t\nTM\nfor t > 0.\nThen s(t) > 0 for all t > 0, and, for all R > 0 and e ∈SN-1,\nsup\nt∈(0,r]\n1 -ˆμ(te)\n≥1\nr\nZ r\n1 -ˆμ(te)\ndt ≥s(rR)μ{y : |(e, y)RN | ≥R}.\nSince\nμ{y : |y| ≥R} ≤N\nsup\ne∈SN-1 μy :\n(e, y)RN\n≥N -1\n2 R ,\nwe have the estimate\n(18.2)\nμ{y : |y| ≥R} ≤\nN\ns(rN -1\n2 R)\nsup\n|ξ|≤r\n1 -ˆμ(ξ)|.\nNow let ε > 0 be given, choose r > 0 so that sup|ξ|≤r |1 -ˆμ(ξ)| < s(1)\nN\nfor μ ∈A,\nand take R = N\nr . Then\nsup\nμ∈A\nμ{y : |y| ≥R} ≤ε.\n□\nBochner found an interesting characterization of characteristic functions, one\nwhich is intimately related to L evy's continuity theorem. To describe his result,\nsay that a function f : RN -→C is non-negative definite if the matrix\nf(ξj -ξk)\n1≤j,k≤n\nis non-negative definite for all n ≥2 and ξ1, . . . , ξn ∈RN, which is equivalent to\nsaying\nn\nX\nj,k=1\nf(ξj -ξk)αjαk ≥0\nfor all α1, . . . , αn ∈C.\n9SN-1 is the unit sphere in RN.\n\nTOPICS IN FOURIER ANALYSIS\nTheorem 18.3. A function f : RN -→C is a characteristic function if and only\nif f is continuous, f(0) = 1, and f is non-negative definite.\nProof. Assume that f = ˆμ for some μ ∈M1(RN). Then it is obvious that f is\ncontinuous and that f(0) = 1. To see that it is non-negative definite, observe that\nn\nX\nj,k=1\nf(ξj -ξk)αjαk =\nZ N\nn\nX\nj,k=1\nei(ξj-ξk,x)RN αjαk\ne\nμ(dx)\n=\nZ\nn\nX\nj,k=1\neiξjxαj\n\nμ(dx) ≥0.\nNow assume that f is a continuous, non-negative definite function with f(0) = 1.\nBecause\nA ≡\nA\nf(ξ)\nf(-ξ)\na\nis non-negative definite, Imf(ξ) + f(-ξ) and Imif(ξ) -if(-ξ) are both 0,\nand therefore f(ξ) = f(-ξ). Thus A is Hermitian, and because it is non-negative\ndefinite, 1 -|f(ξ)|2 ≥0. Therefore |f(ξ)| ≤1. Next, let ψ ∈S (RN; R), and use\nRiemann approximations to see that\nZZ\nf(ξ -η) ˆψ(ξ) ˆψ(η) dξdη ≥0.\nAssume for the moment that f is in L1(λRN ; C), and set\nh(x) = (2π)-N\nZ\ne-i(ξ,x)RN f(ξ) dξ.\nBy Parseval's identity, Fubini's Theorem and the fact that ˆψ(ξ) = ˆψ(-ξ),\n(2π)N\nZ\nh(x)ψ(x)2 dx =\nZ\nf(ξ)c\nψ2(-ξ) dξ =\nZ\nf(ξ) ˆψ ∗ˆψ(-ξ) dξ\n=\nZZ\nf(ξ) ˆψ(ξ + η) ˆψ(η) dξdη =\nZZ\nf(ξ -η) ˆψ(ξ) ˆψ(η) dξdη ≥0.\nHence, since h is continuous, it follows that h ≥0. In addition, by the Fourier\ninversion formula for L1(λRN ; C),\n1 = f(0) = lim\nt↘0 gt ∗f(0) =\nZ\ne-t|ξ|2\n2 h(ξ) dx =\nZ\nh dλRN ,\nand so f is the Fourier transform of the probability measure dμ = h dλRN .\nTo remove the assumption that f is integrable, set gt(x) = (2πt)-N\n2 e-|x|2\n2t\nand\ndefine γt(dx) = gt(x) dx. Then \"\nγt(ξ) = e-t|ξ|2\nand therefore ft ≡\"\nγtf is a continu-\nous, λRN -integrable function that is 1 at 0. To see that ft is non-negative definite,\nnote that\nn\nX\nj,k=1\nft(ξj -ξk)αjαk =\nn\nX\nj,k=1\nf(ξj -ξk)αjαk\nZ\nei(ξj-ξk,x)RN γt(dx)\n=\nZ N\nn\nX\nj,k=1\nf(ξj -ξk)αjei(ξj,x)RN αkei(ξk,x)RN\ne\nγt(dx) ≥0.\n\nDANIEL W. STROOCK\nThus ft = \"\nμt for some μt ∈M1(RN), and so, since ft -→f uniformly on compact\nsubsets, L evy's continuity theorem implies that μt tends weakly to a μ ∈M1(RN)\nfor which f = ˆμ.\n□\nBecause it is difficult to check whether a function is non-negative definite, it\nis the more or less trivial necessity part of Bochner's Theorem that turns out in\npractice to be more useful than the sufficiency conditions.\nExercise 18.1. Given f ∈Cb(RN; C) with f(0) = 1, define the quadratic form\n(φ, ψ)f =\nZZ\nRN×RN φ(ξ)f(ξ -η)ψ(η) dξdη\nfor φ, ψ ∈S (RN; C). Show that this quadratic form is non-negative (i.e., (φ, φ)f ≥\n0) if and only if f is a characteristic function.\nFurther, if f = ˆμ, show that\n(φ, ψ)f = ( ˆφ, ˆψ)L2(μ;C) and therefore that ( · , · )f is non-degenerate (i.e., (φ, φ)f =\n0 =⇒φ = 0) if and only if μ(G) > 0 for all non-empty open sets G.\nExercise 18.2. Here are some interesting facts about characteristic functions.\n(i) It is easy to check that if μ ∈M1(RN), then\n|ˆμ(η) -ˆμ(ξ)|2 ≤2Re1 -ˆμ(η -ξ),\nand so, by Theorem 18.3, one sees that if f is a continuous, non-negative definite\nfunction for which f(0) = 1, then |f(ξ)| ≤1 and |f(η)-f(ξ)|2 ≤21-Ref(η-ξ).\nShow that these inequalities hold even if one drops the continuity assumption.\nHint: Use the non-negative definiteness of the matrices\nA 1\nf(-ξ)\nf(ξ)\na\nand\nN 1\nf(-ξ)\nf(-η)\nf(ξ)\nf(ξ -η)\nf(η)\nf(η -ξ)\ne\nto see that f(-ξ) = f(ξ) and that\n|z|2 -2 z|f(η) -f(ξ)| + 21 -Ref(η -ξ) ≥0.\n(ii) Without using Bochner's theorem, show that if f1 and f2 are non-negative\ndefinite functions, then so are f1f2 and, for any a, b ≥0, af1 + bf2 is also.\nHint: Show that if A and B are non-negative definite, Hermitian N × N matrices,\nthen Ak,lBk,l\n\n1≤k,l≤N is also. One way to see this is to use the fact that B\nadmits a square root.\n(iii) Suppose that f : RN -→C is a non-constant function for which f(0) = 1.\nShow that if lim|x|↘0\n1-f(x)\n|x|2\n= 0, then f cannot be a characteristic function. In\nparticular, if α > 2, then e-|ξ|α is not a characteristic function.\n(iv) Given a finite signed Borel measure μ on RN, define\nˆμ(ξ) =\nZ\nei(ξ,x)RN μ(dx),\nand show that ˆμ = 0 if and only if μ = 0.\nHint: Use the Hahn Decomposition Theorem to write μ as the difference of two,\nmutually singular, non-negative Borel measures on RN.\n\nTOPICS IN FOURIER ANALYSIS\n(v) Suppose that f : R -→C is a non-constant, twice continuously differentiable\ncharacteristic function. Show that f ′′(0) < 0 and that\nf ′′\nf ′′(0) is again a characteristic\nfunction. In addition, show that ∥f ′∥2\nu ∨∥f ′′∥u ≤|f ′′(0)| and that |f(η) -f(ξ)| ≤\n|f ′′(0)|\n2 |η -ξ|.\n(vi) Suppose that {μn : n ≥1} ⊆M1(R) and that f(ξ) = limn→infc\nμn(ξ) exists\nfor each ξ ∈R. Show that f is a characteristic function if and only if it is continuous\nat 0, and notice that this provides an alternative proof of Theorem 18.2.\n(vii) Let μn ∈M1(R) be the measure for which dμn\ndλR = (2n)-11[-n,n]. Show\nthat c\nμn -→1{0} pointwise, and conclude that {μn : n ≥1} has no weak limits.\nThis example demonstrates the essential role that continuity plays in Bochner's and\nL evy's theorems.\n19. Infinitely Divisible Probability Measures\nThe convolution product turns M1(RN) into a commutative ring in which δ0 is\nthe identity. A μ ∈M1(RN) is said to be infinitely divisible in this ring if, for each\nn ≥1, there exists a μ 1\nn ∈M1(RN) such that\nμ = μ∗n\nn ≡μ 1\nn ∗· · · ∗μ 1\nn\n|\n{z\n}\nn times\n,\nand the set I(RN) of infinitely divisible measures is an important source of building\nblocks for constructions in probability theory.\nFor probabililists, an element of I(RN) is the distribution of a random variable\nwhich, for each n ≥1, can be written as the sum of n identically distributed random\nvariables. Using commutativity, it is easy to check that set I(RN) of infinitely\ndivisible measures is a subring of M1(RN).\nA famous theorem of L evy and A. Khinchine describes the characteristic function\nof every element of I(RN). Namely, μ ∈I(RN) if and only if\n(19.1)\nˆμ(ξ) = exp\nA\ni(b, ξ)RN -1\nξ, Aξ\nRN\n+\nZ\nei(ξ,y)RN -1 -i1B(0,1)(y)(ξ, y)RN\n\nM(dy)\na\n,\nfor some b ∈RN, non-negative definite, symmetric A ∈Hom(RN; RN), and Borel\nmeasure M on RN such that M({0}) = 0 and\nR\n|y|2\n1+|y|2 M(dy) < inf. The expression\nin (19.1) is called the L evy-Khinchine formula, a measure M satisfying the stated\nconditions is called a L evy measure, and the triple (b, A, M) is called a L evy system.\nIt is clear that if the right hand side of (19.1) is a characteristic function for every\nL evy system, then these are characteristic functions of infinitely divisible laws.\nIndeed, if μ corresponds to (b, A, M) and μ 1\nn corresponds to b\nn, A\nn , M\nn\n, then ˆμ =\n(\"\nμ 1\nn )n.\nProving that the function f(b,A,M) on the right hand side of (19.1) is a charac-\nteristic function is a relatively easy. To wit, f(0,I,0) = ˆγ, where γ is the standard\nGaussian measure on RN, and so it is easy to check that fb,A,0 is the characteristic\nfunction of the distribution of x ⇝b + A\n2 x under γ. Also, if the L evy measure M\n\nDANIEL W. STROOCK\nis finite and πM is the Poisson measure given by\n(19.2)\nπM = e-M(RN)\ninf\nX\nn=0\nM ∗n\nn! ,\nthen\nd\nπM(ξ) = e-M(RN)\ninf\nX\nn=0\nˆ\nM(ξ)n\nn!\n= e-M(RN)+ ˆ\nM(ξ) = exp\nAZ eı(ξ,y)RN -1\na\nM(dy),\nand so d\nπM = f(bM,0,M), where bM =\nR\nB(0,1) y M(dy). Hence, when M is finite,\nf(b,A,M) is the characteristic function of γb-bM,A ∗πM. Finally, for general L evy\nmeasures M, set Mk(dy) = 1[ 1\nk ,inf)(|y|)M(dy). Then Mk is finite, and so f(b,A,Mk)\nis a characteristic function. Therefore, since f(b,A,Mk) -→f(b,A,M) uniformly on\ncompact subsets, Theorem 18.2 says that f(b,A,M) is a characteristic function.\nThere are no easy proofs that the characteristic function of any μ ∈I(RN) is\ngiven by (19.1). The first step is to show that if μ ∈I(RN), then there is a unique\nl∈C(RN; C) such that l(0) = 0,\n|l(ξ)|\n1+|ξ|2 is bounded, and ˆμ(ξ) = el(ξ). Showing\nthat lexists and is unique comes down to showing that ˆμ never vanishes. To do\nthat, choose r > 0 so that |1-ˆμ(ξ)| ≤1\n2 when |ξ| ≤r. Then there is an lfor which\nl(0) = 0, |l(ξ)| ≤2, and ˆμ(ξ) = el(ξ) if |ξ| ≤r. Using log z = -Pinf\nn=1\n(1-z)n\nn\nwhen\n|1 -z| < 1, one sees that |l(ξ)| ≤2 for |ξ| < r.\nSince \"\nμ 1\nn (ξ)n = ˆμ(ξ), \"\nμ 1\nn (ξ) = 0 when |ξ| ≤r, and so, by uniqueness, it must be\nthat ÷\nμ 1\nn (ξ) = e\nl(ξ)\nn\nfor |ξ| ≤r, and therefore |1 -\"\nμ 1\nn (ξ)| ≤2\nn when |ξ| ≤r. Hence,\nby (18.2), for any R > 0,\nμ 1\nn\n{y : |y| ≥R} ≤\n2N\nns(rN -1\n2 R)\n,\nand so\n|1-÷\nμ 1\nn (ξ)| ≤\nZ 1-eı(ξ,y) μ 1\nn (dy) ≤|ξ|R+2μ 1\nn\n{y : |y| ≥R} ≤|ξ|R+\n2N\nns(rN -1\n2 R)\n.\nGiven ξ = 0, take R =\n4|ξ|, choose n so that\n2N\nns(rN -1\n2 R) ≤1\n4, and conclude that\n|1 -\"\nμ 1\nn (ξ)| ≤1\n2 and therefore |ˆμ(ξ)| ≥2-n. This proves that ˆμ never vanishes\nand therefore that ˆμ = el. In addition, by using the fact that limt↘\ns(t)\nt2\n= 1\n6, the\npreceding line of reasoning shows that there is a C < infsuch that\n1 -e\nl(ξ)\nn ≤1\nwhen n ≥C|ξ|2, and therefore\n|l(ξ)|\n1+|ξ|2 is bounded.\nKnowing that \"\nμ 1\nn = e\nl\nn , one knows that\nl(ξ) = lim\nn→infn\"\nμ 1\nn (ξ) -1.\nThinking of las a tempered distribution, the challenge is to describe the distribution\nof which it is the Fourier transform. Thus, set u = ˇl. Then, since lhas at most\n\nTOPICS IN FOURIER ANALYSIS\nquadratic growth,\n(2π)N⟨φ, u⟩= ⟨ˆφ, l⟩= lim\nn→infn\nZ\nˆφ(ξ)\nAZ e-ı(ξ,x)RN -1μ 1\nn (dx)\na\ndξ\n= lim\nn→infn\nZ AZ e-ı(ξ,x)RN -1 ˆφ(ξ)dξ\na\nμ 1\nn (dx)\n= (2π)N lim\nn→infn\nZ φ(x) -φ(0)μ 1\nn (dx),\nand so\n⟨φ, u⟩= lim\nn→infn\nZ φ(x) -φ(0)μ 1\nn (dx).\nIn particular, u satisfies the obvious RN analog of the minimum principle in (14.4).\nIn addition, because l(0) = 0 and ˇl= ˆl,\n⟨φR, u⟩=\nZ\nφR(ξ)ˆl(ξ) dξ = (2π)NR\nZ\nˇφ(Rξ)l(ξ) dξ\n= (2π)N\nZ\nˇφ(ξ)lR-1ξ dξ -→0\nas R →inf. Thus u satisfies the RN-analog of (14.5), and therefore, by the RN-\nanalog of Theorem 14.7, we know that\n⟨φ, u⟩= 1\nN\nX\ni,j=1\nAi,j∂xi∂xjφ(0) +\nX\ni=1\nbi∂xiφ(0)\n+\nZ\nφ(y) -φ(0) -1B(0,1)(y)y, ∇φ(0)\nRN\n\nM(dy),\nwhere (b, A, M) is a L evy system.\nTo compute the Fourier transform of u, introduce the operator\nL(b,A,M)φ(x) = 1\nN\nX\ni,j=1\nAi,j∂xi∂xjφ(x) +\nN\nX\ni=1\nbi∂xiφ(x)\n+\nZ\nφ(x + y) -φ(x) -b, ∇φ(x)\nRN\n\nM(dy).\nWhat we have shown is that ⟨φ, u⟩= L(b,A,M)φ(0). Using '\n∂xjφ(ξ) = -ıξj ˆφ(ξ) and\nFubini's theorem, one sees that\n⁄L(b,A,M)φ(ξ) = ˆφ(ξ)l(b,A,M)(-ξ),\nwhere\nl(b,A,M)(ξ) = log f(b,A,M)\n= -1\nξ, Aξ)RN + ı(b, ξ)RN +\nZ\neı(ξ,y) -1 -ı1B(0,1)(y)ξ, y)RN\n\nM(dy).\nHence, by Parseval's indentity,\n⟨ˆφ, l⟩= (2π)N⟨φ, u⟩= (2π)NL(b,A,M)(0) = ⟨ˆφ, l(b,A,M)(ξ)⟩,\nand so l= l(b,A,M).\nWe will now use (19.1) to prove some properties of the associated measures\nbased on properties of the L evy system.\nUse μ(b,A,M) ∈S (RN; C)\n∗to denote\n\nDANIEL W. STROOCK\nthe probability measure of which f(b,A,M) is the Fourier transform, and set μt =\nμ(tb,tA,tM) for t > 0. Then\n(2π)N∂t⟨φ, μt⟩= ⟨ˆφ, l(b,A,M)f(tb,tA,tM)⟩= (2π)N⟨L(b,A,M)φ, μt⟩.\nThat is, we have shown that\n(19.3)\n∂t⟨φ, μ(tb,tA,tM)⟩= ⟨L(b,A,M)φ, μ(tb,tA,tM)⟩.\nTheorem 19.1. If either A is non-degenerate or M(G) > 0 for all non-empty open\nsets G ⊆RN \\ {0}, then μ(b,A,M)(G) > 0 for all non-empty open sets G ⊆RN.\nProof. First observe that μ(b,A,M) = δb ∗μ(0,A,M), and therefore we can assume\nthat b = 0. Next note that μ(0,A,M) = γA ∗μ(0,0,M) where γA is the distribution\nof x ⇝A\n2 x under γ, and so, if A is non-degenerate and therefore γA has a strictly\npositive density, μ(0,A,M) does also.\nNow assume that b = 0, A = 0, and M(G) > 0 for all open ∅= G ⊆RN \\ {0}.\nGiven an open G = ∅, choose an η ∈CinfRN; [0, 1] which is strictly positive on G\nand vanishes off of G. Then\nL(0,0,M)η(x) =\nZ\nη(x + y) -η(x) -1B(0,1)(y)∇η(x), y\nRN\n\nM(dy)\n=\nZ\nη(x + y) M(dy) > 0\nif x /∈G. Hence, if f(t) = ⟨η, μ(0,0,tM)⟩, then f ≥0 and, by (19.3), μ(0,0,tM)(G) =\n0 =⇒f ′(t) > 0. But μ(0,0,tM)(G) = 0 also implies that f(t) = 0, which, by the\nfirst derivative test, is possible only if f ′(t) = 0. Hence f(t) > 0 for all t > 0, and\nso μ(0,0,M)(G) > 0.\n□\nTheorem 19.2. If N = 1, then μ(b,A,M)\n(-inf, 0) = 0 if and only if\n(19.4)\nA = 0, M(-inf, 0) = 0, and\nZ\n|y|<1\ny M(dy) ≤b.\nProof. Observe that, for n ≥1,\n{x ∈Rn : xj < 0 for 1 ≤j ≤n|} ⊆\n\nx ∈Rn :\nn\nX\nj=1\nxj < 0\n\n,\nand therefore μ 1\nn\n(-inf, 0)n ≤μ∗n(-inf, 0) for any μ ∈M1(R).\nNow assume that μ(b,A,M)\n(-inf, 0) = 0. Since μ(b,A,M) = γA ∗μ(b,0,M) and\nγA(G) > 0 for all open G = ∅unless A = 0, it follows that A = 0. Next observe\nthat f(b,0,M) has a bounded analytic extension to {ζ ∈C : Reζ < 0}, and there-\nfore M(-inf, 0) must be 0. Finally, to prove the inequality in (19.4), set μ 1\nn =\nμ( b\nn ,0, M\nn ). Since μ1 = μ∗n\nn , the observation above shows that μ 1\nn\n(-inf, 0) = 0, and\ntherefore, if φ ≥0 on [0, inf) and φ(0) = 0, then, by (19.3),\nL(b,0,M)φ(0) = lim\nn→infn⟨φ, μ 1\nn ⟩-φ(0) ≥0,\nand so\nbφ′(0) +\nZ φ(y) -1(-1,1)(y)yφ′(0) M(dy) ≥0.\n\nTOPICS IN FOURIER ANALYSIS\nNow choose η ∈CinfR; [0, 1] so that η = 1 on -1\n2, 1\nand η = 0 off (-1, 1), and,\nfor r ∈(0, 1), set φr(x) = yηr(y) where ηr(y) = η y\nr\n. By the preceding applied to\nφr,\nb -\nZ 1(-1,1)(y) -ηr(y)y M(dy) ≥0,\nand so\nZ\n(r,1)\nyM(dy) ≤b for all r ∈(0, 1).\nFinally, assume that (19.4) holds, and set Mr(dy) = 1[r,inf)(y) M(dy) and br =\nb-\nR\ny Mr(dy) for r > 0. Then (19.4) holds for (b, 0, Mr) and (cf. (19.2)) μ(b,0,Mr) =\nδbr ∗πMr, from which it is clear that μ(b,0,Mr)\n(-inf, 0) = 0.\nTherefore, since\nμ(b,0,Mr)\nw\n-→μ(b,0,M), μ(b,0,M)\n(-inf, 0) = 0.\n□\nExercise 19.1. If M is symmetric, show that the integral in (19.1) can be replaced\nby\nZ cos(ξ, y)RN -1 M(dy).\nIf M(y) = |y|-1-α for some α ∈(0, 2), show that\nZ\nSN-1\ncos(ξ, y)RN -1 M(dy) = |ξ|α\nZ cos(e, y)RN -1 dy,\nfor every e ∈SN-1. In particular, by combining this with part (iii) of Exercise\n18.2, conclude that e-|ξ|α is a characteristic function if and only if α ∈[0, 2].\n20. Singular Integral Operators\nThe classic Poisson problem is that of finding, for a given a function φ, a solution\nu to the equation ∆u = -φ in RN, and one of the questions that arises is determin-\ning how properties of the function φ are reflected by the solution u. In particular,\none wants to know whether second order derivatives of u can be estimated in terms\nof φ. When N = 1, this problem doesn't arise because -φ is the second derivative\nof u. However, when N ≥2, it is not at all clear to what extent the entire Hessian\nmatrix of u is controlled by its trace.\nTo address this question, it is best to begin by giving an integral representation\nof the solution u. Depending on dimension, u is given by\nu(x) =\nZ\nG(N)\n(x -y)φ(y) dy,\nwhere G(N)\nis the (cf. § 16) Green's function for the Laplacian in RN:\nG(N)\n(x) =\n(r) 1\nπ log |x|\nif N = 2\n(N-2)ωN-1|x|N-2\nif N ≥3.\nThus\n∂xi∂xju(x) =\nZ\nG(N)\ni,j (x -y)φ(y) dy\nwhere\n(20.1)\nG(N)\ni,j (x) =\nωN-1|x|N\nZ A\n-δi,j + N xixj\n|x|2\na\n.\n\nDANIEL W. STROOCK\nBecause G(N)\ni,j\nis not an integrable function, one has take care when interpreting\nconvolution with it. On the other hand, since G(N)\n∈S (RN; C)\n∗, so is is G(N)\ni,j , and\ntherefore φ ∗G(N)\ni,j\nmakes perfectly good sense when φ ∈S (RN; C). The question\nthen is whether, using this interpretation, one can derive estimates.\nBefore getting into the details, it is important to know what sort of estimates are\npossible. In particular, because G(N)\ni,j\nis neither integrable nor bounded, one should\nnot expect that convolution with it will map either L1(λRN ; C) or Linf(λRN ; C) into\nitself. Even so, it turns out (cf. (24.2) below) that it maps Lp(λRN ; C) boundedly\ninto itself when p ∈(1, inf), and what follows is one way to prove that.\n21. The Hilbert Transform\nA key fact about G(N)\ni,j\nis that it is a Borel measurable, homogeneous function of\norder N whose integral over SN-1 is 0. That is, it is a function of the form\nk(x) = Ω(x)\n|x|N\nwhere Ω↾SN-1 ∈L1(λSN-1; C) satisfies Ω(rx) = Ω(x) for all r > 0 and\nZ\nSN-1 Ω(ω) λSN-1(dω) = 0.\nA Calder`on-Zygmund kernel k determines a tempered distribution by the prescrip-\ntion\n⟨φ, k⟩= lim\nr↘0\nZ\n|y|≥r\nφ(y) k(y) dy\n= lim\nr↘0\nZ\n|y|≥r\nφ(y) -φ(0)1[-1,1](y) k(y) dy =\nZ φ(y) -φ(0)1[-1,1](y) k(y) dy.\nSuch functions k are called Calder`on-Zygmund kernels because Calder`on and\nZygmund were able to prove a large number of deep results about convolution\nwith respect to them. In particular (cf. (23.2) below), they showed that, in great\ngenerality, for each p ∈(1, inf) there is a constant Cp, depending on N and Ω, such\nthat ∥φ ∗k∥Lp(λRN ;C) ≤Cp∥φ∥Lp(λRN ;C).\nWhen N = 1 there is, up to a multiple constant, only one C-K kernel, namely, the\nfunction h(x) =\nπx. Convolution with respect to h was studied originally by Hilbert\nand has been known as the Hilbert transform ever since. A seminal observation\nmade by Hilbert is that, even though h /∈L1(λR; C), this transform is a bounded\nmapping of L2(λR; C) into itself. Indeed, thinking of h as a tempered distribution,\nwe showed in (6.2) that ˆh(ξ) = ısgn(ξ). Thus, we know that ∥φ ∗h∥L2(λR;C) ≤\n∥φ∥L2(λR;C).\nIn order to prove the estimate for p = 2, I will use an beautiful approach that\nI think was introduced by M. Riesz and is closely related to the ideas we used\nto compute ˆh.\nRecall the functions py(x) =\nπ\ny\nx2+y2 and qy =\nπ\nx\nx2+y2 which\nare, respectively, the real and imaginary parts of\nı\nz when z = x + ıy. Next, set\nhy(x) = 1[y,inf)(x)h(x), and observe that ∥hy -qy∥L1(λR;C) = ∥h1 -q1∥L1(λR;C) ≤\nπ, and therefore ∥φ ∗hy -φ ∗qy∥Lp(λR;C) ≤\nπ∥φ∥Lp(λR;C). Thus, showing that\nsupy>0 ∥φ ∗qy∥Lp(λR;C) ≤Cp∥φ∥Lp(λR;C) for some Cp < infwill show that\nsup\ny>0\n∥φ ∗hy∥Lp(λR;C) ≤Cp∥φ∥Lp(λR;C) for some other Cp < inf.\n\nTOPICS IN FOURIER ANALYSIS\nThe advantage that qy has over hy is its connection to analytic functions. Namely,\nsince ı\nz = py(x) + ıqy(x) when z = x + ıy,\nf(z) ≡φ ∗py(x) + ıφ ∗qy(x) = ı\nπ\nZ\nφ(ξ)\nx + ıy -ξ dξ.\nFurther, because ∥py∥Lp(λR;C) = 1, ∥φ ∗py∥Lp(λR;C) ≤∥φ∥Lp(λR;C), and Riesz's idea\nwas to use these observations to control ∥φ∗qy∥Lp(λR;C) in terms of ∥φ∗py∥Lp(λR;C).\nTo do so he needed the fact that, for each n ≥1 there exist finite constants An and\nBn such that\n(Imζ)2n ≤AnReζ2n + Bn(Reζ)2n for ζ ∈C.\n(∗)\nProving (∗) comes down to showing that cos2n θ ≤An cos 2nθ + Bn sin2n θ for\nθ ∈[-π, π]. Clearly, if θ ∈-π\n8n, π\n8n\n∪ 7π\n8 , 9π\n, An can be chosen so the An cos 2nθ\ndominates cos2n θ; and for θ not in those intervals, Bn can be chosen so that\nBn sin2n θ dominates cos2n θ -An cos 2nθ.\nWith the preceding at hand, we know that\nZ φ ∗qy(x)2n dx ≤AnRe\nAZ\nf(x + ıy)2n dx\na\ndx + Bn\nZ φ ∗py(x)2n dx.\nWhat Riesz saw is that he could use Cauchy's theorem to prove that the integral\nof x ⇝f(x + ıy)2n is independent of y > 0. Indeed, consider the rectangle {z =\nx + ıy : |x| ≤R & y1 ≤y ≤y2}. Cauchy's theorem says that the contour integral\nof f 2n around the boundary is 0. In addition, since φ ∈S (R2; C), as R →inf\nthe contribution to the integral from the vertical parts of the boundary tends to\n0, and so the integrals over the horizontal parts are equal. Finally, as y ↗inf,\nR\nf(x + ıy)2n dx -→0, and so we now know that\n∥φ ∗qy∥L2n(λR;C) ≤B\n2n\nn ∥φ∥L2n(λR;C).\nHence, we have proved that, for each n ≥1 there is a C2n < infsuch that\n(21.1)\nsup\ny>0\n∥φ ∗hy∥L2n(λR;C) ≤C2n∥φ∥L2n(λR;C).\n22. Interpolation\nAlthough (21.1) is already significant, one should suspect that a similar estimate\nholds for all p ∈(0, inf), not just even integers. However, because Riesz needed f p\nto be an analytic function, he needed p to be an integer; and because he needed\n(Ref)p to be non-negative, he needed it to be an even integer. It was to overcome\nthis problem that he proved a powerful general result, known as an interpolation\ntheorem, that can be viewed as an operator theoretic analog of H older's equality.\nThe following version and proof of his result is due to G. Thorin.\nTheorem 22.1. (Riesz-Thorin) Given a σ-finite measure space (E, F, μ) and\nnumbers\n1 ≤p0, p1, q0, q1 ≤infwith p0 ∧p1 < inf,\nassume that T is a linear operator on Lp0(μ; C)∩Lp1(μ; C) into Lq0(μ; C)∩Lq1(μ; C)\nsatisfying\n∥Tf∥Lqj (μ;C) ≤Mj∥f∥Lpj (μ;C) for j ∈{0, 1},\nwhere M0 ∨M1 < inf. Then, for each θ ∈[0, 1]\n∥Tf∥Lqθ (μ;C) ≤M 1-θ\nM θ\n2 ∥f∥Lpθ (μ;C),\n\nDANIEL W. STROOCK\nwhere\npθ = 1-θ\np0 + θ\np1 .\nThorin's proof of Theorem 22.1 requires to following simple version, due to\nHadamard and known as the three lines theorem, of the Phragmen-Lindel of theo-\nrem.\nLemma 22.2. Suppose that F is a bounded continuous function on the closed strip\nS = {z ∈C : Rez ∈[0, 1]} which is analytic on the interior of S. If |F(ıy)| ≤m0\nand |F(1 + ıy)| ≤m1 for all y ∈R, then |F(z)| ≤m1-x\nmx\n1 for z = x + ıy ∈S.\nProof. By replacing F with\nF (z)\nm1-z\nmz\n1 , one can reduce to the case when m0 = m1 = 1,\nin which case one needs to show that |F(z)| ≤1 for z ∈S. Thus we will assume\nthat m0 = m1 = 1 and will prove that |F| ≤1.\nIf lim|y|→infsupx∈[0,1] |F(x + ıy)| = 0, then the maximum principle for analytic\nfunctions says that\nsup\nz∈S\n|Imz|≤R\n|F(z)| = sup|F(x + ıy)| : (x, y) ∈{0, 1} × [-R, R] ∪(0, 1) × {-R, R}\n-→sup\ny∈R\n{|F(ıy) ∨|F(1 + ıy)|} ≤1.\nEven if F(x + ıy) doesn't tend to 0 as |y| →inf, for each n ≥1, the function\nFn(z) = e\nz2-1\nn F(z) does. In addition, |Fn(ıy)|∨|Fn(1+ıy)| ≤1, and so |Fn(z)| ≤1.\nNow let n →inf.\n□\nProof of Theorem 22.1. Without loss in generality, we will assume that p0 ≤p1.\nAlso, q′ will be used to denote the H older conjugate of q ∈[1, inf].\nThe first step is to check that it suffices to prove that\n\nZ\ng(ξ)Tf(ξ) μ(dξ)\n≤M 1-θ\nM θ\n(∗)\nfor simple functions f and g satisfying ∥f∥Lpθ (μ;C) = 1 and ∥g∥Lq′\nθ (μ;C) = 1. In-\ndeed, ∥Tf∥Lqθ (μ;C) equals the supremum of\nR\ngTf dμ\nover simple functions g with\n∥g∥Lq′\nθ (μ;C) = 1, and, if p1 < inf, then, for any f ∈Lp0(μ; C) ∩Lp1(μ; C), we can\nchoose simple function fn such that fn -→f both in Lp0(μ; C) and in Lp1(μ; C).\nHence, if (∗) holds for simple functions, then, by H older's inequality,\n∥Tf∥Lqθ (μ;C) ≤∥T(fn -f)∥Lqθ (μ;C) + ∥Tfn∥Lqθ (μ;C)\n≤∥T(fn -f)∥1-θ\nLq0(μ;C)∥T(fn -f)∥θ\nLq1(μ;C) + M 1-θ\nM θ\n2 ∥fn∥Lpθ (μ;C)\n≤M 1-θ\nM θ\n2∥fn -f∥1-θ\nLp0(μ;C)∥fn -f∥θ\nLp1(μ;C) + ∥f∥Lpθ (μ;C)\n,\nfrom which the required estimate follows when n →inf. When p1 = inf, one can\nchoose the fn's so that they converge to f in Lp1(μ; C) and are uniformly bounded\nand thereby use the preceding argument to get the desired result.\nTurning to the proof of (∗), let θ ∈(0, 1) and determine p and q by 1\np = 1-θ\np0 + θ\np1\nand 1\nq = 1-θ\nq0 + θ\nq1 . Next, define p(z) and q(z) for (cf. Lemma 22.2) z ∈S so that\np(z) = 1-z\np0 + z\np1 and\nq′(z) = 1-z\nq′\n0 + z\nq′\n1 . Given simple functions\nf =\nn\nX\nm=1\nam1Γm and g =\nn\nX\nm=1\nbm1∆m with ∥f∥Lp(μ;C) = 1 and ∥g∥Lq′(μ;C) = 1,\n\nTOPICS IN FOURIER ANALYSIS\ndefine fz = |f|\np\np(z) f\n|f| and gz = |g|\nq′\nq′(z) g\n|g|, where\nh(ξ)\n|h(ξ)| is taken to be equal 0 if\nh(ξ) = 0. Then\nfz =\nn\nX\nm=1\n|am|\np\np(z) am\n|am|1Γm and gz =\nn\nX\nm=1\n|bm|\nq′\nq′(z) bm\n|bm|1∆m.\nNow define\nF(z) =\nZ\ngz(ξ)Tfz(ξ) μ(dξ) =\nn\nX\nk,l=1\n|ak|\np\np(z) ak\n|ak||bl|\nq′\nq′(z) bl\n|bl|\nZ\n∆l\nT1Γk(ξ) μ(dξ).\nThen F is a bounded continuous function on S that is analytic function on the\ninterior of S, and so, by Lemma 22.2,\n|F(θ)| ≤m1-θ\nmθ\n1 where m0 = sup\ny∈R\n|F(ıy)| and m1 = sup\ny∈R\n|F(1 + ıy)|.\nThus, what remains is to check that m0 ≤M0 and m1 ≤M1. But, by H older's\ninequality,\n|F(ıy)| ≤∥gıy∥Lq′\n0(μ;C)∥Tfıy∥Lq0(μ;C) ≤M0∥gıy∥Lq′\n0(μ;C)∥fıy∥Lp0(μ;C),\nand\n∥fıy∥p0\nLp0(μ;C) =\nn\nX\nm=1\n|am|\np\np(ıy) p0μ(Γm) =\nn\nX\nm=1\n|am|pμ(Γm) = 1\nSimilarly\n∥f1+ıy∥p1\nLp1(μ;C) = 1, ∥gıy∥q′\nLq′\n0(μ;C) = 1, and ∥g1+ıy∥q′\nLq′\n1(μ;C) = 1.\n□\nBy combining (21.1) and Theorem 22.1, we know that there is a Cp < infsuch\nsupy>0 ∥φ ∗hy∥Lp(λR;C) ≤Cp∥φ∥Lp(λR;C) for each p ∈[2, inf). To extend this result\nto p ∈(1, 2), observe that if p ∈(1, 2), then p′ ∈(2, inf). Hence, since\n(ψ, φ ∗hy)L2(λR;C) = -(ψ ∗hy, φ)L2(λR;C),\nwe have that\n|(ψ, φ ∗hy)L2(λR;C)| ≤Cp′∥ψ∥Lp′(λR;C)∥φ∥Lp(λR;C)\nand therefore that, for all p ∈(1, inf),\n(22.1)\nsup\ny>0\n∥φ ∗hy∥Lp(λR;C) ≤Cp∥φ∥Lp(λR;C),\nwhere Cp = Cp′ when p ∈(1, 2).\nExercise 22.1. Note that ∥ˆφ∥L2(λRN ;C) = (2π)\nN\n2 ∥φ∥L2(λR;C) and ∥ˆφ∥Linf(λRN ;C) ≤\n∥φ∥L1(λRN ;C), and use Theorem 22.1 to prove that ∥ˆφ∥Lp′(λRN ;C) ≤(2π)\nN\np′ ∥φ∥Lp(λRN ;C)\nfor p ∈[1, 2]. Next, let ψ ∈Lp(λRN ; C) for some p ∈[1, inf), and define Tφ = φ ∗ψ.\nRemember that ∥Tφ∥Lp(λRN ;C) ≤∥φ∥Lp(λRN ;C)∥ψ∥L1(λRN ;C) and ∥Tφ∥Linf(λRN ;C) ≤\n∥φ∥Lp(λRN ;C)∥ψ∥Lp′(λRN ;C), and use Theorem 22.1 to prove Young's inequality\n∥ψ ∗ψ∥Lr(λRN ;C) ≤∥φ∥Lp(λRN ;C)∥ψ∥Lq(λRN ;C) if 1\nr = 1\np + 1\nq -1 ≥0.\n\nDANIEL W. STROOCK\n23. The Method of Rotations\nCalder`on and Zygmund noticed that the Hilbert transform, and especially (22.1),\ncan be used to prove the Lp boundedness of their kernels when Ω∈L1(λSN-1; C) is\nodd (i.e., Ω(-ω) = -Ω(ω) for ω ∈SN-1). For example, set ky(x) = 1[y,inf)(|x|)k(x)\nfor (x, y) ∈RN × (0, inf). Then because\nc\nky(ξ) = lim\nR→inf\nZ\ny<|x|≤R\neı(ξ,x)k(x) dx\n= lim\nR→inf\nZ\nSN-1 Ω(ω)\nCZ\n(y,R]\neır(ξ,ω) 1\nr dr\na\nλSN-1dω,\nif Ωis odd, one has that\nc\nky(ξ) = lim\nR→inf\nZ\nSN-1 Ω(ω)\nCZ\ny<|r|≤R\neır(ξ,ω) 1\nr dr\na\nλSN-1(dω)\n= π\nZ\nSN-1 Ω(ω)c\nhy\n(ξ, ω) λSN-1(dω).\nHence,\n(23.1)\nc\nky(ξ) = ıπ\nZ\nSN-1 Ω(ω)c\nhy\n(ξ, ω) λSN-1(dω),\nand so\n∥c\nky∥u ≤\nπ∥Ω∥L1(λSN-1;C)∥c\nhy∥u\n.\nIn particular, we already know that\n∥φ ∗k∥L2(λRN ;C) ≤\nπ∥Ω∥L1(λSN-1;C)\n∥φ∥L2(λRN ;C).\nThe same trick as we just used allows us to prove estimates for general p ∈(1, inf).\nNamely, again using the oddness of k, one can first write\nφ ∗ky(x) = 1\nZ\nSN-1 Ω(ω)\nCZ\n|r|>y\nφ(x -rω)dr\nr\na\nλSN-1(dω),\nand then, after applying Minkowski's inequality,\n∥φ ∗kε∥Lp(λRN ;C) ≤1\nZ\nSN-1 |Ω(ω)|\nZ\nRN\n\nZ\n|r|>y\nφ(x -rω) dr\nr\n\np\ndx\n! 1\np\nλSN-1(dω).\nFinally, for fixed e ∈SN-1, choose Euclidean coordinates for RN so that e points\nin the direction of the first coordinate. Then\nZ\nRN\n\nZ\n|r|>y\nφ(x -re) dr\nr\n\np\ndx\n= πp\nZ\n· · ·\nZ\nRN-1\nAZ\nR\n[φ ∗hy( · , x2, . . . , xN)](x1)\np dx1\na\ndx2 · · · dxN\n≤(πCp)p\nZ\n· · ·\nZ\nRN-1\n∥φ( · , x2, . . . , xN)∥p\nLp(λR;C) dx2 · · · dxN = (πCp)p∥φ∥p\nLp(λRN ;C),\n\nTOPICS IN FOURIER ANALYSIS\nwhich, together with the preceding, leads immediately to\n(23.2)\n∥φ ∗k∥Lp(λRN ;C) ≤kp∥φ∥Lp(λRN ;C) for p ∈(1, inf),\nwhere Kp = πCp∥Ω∥L1(λSN-1;C).\n24. The Riesz Kernels\nIn a sense which can be made very precise, the basic C-Z kernels for RN are the\nRiesz kernels ri(x) = cN\nxi\n|x|N+1 , 1 ≤i ≤N, where\ncN ≡\nAπ\nZ\nSN-1 |ω1| λSN-1(dω)\na-1\n.\nObviously, the preceding applies to each of these.\nTo get a feeling for how\nconvolution with respect to ri acts, apply (23.1) to see that\n\"ri(ξ) = ıπcN\nZ\nSN-1 ωisgn(ξ, ω) λSN-1(dω).\nCertainly, \"ri is homogeneous of degree 0, and so we need only worry about ξ ∈SN-1.\nGiven ξ ∈SN-1, write ω = (ω, ξ)ξ + ω⊥ξ. Then\nZ\nSN-1ωisgn(ξ, ω) λSN-1(dω)\n= ξi\nZ\nSN-1 |(ω, ξ)| λSN-1(dω) +\nZ\nSN-1\nω⊥ξ\nisgn(ξ, ω) λSN-1(dω).\nBecause the integrand in the second term is an odd function of ω ⇝(ξ, ω), the\nsecond term vanishes. Hence,\n(24.1)\n\"ri(ξ) = ıξi\n|ξ|,\nξ ∈RN \\ {0}.\nTo evaluate cN, observe that c1 = 1\nπ is trivial. When N ≥2, use\nZ\nSN-1|ω1| λSN-1(dω) = ωN-2\nZ\n(-1,1)\n|ρ|1 -ρ2 N-3\ndρ\n= ωN-2\nZ\n(0,1)\n(1 -t)\nN-3\ndt = 2ωN-2\nN -1 = 2ΩN-1,\nwhere ΩN-1 is the volume to the unit ball in RN-1, and so cN =\nπΩN-1 .\nFrom the Riesz transforms one can build other kernels. For instance, recall the\nkernels in (20.1). Because ∂xi∂xjφ = -(∆φ) ∗G(N)\ni,j , -ξiξj ˆφ = |ξ|2'\nG(N)\ni,j ˆφ, and so\n'\nG(N)\ni,j (ξ) = -ξiξj\n|ξ|2 = -\"ri(ξ)\"\nrj(ξ).\nHence, φ ∗G(N)\ni,j\n= -(φ ∗ri) ∗rj, and so\n(24.2)\n∥φ ∗G(N)\ni,j ∥Lp(λRN ;C) ≤K2\np∥φ∥Lp(λRN ;C) for p ∈(1, inf).\nEquivalently, we now know that\n∥∂xi∂xjφ∥Lp(λRN ;C) ≤K2\np∥∆φ∥Lp(λRN ;C) for p ∈(1, inf).\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\nRES.18-015 Topics in Fourier Analysis\nSpring 2024\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms."
        },
        {
          "category": "Lecture Notes",
          "title": "RES.18-015 S24 Lecture 01: Basic Theory of Fourier Series",
          "type": "PDF",
          "source_url": "https://ocw.mit.edu/courses/res-18-015-topics-in-fourier-analysis-spring-2024/mitres_18_015_s24_lec01.pdf",
          "content": "1. Basic Theory of Fourier Series\nSet em(x) = eı2πmx for m ∈Z and x ∈R, and observe that {em : m ∈Z} is an\northonormal family in L2(λ[0,1); C).1 Even though it involves an abuse of notation,\nwe will use (φ, em)L2(λ[0,1);C) to denote\nR\n[0,1) φ(y)e-m(y) dy for φ ∈L1(λ[0,1); C).\nGiven a function φ : [0, 1) -→C, define its periodic extension φ : R -→C\nby φ(x) = φx -⌊x⌋, where ⌊x⌋= max{n ∈Z : x ≥n}. Notice that if φ ∈\nL1(λ[0,1); C), then\nZ\n[0,1)\nφ(x) dx =\nZ\n[a,a+1)\nφ(x) dx for all a ∈R.\nSimilarly,\nZ\n[0,1)\nφ(-x) dx =\nZ\n[0,1)\nφ(x) dx.\nFor bounded, continuous functions φ and ψ on [0, 1), define\nφ ∗ψ(x) =\nZ\n[0,1)\nφ(x -y)ψ(y) dy,\nand use the preceding to check that\nφ ∗ψ(x) =\nZ\n[-x,-x+1]\nφ(y) ψ(x -y) dy = ψ ∗φ(x).\nFinally, by the continuous version of Minkowski's inequality,2\n∥φ ∗ψ∥Lp(λ[0,1);C) ≤∥φ∥Lp(λ[0,1);C)∥ψ∥L1(λ[0,1);C) ∧∥ψ∥Lp(λ[0,1);C)∥φ∥L1(λ[0,1);C)\nfor any p ∈[1, inf).\nHence, for each p ∈[1, inf), (φ, ψ) ⇝φ ∗ψ has a unique\ncontinuous extension as a map bilinear map from L1(λ[0,1); C) × Lp(λ[0,1); C) into\nLp(λ[0,1); C), and\n(1.1)\n∥φ ∗ψ∥Lp(λ[0,1);C) ≤∥φ∥L1(λ[0,1);C)∥ψ∥Lp(λ[0,1);C)\ncontinues to hold.\nTheorem 1.1. If φ ∈Lpλ[0,1]; C for some p ∈[1, inf), then\nlim\nr↗1\nφ -\nX\nm∈Z\nr|m|φ, em\n\nL2(λ[0,1);C)em\n\nLp(λ[0,1];C)\n= 0,\nand, if φ ∈C[0, 1]; C satisfies φ(0) = φ(1), then3\nlim\nr↗1\nφ -\nX\nm∈Z\nr|m|φ, em\n\nL2(λ[0,1);C)em\n\nu\n= 0.\nProof. Define\npr(x) =\nX\nm∈Z\nr|m|em(x) for r ∈[0, 1) and x ∈[0, 1).\n1For a measure space (E, F, μ) and p ∈[1, inf], Lp(μ; C) is the associated Lebesgue space. For\na Borel measurable subset S ⊆RN, λS is the Lebesgue's measure resticted to S.\n2If φ ∈Lp(μ; C), then ∥φ∥Lp(μ;C) is its Lp-norm.\n3∥· ∥u is the uniform (i.e., supremum norm).\n\nClearly\nR 1\n0 pr(x) dx = 1, pr(-x) = pr(x), and epr is continuous. In addition,\npr(x) =\n1 -re1(x)+\nre-1(x)\n1 -re-1(x) =\n1 -r2\n|1 -re1(x)|2 =\n1 -r2\n1 -2r cos 2πx + r2 for r ∈[0, 1),\nand so pr ≥0.\nObviously,\nX\nm∈Z\nr|m|φ, em\n\nL2(λ[0,1);C)em(x) = pr ∗φ(x) =\nZ\n[0,1)\npr(y) φ(x + y) dy\nsince pr is even. Now suppose that φ ∈C[0, 1] : C with φ(0) = φ(1). Then, since\nlimr↗1\nR 1\nδ pr(y) dy = 0 for each δ ∈(0, 1), it is easy to check that\nlim\nr↗1 sup\nx∈[0,1]\n\nZ 1\nφ(x + y) dy -f(x)\n≤ωφ(δ),\nwhere ωφ is the modulus of continuity of φ. Thus the second part of the theorem\nhas been proved.\nTo prove the first part, let φ ∈Lp(λ[0,1); C), and choose choose a sequence {φk :\nk ≥1} ⊆C[0, 1]; C which satisfy φk(0) = φk(1) and ∥φ -φk∥Lp(λ[0,1];C) -→0 as\nk →inf. Then, for each k,\n∥pr ∗φ -φ∥Lp(λ[0,1];C)\n≤∥pr ∗(φ -φk)∥Lp(λ[0,1];C) + ∥pr ∗φk -φk∥Lp(λ[0,1];C) + ∥φk -φ∥Lp(λ[0,1];C),\nand so, by (1.1), for all k.\nlim\nr↗1 ∥pr ∗φ -φ∥Lp(λ[0,1];C) ≤2∥φk -φ∥Lp(λ[0,1];C).\nFinally, let k →inf.\n□\nTheorem 1.2. {em : m ∈Z} is an orthonormal basis in L2(λ[0,1); C), and so, for\neach φ ∈L2(λ[0,1); C),\n(1.2)\nX\nm∈Z\n(φ, em)L2(λ[0,1);C)em ≡lim\nn→inf\nX\n|m|≤n\n(φ, em)L2(λ[0,1);C) = φ,\nwhere the convergence is in L2(λ[0,1); C). In addition, for all φ, ψ ∈L2(λ[0,1); C),\n(φ, ψ)L2(λ[0,1);C) =\nX\nm∈Z\n(φ, em)L2(λ[0,1);C)(ψ, em)L2(λ[0,1);C).\nProof. It suffices to check the first statement, and to do so all we need to know is\nthat (φ, em)L2(λ[0,1);C) = 0 for all m ∈Z implies φ = 0 for a set of φ's which is dense\nin L2(λ[0,1); C). But, by Theorem 1.1, we know this for continuous φ's satisfying\nφ(0) = φ(1), and these are dense in L2(λ[0,1); C).\n□\nEquation (1.2) is known as Parseval's identity for Fourier series.\nDefine the partial sum Snφ = P\n|m|≤n(φ, em)L2(λ[0,1);C)em.\nCorollary 1.3. If φ ∈C([0, 1]; C) and\nX\nm=0\n(φ, em)L2(λ[0,1);C)\n< inf,\n\nthen the series\nX\nm∈Z\n(φ, em)L2(λ[0,1);C)em(x)\nis uniformly absolutely convergent to φ. In fact,\nSn(φ) -φ\n\nu ≤\nX\n|m|>n\n(φ, em)L2(λ[0,1);C)\n.\nProof. That the series if uniformly absolutely convergent is obvious. To see that\nit must be converging to φ, let ψ be uniform limit of {Snφ : n ≥0}. Then ψ is\ncontinuous and, because φ is the L2(λ[0,1); C) limit of this series, ψ = φ λ[0,1]-almost\neverywhere, which, since both are continues, means that they are equal everywhere.\nGiven these statements, the final estimate is trivial.\n□\nLemma 1.4. Let l≥1 and assume that φ ∈Cl([0, 1]; C) satisfies φ(k)(0) = φ(k)(1)\nfor 0 ≤k ≤l-1. Then\n(φ, em)L2(λ[0,1);C) =\n\nı\n2πm\nlφ(l), em\n\nL2(λ[0,1);C) for m = 0.\nProof. Clearly it suffices that prove the result when l= 1. To do so, use integration\nby parts and the condition φ(0) = φ(1) to check that\nZ 1\nφ(y)e-m(y) dy =\n-ı2πm\nZ 1\nφ′(y)e-m(y) dy.\n□\nAs a consequence of Lemma 1.4, we see that if φ ∈C1([0, 1]; C) satisfies φ(0) =\nφ(1), then\nX\n|m|>n\n(φ, em)L2(λ[0,1);C)\n≤\nX\n|m|>n\n(φ′, em)L2(λ[0,1);C)\n\n2π|m|\n≤1\n2π\n\nX\nm>n\nm-2\n! 1\n∥φ′∥L2(λ[0,1);C) ≤\n∥φ′∥L2(λ[0,1);C)\nπ(2n)\n.\nHence, by Corollary 1.3,\n∥Snφ -φ∥u ≤∥φ′∥u\nπ(2n)\n2 .\nExercise 1.1. Prove the Riemann-Lebesgue lemma, which is the statement that\nlimn→inf(φ, en)L2(λ[0,1);C) = 0 for all φ ∈L1(λ[0,1); C).\nExercise 1.2. Let φ be a Lipschitz continuous function satisfying φ(0) = φ(1),\nand show that\nSnφ -φ∥u ≤∥φ∥Lip\nπ(2n)\n2 .\nHint: Introduce the functions φk = p 1\nk ∗φ.\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\nRES.18-015 Topics in Fourier Analysis\nSpring 2024\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms."
        },
        {
          "category": "Lecture Notes",
          "title": "RES.18-015 S24 Lecture 02: The Gibbs Phenomenon",
          "type": "PDF",
          "source_url": "https://ocw.mit.edu/courses/res-18-015-topics-in-fourier-analysis-spring-2024/mitres_18_015_s24_lec02.pdf",
          "content": "2. Gibbs Phenomenon\nHere we will examine what can be said for a φ ∈C([0, 1]; C) that is not periodic.\nFor example, consider the function φ(x) = x for x ∈[0, 1]. Clearly\n(φ, em)L2(λ[0,1);C) =\nı\n2πm for m = 0,\nand so\nSn(x) = 1\n2 -1\nπ\nn\nX\nm=1\nsin 2πmx\nm\n,\nwhere Sn ≡Snφ. Now set\nΦm(x) =\nm\nX\nk=1\nsin 2πkx.\nThen Φm(x) is the imaginary part of\nm\nX\nk=1\nek(x) = e1(x)1 -em(x)\n1 -e1(x) =\ne1(x) -em+1(x)1 -e-1(x)\n2(1 -cos 2πx)\n= e1(x) -1 -em+1 + em(x)\n2(1 -cos 2πx)\n,\nwhich is\nsin 2πx -sin 2π(m + 1)x + sin 2πmx\n2(1 -cos 2πx)\n.\nAfter using some of trigonometric identities, one sees that\n(2.1)\nΦm(x) = cos πx sin2 πmx\nsin πx\n+ sin πmx cos πmx.\nIn particular, |Φm(x)| ≤3 1\nx ∨\n1-x\n.\nSumming by parts, one sees that\nSn(x) = 1\n2 -Φn(x)\nπn\n-\nn-1\nX\nm=1\nΦm(x)\nπm(m + 1),\nwhich means that\n(2.2)\nSn(x) -x\n≤ 1\nx ∨\n1-x\nπn.\nIn particular, Sn(x) is converging to x uniformly on compact subsets of (0, 1).\nTo see what happens for x near to 0, consider x =\nk\n2n for k ≥1, and observe\nthat\nn\nX\nm=1\nsin πkm\nn\nm\n= 1\nn\nn\nX\nm=1\nsin πkm\nn\nm\nn\n-→\nZ\n[0,1]\nsin πkx\nx\ndx -→\nZ\n[0,πk]\nsin x\nx\ndx.\nHence, since (cf. (7.11) in §7)\nlim\nR→inf\nZ\n[0,R]\nsin x\nx\ndx = π\n2 ,\n\nSn\nk\n2n\n= -1\nπ lim\nR→inf\nZ\n[πk,R]\nsin x\nx\ndx\n= (-1)k+1\nπ2k\n-1\nπ\nZ\n[πk,inf)\ncos x\nx2\ndx = (-1)k+1\nπ2k\n+ 2\nπ\nZ\n[πk,inf)\nsin x\nx3\ndx\nas n →inf. Therefore\nSn\nk\n2n\n= (-1)k+1\nπ2k\n\n1 -ak\nπk\n\n+ εn(k),\nwhere\nak = (-1)k2(πk)2\nZ inf\nπk\nsin x\nx3\ndx ∈(-1, 1)\nand limn→infεn(k) = 0. This shows that, for large n, Sn\nk\n2n\nis at least\n2π2k if k is\nodd and at most -\n2π2k if k is even. This sort of oscillatory behavior is known as\nGibbs's phenomenon, although Gibbs seems not to have been the first to discover\nit.\nExercise 2.1. By considering Sn\nand using equations (2.1) and (2.2), show\nthat\nπ = 8\ninf\nX\nl=0\n(4l+ 1)(4l+ 3).\nExercise 2.2. Show that if φ ∈C1[0, 1]; C then,\nsup\nx∈[n-1\n2 ,1-n-1\n2 ]\nSnφ(x) -φ(x)\n≤\n8∥φ′∥L2(λ[0,1);C)\nπn\n.\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\nRES.18-015 Topics in Fourier Analysis\nSpring 2024\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms."
        },
        {
          "category": "Lecture Notes",
          "title": "RES.18-015 S24 Lecture 03: Bernoulli Polynomials",
          "type": "PDF",
          "source_url": "https://ocw.mit.edu/courses/res-18-015-topics-in-fourier-analysis-spring-2024/mitres_18_015_s24_lec03.pdf",
          "content": "3. Bernoulli Polynomials\nTheorem 3.1. Define {bl: l≥0} ⊆R inductively by\nb0 = 1 and bl+1 =\nl\nX\nk=0\n(-1)kbl-k\n(k + 2)! ,\nand set\n(3.1)\nBl(x) =\nl\nX\nk=0\n(-1)kbl-k\nk!\nxk for l≥0.\nThen {Bl: l≥0} are the one and only functions satisfying\n(3.2)\nB0 = 1, B′\nl+1 = -Blfor l≥0, and Bl(1) = Bl(0) for l≥2.\nProof. To see that there is at most one set of functions satisfying (3.2), let {Dl:\nl≥0} be the set of differences between two solutions, and set l= inf{l: Dl= 0}.\nThen l≥1, and, if l< inf, then Dlis a constant a and there is a b ∈R such that\nDl+1(x) = -ax + b. But -a + b = Dl+1(1) = Dl+1(0) = b, and therefore a = 0.\nSince this would mean that Dl= -D′\nl+1 = 0, no such lcan exist.\nBy definition, B0 = 1, and it is easy to check that B′\nl+1 = -Bl. To verify the\nperiodicity property, note that\nBl+2(1) -Bl+2(0) =\nl+2\nX\nk=1\n(-1)kbl+2-k\nk!\n= -bl+1 +\nl+2\nX\nk=2\n(-1)kbl+2-k\nk!\n= -bl+1 +\nl\nX\nk=0\n(-1)kbl-k\n(k + 2)!\n= 0.\n□\nThe functions {Bl: l≥0} in (3.1) are known as Bernoulli polynomials.\nTheorem 3.2. For l≥2 and x ∈[0, 1],\n(3.3)\nBl(x) = -ıl\n(2π)l\nX\nn=0\nen(x)\nnl\n.\nIn particular, b2l+1 = 0 and\n(3.4)\nζ(2l) ≡\ninf\nX\nm=1\nm2l= (-1)l+122l-1π2lb2l\nfor l≥1.\nProof. First observe that, for l≥1,\nBl, e0\n\nL2(λ[0,1];C) = -\nZ 1\nB′\nl+1(x) dx = Bl+1(0) -Bl+1(1) = 0\nand, for l≥2 and n = 0,\nBl, en\n\nL2(λ[0,1];C) =\nı\n2πn\nBl-1, en\n\nL2(λ[0,1];C)\nand therefore\nA2πn\nı\nal-1 Bl, en\n\nL2(λ[0,1];C) = B1, en\n\nL2(λ[0,1];C) =\nZ 1\n2 -xe-n(x) dx = -ı\n2πn.\n\nHence\nBl, en\n\nL2(λ[0,1];C) =\n-ıl\n(2πn)l\nfor l≥2 and n = 0, which completes the proof of (3.3). Finally, because bl= Bl(0),\nit is clear from (3.3) that b2l+1 = 0 and that (3.4) holds.\n□\nBesides (3.4), the Bernoulli polynomials play a critical role in what is known as\nthe Euler-Maclauren formula:\n(3.5)\nZ n\nf(x) dx -\nn\nX\nm=1\nf(m)\n= -\nl\nX\nk=1\nbk\nf (k-1)(n) -f k-1(0) +\nZ n\nBl(x)f (l)(x) dx\nfor l≥1,\nwhere Blis the periodic extension of Bl↾[0, 1) to R. To prove (3.5), first note that\nZ n\nf(x) dx -\nn\nX\nm=1\nf(m) =\nn\nX\nm=1\nZ m\nm-1\nf(x) -f(m) dx\n= -\nn\nX\nm=1\nZ m\nm-1\nx -(m -1)f ′(x) dx\n=\nn\nX\nm=1\nA\n-b1\nf(m) -f(m -1) +\nZ m\nm-1\nB1\nx -(m -1)f ′(x) dx\na\n= -b1\nf(n) -f(0) +\nZ n\nB1(x)f ′(x) dx.\nHence, (3.5) holds when l= 1. Next observe that for any l≥1,\nZ n\nBl(x) = n\nZ 1\nBl(x) dx = nBl+1(1) -Bl+1(0) = 0,\nand therefore\nZ n\nBl(x)f (l)(x) dx =\nn\nX\nm=1\nZ m\nm-1\nBl\nx -(m -1)f (l)(x) -f (l)(m) dx\n=\nn\nX\nm=1\nA\n-bl+1\nf (l)(m) -f (l)(m -1) +\nZ m\nm-1\nBl+1\nx -(m -1)f (l+1)(x) dx\na\n= -bl+1\nf (l)(n) -f(0) +\nZ n\nBl+1(x)f (l+1)(x) dx.\nTherefore, (3.5) for limplies (3.5) for l+ 1.\nTheorem 3.3. If l≥1 and φ ∈Cl[0, 1]; C, then\n(3.6)\nZ 1\nφ(x) -1\nn\nn\nX\nm=1\nφ m\nn\n\n= -\nl\nX\nk=1\nbk\nnk\nφ(k-1)(1) -φ(k-1)(0) + 1\nnl\nZ 1\nBl(nx)φ(l)(x) dx,\n.\n\nProof. Take f(x) = φ x\nn\n, apply (3.5) to f, and make a simple change of variables.\n□\nBy Schwarz's inequality,\n\nZ 1\nBl(nx)φ(l)(x) dx\n≤\nCZ 1\nBl(nx)2 dx\na 1\n∥φ(l)∥L2(λ[0,1];C),\nand\nZ 1\nBl(nx)2 dx = 1\nn\nZ n\nBl(x)2 dx = ∥Bl∥2\nL2(λR;C).\nFurther, by (1.2) and (3.3),\n∥Bl∥2\nL2(λR;C) =\n(2π)2l\nX\nn=0\nn2l.\nHence, by (3.6),\n(3.7)\n\nZ 1\nφ(x) dx -1\nn\nn\nX\nm=1\nφ m\nn\n+\nl\nX\nk=1\nbk\nnk\nφ(k-1)(1) -φ(k-1)(0)\n\n≤\np\n2ζ(2l)\n(2πn)l∥φ(l)∥L2(λ[0,1];C).\nFrom (3.7) one sees that if, for some n ≥1,\n(3.8)\nlim\nl→inf\n∥φ(l)∥L2(λ[0,1];C)\n(2πn)l\n= 0,\nthen\nZ 1\nφ(x) dx -1\nn\nn\nX\nm=1\nφ m\nn\n= -lim\nl→inf\nl\nX\nk=1\nbk\nnk\nφ(k-1)(1) -φ(k-1)(0).\nIn particular, if φ ∈Cinf[0, 1]; C and φ(k) is periodic for all k ≥0, then (3.8)\nimplies that\nZ 1\nφ(x) dx = 1\nn\nn\nX\nm=1\nφ m\nn\n,\na result that has a much simpler derivation (cf. Exercise 3.1 below).\nMore generally, because\nφ(k-1)(1) -φ(k-1)(0)\n≤∥φ(k)∥L2(λ[0,1];C) and |bk| ≤\n(2π)k ,\ninf\nX\nk=1\n∥φ(k)∥L2(λ[0,1];C)\n(2πn)k\n< inf\nimplies that\n(3.9)\nZ 1\nφ(x) dx -1\nn\nn\nX\nm=1\nφ m\nn\n= -\ninf\nX\nk=1\nbk\nnk\nφ(k-1)(1) -φ(k-1)(0),\nwhere the series is absolutely convergent.\n\nExercise 3.1. Suppose that φ and all its derivatives are periodic on [0, 1], and\nshow that\nlim\nl→inf\n∥φ(l)∥L2(λ[0,1];C)\n(2πn)l\n= 0 ⇐⇒φ, em\n\nL2(λ[0,1];C) = 0 if |m| ≥n\n⇐⇒φ =\nX\n|m|<n\nφ, em\n\nL2(λ[0,1];C)em.\nNext, show that\nn\nn\nX\nj=1\nem\nj\nn\n= 0\nfor 1 ≤|m| < n, and thereby arrive at the conclusion reached above.\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\nRES.18-015 Topics in Fourier Analysis\nSpring 2024\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms."
        },
        {
          "category": "Lecture Notes",
          "title": "RES.18-015 S24 Lecture 04: Comparing Summability Methods",
          "type": "PDF",
          "source_url": "https://ocw.mit.edu/courses/res-18-015-topics-in-fourier-analysis-spring-2024/mitres_18_015_s24_lec04.pdf",
          "content": "4. Comparing Summability Methods\nIn preparation for the following section, we will review here basic definitions and\nresults for different notions of convergence of a series.\nGiven a sequence {am : m ≥1} ⊆C, set\nSn =\nn\nX\nm=1\nam and An = 1\nn\nn\nX\nm=1\nSm,\nand when limn→inf|am|\nm ≤1, set\nA(r) =\ninf\nX\nm=1\namrm-1 for r ∈[0, 1).\nThe Sn's are called the partial sums of the corresponding series, the An's are its\nC esaro means, and r ⇝A(r) is its Abel function. The series is said to be summable\nto s ∈C if s = limn→infSn, it is C esaro summable to s ∈C if limn→infAn = s, and\nit is Abel summable to s ∈C if s = limr↗1 A(r)\nHere we will show that\nsummable to s =⇒C esaro summable to s =⇒\nlim\nm→inf\nam\nm = 0 and Abel summable to s.\nThe Exercise 4.1 below outlines a proof that neither implication can be reversed.\nThe first implication is trivial. To prove the second, assume C esaro summability,\nand note that\nan\nn = An -An-1 + An-1\nn\n-→0.\nNext, write\nam =\n\nA1\nif m = 1\n2A2 -A1\nif m = 2\nmAm -2(m -1)Am-1 + (m -2)Am-2\nif m ≥3,\nand therefore\nA(r) =\ninf\nX\nm=1\nmrm-1Am -2\ninf\nX\nm=2\n(m -1)rm-1Am-1 +\ninf\nX\nm=3\n(m -2)rm-1Am-2\n=\ninf\nX\nm=1\n(rm-1 -2rm + rm+1)mAm = (1 -r)2\ninf\nX\nm=1\nmrm-1Am.\nNow observe that\nn\nX\nm=1\nmrm-1 = ∂r\nn\nX\nm=0\nrm = ∂r\n1 -rn\n1 -r = 1 -rn -n(1 -r)rn-1\n(1 -r)2\n.\nHence,\n(1 -r)2\nn\nX\nmrm-1 ≤1 -rn and (1 -r)2\ninf\nX\nmrm-1 = 1.\n\nAssume that An -→s, and, given ε > 0, choose n so that |Am -s| ≤ε for m > n.\nThen\nA(r) -s\n= (1 -r)2\n\ninf\nX\nm=1\nmrm-1(Am -s)\n≤(1 -r)2\nn\nX\nm=1\nmrm-1|Am -s| + ε\n≤(1 -rn) max\n1≤m≤n |Am -s| + ε,\nand therefore limr↗1 |A(r) -s| ≤ε.\nExercise 4.1. Show that\n(i) the series for {(-1)m-1 : m ≥1} is C esaro summable to 1\n2 but not summable,\n(ii) the series for {(-1)m-1m : m ≥1} is Abel summable to 1\n4 but not C esaro\nsummable. In fact, show that A2n = 0 and A2n+1 =\nn+1\n2n+1 -→1\n2.\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\nRES.18-015 Topics in Fourier Analysis\nSpring 2024\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms."
        },
        {
          "category": "Lecture Notes",
          "title": "RES.18-015 S24 Lecture 05: Some Refinements",
          "type": "PDF",
          "source_url": "https://ocw.mit.edu/courses/res-18-015-topics-in-fourier-analysis-spring-2024/mitres_18_015_s24_lec05.pdf",
          "content": "5. Some Refinements\nIn this section we will apply the notions of summability discussed in the previous\nsection to Fourier series. Observe that we have already considered Abel summability\nin §1.\nTo examine further when the series is summable, introduce the function\nDn(x) =\nX\n|m|≤n\nem(x) for x ∈R.\nThen Dn, which is often called the Dirichlet kernel, is an even, periodic function\nwith period 1,\nR 1\n0 Dn(x) dx = 1, and Snφ = Dn ∗φ. In addition\nDn(x) = e-n(x)\n2n\nX\nm=0\nem(x) = e-n(x)1 -e2n+1(x)\n1 -e1(x)\n= e-ıπ(2n+1)x -eıπ(2n+1)x\ne-ıπx -eıπx\n= sin π(2n + 1)x\nsin πx\n.\nHence,\nSnφ(x) -φ(x) =\nZ\n[0,1]\nφ(x + y) -φ(x)\nsin πy\nsin π(2n + 1)y dy.\nNow suppose that φ is an R-valued function for which φ(0) = φ(1), and assume\nthat φ ∈Cα[0, 1]; C) 1 is H older continuous of order α ∈(0, 1). Set\nψ(y) = eıπy φ(x + y) -φ(x)\nsin πy\n.\nThen ψ ∈L1(λ[0,1); C) and Snφ(x) -φ(x) is the imaginary part of\nZ\n[0,1]\nψ(y)e-2n+1(y) dt = ψ, e2n-1\n\nL2(λ[0,1);C),\nand so, by the Riemann-Lebesgue lemma (cf. Exercise 1.1), Snφ(x) -→φ(x) as\nn →inf. The preceding shows that if φ ∈Cα[0, 1]; C satisfies φ(0) = φ(1), then\nSnφ -→φ pointwise, but it does not provide a rate of convergence or even say if\nthe convergence is uniform.\nC esaro summability of Fourier series was initiated by Fej er. Obviously,\nn\nn-1\nX\nm=0\nSmφ = Fn ∗φ,\nwhere\nFn(x) ≡1\nn\nn-1\nX\nm=0\nDn(x).\nThe function Fn is called the Fej er kernel, and it is clear that Fn is a continuous,\neven function of period 1 for which\nR\n[0,1] Fn(x) dx = 1. In addition, nFn(x) sin πx\nis the imaginary part of\neıπx\nn-1\nX\nm=0\ne2m(x) = eıπx 1 -eıπ2nx\n1 -eı2πx = ı(1 -eı2πnx)\n2 sin πx\n,\n1Cα(E; C) space of C-valued functions on a metric space E which are uniformly H older con-\ntinuous of order α ∈(0, 1).\n\nand so\n(5.1)\nFn(x) = 1 -cos 2πnx\n2n sin2 πx\n= 1\nn\nAsin πnx\nsin πx\na2\n.\nProceeding as in the proof of Theorem 1.1, one sees that\nFn ∗φ(x) -φ(x) =\nZ\n[0,1]\nFn(y) φ(x + y) -φ(x) dx -→0\nuniformly if φ is continuous and satisfies φ(1) = φ(0). Equivalently,\nlim\nn→inf\n\nn\nn-1\nX\nm=0\nSmφ -φ\n\nu\n= 0.\nIt turns out that one can do much better.\nTheorem 5.1. Let φ : [-1\n2, 1\n2] -→C be a measurable function, let x ∈-1\n2, 1\n, and\nassume that there is a C ∈(0, inf) and α ∈(0, 1] such that | φ(x+y)-φ(x)| ≤C|y|α\nfor y ∈-1\n2, 1\n. For n ≥5\n(5.2)\nFn ∗φ(x) -φ(x)\n≤C\n(\n(1+α)nα + 4(n1-α-41-α)\nπ2(1-α)n\n+ 1-2-(1+α)\n2α(1+α)n\nif α ∈(0, 1)\n16n +\n4 log n\nπ2n(1-α)\nif α = 1.\nHence\nlim\nn→infnα|Fn ∗φ(x) -φ(x)\n≤\n1 + α +\nπ2(1 -α)\nif α ∈(0, 1)\nand\nlim\nn→inf\nn\nlog n|Fn ∗φ(x) -φ(x)\n≤4\nπ2\nif α = 1.\nProof. Without loss in generality, I will assume that C = 1.\nThe proof turns on the estimates\n(5.3)\nFn(y) ≤\n\nn\nfor all y ∈-1\n2, 1\n\nπ2ny2\nwhen |y| ∈0, 1\n\nn\nwhen |y| ∈ 1\n4, 1\n\nThat Fn(y) ≤n is clear from the fact that ∥Dm∥u ≤1 and therefore that nFn(y) ≤\n2 Pn-1\nm=1 m + n = n2.\nTo see second inequality, note that cos πt ≥2-1\n2 when\n|y| ∈0, 1\nand therefore that\n| sin πy| =\nZ π|y|\ncos t dt ≥2-1\n2 π|y|.\nAs for Fn(y) ≤2\nn when |y| ∈ 1\n4, 1\n, simply remember that | sin πy| ≥2-1\n2 for such\ny's.\n\nAssume that α ∈(0, 1). Because\nR 1\n-1\n2 Fn(y) = 1\nFn ∗φ(x) -φ(x)\n≤\nZ\n-1\nFn(y)\nφ(x + y) -φ(x)\ndy\n≤n\nZ\nn\n|y|α dy +\nπ2n\nZ\nn\n|y|α-2 dy + 2\nn\nZ\n4 ≤|y|≤1\n|y|α dy\n≤\n(1 + α)nα + 4(n1-α -41-α)\nπ2(1 -α)n\n+ 1 -2-(1+α)\n2α(1 + α)n .\nIf α = 1, the top line in (5.2) holds for all α ∈(0, 1), and therefore one need\nonly examine what happens as α ↗1. Clearly\n(1+α)nα ↘1\nn and 1-2-(1+α)\n2α(1+α)n ↘\n16n\nas α ↗1. To handle the remaining term, note that it can be written as\n42-α\nπ2n\nn\n1-α -1\n1 -α\nwhich decreases to 4 log n\nπ2n\nas α ↗1.\n□\nOne could of course have derived the estimate when α = 1 directly by the same\nargument as was used when α < 1. However, the derivation given has the advantage\nthat it shows the estimates get stronger for all n ≥5, not just asymptotically, as α\nincreases.\nObviously, results like those in Theorem 5.1 turn on the continuity properties of\nφ, properties that a generic element of L1(λ[0,1); C) will not possess. Nonetheless,\nLebesgue showed that every locally λR-integrable φ does have a continuity property\nat almost everywhere point. Namely, he showed that\nlim\nr↘0\nr\nZ r\n| φ(x ± t) -φ(x)| dt = 0\nfor λR-almost every x ∈R,\nand he used this fact to prove the following theorem.\nTheorem 5.2. If φ ∈ L1λ[-1\n2 , 1\n2 ]; C, then\nlim\nn→infFn ∗φ(x) = φ(x) for λ[-1\n2 , 1\n2 ]-almost every x ∈[0, 1].\nProof. Set φx(y) = | φ(x + y) -φ(x)| and\nΦx(y) = 1\n|y|\nZ |y|\nφx(sgn(y)t) dt.\nBy Lebesgue's theorem, lim|y|↘0 Φx(y) = 0 for λ[-1\n2 , 1\n2 ]-almost every x ∈-1\n2, 1\n.\nLet x be such a point. Then\nFn ∗φ(x) -φ(x)\n≤\nZ 0\n-1\nFn(y)φx(y) dy +\nZ\nFn(y)φx(y) dy.\nWe will show only that limn→inf\nR 1\n0 Fn(y)φx(y) dy = 0 because the proof that\nlimn→inf\nR 0\n-1\n2 Fn(y)φx(y) dy = 0 is essentially the same.\n\nUsing our estimates for Fn in (5.3), one has\nZ\nFn(y)φx(y) dy =\nZ\nn\nFn(y)φx(y) dy +\nZ\nn\nFn(y)φx(y) dy\n≤n\nZ\nn\nφx(y) dy + 2\nn\nZ\nn\nφx(y)\ny2\ndy.\nSince\nn\nZ\nn\nφx(y) dy = Φx\nn\n,\nthe first term tends to 0. As for the second, use integration by parts to see that it\nis dominated by\n4Φx\n\nn\n+ 4\nn\nZ\nn\nΦx(y)\ny2\ndy.\nFinally, given ε > 0, choose δ ∈0, 1\nso that Φx(y) ≤ε for 0 ≤y ≤δ. Then, for\nn > 1\nδ ,\nn\nZ\nn\nΦx(y)\ny2\ndy ≤ε\nn\nZ δ\nn\ny2 dy + 1\nn\nZ\nδ\nΦx(y)\ny2\ndy ≤2ε + ∥Φx∥u\nδn\n,\nand so\nlim\nn→inf\nZ\nFn(y)φx(y) dy ≤4ε.\n□\nTheorem 5.2 is a stark contrast to a famous example produced in 1926 by Kol-\nmogorov2 of a function in L1λ[-1\n2 , 1\n2 ]; C for which {Snφ(x) : n ≥0} diverges\nat every x. It is also interesting to compare it to more recent results by L. Car-\nleson and R. Hunt.\nNamely, Carleson showed that Snφ -→φ (a.e.,λ[-1\n2 , 1\n2 ]) if\nφ ∈L2λ[-1\n2 , 1\n2 ]; C, and Hunt showed that the same is true for φ ∈Lpλ[-1\n2 , 1\n2 ]; C\nfor p ∈(1, inf).\nExercise 5.1. Show that\nlim\nn→inf\nnα\nZ\n-1\nFn(y)|y|α dy > 0 for α ∈(0, 1)\nand that\nlim\nn→inf\nn\nlog n\nZ\n-1\nFn(y)|y| dy > 0.\nHence the rates given Theorem 5.1 are optimal.\nHint: If 0 ≤m ≤n -1, show that\nFn(y) ≥\n2π2ny2 if 4m + 1\nn4\n≤y ≤2m + 1\n2n\n.\n2A.N. Kolmogorov, Une s erie de Fourier-Lebesgue divergente partout, C.R. 183 (1926),\npp. 1327-1328.\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\nRES.18-015 Topics in Fourier Analysis\nSpring 2024\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms."
        },
        {
          "category": "Lecture Notes",
          "title": "RES.18-015 S24 Lecture 06: The L^1 Fourier Transform",
          "type": "PDF",
          "source_url": "https://ocw.mit.edu/courses/res-18-015-topics-in-fourier-analysis-spring-2024/mitres_18_015_s24_lec06.pdf",
          "content": "6. The L1 Fourier Transform\nBy an easy rescaling argument, one knows that, for any L ∈Z+ and f ∈\nC1([-L, L]; C) satisfying f(-L) = f(L),\nf(x) = 1\n2L\nX\nm∈Z\nZ L\n-L\neı 2πm(y-x)\n2L\nf(y) dy = lim\nR→inf\nZ L\n-L\nN\n2L\nX\n|m|≤R\neı 2πm(y-x)\n2L\ne\nf(y) dx.\nNow suppose that f ∈C1\nc (R; C). Then\nf(x) = lim\nL→inflim\nR→inf\nZ L\n-L\nN\n2L\nX\n|m|≤R\neı 2πm(y-x)\n2L\ne\nf(y) dy.\nThus, if one can justify reversing the order in which the limits are taken, one would\nhave that\nf(x) = lim\nR→inf\nZ CZ R\n-R\neıξ2π(x-y) dξ\na\nf(y) dy\n= lim\nR→inf\n2π\nZ 2πR\n-2πR\ne-ıξx\nAZ\neıξyf(y) dy\na\ndξ.\nIn other words, there is reason to hope that, under suitable conditions on f,\n(6.1)\nf(x) = 1\n2π\nZ\ne-ıξx ˆf(ξ) dξ where ˆf(ξ) ≡\nZ\neıξyf(y) dy.\nThe function ˆf is called the Fourier transform of f, and our primary goal here\nwill be to find out in what sense (6.1) is true, first when f ∈L1(λR; C) and then\nwhen f ∈L2(λR; C). However, we will begin with some computations involving ˆf\nthat don't require our knowing when (6.1) holds.\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\nRES.18-015 Topics in Fourier Analysis\nSpring 2024\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms."
        },
        {
          "category": "Lecture Notes",
          "title": "RES.18-015 S24 Lecture 07: Computations and Applications of L^1 Fourier Transforms",
          "type": "PDF",
          "source_url": "https://ocw.mit.edu/courses/res-18-015-topics-in-fourier-analysis-spring-2024/mitres_18_015_s24_lec07.pdf",
          "content": "7. Computations and Applications of L1 Fourier Transforms\nIf f ∈L1(λR; C), then it is clear that ˆf is continuous and that\n(7.1)\n∥ˆf∥u ≤∥f∥L1(λR;C).\nLemma 7.1. If f ∈C1(R, C) ∩L1(λR; C) and f ′ ∈L1(λR; C), then\n(7.2)\n\"\nf ′(ξ) = -ıξ ˆf(ξ).\nProof. If f has compact support, then (7.2) is an easy application of integration by\nparts. To prove it under the given conditions, choose a function η ∈CinfR; [0, 1]\nfor which η(y) = 1 when y ∈[-1, 1] and η(y) = 0 when y /∈[-2, 2], and set\nfn(y) = η y\nn\nf(y). Then fn -→f and f ′\nn -→f ′ in L1(λR; C) and so\n\"\nf ′(ξ) = lim\nn→inf\nc\nf ′n(ξ) = -ıξ lim\nn→inf\nc\nfn(ξ) = -ıξ ˆf(ξ).\n□\nAs a consequence of Lemma 7.1, it is easy to prove the Riemann-Lebesgue lemma\nin this context. Namely, (7.2) makes it clear for compactly support f ∈C1(R; C),\nand (7.1) makes it clear that the set of f's for which it is holds is closed in L1(λR; C).\nWe next turn to the computation of ˆf in two important cases.\nSet gt(x) = (2πt)-1\n2 e-x2\nfor (t, x) ∈(0, inf) × R, and check that ∂tgt(x) =\n2∂2\nxgt(x). Hence, for any ζ ∈C, integration by parts leads to\n∂t\nZ\neζxgt(x) dx = 1\nZ\neζx∂2\nxgt(x) dx = ζ2\nZ\neζxgt(x) dx.\nSince\nZ\neζxgt(x) dx =\nZ\net\n2 ζxg1(x) dx -→1\nas t ↘0,\nZ\neζxgt(x) dx = e\ntζ2\n2 .\nIn particular\n(7.3)\n\"\ngt(ξ) = e-ξ2\nEquivalently, \"\ngt = 2π\nt\n2 g 1\nt and so\n(7.4)\nbgt)∧= 2πgt.\nSet py(x) = 1\nπ\ny\nx2+y2 for (y, x) ∈(0, inf) × R, and note that\nZ\npy(x) dx =\nZ\np1(x) dx = 1 for all y > 0.\nIn addition, because py(x) is the real part of\nı\nπz with z = x + ıy, (x, y) ⇝py(x) is\nharmonic. Thus, ∂2\nxpy = -∂2\nypy, and so, by (7.2),\n∂2\ny \"\npy(ξ) = ξ2 \"\npy(ξ).\nThus, for each ξ,\n'\npy(ξ) = a(ξ)eyξ + b(ξ)e-yξ,\n\nwhere, since \"\npy(0) = 1, a(ξ) + b(ξ) = 1. Because |'\npy(ξ)| ≤1, ξ ≥0 =⇒a(ξ) =\n0 & b(ξ) = 1 and ξ < 0 =⇒a(ξ) = 1 & b(ξ) = 0. Hence\n(7.5)\n\"\npy(ξ) = e-y|ξ|.\nHere is an interesting application of equations (7.3) and (7.5). Since\nξ2 + y2 =\nZ inf\ne-t(ξ2+y2) dx =\nZ inf\ne-ty2\"\ng2t(ξ) dt\nand \"\ng2t\n∧= 2πg2t,\nπ\ny e-y|x| = 2π\nZ inf\ne-ty2g2t(x) dt = π\nZ inf\nt-1\n2 e-ty2e-x2\n4t dt.\nThus, for x, y ∈(0, inf),\n(7.6)\nZ inf\nt-1\n2 e-ty2e-x2\nt dt = π\n2 e-2yx\ny\n,\na computation which can also be done using a somewhat tricky change of variables.\nTheorem 7.2. (Poisson Sum) Let f ∈L1(λR; C) ∩C(R; C), and assume that\nX\nn∈Z\nC\nsup\nx∈[0,1]\n|f(x + n)| + | ˆf(2πn)|\na\n< inf.\nThen\n(7.7)\nX\nn∈Z\nf(n) =\nX\nn∈Z\nˆf(2πn).\nProof. Define f(x) = P\nn∈Z f(x + n). Then f is a continuous periodic function\nwith period 1, and\nf, em\n\nL2(λ[0,1];C) =\nX\nn∈Z\nZ 1\ne-ı2πmxf(x + n) dx =\nZ\ne-ı2πmxf(x) dx = ˆf(-2πm).\nThus, P\nm∈Z\n( f, em)L2(λ[0,1];C)\n< inf, and therefore\nf(x) =\nX\nm∈Z\nˆf(-2πm)em(x) =\nX\nm∈Z\nˆf(2πm)e-m(x),\nwhere the convergence of the series is absolute and uniform. By taking x = 0, (7.7)\nfollows.\n□\nEquation (7.7) is known as the Poisson summation formula. Among its many\napplications is the following.\nWhen f = py, (7.7) says that\ny\nπ\nX\nn∈Z\ny2 + n2 =\nX\nn∈Z\ne-2πy|n| = 1 + e-2πy\n1 -e-2πy = coth πy,\nand so\n(7.8)\nX\nn∈Z\ny2 + n2 = π coth πy\ny\nfor y > 0.\n\nA famous application of (7.8) is Euler's product formula:\n(7.9)\nsin πx = πx\ninf\nY\nm=1\nA\n1 -x2\nm2\na\n.\nTo prove it, first observe that\nx2 + m2 = 1\n2x∂x logx2 + m2 = 1\n2x∂x log\nA\n1 + x2\nm2\na\nfor m = 0\nand that π coth πy = ∂y log(sinh πy). Hence, by (7.8)\nx∂x log\ninf\nY\nn=1\nA\n1 + x2\nn2\na\n+ 1\nx2 = 1\nx∂x log(sinh πx),\nwhich means that\n∂x log\ninf\nY\nn=1\nA\n1 + x2\nn2\na\n= ∂x log(x-1 sinh πx).\nIntegrating both sides from 0 to x, one gets\nlog x\ninf\nY\nn=1\nA\n1 + x2\nn2\na\n= log(sinh πx) -log π = log sinh πx\nπx\n,\nwhich means that\n(7.10)\nsinh πx = πx\ninf\nY\nn=1\nA\n1 + x2\nn2\na\nfrom which (7.9) follows by analytic continuation.\nAnother application of (7.5) is a proof1 that\n(7.11)\nlim\nR→inf\nZ R\n-R\nsin ξx\nx\ndx = sgn(ξ)π\nfor ξ = 0.\nWe begin with the more or less trivial observation that\nZ R\n-R\nsin ξx\nx\ndx = sgn(ξ)\nZ R\n-R\nsin |ξ|x\nx\ndx = sgn(ξ)\nZ |ξ|R\n-|ξ|R\nsin x\nx\ndx.\nThus, what we have to show is that\nlim\nR→inf\nZ R\n-R\nsin x\nx\ndx = π.\n(∗)\nThe first step in the proof (∗), is to show that if\ngR(ξ, y) ≡\nZ R\n-R\nx sin ξx\nx2 + y2 dx -→πe-yξ\nfor ξ > 0,\n(∗∗)\nthen (∗) holds. Indeed,\n\nZ R\n-R\nsin ξx\nx\ndx -gR(ξ, y)\n≤2y2\n\nZ inf\n| sin ξx|\nx(x2 + y2) dx\na\n≤ξπy,\nand so (∗∗) implies (∗).\n1The most commonly given proof is based on contour integration and Cauchy's theorem.\n\nThe next step is to show that for each y > 0 there exists a continuous ξ ∈\n(0, inf) 7-→g(ξ, y) ∈C such that gR(ξ, y) -→g(ξ, y) uniformly for ξ compact\nsubsets of (0, inf). To this end, note that\ngR(ξ, y) = 2\nZ R\nx sin ξx\nx2 + y2 dx = 2\nξ\nC\n-R cos ξR\nR2 + y2 + 2\nZ R\n(y2 -x2) cos ξx\n(x2 + y2)2\ndx\na\n-→4\nξ\nZ inf\n(y2 -x2) cos ξx\n(x2 + y2)2\ndx\nuniformly for ξ in compacts subsets of (0, inf).\nThe final step is the identify g(ξ, y) as πe-yξ. For this purpose, observe that\ngR(ξ, y) = -ı\nZ R\n-R\nxeıξx\nx2 + y2 dx = ∂ξfR(ξ, y)\nwhere\nfR(ξ, y) = -π\ny\nZ R\n-R\npy(x)eıξx dx -→-π\ny e-yξ.\nHence\nfR(η) -fR(ξ) =\nZ η\nξ\ngR(t, y) dt,\nand therefore\nπ\ny\ne-yξ -e-yη =\nZ η\nξ\ng(t, y) dt,\nfrom which g(ξ, y) = πe-yξ follows easily.\nExercise 7.1. Show that if f ∈L1(λR; C) and ft(x) = t-1ft-1x), then ˆft(ξ) =\nˆf(tξ).\nExercise 7.2. Show that if f ∈C2(R; C) ∩L1(λR; C) and both f ′ and f ′′ are in\nL1(λR; C), then ˆf ∈L1(λR; C).\nExercise 7.3. Using cosh t = 1+ t2\n2 +O(t4) and sinh t = t+ t3\n6 +O(t5), prove from\n(7.8) that Pinf\nn=1\nn2 = π2\n6 .\nExercise 7.4. Show that\nX\nn∈Z\ne-πn2\nt\n= t\n2 X\nn∈Z\ne-πtn2,\na formula that plays an important role in the theory of Theta functions.\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\nRES.18-015 Topics in Fourier Analysis\nSpring 2024\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms."
        },
        {
          "category": "Lecture Notes",
          "title": "RES.18-015 S24 Lecture 08: The L^1 Fourier Inversion Formula",
          "type": "PDF",
          "source_url": "https://ocw.mit.edu/courses/res-18-015-topics-in-fourier-analysis-spring-2024/mitres_18_015_s24_lec08.pdf",
          "content": "8. The L1 Fourier Inversion Formula\nHere we will see to what extent (6.1) can be justified, and the idea is to use the\nfact that we already know (cf. (7.4)) that it holds for gt. With this in mind, we\nhave, by Fubini's theorem,\n2πgt ∗f(x) = 2π\nZ\ngt(y)f(x -y) dy = 2π\nZ\ngt(y)f(x + y) dy\n=\nZ\n(bgt)∧(y)f(x + y) dy =\nZ\n\"\ngt(ξ)\nAZ\neıξyf(x + y) dy\na\ndξ =\nZ\ne-tξ2\n2 e-ıξx ˆf(ξ) dξ,\nand so\ngt ∗f(x) = 1\n2π\nZ\ne-tξ2\n2 e-ıξx ˆf(ξ) dξ.\nLet f ∈L1(λR; C). If f is continuous at x, then limt↘0 gt ∗f(x) = f(x), and so\n(8.1)\nf(x) = 1\n2π lim\nt↘0\nZ\ne-tξ2\n2 e-ıξx ˆf(ξ) dξ\nif f is continuous at x.\nIn particular\n(8.2)\nf(x) = 1\n2π\nZ\ne-ıξx ˆf(ξ) dξ\nif ˆf ∈L1(λR; C).\nMore generally, for any f ∈L1(λR; C), gt ∗f -→f in L1(λR; C), and so\n(8.3)\n2π\nZ\ne-tξ2\n2 e-ıξx ˆf(ξ) dξ -→f(x) in L1(λR; C),\nwhich can be thought of the Abel version of (6.1). As an immediate consequence,\nwe know that f = 0 ⇐⇒ˆf = 0.\nExercise 8.1. Show that if f ∈C2(R; C) ∩L1(λR; C) and both f ′ and f ′′ are in\nL1(λR; C), then ˆf ∈L1(λR; C) and therefore f = (2π)-1 R\ne-ıξx ˆf(ξ) dξ.\nExercise 8.2. Using Exercise 8.1, give another proof that \"\npt(ξ) = e-t|ξ|.\nExercise 8.3. There is nothing sacrosanct about gt in producing formulas like\n(8.1) and (8.3).\nIndeed, give a ρ ∈CR, [0, inf) for which\nR\nρ(x) dx = 1, set\nρt(x) = t-1ρ(t-1x). Then it is well known that, as t ↘0, ρt ∗f(x) -→f(x)\nif f ∈L1(λR; C) is continuous at x and that ρt ∗f -→f in L1(λR; C) for any\nf ∈L1(λR; C). Now suppose that ρ ∈C2R, [0, inf) and that ρ′ and ρ′′ are in\nL1(λR; C), and show that\n2π\nZ\ne-ıξxˆρ(tξ) ˆf(ξ) dξ -→f(x)\nif f ∈L1(λR; C) is continuous at x\nand\n2π\nZ\nˆe-ıξxˆρ(tξ) ˆf(ξ) dξ -→f(x) in L1(λR; C) for any f ∈L1(λR; C).\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\nRES.18-015 Topics in Fourier Analysis\nSpring 2024\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms."
        },
        {
          "category": "Lecture Notes",
          "title": "RES.18-015 S24 Lecture 09: The Ornstein-Uhlenbeck Semigroup",
          "type": "PDF",
          "source_url": "https://ocw.mit.edu/courses/res-18-015-topics-in-fourier-analysis-spring-2024/mitres_18_015_s24_lec09.pdf",
          "content": "9. The Ornstein-Uhlenbeck Semigroup\nSet gt(x) = (2πt)-1\n2 e-x2\n2t , and note that\n(9.1)\nZ\ngs(x -ξ)gt(ξ -y) dξ = gs+t(y -x) and ∂tgt(x) = 1\n2∂2\nxgt(x).\nFor (t, x, y) ∈(0, inf) × R × R, define\n(9.2)\np(t, x, y) = g1-e-ty -e-t\n2 x\n= 2π(1 -e-t)-1\n2 exp\nC\n-(y -e-t\n2 x)2\n2(1 -e-t)\na\n= e\nt\n2 get-1\nx -e\nt\n2 y.\nFrom the first part of (9.1) and the third equality in (9.2), we see that\nZ\np(s, x, ξ)p(t, ξ, y) dξ = e\nt\nZ\ng1-e-sξ -e-s\n2 yget-1\nξ -e\nt\n2 x dξ\n= e\nt\n2 get-e-se\nt\n2 y -e-s\n2 x = p(s + t, x, y).\nHence p(t, x, y) satisfies the Chapman-Kolmogorov equation\n(9.3)\np(s + t, x, y) =\nZ\np(s, x, ξ)p(t, ξ, y) dξ.\nIn addition, using the second part of (9.1), one sees that\n(9.4)\n∂tp(t, x, y) = Lxp(t, x, y) where Lx = 1\n∂2\nx -x∂x\n.\nNext define\n(9.5)\nPtφ(x) =\nZ\nφ(y)p(t, x, y) dy\nfor φ ∈C(R; C) with at most exponential growth at inf, and use (9.3) to see that\n{Pt : t > 0} is a semigroup (i.e., Ps+t = Ps *Pt). In addition, use (9.4) to show\nthat\n(9.6)\n∂tPtφ = LPtφ.\nAfter making the change of variable y →e\nt\n2 y, one sees that another expression for\nPtφ is\n(9.7)\nPtφ(x) =\nZ\nφe-t\n2 yget-1(y -x dy =\nZ\ng1(y)φ(1 -e-t)\n2 y + x dy,\nfrom which it is easy to see that Ptφ -→φ uniformly on compact subsets as t ↘0.\nFurther, if p ∈[1, inf), then, by Minkowski's inequality,\n∥Ptf∥Lp(λR;C) ≤\nZ\ng1(y)\nAZ f(1 -e-t)\n2 y + xp dx\na 1\np\ndy = ∥f∥Lp(λR;C),\nand, as t ↘0,\n∥Ptf -f∥Lp(λR;C) ≤\nZ\ng1(y)\nAZ f(1 -e-t)\n2 y + x -f(x)\np dy\na 1\np\ndx -→0\nsince\n2∥f∥Lp(λR;C) ≥\nAZ f(1 -e-t)\n2 y + x -f(x)\np dx\na 1\np\n-→0.\n\nTherefore we know that\n(9.8)\n∥Ptf∥Lp(λR;C) ≤∥f∥Lp(λR;C) and lim\nt↘0 ∥Ptf -f∥Lp(λR;C) = 0.\nIn particular, we have now shown that {Pt : t > 0} is a continuous contraction\nsemigroup, known as the Ornstein-Uhlenbeck semigroup, on Lp(λR; C) for each\np ∈[1, inf).\nAlthough {Pt : t > 0} is a continuous semigroup on the Lebesgue spaces\nLp(λR; C), these are not the Lebesgue spaces on which it acts most naturally. In-\nstead, one should consider its action on the spaces Lp(γ; C), where γ is the standard\nGauss measure γ(dx) = (2π)-1\n2 e-x2\n2 λR(dx). The reason why is that\ne-x2\n2 p(t, x, y) = p(t, y, x)e-y2\n2 ,\nwhich means that\n(9.9)\nφ, Ptψ\nL2(γ;C) = Ptφ, ψ\nL2(γ;C).\nHence, since Pt1 = 1,\nZ\nPtφ dγ = φ, Pt1\nL2(γ;C) =\nZ\nφ dγ.\nAt the same time, by Jensen's inequality, |Ptφ|p ≤Pt|φ|P , and so,\nZ\n|Ptφ|p dγ ≤\nZ\nPt|φ|p dγ =\nZ\n|φ|p dγ.\nThus,\n(9.10)\n∥Ptφ∥Lp(γ;C) ≤∥φ∥Lp(γ;C) for all p ∈[1, inf).\nIn addition, if φ ∈Cb(R; C), then ∥Ptφ∥u ≤∥φ∥u and Ptφ -→φ pointwise as\nt ↘0, and therefore, for each p ∈[1, inf), ∥Ptφ -φ∥Lp(γ;C) -→0 as t ↘0. Finally,\nif φ ∈Lp(R; C), then there exists a sequence {φn : n ≥1} ⊆Cb(R; C) such that\nlimn→inf∥fn -f∥Lp(γ;C) = 0, and\n∥Ptφ -φ∥Lp(γ;C) ≤∥Pt(φ -φn)∥Lp(γ;C) + ∥Ptφn -φn∥Lp(γ;C) + ∥φn -φ∥Lp(γ;C)\n≤2∥φn -φ∥Lp(γ;C) + ∥Ptφn -φn∥Lp(γ;C).\nThus, after first letting t ↘0 and then n →inf, we see that\n(9.11)\nlim\nt↘0 ∥Ptφ -φ∥Lp(γ;C) = 0 for all p ∈[1, inf).\nSummarizing, {Pt : t > 0} is a continuous contraction semigroup on Cb(R; C)\nand on Lp(γ; C) for each p ∈[1, inf), and Pt is self-adjoint on L2(γ; C).\nExercise 9.1. Show that\n(9.12)\nφ -(φ, 1)L2(γ;C)\nL2(γ;C) ≤∥φ′∥2\nL2(γ;C) for φ ∈C1\nb(R; C)\nand that\n(9.13)\nPtφ -(φ, 1)L2(γ;C)\nL2(γ;C) ≤e-tφ -(φ, 1)L2(γ;C)\nL2(γ;C)\nfor φ ∈L2(γ; C). The inequality in (9.12) is the Poincar e inequality for γ.\n\nHint: Note that if suffices to handle φ ∈C2\nb(R; C) for which (φ, 1)L2(γ;C) = 0.\nNext, given such a φ, show that\n(Ptφ)′ = e-t\n2 Ptφ′ and -∂t∥Ptφ∥2\nL2(γ;C) = ∥(Ptφ)′∥2\nL2(γ;C).\nUse these to show that\n-∂t∥Ptφ∥2\nL2(γ;C) =\n(Ptφ)′2\nL2(γ;C) ≤e-t∥φ′∥2\nL2(γ;C).\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\nRES.18-015 Topics in Fourier Analysis\nSpring 2024\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms."
        },
        {
          "category": "Resource",
          "title": "RES.18-015 S24 Solutions",
          "type": "PDF",
          "source_url": "https://ocw.mit.edu/courses/res-18-015-topics-in-fourier-analysis-spring-2024/mitres_18_015_s24_sol.pdf",
          "content": "Solutions\nExercise 1.1: First note if φ ∈L2(λ[0,1); C), then P\nn∈Z(φ, en)2\nL2(λ[0,1);C) < infand\ntherefore (φ, en)L2(λ[0,1);C) -→0. Next observe that\n|(φ, en)L2(λ[0,1);C) -(ψ, en)L2(λ[0,1);C)| ≤∥φ -ψ∥L1([0,1];C)\nand therefore, if φ ∈L1([0, 1]; C) and ε > 0, there is an R < infand an m ≥0 such\nthat\nsup\nn∈Z\n|(φ, en)L2(λ[0,1);C) -(φ ∧R, en)L2(λ[0,1);C)| ≤∥f -φ ∧R∥L1([0,1];C) < ε\nand supn≥m |(φ ∧R, en)L2(λ[0,1);C)| < ε. Thus, |(φ, en)L2(λ[0,1);C)| ≤2ε for n ≥m.\nExercise 1.2: Set φk = p 1\nk ∗φ, and check that φk ∈C1([0, 1]; C) and ∥φ′\nk∥u ≤\n∥φ∥Lip. Hence\n|(φ, en)L2(λ[0,1);C)| = lim\nk→inf|(φk, en)L2(λ[0,1);C)| ≤∥φ∥Lip\n2π|n| ,\nand so the required estimate follows by the same argument as was used when\nφ ∈C1([0, 1]; C).\nExercise 2.1: Using the initial formula for Sn(x), show that\nSn\n= 1\n2 -1\nπ\n\nn\nX\nm=1\n4m + 1 +\nn\nX\nm=1\n4m + 3\n!\n= 1\n2 + 2\nπ\ninf\nX\nm=1\n(4m + 1)(4m + 3).\nHence, after n →inf, one has that\n4 = 1\n2 -2\nπ\ninf\nX\nm=1\n(4m + 1)(4m + 3),\nfrom which\nπ = 8\ninf\nX\nm=1\n(4m + 1)(4m + 3)\nfollows.\nExercise 2.2: Set η(x) = φ(1) -φ(0)x and ψ = φ -η. Then ψ ∈C1[0, 1]; C\nand ψ(1) = ψ(0), and so\n∥Snψ -ψ∥u ≤∥ψ′∥L1(λR;C)\nπn\n≤\n2∥φ′∥L1(λ[0,1);C)\nπn\n,\nand\n|Snη(x) -η(x)| ≤6\nπn|φ(1) -φ(0)| 1\nx ∨\n1-x\n| ≤\n6∥φ′∥L1(λ[0,1);C)\nπn\n| 1\nx ∨\n1-x\n|.\nExercise 3.1: By Lemma 1.4,\n(φ, em)L2(λ[0,1);C)\n=\n|(φ(l), em)L2(λ[0,1);C)|\n(2πm)l\n≤\nn\nm\nl∥φ(l)∥L2(λ[0,1);C)\n(2πn)l\n.\nThus, if liml→inf\n∥φ(l)∥L2(λ[0,1);C)\n(2πn)l\n= 0, then (φ, em)L2(λ[0,1);C) = 0 for |m| ≥n. Con-\nversely, if (φ, em)L2(λ[0,1);C) = 0 for |m| ≥n, then\n∥φ(l)∥2\nL2(λ[0,1);C) =\nX\n|m|<n\n(2πm)-2l|(φ, em)L2(λ[0,1);C)|2 ≤(2π)-2l∥φ∥2\nL2(λ[0,1);C)\nX\n|m|<n\nm-2l,\n\nand so liml→inf\n∥φ(l)∥L2(λ[0,1);C)\n(2πn)l\n= 0.\nIt is obvious that\n(φ, em)L2(λ[0,1);C) = 0 for m ≥n ⇐⇒φ =\nX\n|m|<n\n(φ, em)L2(λ[0,1);C)em.\nFinally, if 1 ≤|m| < n, then\nn\nX\nj=1\nem\nj\nn\n= e\nı2π\nn 1 -eı2πm\n1 -e\nı2πm\nn\n= 0,\nand so, if (φ, em)L2(λ[0,1);C) = 0 for |m| ≥n, then\nn\nX\nj=1\nφ j\nn\n= 1\nn\nn\nX\nj=1\nX\n|m|<n\n(φ, em)L2(λ[0,1);C)em\nj\nn\n\n=\nZ 1\nφ(x) dx + 1\nn\nX\n1≤|m|<n\n(φ, em)L2(λ[0,1);C)\nN\nn\nX\nj=1\nem\nj\nn\n\ne\n=\nZ 1\nφ(x) dx.\nExercise 4.1:\n(i) Clearly\nSn ≡\nn\nX\nm=1\n(-1)m-1 =\n(r)\nif m is odd\nif m is even,\nand so {Sn : n ≥1} doesn't converge and\nn\nn\nX\nm=1\nSm =\n(r) 1\nif n is even\n2 -\n2n\nif n is odd,\nwhich means that the series is C esaro summable to 1\n2.\n(ii) Since am\nm -→0, the series can't be C esaro summable. In fact, using induction\non n ≥1, one sees that S2n+1 = n + 1 = -S2(n+1), and therefore that A2n = 0\nand A2n+1 =\nn+1\n2n+1 for n ≥1. To see that it is Abel summable, observe that, for\nr ∈(0, 1),\ninf\nX\nm=1\n(-1)mmrm = -r∂\ninf\nX\nm=0\n(-r)m =\nr\n(1 + r)2 -→1\nas r ↗1.\nExercise 5.1: Because | sin πx| ≤π|x| for all x and | sin πx| ≥2-1\n2 if 1\n4 ≤|x| ≤1\n2,\nAsin πnx\nsin πx\na\n≥\n2π2x2 if 1\n4n ≤x ≤1\n2n.\nThus,\nnα\nZ\n-1\nFn(x)|x|α dx ≥π-2n-1+α\nZ\n2n\n4n\nx-2+α dx ≥\n4nπ2 n-2+α(2n)2-α =\n2απ2 .\nExercise 7.1: This is an elementary change of variables.\n\nExercise 7.2: Because f ′, f ′′ ∈L1(λR; C) ˆf ′(ξ) = -ı2πξ ˆf and c\nf ′′ = -(2πξ)2 ˆf.\nThus,\nZ\n|f(x)| dx =\nZ\n|ξ|≤1\n| ˆf(ξ)|dξ +\nZ\n|ξ|>1\n| bf ′′(ξ)|\n(2πξ)2 dξ ≤∥f∥L1(λR;C) + ∥f ′′∥L1(λR;C)\n2π2\n.\nExercise 7.3: We know that\nX\nn∈Z\ny2 + n2 = π coth πy\ny\nand therefore\nX\nn≥1\ny2 + n2 = πy cosh π -sinh πy\ny2 sinh πy\n= πy + π3y3\n-πy -π3y3\n+ O(y5)\nπy + O(y3)\n-→π2\nas y ↘0.\nExercise 7.4: Take f(x) = t-1\n2 e-πx2\nt .\nThen ˆf(ξ) = e-tξ2\n4π , and therefore, by\nTheorem 7.2,\nt-1\n2 X\nn∈Z\ne-πn2\nt\n=\nX\nn∈Z\ne-πtn2.\nExercise 8.1: By the result in Exercise 7.4, we know that ˆf ∈L1(λR; C). Thus,\nby Lebesgue's dominated convergence theorem,\nf(x) = lim\nt↘0\nZ\ne-tξ2\n2 e-ıξx ˆf(ξ) dξ =\nZ\ne-ıξx ˆf(ξ) dξ.\nExercise 8.2: Since e-t|ξ| = \"\npt(ξ),\n2πpt(x) =\nZ inf\ne-ıξx-tξ dξ +\nZ inf\neıξx-tξ dξ =\nıx + t +\n-ıx + t =\n2t\nt2 + x2 .\nExercise 8.3: For the cited facts about convolution, see § 6.3.3 in my text Es-\nsentials of Integration Theory for Analysis, 2nd ed. published by Springer in their\nGTM series. Given those facts, the asserted results follow easily from: '\nρt ∗f(ξ) =\nˆρ(tξ) ˆf(ξ) ∈L1(λR; C) and\n2πρt ∗f(x) =\nZ\ne-ıξxˆρ(tξ) ˆf(ξ) dξ.\nExercise 9.1: First show that it suffices to treat the case when (φ, 1)L2(γ;C) = 0\nand therefore (Ptφ, 1)L2(γ;C) = 0 for all t ≥0.\nLet φ ∈Cb(R; C), and check that\nlim\nt↘0 Ptφ = φ and lim\nt↗infPtφ = (φ, 1)L2(γ;C)⟩boundedly and uniformly on compact subsets.\nNext, suppose that φ ∈C2\nb(R; C) with (φ, 1)L2(γ;C) = 0. Then\n∂xPtφ(x) = ∂x\nZ\nφy + e-t\n2 xp(t, 0, y) dy = e-t\nZ\nφ′(y)p(t, x, y) dy,\nand\n∂t∥Ptφ∥2\nL2(γ;C) = 2Ptφ, LPtφ\nL2(γ;C) = -∥(Ptφ)′∥2\nL2(γ;C)\n= -e-t∥Ptφ′∥2\nL2(γ;C) ≥-e-t∥φ′∥2\nL2(γ;C).\n(∗)\nAfter integrating (∗) in t from 0 to inf, one has\n-∥φ∥2\nL2(γ;C) ≥-∥φ′∥2\nL2(γ;C)\n\nwhich means that\nφ -(φ, 1)L2(γ;C)∥2\nL2(γ;C) = ∥φ∥2\nL2(γ;C) -(φ, 1)2\nL2(γ;C) ≤∥φ′∥2\nL2(γ;C),\nfirst for φ ∈C2\nb(R; C) and then, by an easy limit argument, for φ ∈C1\nb(R; C).\nFinally, because (Ptφ, 1)L2(γ;C) = 0 for all t ≥0 and therefore, by the preceding,\n∂t∥Ptφ∥2\nL2(γ;C) = -∥(Ptφ)′∥2\nL2(γ;C) ≤-∥Ptφ∥2\nL2(γ;C).\nThus et∥Ptφ∥2\nL2(γ;C) is non-increasing. Again an easy limit argument shows that\nthe assumption that φ ∈C2(R; C) can be replaced by φ ∈L2(γ; C).\nExercise 10.1: Reduce to the case when (φ, 1)L2(γ;C) = 0. Then, from (10.3), one\nhas\nPtφ =\ninf\nX\nm=1\ne-mt\n2 (φ, Hm)L2(γ;C)Hm,\nand so\n∥Ptφ∥2\nL2(γ;C) =\ninf\nX\nm=1\ne-mt|(φ, Hm)L2(γ;C)|2\n≤e-t\ninf\nX\nm=0\n|(φ, Hm+1)L2(γ;C)|2 = e-t∥φ∥L2(γ;C),\nand\n∥Ptφ∥2\nL2(γ;C) = e-t\ninf\nX\nm=0\ne-mt|(φ, Hm+1)L2(γ;C)|2 = e-t\ninf\nX\nm=0\ne-mt|(φ, A+Hm)L2(γ;C)|2\n= e-t\ninf\nX\nm=0\ne-mt|(φ′, Hm)L2(γ;C)|2 ≤e-t∥φ′∥2\nL2(γ;C).\nExercise 11.1: Using the estimates in Corollary 11.2, one knows that the se-\nries Pinf\nm=0 e-mt\n2 Hm(x)Hm(y) is absolutely and uniformly convergent on compact\nsubsets of (0, inf) × R × R. Thus, if φ ∈Cc(R; C),\nPtφ = lim\nn→inf\nn\nX\nm=0\n(φ, Hm)L2(γ;C)PtHm =\ninf\nX\nm=0\ne\nmt\n2 (φ, Hm)L2(γ;C)Hm,\nand so\nZ\nφ(y)p(t, x, y) dy = (2π)-1\nZ inf\nX\nm=0\ne-mt\n2 Hm(x)Hm(y)\n!\ne-y2\n2 φ(y) dy,\nfrom which it follows that\n(2π)\n2 p(t, x, y)e\ny2\n2 =\ninf\nX\nm=0\ne-mt\n2 Hm(x)Hm(y).\nFinally, set e-t\n2 = θ, and check that the preceding is Mehler's formula.\nExercise 12.1: Since f ⇝ˆf is an isomorphism on L2(λR; C) and\n∥Ff∥2\nL2(λR;C) =\nZ\n| ˆf(2πξ)|2 dξ = (2π)-1∥ˆf∥2\nL2(λR;C) = ∥f∥2\nL2(λR;C),\n\nF is an orthogonal operator on L2(λR; C). Thus F-1 = F∗. Finally, by Fubini's\ntheorem,\nf, Fg\nL2(λ[0,1);C) =\nZ\nf(ξ)\nAZ\ne-2πıξxg(x) dx\na\ndξ =\nZ\ng(x)\nAZ\ne-2πξxf(ξ) dξ\na\ndx,\nand so F∗f = (Ff)∪= F f.\nExercise 13.1: The lower bound is an easy application of Lemma 13.1. To prove\nthe upper bound, first check that an\n-hk+n = (k+n)!\nk!\nhk and therefore that an\n- hk+n =\nA (k+n)!\nk!\na 1\n2 hk. Hence\nφ, hk\n\nL2(λR;C)\n2 =\nk!\n(k + n)!\nφ, an\n- hk+n\n\nL2(λR;C)\n2 =\nk!\n(k + n)!\nan\n+φ, hk+n\n\nL2(λR;C)\n2,\nand so\n∥φ∥2\nS (m+n)(R;C) =\ninf\nX\nk=0\nμm\nk\nA\nk!μn\nk\n(k + n)!\na an\n+φ, hk+n\n\nL2(λR;C)\n2.\nUsing Stirling's formula, show that\nC = sup\nk≥0\nA\nk!μn\nk\n(k + n)!\na\n< inf,\nand therefore that ∥φ∥S (m+n)(R;C) ≤C\n2 ∥an\n+φ∥S (m)(R;C). Finally, write an\n+φ as a\nlinear combination of terms of the form xk∂lφ with k + l≤n, and apply the lower\nbound to each of these terms.\nExercise 13.2: Because, by Theorem 13.5, the sequence is relatively compact,\nand, by assumption, it is pointwise convergent, it can have at most one limit. Thus\nit must be convergent.\nExercise 13.3: Choose η ∈CinfR; [0, 1] so that η(x) = 1 if |x| ≤1 and η(x) = 0\nif |x| ≥2. For R > 0 define ηR(x) = ηR-1x.\n(i) Given φ ∈S (R; C), set φR = ηRφ for R > 0. Clearly φR ∈Cinf\nc (R; C) and\nφR = φ on [-R, R]. In addition,\n∥xk∂l(φ -φR)∥u ≤sup\n|x|≥R\n∥xk∂lφ(x)| + sup\n|x|≥R\n∥xk∂lφR(x)|\n≤1\nR\n∥xk+1∂lφ∥u + ∥xk+1∂lφl\nRφ∥u\n≤1\nR\n∥φ∥(k+l+1)\nu\n+ ∥φR∥(k+l+1)\nu\n.\nFinally, because ∂lφR(x) is a linear combination of terms of the form\nR-kη(k)R-1xφl-k(x),\nsupR≥1 ∥φR∥(k+l+1)\nu\n< inf.\n(ii) Because C0(R; C) is a closed subset of Cb(R; C) with respect of the uniform\ntopology, it is a Banach space. Now choose ρ ∈CinfR; [0, inf) so that ρ = 0 off\nof (-1, 1) and\nR\nρ(x) dx = 1, and define ρε(x) = ε-1ρε-1x for ε > 0. Given\nφ ∈Cc(R; C), ρε ∗φ ∈Cinf\nc (R; C) and ∥ρε ∗φ -φ∥u -→0 as ε ↘0. Thus, we\nwill know that Cinf\nc (R; C), and therefore also S (R; C), is dense in C0(R; C) once we\nshow that Cc(R; C) is dense in C0(R; C). But if φ ∈C0(R; C), then φR ∈Cc(R; C)\nand ∥φR -φ∥u ≤2 sup|x|≥R |φ(x)| as R →inf.\n\nExercise 13.4: Begin by checking that\n|y| ≤\n(r)\n2|x|\nif |y| ≤2|x|\n2|x + y|\nif |y| ≥2|x|.\nThus,\n|yk∂lφ(x + y)| ≤\n(r)\n2k|x|k|∂lφ(x + y)|\nif |y| ≤2|x|\n2k|x + y|k|∂lφ(x + y)|\nif |y| ≥2|x|,\nand so, if k + l≤m, then\nyk∂lτxφ\n\nu ≤2m(|x| ∨1)m∥φ∥(m)\nu\n.\nNext suppose that x1 < x2. Then\nykτx2φ(l)(y) -τx1φ(l)(y) =\nZ x2\nx1\nykφ(l+1)(t + y) dt,\nand so, if k + l≤m, then\nykτx2φ(l)(y) -τx1φ(l)(y) ≤|x2 -x1|\nmax\nx1≤t≤x2\nykφ(l+1)(t + y)\n\n≤2k(|x2| ∨1)k∥φ∥(m+1)\nu\n|x2 -x1|.\nExercise 14.1: Set u = f(|x|). Then\n⟨φ, u′⟩= -\nZ inf\nφ′(x) f(x) dx -\nZ 0\n-inf\nφ′(x) f(-x) dx\n= φ(0) f(0) +\nZ inf\nφ(x) f ′(x) dx -φ(0) f(0) -\nZ 0\n-inf\nφ(x) f ′(-x) dx\n=\nZ\nφ(x)sgn(x) f ′(|x|) dx,\nand so u′ = sgn(x) f ′(|x|). Next\n⟨φ, u′′⟩= -\nZ inf\nφ′(x) f ′(x) dx +\nZ 0\n-inf\nφ′(x) f ′(-x) dx\n= 2φ(0) f ′(0) +\nZ inf\nφ(x)f ′′(x) dx -\nZ 0\n-inf\nφ(x)f ′′(-x) dx\n= 2 f(0)φ(0) +\nZ\nφ(x)sgn(x)f ′′(|x|) dx,\nwhich means that u′′ = 2f(0)δ0 + sgn(x)f ′′(|x|).\nExercise 15.1:\n(i) By Fubini's theorem,\n⟨φ, ψ ∗μ⟩=\nZ AZ\nφ(x + y) ψ(x) dx\na\nμ(dy) =\nZ\nφ(x)\nCZ\nψ(x -y) μ(dy)\na\ndx,\nand so ψ ∗μ =\nR\nψ(x -y) μ(dy).\n\n(ii) Again by Fubini's theorem,\n⟨φ, ˆμ⟩= ⟨ˇφ, μ⟩=\nZ AZ\ne-ıξxφ(ξ) dξ\na\nμ(dx)\n=\nZ\nφ(ξ)\nCZ\neıξxμ(dx)\na\ndξ,\nand so ˆμ =\nR\neıξx μ(dx).\n(iii) Using Lebesgue's dominated convergence theorem, one can check that\nZ\n|x|k+1 μ(dx) =⇒∂ξ\nZ\nxkeıξx dx =\nZ\nxk+1eıξx μ(dx).\nThus, ˆμ ∈Cinf\nb (R; C), and so, since ˆψ ∈S (R; C), ˆψˆμ ∈S (R; C).\nExercise 16.1: Because the real and imaginary parts of f are harmonic elements\nof S (R; C), they, and therefore f, are polynomials. Thus, if f is an entire function\nthat is not a polynomial, it can't be an element of S (R; C), which means that it\nmust grow at infinity faster than a polynomial.\nExercise 17.1: Trivially, μn\nw\n-→μ =⇒μn -→μ in S (R; C)∗, and, by Theorem\n17.3, μ -→μ in S (R; C)∗=⇒μn\nw\n-→μ.\nExercise 18.1: In the proof of Theorem 18.3, it was shown that f is a characteristic\nfunction if f(0) = 1 and\nZZ\nf(ξ -η)φ(ξ)φ(η) dξdη ≥0\nfor all φ ∈S (R; C). Thus, f is a characteristic function if and only if f(0) = 1\nand (φ, ψ)f is a non-negative quadric form. Conversely, if f is a Finally, if f = ˆμ,\nthen, by Parseval's idententy and Fourier inversion formula,\nZ\nˆφ(x) ˆψ(x) μ(dx) =\nZ\nˆφ(x) ψ∧(x) μ(dx) = (2π)-N\nZ\nˆφ ψ∧∨\n(ξ) μ(ξ) dξ\n=\nZ φ ∗ ψ(ξ)f(ξ) dξ =\nZZ\nf(ξ)φ(ξ -η)ψ(-η) dξ dη\n=\nZZ\nf(ξ -η)φ(ξ)ψ(η) dξdη.\nExercise 18.2:\n(i) If A is an bounded operator on a complex Hilbert H space and (Ah, h)H ∈R\nfor all h ∈H, then A is self-adjoint. Thus, if A =\nA 1\nf(-ξ)\nf(ξ)\na\n, then f(-ξ) =\nf(ξ), and so A is non-negative definite Hermitian matrix and 0 ≤det(A) = 1 -\n|f(ξ)|2.\nNext take\nA =\nN 1\nf(-ξ)\nf(-η)\nf(ξ)\nf(ξ -η)\nf(η)\nf(η -η)\ne\n\nand α1 = z, α2 = -1, α3 = 1. Then\n0 ≤\nX\nk,l=1\nAk,lαkαl= |z|2 -2Re zf(ξ) + 2Re zf(η) + 2 -Ref(η -ξ)\n= |z|2 -2Re zf(η) -f(ξ) + 21 -Ref(η -ξ).\nNow take z = f(η) -f(ξ).\n(ii) Clearly af1 + bf2 is non-negative definite for all a, b ≥0. To see that f1f2 is\nnon-negative definite, it suffices to show that if A and B are non-negative definite\nmatrices, then so is Ak,lBk,l\n\n1≤k,l≤N. To this end, use the fact that B = C C,\nwhere C is again a non-negative definite matrix. Hence\nN\nX\nk,l=1\nAk,lBk,lαlαl=\nN\nX\nj=1\nN\nX\nk,l=1\nAk,lαkCk,jCl,jαl≥0\n(iii) Assume lim|x|↘0\n1-f(x)\n|x|2\n= 0. Since, for each e ∈SN-1,\n|f(ξ + te) -f(ξ)|2\nt2\n≤21 -Ref(te)\nt2\n-→0\nas t →0, f ′ is 0 everwhere and therefore f is constant.\n(iv) Using the Hahn decompostion theorem, write μ = μ+ -μ-where μ+ ⊥μ-.\nThen, for φ ∈S (RN; C),\n(2π)N\nZ\nφ(x) μ(dx) =\nZ\nˆφ(ξ) \"\nμ+(ξ) dξ-\nZ\nˆφ(ξ) \"\nμ-(-ξ) dξ =\nZ\nˆφ(ξ)ˆμ(-ξ) dξ = 0,\nand so\nR\nφ dμ+ =\nR\nφ(x) dμ-for all φ ∈S (RN; C) and therefore μ+ = μ-.\n(v) Choose μ ∈M1(R) so that f = ˆμ. Since f is not constant, μ = δ0.\nThe first step is to show that f ′′(ξ) = -\nR\nx2eıξx μ(dx). To this end, observe\nthat\n-f ′′(0) = lim\nt→0\n2 -f(t) -f(-t)\nt2\n= lim\nt→0 2\nZ 1 -cos tx\nt2\nμ(dx) -→\nZ\nx2 μ(dx).\nKnowing that\nR\nx2 μ(dx) < inf, the same reasoning shows that -f ′′(ξ) =\nR\nx2eıξx μ(dx).\nSince μ = δ0, -f ′′(0) < 0, and so\nf ′′\nf ′′(0) = ˆν, where ν(dx) =\nx2\n-f ′′(0)μ(dx).\nClearly |f ′′(ξ)| ≤\nR\nx2 μ(dx) = |f ′′(0)|. Knowing that x is μ-square integrable,\nit is easy to check that f ′(ξ) = ı\nR\nxeıξx μ(dx), and therefore that |f ′(ξ)|2 ≤\nR\nx2 μ(dx) = |f ′′(0)|. Finally, |f(η) -f(ξ)| ≤∥f ′∥u|η -ξ| ≤|f ′′(0)|\n2 |η -ξ|.\n(vi) It is easy to check that f must be a non-negative definite function for which\nf(0) = 1. By part (i), we know that f is continuous everywhere since it is contin-\nuous at 0. Hence, f = ˆμ for some μ ∈M1(R), and so, by Theorem 18.1, μn\nw\n-→μ.\nClearly, this proves that if {ˆμn : n ≥1} is unformly convergent at 0, then μn\nw\n-→μ\nfor some\n(vii) There is essentially nothing to do.\n\nExercise 19.1: Set Mr(dy) = 1[r,inf)(|y|) M(dy) for r > 0. If M is symmetric,\nthen\nZ A\neı(ξ,y)RN -1 -1B(0,1)(y)\na\nMr(dy)\n=\nZ cos(ξ, y)RN -1Mr(dy) +\nZ ı sin(ξ, y)RN -1B(0,1)(y)(ξ, y)RN Mr(dy)\n=\nZ cos(ξ, y)RN -1Mr(dy)\nfor all r > 0. Since | cos(ξ, x)RN -1| ≤|ξ|2|x|2, Lebesgue's dominated convergence\njustifies\nlim\nr↘0\nZ cos(ξ, y)RN -1Mr(dy) =\nZ cos(ξ, y)RN -1M(dy).\nNext assume that M is invariant under orthogonal transformations and choose\ne ∈SN-1. Then it is symmetric and\nZ cos(ξ, y)RN -1M(dy) =\nZ cos(|ξ|e, y) -1 M(dy).\nFinally, if M(dy) = |y|-N-αλRN (dy) for some α ∈(0, 2) and e ∈SN-1, then\nZ cos(ξ, y)RN -1M(dy) =\nZ cos(e, |ξ|y)RN -1|y|-1-α λRN (dy)\n= |ξ|α\nZ cos(e, y)RN -1|y|-1-α λRN (dy).\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\nRES.18-015 Topics in Fourier Analysis\nSpring 2024\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms."
        }
      ],
      "source_url": "https://ocw.mit.edu/courses/res-18-015-topics-in-fourier-analysis-spring-2024/",
      "course_info": "RES.18-015 | Non-Credit",
      "subject": "General"
    },
    {
      "course_name": "7.06x Cell Biology",
      "course_description": "In this course, you will engage in the biology of cells of higher organisms. You will study the structure, function, and biosynthesis of cellular membranes and organelles; cell growth and oncogenic transformation; transport, receptors, and cell signaling; the cytoskeleton, the extracellular matrix, and cell movements; cell division and cell cycle; functions of specialized cell types. This course emphasizes the current molecular knowledge of cell biological processes as well as the genetic, biochemical, and other experimental approaches that resulted in these discoveries.\nThis course, based on the MIT course 7.06 Cell Biology taken by enrolled MIT students, was organized as a three-part series on edX by MIT’s Department of Biology. It is self-paced and free as long as you enroll in the Audit Track option, which you can select after creating a free account on edX.",
      "topics": [
        "Science",
        "Biology",
        "Cell Biology",
        "Molecular Biology",
        "Science",
        "Biology",
        "Cell Biology",
        "Molecular Biology"
      ],
      "syllabus_content": "",
      "files": [],
      "source_url": "https://ocw.mit.edu/courses/res-7-007-7-06x-cell-biology/",
      "course_info": "RES.7-007 | Non-Credit",
      "subject": "General"
    },
    {
      "course_name": "Ethics of AI Bias",
      "course_description": "This video aims to delve into the human problems brought out by issues in artificial intelligence, specifically with respect to bias. It is suitable for classroom use or as a standalone video for those who wish to understand the issue more deeply than is conventionally covered. For classroom use, we recommend watching the chapterized version of the video and working through the teaching materials provided for each chapter.",
      "topics": [
        "Engineering",
        "Computer Science",
        "Artificial Intelligence",
        "Humanities",
        "Philosophy",
        "Ethics",
        "Engineering",
        "Computer Science",
        "Artificial Intelligence",
        "Humanities",
        "Philosophy",
        "Ethics"
      ],
      "syllabus_content": "",
      "files": [],
      "source_url": "https://ocw.mit.edu/courses/res-10-002-ethics-of-ai-bias-spring-2023/",
      "course_info": "RES.10-002 | Non-Credit",
      "subject": "General"
    },
    {
      "course_name": "Envisioning the Graduate of the Future",
      "course_description": "Communities have always wrestled with the multiple purposes of education: to train young people for careers, vocations, and college; to prepare them for their roles as citizens; to develop habits of reflective, ethical adults; and to create a common experience in a pluralistic society while meeting the needs of individual learners. As the world changes and grows more complex, returning to these important questions of purpose can help guide schools in their growth and strategic change.\nTo ensure our schools are effective, we need to routinely reimagine what the high school graduate of the future will need to know and be able to do. The artifact that communicates these ideas is called a graduate profile. Making explicit the capabilities, competencies, knowledge, and attitudes for secondary school graduates, and inviting key stakeholders like students and community members to be engaged in the process, can help you and your school to focus your vision of success and drive school innovation efforts.\nThis course is part of the Open Learning Library, which is free to use. You have the option to sign up and enroll in the course if you want to track your progress, or you can view and use all the materials without enrolling.",
      "topics": [
        "Teaching and Education",
        "Curriculum and Teaching",
        "Teaching and Education",
        "Curriculum and Teaching"
      ],
      "syllabus_content": "",
      "files": [],
      "source_url": "https://ocw.mit.edu/courses/res-cms-501-envisioning-the-graduate-of-the-future-spring-2020/",
      "course_info": "RES.CMS-501 | Non-Credit",
      "subject": "General"
    },
    {
      "course_name": "Brain and Cognitive Sciences Computational Tutorial Series",
      "course_description": "This is a seminar series led by graduate students and postdocs in the MIT Department of Brain and Cognitive Sciences (BCS) from 2015 to the present, featuring tutorials on computational topics relevant to research on intelligence in neuroscience, cognitive science, and artificial intelligence. These tutorials are aimed at participants who have some computational background but are not experts on these topics.\nA computational tutorial can consist of any method, tool, or model that is broadly relevant within neuroscience, cognitive science, and artificial intelligence. The goal is to bring researchers in brain and cognitive sciences closer to the researchers creating computational methods. \nResources posted here include lecture videos, lecture slides, code and datasets for exercises, background references, and other supplementary material. Typically, each tutorial consists of a short lecture, and an interactive part with tutorials or “office hours” to work through practice problems and discuss how the material may be applied to participants’ research. \nThis series was organized by Emily Mackevicius, Jenelle Feather, Nhat Le, Fernanda De La Torre Romo, and Greta Tuckute, with financial support from BCS. Videos were filmed, edited, and produced by Kris Brewer, Director of Technology at the Center for Brains, Minds, and Machines (CBMM).",
      "topics": [
        "Mathematics",
        "Computation",
        "Science",
        "Biology",
        "Neuroscience",
        "Cognitive Science",
        "Mathematics",
        "Computation",
        "Science",
        "Biology",
        "Neuroscience",
        "Cognitive Science"
      ],
      "syllabus_content": "",
      "files": [],
      "source_url": "https://ocw.mit.edu/courses/res-9-008-brain-and-cognitive-sciences-computational-tutorials/",
      "course_info": "RES.9-008 | Non-Credit",
      "subject": "General"
    },
    {
      "course_name": "Marguerite de Navarre Society Website",
      "course_description": "Recent decades have seen a sharp increase in critical interest in Marguerite de Navarre and her work. This society website is dedicated to the study of Marguerite, her network, and her historical and cultural influence. The main goals are to facilitate scholarly exchange, to encourage collaboration, and to make digital resources available to the wider community. The society seeks to bring together the multiple lines of inquiry which inspire our understanding and appreciation of Marguerite, and to inspire new ones.\nThe Marguerite de Navarre Society website is published under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 (CC BY-NC-SA) International license.",
      "topics": [
        "Humanities",
        "Language",
        "French",
        "Literature",
        "International Literature",
        "Humanities",
        "Language",
        "French",
        "Literature",
        "International Literature"
      ],
      "syllabus_content": "",
      "files": [],
      "source_url": "https://ocw.mit.edu/courses/res-21g-3004-marguerite-de-navarre-society-website-fall-2023/",
      "course_info": "RES.21G-3004 | Non-Credit",
      "subject": "General"
    },
    {
      "course_name": "MIT Little Devices Lab",
      "course_description": "The MIT Little Devices Lab collaborates with healthcare professionals in developing countries to create affordable health and medical technologies. A large number of these healthcare professionals are nurses, and have been described as “stealth innovators,” “NurseMakers,” and “MacGyver Nurses.” (Rice, S. “Nurses Devise Their Own Innovations.” Modern Healthcare, 17 Oct., 2015).\nThe Little Devices Lab helps support these inventors by sending them kits with the modular parts and materials to invent and build their own customized, cost-effective medical devices. They can then solve challenges specific to their patients and work environments, for a range of applications from diagnostics to microfluidics to drug delivery.\nSimilar to how breadboards enabled people to more easily build their own electronics, one of the lab’s projects involved creating a biochemical breadboard with plug-and-play sets of blocks for building paper analytical devices, which healthcare workers can use to make diagnostic tests that meet their needs.\nOn the Little Devices Lab’s site, users will find more details about the lab’s ongoing projects and research, video presentations about its work, and several of its members’ publications.",
      "topics": [
        "Engineering",
        "Electrical Engineering",
        "Electronics",
        "Mechanical Engineering",
        "Health and Medicine",
        "Biomedical Instrumentation",
        "Science",
        "Chemistry",
        "Analytical Chemistry",
        "Engineering",
        "Electrical Engineering",
        "Electronics",
        "Mechanical Engineering",
        "Health and Medicine",
        "Biomedical Instrumentation",
        "Science",
        "Chemistry",
        "Analytical Chemistry"
      ],
      "syllabus_content": "",
      "files": [],
      "source_url": "https://ocw.mit.edu/courses/res-hst-001-mit-little-devices-lab-fall-2021/",
      "course_info": "RES.HST-001 | Non-Credit",
      "subject": "General"
    },
    {
      "course_name": "Pre-7.01: Getting up to Speed in Biology",
      "course_description": "This self-paced course was originally designed to help prepare incoming MIT students for their first Introductory Biology Course (known at MIT as 7.01). It will also be useful for anyone preparing to take an equivalent college-level introductory biology class elsewhere. It includes lecture videos, interactive exercises, problem sets, and one exam.  Lecture Topics: Molecules of Life, The Cell and How it Works, Information Transfer in Biology, Inheritance and Genetics, and Building with DNA.\nGo to OCW’s Open Learning Library site for Pre-7.01: Getting up to Speed in Biology. The site is free to use, just like all OCW sites. You have the option to sign up and enroll in the course if you want to track your progress, or you can view and use all the materials without enrolling.",
      "topics": [
        "Science",
        "Biology",
        "Science",
        "Biology"
      ],
      "syllabus_content": "",
      "files": [],
      "source_url": "https://ocw.mit.edu/courses/res-7-001-pre-7-01-getting-up-to-speed-in-biology-summer-2019/",
      "course_info": "RES.7-001 | Non-Credit",
      "subject": "General"
    },
    {
      "course_name": "How to Speak",
      "course_description": "Patrick Winston’s How to Speak talk has been an MIT tradition for over 40 years. Offered every January during the Independent Activities Period (IAP), usually to overflow crowds, the talk is intended to improve your speaking ability in critical situations by teaching you a few heuristic rules. Professor Winston’s collection of rules is presented along with examples of their application in job-interview talks, thesis defenses, oral examinations, and lectures.\nAbout Professor Winston\nA professor at MIT for almost 50 years, Patrick Winston was director of MIT’s Artificial Intelligence Laboratory from 1972 to 1997 before it merged with the Laboratory for Computer Science to become MIT’s Computer Science and Artificial Intelligence Laboratory (CSAIL). He led CSAIL’s Genesis Research Group, which focused on developing a computational account of human intelligence and how human intelligence differs from that of other species, with special attention to modeling human story comprehension. Professor Winston passed away on July 19, 2019.",
      "topics": [
        "Teaching and Education",
        "Curriculum and Teaching",
        "Educational Technology",
        "Teaching and Education",
        "Curriculum and Teaching",
        "Educational Technology"
      ],
      "syllabus_content": "",
      "files": [],
      "source_url": "https://ocw.mit.edu/courses/res-tll-005-how-to-speak-january-iap-2018/",
      "course_info": "RES.TLL-005 | Non-Credit",
      "subject": "General"
    },
    {
      "course_name": "MIT-Haiti Initiative / Inisyativ MIT-Ayiti",
      "course_description": "The mission of the MIT-Haiti Initiative is to promote active learning in Kreyòl so that Haitians can have universal access to quality education in the language that most of them speak at home. \nPlatfòm MIT-Ayiti, launched in 2019, offers a wealth of freely accessible educational resources in Kreyòl, including downloadable lesson plans and picture books categorized by topic, alongside official curricula from Haiti’s Ministry of National Education. The target audience for these resources includes students at all levels from pre-kindergarten through high school, and we offer materials in all disciplines. We also host and invite contributions from all educators who are willing to submit their own materials in Kreyòl. We work with these contributions, in konbit (collaborative) mode, to improve these submissions before publication. Men anpil, chay pa lou! (That is, many hands make light work!)\nThe Initiative’s original website, launched in 2010, includes software tools for math, physics, genetics, and biochemistry education, as well as a preliminary (work-in-progress) glossary of Kreyòl equivalents for English words commonly used in the STEM disciplines.",
      "topics": [
        "Humanities",
        "Linguistics",
        "Society",
        "Latin and Caribbean Studies",
        "Teaching and Education",
        "Curriculum and Teaching",
        "Humanities",
        "Linguistics",
        "Society",
        "Latin and Caribbean Studies",
        "Teaching and Education",
        "Curriculum and Teaching"
      ],
      "syllabus_content": "",
      "files": [],
      "source_url": "https://ocw.mit.edu/courses/res-24-002-mit-haiti-initiative-inisyativ-mit-ayiti-spring-2023/",
      "course_info": "RES.24-002 | Non-Credit",
      "subject": "General"
    },
    {
      "course_name": "Launching Innovation in Schools",
      "course_description": "Every great teacher and every great school constantly work towards creating better learning conditions for students. Just as we hope our students become lifelong learners, we as educators should be constantly learning and improving. This education course is for school leaders of all kinds (from teacher-leaders to principals to superintendents) who are launching innovation in schools—starting new efforts to work together to improve teaching and learning.\nYou will complete a cycle of study, experimentation, and reflection to gain confidence and skills to lead instructional improvement efforts. Through experiential activities and assignments, you will begin working with colleagues to envision the next level of work for your team or organization, to launch a new initiative, and to measure your progress along the way. Based on the work of Prof. Justin Reich and Dr. Peter Senge, this course will focus on visioning and capacity-building, with an emphasis on collaboration and building partnerships with stakeholders at multiple levels.\nAt the end of the course, you will have started the process of launching an instructional improvement initiative in your school or learning environment, and you will better understand yourself as a leader and change agent. You will have made connections with peers who are also undertaking this important work.\nThis course is part of the Open Learning Library, which is free to use. You have the option to sign up and enroll in the course if you want to track your progress, or you can view and use all the materials without enrolling.",
      "topics": [
        "Teaching and Education",
        "Curriculum and Teaching",
        "Education Policy",
        "Educational Technology",
        "Teaching and Education",
        "Curriculum and Teaching",
        "Education Policy",
        "Educational Technology"
      ],
      "syllabus_content": "",
      "files": [],
      "source_url": "https://ocw.mit.edu/courses/res-cms-154-launching-innovation-in-schools-spring-2019/",
      "course_info": "RES.CMS-154 | Non-Credit",
      "subject": "General"
    },
    {
      "course_name": "STAR: Software Tools for Academics and Researchers",
      "course_description": "The Software Tools for Academics and Researchers (STAR) program at MIT seeks to bridge the divide between scientific research and the classroom. Understanding and applying research methods in the classroom setting can be challenging due to time constraints and the need for advanced equipment and facilities. The multidisciplinary STAR team collaborates with faculty from MIT and other educational institutions to design software exploring core scientific research concepts. The goal of STAR is to develop innovative and intuitive teaching tools for classroom use.\nAll of the STAR educational tools are freely available. To complement the educational software, the STAR website contains curriculum components/modules which can facilitate the use of STAR educational tools in a variety of educational settings. Students, teachers, and professors should feel welcome to download software and curriculum modules for their own use.\nOnline Publication",
      "topics": [
        "Engineering",
        "Computer Science",
        "Computer Networks",
        "Software Design and Engineering",
        "Environmental Engineering",
        "Hydrology and Water Resource Systems",
        "Science",
        "Biology",
        "Biochemistry",
        "Cell Biology",
        "Genetics",
        "Molecular Biology",
        "Physics",
        "Atomic, Molecular, Optical Physics",
        "Teaching and Education",
        "Educational Technology",
        "Engineering",
        "Computer Science",
        "Computer Networks",
        "Software Design and Engineering",
        "Environmental Engineering",
        "Hydrology and Water Resource Systems",
        "Science",
        "Biology",
        "Biochemistry",
        "Cell Biology",
        "Genetics",
        "Molecular Biology",
        "Physics",
        "Atomic, Molecular, Optical Physics",
        "Teaching and Education",
        "Educational Technology"
      ],
      "syllabus_content": "",
      "files": [],
      "source_url": "https://ocw.mit.edu/courses/res-tl-002-star-software-tools-for-academics-and-researchers-spring-2012/",
      "course_info": "RES.TLL-002 | Non-Credit",
      "subject": "General"
    },
    {
      "course_name": "Climate Science, Risk & Solutions: A Climate Primer",
      "course_description": "The goal of the Climate Primer website is to summarize the most important lines of evidence for human-caused climate change. It confronts the stickier questions about uncertainty in our projections, engages in a discussion of risk and risk managment, and concludes by presenting different options for taking action. We hope that the facts prepare you for more effective conversations with your community about values, trade-offs, politics, and actions.\nIn March 2024, the MIT Environmental Solutions Initiative launched the first major update to the Climate Primer. The updated Primer includes more precise estimates of future global warming and its effects on global temperatures and extreme weather events, important advances in climate modeling, new actions taken around the world to adapt to the impacts of climate change, and the latest data about the pace at which clean energy and other critical climate solutions are being deployed. Read more about the update on the MIT Environmental Solutions website.",
      "topics": [
        "Energy",
        "Climate",
        "Technology",
        "Science",
        "Earth Science",
        "Climate Studies",
        "Sustainability",
        "Energy",
        "Climate",
        "Technology",
        "Science",
        "Earth Science",
        "Climate Studies",
        "Sustainability"
      ],
      "syllabus_content": "",
      "files": [],
      "source_url": "https://ocw.mit.edu/courses/res-env-005-climate-science-risk-solutions-a-climate-primer/",
      "course_info": "RES.ENV-005 | Non-Credit",
      "subject": "General"
    },
    {
      "course_name": "AFNI Training Bootcamp",
      "course_description": "This training course is an introduction to the use of the AFNI software suites for the analysis of functional MRI (fMRI) data. It is not intended as an introduction to how fMRI works but is aimed at people who are already doing fMRI data analysis, or those who will be in the near future. \nAFNI (Analysis of Functional NeuroImages) is a leading software suite of C, Python, and R programs and shell scripts, primarily developed for the analysis and display of anatomical and fMRI data. It is freely available for research purposes. \nThis event was organized by the Center for Brains, Minds, and Machines (CBMM) Trainee Leadership Council.\nCBMM is a multi-institutional NSF Science and Technology Center headquartered at MIT that is dedicated to developing a computationally based understanding of human intelligence and establishing an engineering practice based on that understanding. CBMM brings together computer scientists, cognitive scientists, and neuroscientists to create a new field—the science and engineering of intelligence.",
      "topics": [
        "Health and Medicine",
        "Biomedical Signal and Image Processing",
        "Medical Imaging",
        "Science",
        "Cognitive Science",
        "Health and Medicine",
        "Biomedical Signal and Image Processing",
        "Medical Imaging",
        "Science",
        "Cognitive Science"
      ],
      "syllabus_content": "",
      "files": [],
      "source_url": "https://ocw.mit.edu/courses/res-9-006-afni-training-bootcamp-spring-2018/",
      "course_info": "RES.9-006 | Non-Credit",
      "subject": "General"
    },
    {
      "course_name": "Exploring Fairness in Machine Learning for International Development",
      "course_description": "In an effort to build the capacity of the students and faculty on the topics of bias and fairness in machine learning (ML) and appropriate use of ML, the MIT CITE team developed capacity-building activities and material. This material covers content through four modules that an be integrated into existing courses over a one to two week period.",
      "topics": [
        "Engineering",
        "Computer Science",
        "Artificial Intelligence",
        "Teaching and Education",
        "Curriculum and Teaching",
        "Engineering",
        "Computer Science",
        "Artificial Intelligence",
        "Teaching and Education",
        "Curriculum and Teaching"
      ],
      "syllabus_content": "",
      "files": [],
      "source_url": "https://ocw.mit.edu/courses/res-ec-001-exploring-fairness-in-machine-learning-for-international-development-spring-2020/",
      "course_info": "RES.EC-001 | Non-Credit",
      "subject": "General"
    },
    {
      "course_name": "Facilitative Leadership in the Public Sector",
      "course_description": "This four-part dinner series was created by Prof. Lawrence Susskind at the request of a group of students in MIT’s Department of Urban Studies and Planning (DUSP) who felt the need for a graduate-level leadership course that would be attuned specifically to the needs of public sector professionals.\nThe trailer and session videos may be freely viewed, downloaded, and reused under MIT OpenCourseWare’s Creative Commons BY-NC-SA license.",
      "topics": [
        "Business",
        "Leadership",
        "Social Science",
        "Communication",
        "Public Administration",
        "Urban Studies",
        "Regional Planning",
        "Urban Planning",
        "Business",
        "Leadership",
        "Social Science",
        "Communication",
        "Public Administration",
        "Urban Studies",
        "Regional Planning",
        "Urban Planning"
      ],
      "syllabus_content": "",
      "files": [],
      "source_url": "https://ocw.mit.edu/courses/res-11-004-facilitative-leadership-in-the-public-sector-fall-2024/",
      "course_info": "RES.11-004 | Graduate, Non-Credit",
      "subject": "General"
    },
    {
      "course_name": "How to CAD Almost Anything",
      "course_description": "Have you ever wondered how objects from our daily lives are designed? How can we generate a computer 3D model of a mug, a bottle of Diet Coke, or a Saturn V rocket? What about designing the blades of a jet engine? A test dummy? How about making an animation of a LEGO house building itself? Or making a realistic render of a bowl of fruit? In this workshop, you will learn skills to design all these and much more!\nHow to CAD Almost Anything introduces students to CAD (Computer-Aided Design) through various fun examples focused on reverse engineering. In contrast to traditional mechanical design courses, this workshop emphasizes the design process itself, understanding how to plan and best leverage our available tools to arrive at our desired result. Thus, the sessions are less about following the instructions on an engineering drawing and more about independent thinking and strategizing, such as reverse engineering an object into a 3D model.\nCome and learn how to CAD almost anything!\nThis supplemental resource offers links to the class’s Solidworks, Fusion 360, Onshape, and Siemens NX website materials and companion playlists of the Solidworks, Fusion 360, Onshape, and Siemens NX session recordings on YouTube.",
      "topics": [
        "Engineering",
        "Aerospace Engineering",
        "Mechanical Engineering",
        "Engineering",
        "Aerospace Engineering",
        "Mechanical Engineering"
      ],
      "syllabus_content": "",
      "files": [],
      "source_url": "https://ocw.mit.edu/courses/res-16-002-how-to-cad-almost-anything-january-iap-2024/",
      "course_info": "RES.16-002 | Non-Credit",
      "subject": "General"
    },
    {
      "course_name": "Teaching with Sustainability",
      "course_description": "Solving the interconnected complex problems that pervade our social, environmental, economic, and health systems requires concerted change. To achieve the lasting impact necessary for true change to occur, sustainability needs to be holistically integrated throughout an academic program, leveraging the knowledge of instructors to create a more sustainability-literate population.\nThis resource presents materials associated with a four-week noncredit course intended to provide current and future educators with the knowledge and skills to infuse their lessons and practices with sustainability, along with a link to an online resource library designed to help educators find activities and lessons that align with the United Nations Sustainable Development Goals.",
      "topics": [
        "Science",
        "Earth Science",
        "Sustainability",
        "Teaching and Education",
        "Curriculum and Teaching",
        "Science",
        "Earth Science",
        "Sustainability",
        "Teaching and Education",
        "Curriculum and Teaching"
      ],
      "syllabus_content": "Schedule\n\nThe class ran as four 2-hour sessions during MIT's Independent Activities Period in January 2022.\n\nTopics and Activities\n\nThe goal of this class was to provide participants with the opportunity to connect sustainable pedagogies with their teaching practices.\n\nEach student was asked to think about a lesson, activity, syllabus, whole course design, or other course product that they would like to workshop during the last session with others in our group.\n\nBroad Topic for the Week\n\nMain Class Activity\n\nLecture slides\n\nWeek 1\n\nWhat is sustainability education?\n\nWelcome activity\n\nJigsaw activity about the foundations of sustainability education\n\nWeek 1 (PDF)\n\nWeek 1 (PPTX)\n\nWeek 2\n\nWhat makes effective teaching?\n\nReflect on previous effective teachers\n\nBrainstorm goals for students\n\nWeek 2 (PDF)\n\nWeek 2 (PPTX)\n\nWeek 3\n\nWhat is the connection between sustainability and teaching?\n\nInformation about how to use sustainable pedagogies in your teaching practice\n\nWeek 3 (PDF)\n\nWeek 3 (PPTX)\n\nWeek 4\n\nHow can I leverage this knowledge in my professional practice?\n\nWorkshop to plan, discuss, and work through course material(s)\n\nWeek 4 (PDF)\n\nWeek 4 (PPTX)",
      "files": [
        {
          "category": "Resource",
          "title": "MITRES_ENV-006iap22sort.pdf",
          "type": "PDF",
          "source_url": "https://ocw.mit.edu/courses/res-env-006-teaching-with-sustainability-january-iap-2022/mitres_env-006iap22sort.pdf",
          "content": "Group 1 - Sorting\nPositivist\nPostpositivist\nUnsure/More Questions\n\nGroup 1 - Questions\nQuestion\nGroup Response\nBriefly describe how your group put different\nactivities into their categories. What was easy?\nChallenging?\nHow did your group handle your unknowns/more\nquestions? What are you wondering about these\nactivities?\nWhat are activities you are familiar with?\nWhat are activities that are new to you?\nWhat questions are you thinking about from this\nactivity?\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\nRES.ENV-006 Teaching with Sustainability IAP 2022\nFor more information about citing these materials or our Terms of Use, visit\nhttps://ocw.mit.edu/terms."
        },
        {
          "category": "Resource",
          "title": "MITRES_ENV-006iap22week1.pdf",
          "type": "PDF",
          "source_url": "https://ocw.mit.edu/courses/res-env-006-teaching-with-sustainability-january-iap-2022/mitres_env-006iap22week1.pdf",
          "content": "Presentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nPresentation template by SlidesCarnival\nExcept where noted otherwise this work is licensed under CC BY-NC-SA 4.0\nTeaching with\nSustainability\nA course offered during IAP - January 2022\nInstructors:\nLiz Potter-Nelson and Sarah Meyers\nEnvironmental Solutions Initiative at MIT\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nWeek 1 - What is sustainability education?\n❏\nDefining sustainability using the Brundtland\nReport & sustainability education\n❏\nBrief timeline of education to accomplish\nsustainability initiatives\n❏\nExplanation of a Jigsaw Activity\n❏\nJigsaw activity of foundational sustainability\ndocuments\nOverview of\nTopics\nWeek 2 - What is effective teaching?\n❏\nEffective teaching is complex\n❏\nLearning theories provide a framework for how\npeople learn\n❏\nTheoretical perspectives used in sustainability\neducation\n❏\nSustainability Learning Approaches\n❏\nPositivism vs Postpositivism\n❏\nPositivism and Postpositivism Activity\n❏\nPracticality of Sustainability Education\nWeek 3 - How do we teach sustainably?\n❏\nAsset vs Deficit Approaches\n❏\nCriticism of US Education\n❏\nBloom's Taxonomy\n❏\nSustainability education looks to paradigm shifts\n❏\nLevels of implementing sustainability\n❏\nLevel 1, Level 2, Level\n❏\nTransitioning through Sustainability Levels\nWeek 4 - What does this look like for me?\n❏\nExplanation of Categories of Sustainability Literacy\nCompetencies\n❏\nExplanation of Sustainable Instructional\nApproaches\n❏\nOverview of Understand by Design (UbD\n)\n❏\nModified UbD template\n❏\nSticking Points\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nWhat is Sustainability\nEducation?\nWeek 1\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nTeaching\nwith\nSustainability\nQuick\nOverview\n▫\nThe goal of this class is to provide participants with the\nopportunity to connect sustainable pedagogies with their\nteaching practices (current or future).\n▫\nAt times we'll ask you to reflect on the practices that we are\nusing during these sessions\n▪\nParticipant - Learning and building knowledge\n▪\nObserver - Reflecting on how we are teaching\n▫\nOne of the best ways to engage in learning is to fully\nparticipate\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nIntroductions\nWho are you?\n▫\nPlease share the following about yourself:\n▪\nPreferred first name\n▪\nWhat do you do?\n▪\nWhy are you interested in this class?\n▪\nWhat is something that is exciting for you and you could\ntalk for hours about?\n▫\n2 minutes to generate ideas, we'll model how to\nrespond, before asking for volunteers, everyone will get\na chance to share! (You can type your responses in the\nchat if that is more comfortable for you)\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nIntroductions\nLet's break it\ndown...\n1. Why do you think we did this activity?\n2. What were some ways we supported participants\nin this activity?\n3. What are other ways we could have supported\nparticipants in this activity?\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nLearning\nObjectives for\nToday\n▫\nParticipants will get a foundational view of\nsustainability education\n▫\nParticipants will begin to situate sustainability\neducation within their professional practice\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nWhat Does\nSustainability\nMean to You?\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nCommon\nDefinition\nThe Our Common Future Report, commonly referred\nto as the Brundtland Reportshares two important\nunderstandings around sustainability:\n▫\nSustainable Development is \"development that meets\nthe needs of the present without compromising the\nability of future generations to meet their own needs.\"\n▫\nIdentifies the following 3 components of sustainable\ndevelopment: environmental protection, economic\ngrowth, and social equity\nhttps://sustainabledevelopment.un.org/content/documents/5987our\n-common -future.pdf\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nSustainability\nSustainability emerged not as a discipline but as\nfield focused on solving complex wicked\nproblems that are interconnected socially,\nenvironmentally, and economically\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nSustainability\nEducation\nSustainability education works to creating\nsustainability literate individuals - people who not\nonly know about sustainability but are able to embody\nthe knowledge, skills and dispositions of sustainability\nTransforming systems of thinking and learning.\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nBrief\nTimeline -\nEducation to\nAccomplish\nSustainability\nInitiatives\nOur Common Future Report\n(Brundtland Report)\nDefined sustainable development\nUnited Nations Conference on\nEnvironment and Development\n(Rio Summit, Earth Summit)\nChapter 36 of Agenda 21 identified the critical role\nof education, training, and public awareness in\nachieving sustainable development\nRelease of the Earth Charter\nThe Earth Charter is a collaborative document\nwhich articulates a worldwide vision for, and the\nsteps necessary to accomplish a sustainable future\nMillennium Development Goals\nGoal of ending worldwide poverty\nUN Decade of Education for\nSustainable Development (DESD)\nGoal of incorporating sustainable development\ninto education systems\nGlobal Action Program (GAP) on\nESD\nContinued the work of DESD by identifying five\npriority action areas, and four strategies in an\neffort to support the SDGs\nSustainable Development Goals\n(SDGs)\n17 goals which were identified to build a blueprint\nfor a better and more sustainable future for all\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nJigsaw\nActivity -\nFoundational\nDocuments\n▫\nJigsaw Activity\n▪\nWork with a group to unpack something (in this\ncase an article) and then share that knowledge with\na different group of people to build a collective,\ngroup understanding\n▪\nExamples of Classroom Uses:\n▫\nReadings (Chapters of a Book; Articles)\n▫\nLearning new content (Ex - Families on\nPeriodic Table)\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nJigsaw\nActivity -\nFoundational\nDocuments\n▫\nJigsaw Activity - Foundational Documents - Preview\n▪\nPart 1 - Time to read individually & answer questions\n▪\nPart 2 - Work as a group to answer questions & unpack\narticle\n▪\nPart 3 - Move to new groups to learn about other\ndocuments\n▪\nPart 4 - Large group debrief of documents\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nJigsaw\nActivity -\nPart 1\n▫\nTake 15 minutes to read your article and work to\nanswer the questions.\n▪\nDo what you need to do to be successful in reading\nyour document.\n▫\nWork to answer the questions, individually\n▫\nExtra time is yours to stretch, rest your brain, etc.\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nJigsaw\nActivity -\nFoundational\nDocuments\n▫\nGroup 1: Earth Charter\n▪\nRead all\n▫\nGroup 2: Roadmap for Implementing the GAP on ESD\n▪\nRead print pages 14-25\n▫\nGroup 3: Our Common Future Report\n▪\nRead print pages 5-9\n▫\nGroup 4: Education for SDGs Learning Objectives\n▪\nRead print pages 1 and 6-8\n▫\nGroup 5: Education 2030 Incheon Declaration and\nFramework for SDG 4\n▪\nRead print pages pages 7-11\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nJigsaw\nActivity -\nFoundational\nDocuments\nQuestions to Answer\n1. Who wrote the document?\n2. When was the document written?\n3. What do you think the document asking people to\naccomplish?\n4. What effect do you think the document has had on\neducation, either intended or unintended?\n5. How does the document connect to your professional\npractice?\n6. What questions do you have after reading this excerpt?\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nJigsaw\nActivity -\nPart 2\nDebrief as a group\n1. Brief introductions\n2. 10ish minutes to work through the answers with your\ngroup\n3. Consider - what do you want to share with others about\nyour document?\n4. Before you leave you group, make sure that everyone\nhas a different letter...A, B, C, D, E\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nJigsaw\nActivity -\nPart 3\nNew Groups\n▫\n15ish minutes to share about your documents with your\nnew groups\nIf time permits:\n▫\nWhat commonalities are there in these documents?\n▫\nWhat differences/competing ideas are there in these\ndocuments?\n▫\nHow do these documents connect to your professional\npractice?\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nJigsaw\nActivity -\nPart 4\nReflect as a large group\n▫\nWhat commonalities do you think are in these\ndocuments?\n▫\nWhat differences/competing ideas are there in\nthese documents?\n▫\nHow do you think these documents connect to\nyour professional practice?\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nPause for\nPedagogy\nLet's unpack the Jigsaw Activity:\n1. How could you use an activity like this in your\nprofessional practice?\n2. What were strengths of this activity?\n3. What barriers could there be for participants?\n4. What value is there in including the phrase \"do you\nthink\" in a question for students?\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nReview of\nLearning\nObjectives\n▫\nParticipants will get a foundational view of\nsustainability education\n▫\nParticipants will begin to situate sustainability\neducation within their professional practice\n1. What did you learn today?\n2. How will people you interact with know and\nbenefit?\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nPreview of\nNext Week\n▫\nNext week we'll look at education research to\nunderstand effective teaching practices.\n▫\nWe'll also work to identify our goals for students\nand how to tie our goals to our instruction\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nMIT OpenCourseWare\nhttps://ocw.mit.edu\nRES.ENV-006 Teaching with Sustainability IAP 2022\nFor more information about citing these materials or our Terms\nof Use, visit https://ocw.mit.edu/terms."
        },
        {
          "category": "Resource",
          "title": "MITRES_ENV-006iap22week2.pdf",
          "type": "PDF",
          "source_url": "https://ocw.mit.edu/courses/res-env-006-teaching-with-sustainability-january-iap-2022/mitres_env-006iap22week2.pdf",
          "content": "Presentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nPresentation template by SlidesCarnival\nExcept where noted otherwise this work is licensed under CC BY-NC-SA 4.0\nTeaching with\nSustainability\nA course offered during IAP - January 2022\nInstructors:\nLiz Potter-Nelson and Sarah Meyers\nEnvironmental Solutions Initiative at MIT\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nWeek 1 - What is sustainability education?\n❏\nDefining sustainability using the Brundtland\nReport & sustainability education (link)\n❏\nBrief timeline of education to accomplish\nsustainability initiatives (link)\n❏\nExplanation of a Jigsaw Activity (link)\n❏\nJigsaw activity of foundational sustainability\ndocuments (link)\nOverview of\nTopics\nWeek 2 - What is effective teaching?\n❏\nEffective teaching is complex\n❏\nLearning theories provide a framework for how\npeople learn\n❏\nTheoretical perspectives used in sustainability\neducation\n❏\nSustainability Learning Approaches\n❏\nPositivism vs Postpositivism\n❏\nPositivism and Postpositivism Activity\n❏\nPracticality of Sustainability Education\nWeek 3 - How do we teach sustainably?\n❏\nAsset vs Deficit Approaches (\nlink)\n❏\nCriticism of US Education (link)\n❏\nBloom's Taxonomy (link)\n❏\nSustainability education looks to paradigm shifts\n(link)\n❏\nLevels of implementing sustainability (link)\n❏\nLevel 1, Level 2, Level 3 (\nlink)\n❏\nTransitioning through Sustainability Levels (link)\nWeek 4 - What does this look like for me?\n❏\nExplanation of Categories of Sustainability Literacy\nCompetencies (link)\n❏\nExplanation of Sustainable Instructional\nApproaches (link)\n❏\nOverview of Understand by Design (UbD) (\nlink)\n❏\nModified UbD template (link)\n❏\nSticking Points (link)\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nWhat is effective\nteaching?\nWeek 2\nBack to Overview of Topics\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nLearning\nObjectives for\nToday\n▫\nParticipants will be exposed to different education\nlearning theories\n▫\nParticipants will begin to identify what types of\nlearning activities support sustainability education\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nOpening\nActivity\nTake a moment and reflect on a happy classroom\nmemory for you.\nShare this moment on the class different methods,\ninclude a Jamboard, padlet, a Google Doc or even\ngenerating comments on board.\nWhat do you\nthink is the\nvalue in\nhaving an\nopening\nactivity?\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nEffective\nTeaching\nMany practitioners view education as a pendulum;\nstick around long enough and you'll be back to what\nyou were doing when you started.\n▫\nOne of these continuums is content knowledge vs\nskill knowledge\n▪\nCurrent trend in education is to stress the building\nof skills over content knowledge\n▪\nYes, students do need content. Do they need it all?\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nEffective\nTeaching\nSimilar to sustainability,\neffective teaching is complex & nuanced.\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nEffective\nTeaching\n▫\nInstructors, at any grade/age level need to consider:\n▪\nStandards\n▪\nCurriculum\n▪\nBehavior\n▪\nLearning Goals for Students\n▪\nInstitutional Expectations\n▪\nStakeholders\n▫\nIn addition instructors also need to consider:\n▪\nStudents' prior knowledge\n▪\nHow students think\n▪\nHow students process new information\n▪\nHow students are motivated\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nEffective\nTeaching -\nLearning\nTheories\n▫\nLearning theories address the complex nature of how\npeople learn.\n▫\nThe following are often cited in education literature:\n▫\nConstructivist Learning Theory (Piaget)\n▫\nSocial Learning Theory (Vygotsky)\n▫\nTransformative Learning Theory (Mezirow)\n▫\nBehavioral Learning Theory (Skinner and Pavlov)\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nLearning\nTheories\nConstructivist\nLearning Theory\nLearners construct their\nlearning based on their own\npersonal understandings\nexperiences\nRole of instructor is to guide\nand assist students in\nequilibrating new\ninformation with old ideas\nSocial Learning\nTheory\nLearners engage with new\nunderstandings of concepts\nthrough interactions with\nsociety\nRole of instructor is to\nprovide students with\nopportunities to socially\ninteract with new\ninformation\nTransformative\nLearning Theory\nLearners critically reflect\nand change viewpoints\nbased on a disorienting\ndilemma\nRole of of instructor is to\nserve as a facilitator in\nproviding experiences where\nstudents can be conscious\nof their assumptions, beliefs\nand perspectives through\nexposure to new view points\nScaffolding\nMany of these learning theories require the instructor to scaffold students from concrete\nconcepts to abstract understandings\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nLearning\nTheories\n▫\nBehavioral Learning Theory is often viewed as a mor\npassive way for students to acquire knowledge\n▫\nIn behavioral learning theory students' behaviors can\nbe shaped based on the stimulus they receive\n▫\nThere is a place for behavioral learning theory in the\nclassroom and is often used in the setting of routines\nand expectations for students\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nSustainability\nEducation\nInstrumental\nIntrinsic\nCritical\nFounded in pragmatism and behaviorism.\nResponds to the urgency for change.\nKnowledge will lead to behavioral\nchanges.\nFounded in idealism and social constructivism\nLooks toward the process for the learner\nLearner is encouraged to be a systemic, critical\nthinker\nCounters the view that education is innocuous\nFosters an education system that brings\nawareness to and overcomes patterns of\ndominance and injustice.\n(Nolet, 2016)\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nReflection\nIn the chat, please take a moment or two and share,\ngenerally speaking, how you were taught when you\nwere a student.\nNot the awesome field trip or the cool chemistry lab\nyou were in but how 80% or more of your time in class\nwas spent.\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nSustainability\nEducation\nSustainability education looks at ways to\ntransform systems of thinking and learning .\nJuxtaposed with that idea is that most people teach\nthe way that they were taught.\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nBrainstorm\nLet's generate a list of different types of classroom\nactivities that students could participate in\nthroughout a course.\n1. Take a few minutes and brainstorm some ideas, stretch,\nmove around\n2. Share your ideas with a small group through Jamboard\n3. Preview each other's ideas\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nSustainability\nEducation\nSustainability education looks at ways to\ntransform systems of thinking and learning .\nJuxtaposed with that idea is that most people teach\nthe way that they were taught.\nEducation of a different kind\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nSustainability\nEducation\nTeaching for Sustainability encourages the following\ntypes of learning:\n▫\nActive\n▫\nParticipatory\n▫\nExperiential\n▫\nEngaging head, heart, and hands\n▫\nInterdisciplinary approaches\n▫\nHolistic and critical thinking\n▫\nPlace-based Learning\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nSustainability\nEducation\nThinking of education like this, in many cases, is a shift\nfrom what we know, what we've experience, and what\nis expected from our students, and our colleagues.\nLet's dive a little deeper into the differences between\nPositivism & Postpositivsm\nChristie, B. A., Miller, K. K., Cooke, R., & White, J. G. (2013). Environmental sustainability in higher education: how do\nacademics teach? Environmental Education Research, 19(3), 385-414. https://doi.org/10.1080/13504622.2012.698598\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nSustainability\nEducation -\nAssumptions\nPositivist Approaches to\nEducation:\nObjective, value free, truth,\nwhich can be measured,\ndefined and taught to\nstudents (Littledyke and\nManolas 2010)\nPostpositivist Approaches\nto Education:\nSubjective, value laden,\ntentative knowledge which\nis recognised as subject to\nchange due to context,\nconstructivist knowledge\n(Littledyke and Manolas\n2010)\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nSustainability\nEducation -\nIdeological\nInfluences\nPositivist Approaches to\nEducation:\n-\nInstrumental ideology\nencourages learning\nfor economic gain\nPostpositivist Approaches\nto Education:\n-\nReconstructive\nideology emphasizes\nsocial change with a\nfocus on the future\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nSustainability\nEducation -\nAssociated\nPedagogies\nPositivist Approaches to\nEducation:\n-\nKnowledge-centered\n-\nDiscipline specific\n-\nPrescribed by\ncurriculum and\nassessment\nrequirements\nPostpositivist Approaches\nto Education:\n-\nStudent-centered\n-\nMultidisciplinary\n-\nConnected to real\nworld application,\nfocused on shared\nlearning experiences\nand active learning\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nSustainability\nEducation -\nRoles of\nteacher and\nstudent\nPositivist Approaches to\nEducation:\n-\nTeachers are directors\nand vessels of\nknowledge who\ntransmit knowledge to\nstudents\nPostpositivist Approaches\nto Education:\n-\nTeachers are\nfacilitators who\nsupport students'\ninvestigations\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nSustainability\nEducation -\nTypes of\nActivities\nPositivist Approaches to\nEducation:\nPostpositivist Approaches\nto Education:\nLet's revisit the list of activities that we compiled earlier\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nWhat Type of\nActivities?\n1. Find your group's Google Slides (Link)\na. Move things around by clicking and dragging\nb. You can reference this list of activities (Link)\n2. Determine which activities are more positivistic in\nnature, which are more postpositivistic in nature\nand which activities you're not sure about\n3. If time permits...Answer the questions for the\ngroup\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nPracticality\n▫\nTeaching is all about choices.\n▫\nAs much as we want to do everything perfectly all\nthe time, we can't\n▫\nWeigh different factors and make the best\ndecision possible with the various pieces of\ninformation\n▫\nIf change isn't possible this time, take a small step\nand promise yourself you'll address it next time.\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nSticking\nPoints\n▫\nYou're changing the norm for:\n▪\nStudents\n▫\nStudents are familiar with the status quo and they\nbecome more familiar the older they get. If you\nshake it up on them there is some inherent push\nback because they know the system and you're\nchanging the system.\n▪\nColleagues\n▫\nColleagues may bristle at you teaching differently\nthan you have in the past.\n▪\nYou\n▫\nNot everything you try will be a success the first\ntime. That doesn't mean you should give up!\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nPause for\nPedagogy\nDiscussion 1: Let's dissect the brainstorming activity\n1.\nWhat was unique about this brainstorming activity?\n2.\nWhat are ways that you can respond to students to be more\ninclusive during a brainstorming session?\nDiscussion 1: Let's dissect the brainstorming activity\n1.\nWhat was unique about this brainstorming activity?\n2.\nWhat are ways that you can respond to students to be more\ninclusive during a brainstorming session?\nDiscussion 2: A lot of class was a lecture...\n1.\nWhy do you think I made the decision to provide information to\nyou in a lecture format?\n2.\nHow did I engage you throughout the lecture?\n3.\nWhat are some ways you could have learned this material that\nwasn't a lecture?\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nArticles that address topics from class today:\n▫\nChristie, B. A., Miller, K. K., Cooke, R., & White, J. G. (2013). Environmental sustainability\nin higher education: how do academics teach? Environmental Education\nResearch,19(3), 385-414. https://doi.org/10.1080/13504622.2012.698598\n▫\nArmstrong, C. M. (2011). Implementing education for sustainable development: The\npotential use of time-honored pedagogical practice for the progressive era of\neducation. Journal of Sustainability Education, 2.\n▫\nEvans, N., Ferreira, J. (2020). What does the research evidence base tell us about the\nuse and impact of sustainability pedagogies in initial teacher education?\nEnvironmental Education Research, 26\n(1), 27-42.\nhttps://doi.org/10.1080/13504622.2019.1703908\nGoing\nFurther\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nPreview of\nNext Week\n▫\nNext week we'll dive more deeply into Education\nabout sustainability, for sustainability and\neducation as sustainability\n▫\nWe'll also work to identify our goals for students\nand how to tie our goals to our instruction\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nReview of\nLearning\nObjectives\n▫\nParticipants will be exposed to different education\nlearning theories\n▫\nParticipants will begin to identify what types of\nlearning activities support sustainability education\n1. What did you learn today?\n2. How will people you interact with know and\nbenefit?\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nMIT OpenCourseWare\nhttps://ocw.mit.edu\nRES.ENV-006 Teaching with Sustainability IAP 2022\nFor more information about citing these materials or our\nTerms of Use, visit https://ocw.mit.edu/terms."
        },
        {
          "category": "Resource",
          "title": "MITRES_ENV-006iap22week3.pdf",
          "type": "PDF",
          "source_url": "https://ocw.mit.edu/courses/res-env-006-teaching-with-sustainability-january-iap-2022/mitres_env-006iap22week3.pdf",
          "content": "Presentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nPresentation template by SlidesCarnival\nExcept where noted otherwise this work is licensed under CC BY-NC-SA 4.0\nTeaching with\nSustainability\nA course offered during IAP - January 2022\nInstructors:\nLiz Potter-Nelson and Sarah Meyers\nEnvironmental Solutions Initiative at MIT\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nWeek 1 - What is sustainability education?\n❏\nDefining sustainability using the Brundtland\nReport & sustainability education\n❏\nBrief timeline of education to accomplish\nsustainability initiatives\n❏\nExplanation of a Jigsaw Activity\n❏\nJigsaw activity of foundational sustainability\ndocuments\nOverview of\nTopics\nWeek 2 - What is effective teaching?\n❏\nEffective teaching is complex\n❏\nLearning theories provide a framework for how\npeople learn\n❏\nTheoretical perspectives used in sustainability\neducation\n❏\nSustainability Learning Approaches\n❏\nPositivism vs Postpositivism\n❏\nPositivism and Postpositivism Activity\n❏\nPracticality of Sustainability Education\nWeek 3 - How do we teach sustainably?\n❏\nAsset vs Deficit Approaches\n❏\nCriticism of US Education\n❏\nBloom's Taxonomy\n❏\nSustainability education looks to paradigm shifts\n❏\nLevels of implementing sustainability\n❏\nLevel 1, Level 2, Level\n❏\nTransitioning through Sustainability Levels\nWeek 4 - What does this look like for me?\n❏\nExplanation of Categories of Sustainability Literacy\nCompetencies\n❏\nExplanation of Sustainable Instructional\nApproaches\n❏\nOverview of Understand by Design (UbD\n)\n❏\nModified UbD template\n❏\nSticking Points\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nHow do we teach\nsustainably?\nWeek 3\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nLearning\nObjectives for\nToday\n▫\nParticipants will be exposed to Bloom's Taxonomy\n▫\nParticipants will explore education about\nsustainability, education for sustainability, and\neducation as sustainability\n▫\nParticipants will consider how this applies to their\narea of interest.\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\n▫\nLinking back to last week and thinking forward to\nthis week, let's take a moment put these different\nactivities on a continuum from least cognitively\ndemanding to most cognitively demanding\n▪\nInvestigation : Proposing and conducting an investigation around a\ntopic from class\n▪\nQuiz: Completing a multiple choice quiz\n▪\nPresentation: Giving a presentation about a specific topic\n▪\nConcept Map: Creating a concept map of topics learned in class\n▪\nCompare & Contrast: Comparing & contrasting different viewpoints\n▪\nInterview : Interviewing someone about a class topic\nOpening\nActivity\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nA quick word\non...\nAsset vs.\nDeficit\nApproaches\nin Education\n▫\nDeficit Approach\n▪\nFocuses on what students can't do.\n▪\nIf a student is struggling it is because the student is not trying hard\nenough\n▪\nCan lead to low expectations of students\n▫\nAsset Approach\n▪\nFocuses on what students can do, including strengths, skills, talents,\nand interests\n▪\nChallenges assumptions that we may hold about students\n▪\nStudents rise to the challenge when they feel supported\nWhat are some\nreasons that a\nstudent may be\nstruggling that are\nnot related to the\namount they are\ntrying?\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nCriticism of\nEducation\n▫\nEducation in the United States is often criticized\nfor being a mile-wide and an inch deep.\n▫\nThis leads students to a surface\n-level\nunderstanding of the content\n▪\nStudents learn material for the test\n▪\nStudents learn vocabulary and definitions but not\napplications\n▪\nStudents learn a lot of little things but not how\nthey systematically connected\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nWhat are our\ngoals?\nHow do we decide what to teach our students?\nWhat are our goals for students?\nHow demanding and/or attainable are these goals?\nHow do we support students in achieving these goals?\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nBloom's\nTaxonomy\n▫\n1956 - Benjamin Bloom presented a taxonomy\nthat allowed for the classification of the cognitive\ndemand of learning objectives\n▫\nIn theory, students move up each level of the\npyramid as they build their understandings and\nteachers can facilitate this growth\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nScaffolding\n▫\nScaffolding is used to build and provide support to\nstudents.\n▫\nOften the building is from concrete ideas to\nabstract ideas\n▫\nThis can be done during on multiple scales when\nyou are an instructor\n▪\nResponding to a student question\n▪\nBuilding an idea through a class period\n▪\nBuilding to abstract ideas in a course\n▫\nYou can't just jump into the deep end!\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nBloom's\nTaxonomy\n▫\n2001 Bloom's Taxonomy was revised\n▫\nReplaced nouns with verbs were swapped to\nbetter identify the actions at each level\n▫\nTop two levels are swapped\n- leading to the\napplication of knowledge into something new\nas the most important in learning\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nBloom's\nTaxonomy\nIf nothing else, Bloom's Taxonomy gives us a common\nlanguage to think about how we can increase the rigor\nor cognitive demand of our lessons with our students.\nFor many teachers this moves the conversation past\nrote knowledge into how students are engaging with\nthe information they are learning.\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nSustainability\nEducation\nSustainability education looks at ways to\ntransform systems of thinking and learning .\nLooking to shift and/or transcend the paradigms of\nour learners (Meadows, 2008)\nThere is a time and place for knowledge transfer in\nschool settings, however, if the goal is deeper-level\nthinking, which leads to transformation, then this\nlikely will not occur with surface-level learning\nTime and place for\neverything! Teaching is\nabout choices.\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nSustainability\nEducation\n▫\nSustainability Education is no stranger to the\nconversation about cognitive demand.\n▫\nResearch has pointed to much of sustainability\nbeing covered at a surface-level, if at all, in many\nlearning environments (Cortese, 2003; Everett,\n2008; Sterling, 2011)\n▫\nPotter-Nelson Studies\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nSustainability\nEducation\n▫\nSterling discusses paradigm shifts in the guise of\ntransformative learning experiences using the terms:\n▪\nFirst-Order: Change in thinking\n▪\nSecond-Order: Change in Behavior\n▪\nThird-Order: Epistemological Change\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nSustainability\nEducation\nWeiss, M., Barth, M., Wiek, A., & von Wehrden, H. (2021). Drivers and barriers of implementing sustainability curricula in hi\ngher\neducation: Assumptions and evidence.\nHigher Education Studies, 22(2), 42-64.\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nBold Goals\n▫\nMoving from a Level 1 to a Level 2 is BIG\n▫\nArguably, it is an even bigger shift to move into a\nLevel 3 from an instructional standpoint..\n▫\nYou have to start somewhere!\nSmall changes lead to big impacts.\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nWhat does\nthis look like\nin practice?\nLevel 1 -\nEducation\nabout\nSustainability\n▫\nProviding examples that are linked to sustainability,\nclimate change, and the environment in problem sets\nand other worksheets (link)\n▫\nMentions during lectures about sustainability, climate\nchange, and/or the environment (link)\n▫\nA paper or other writing about how a specific\nsustainability technology works or affects people (link)\n▫\nStudents giving presentations about specific topics,\npolicies, ideas (link)\n▫Listening to podcasts on topics about climate change,\nsustainability and/or the environment\nNot bad! If the goal is\nincreased cognition, then\nany of these examples,\nwithout reflection, means\nthat students may not\nnotice the link to\nsustainability!\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nWhat does\nthis look like\nin practice?\nLevel 2 -\nEducation for\nSustainability\n▫\nExperiential learning about the content\n▪\nCreating a school garden (link)\n▫\nInterdisciplinary papers, projects and presentations\n▪\nWhat are the consequences of this? How will this affect\nother people?\n▫\nGeoengineering Term Project (link)\n▫\nStudent reflection and interaction on any of the\nlessons from Level 1\n▪\nProblem sets that encourage reflection\n▪\nPresentations/Final Assignments\n▫\nSide conversations with students\nOften takes more\ninstructional time to\nimplement and needs to\nbe intentionally\nscaffolded. Likely will\noccur later in a course.\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nWhat does\nthis look like\nin practice?\nLevel 3 -\nEducation as\nSustainability\n▫\nLevel 3 changes are hard to \"measure\" without\nconducting interviews of instructors and/or students.\n▫\nInstructors can set the foundation for a\ntransformative change\n▫\nSome argue systemic change is necessary\n▫\nSome students may reach transformative changes\nwith Level 2 Projects\n▫\nD:Lab Project (link)\n▫\nMulti -step Teacher Research Project\n▫\nThermodynamics w/o combustion engines\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nTransitioning\nthrough\nSustainability\nin Classroom\nActivities\nOriginal Activity\nLevel 1\nLevel 2\nLevel 3\nStudents are\nworking to\nunderstand reaction\nrates in chemistry\nusing a generic\nchemical equation\nand scenario.\nInstead of using a\ngeneric equation,\ninstructors have re-\ncentered the\nproblem around the\nchemical equation\nfor smog\nStudents engage in\nhands-on data\ncollection around\nsmog in local\ncommunities and\nanalyze in\nconjunction with\ncalculations\nFaculty add an\nadditional question\nafter student\ncomplete their\ncalculations asking\nthem to reflect on or\nexpand on the\nsocial impact of\ntheir calculation\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nTransitioning\nthrough\nSustainability\nin Classroom\nActivities\nOriginal Activity\nLevel 1\nLevel 2\nLevel 3\nStudents are\nworking to\nunderstand reaction\nrates in chemistry\nusing a generic\nchemical equation\nand scenario.\nInstead of using a\ngeneric equation,\ninstructors have re-\ncentered the\nproblem around the\nchemical equation\nfor smog\nFaculty add an\nadditional question\nafter student\ncomplete their\ncalculations asking\nthem to reflect on or\nexpand on the social\nimpact of their\ncalculation\nStudents engage in\nhands-on data\ncollection around\nsmog in local\ncommunities and\nanalyze in\nconjunction with\ncalculations\nStudents write a\none-page reaction\npiece to a content\narea reading.\nStudents write a\none-page reaction\npiece to an\nenvironmentally\nfocused content area\nreading.\nStudents are asked\nto write a one-page\nreaction/reflection\npiece on how their\nbehaviors will\nchange, if at all,\nbased on what they\nread\nStudents are asked\nto temporarily\nchange their\nbehavior(s) based on\nwhat they read and\nrespond to how it\naffected them\nStudents are asked\nto write a one-page\nreaction/reflection\npiece on how their\nbehaviors will\nchange, if at all,\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nWhat are our\ngoals?\nHow do we decide what to teach our students?\nWhat are our goals for students?\nHow demanding and/or attainable are these goals?\nHow do we support students in achieving these goals?\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nSustainability\nEducation -\nReminder\n▫\nSustainability scholars would argue that the goal is\ntransformative learning in all cases\n▫\nPragmatically there are different ways to approach\nsustainability, climate change and the\nenvironment in how you teach\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nGreat!\nBut...\nI have so much to teach already, how do I add in one\nmore thing?\n▫\nSustainability should not become an add-on to your already full\ncurriculum.\n▫\nFind places where your instruction already supports sustainability\nand be intentional about growing your practice from there.\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nGreat!\nBut...\nIs sustainability or climate change in my content\nstandards?\n▫\nYou may not find the wordsclimate or sustainability in your content standards.\n▫\nThe skills that you wish to build such as critical thinking, creative thinking, clear\ncommunication, analyzing information, and using evidence, are all key skills that\nsupport building sustainability literacy in students.\n▫\nSustainability looks to build knowledge, skills and dispositions for students in the areas\nof sustainability, systems thinking, social justice, futures thinking and active\ncitizenship.\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nWhere does it\nfit?\nCategories of Sustainability\nCompetencies\n▫\nSustainability\nKnowledge\n▫\nSystems Thinking\n▫\nSocial Justice\n▫\nFutures Thinking\n▫\nActive Citizenship\n▫\nContent Knowledge\nSustainability Instructional\nApproaches\n▫\nCollaborative, Small\nGroup Learning\n▫\nInquiry-based Learning\n▫\nExperiential Learning\n▫\nService Learning\n▫\nPlace-based Learning\n▫\nCulturally Sustained\nLearning\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nPause for\nPedagogy\nA. Padlet\nB. Zoom Questions\n▫\nWhat were strengths of these activities?\n▫\nWhat were barriers in these activities?\n▫\nWhat are ways that we could have more fully\nembodied sustainability in this lesson?\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nArticles that address topics from class today:\n▫\nWeiss, M., Barth, M., Wiek, A., & von Wehrden, H. (2021). Drivers and barriers of\nimplementing sustainability curricula in higher education: Assumptions and\nevidence. Higher Education Studies, 22(2), 42-64.\nhttps://doi.org/10.5539/hes.v11n2p42\n▫\nParis, D. (2012). Culturally sustaining pedagogy: A needed change in stance,\nterminology, and practice. Educational Researcher, 41(3), 93-97.\nhttps://doi.org/10.3102/0013189X12441244\n▫\nSterling, S. (2011). Transformative learning and sustainability: Sketching the\nconceptual ground. Learning and Teaching in Higher Education, 5, 17-33.\nGoing\nFurther\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nPreview of\nNext Week\n▫\nNext week please have on hand the resources that\nyou need to (re)vision an activity that you teach or\nhope to teach to be more sustainable\n▫\nWe'll go more in detail on the framework\n▫\nYou'll have time to work and share ideas with each\nother\n▫\nYou'll be able to share out what your tentative\nplan to the large group\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nReview of\nLearning\nObjectives\n▫\nParticipants will be exposed to Bloom's Taxonomy\n▫\nParticipants will explore education about sustainability,\neducation for sustainability, and education as\nsustainability\n▫\nParticipants will consider how this applies to their area\nof interest.\n1. What did you learn today?\n2. How will people you interact with know and benefit?\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nMIT OpenCourseWare\nhttps://ocw.mit.edu\nRES.ENV-006 Teaching with Sustainability IAP 2022\nFor more information about citing these materials or our\nTerms of Use, visit https://ocw.mit.edu/terms."
        },
        {
          "category": "Resource",
          "title": "MITRES_ENV-006iap22week4.pdf",
          "type": "PDF",
          "source_url": "https://ocw.mit.edu/courses/res-env-006-teaching-with-sustainability-january-iap-2022/mitres_env-006iap22week4.pdf",
          "content": "Presentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nPresentation template by SlidesCarnival\nExcept where noted otherwise this work is licensed under CC BY-NC-SA 4.0\nTeaching with\nSustainability\nA course offered during IAP - January 2022\nInstructors:\nLiz Potter-Nelson and Sarah Meyers\nEnvironmental Solutions Initiative at MIT\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nWeek 1 - What is sustainability education?\n❏\nDefining sustainability using the\nBrundtland Report & sustainability\neducation\n❏\nBrief timeline of education to accomplish\nsustainability initiatives\n❏\nExplanation of a Jigsaw Activity\n❏\nJigsaw activity of foundational\nsustainability documents\nOverview of\nTopics\nWeek 2 - What is effective teaching?\n❏\nEffective teaching is complex\n❏\nLearning theories provide a framework for\nhow people learn\n❏\nTheoretical perspectives used in\nsustainability education\n❏\nSustainability Learning Approaches\n❏\nPositivism vs Postpositivism\n❏\nPositivism and Postpositivism Activity\n❏\nPracticality of Sustainability Education\nWeek 3 - How do we teach sustainably?\n❏\nAsset vs Deficit Approaches\n❏\nCriticism of US Education\n❏\nBloom's Taxonomy\n❏\nSustainability education looks to paradigm\nshifts\n❏\nLevels of implementing sustainability\n❏\nLevel 1, Level 2, Level 3\n❏\nTransitioning through Sustainability Levels\nWeek 4 - What does this look like for me?\n❏\nExplanation of Categories of Sustainability Literacy\nCompetencies\n❏\nExplanation of Sustainable Instructional\nApproaches\n❏\nOverview of Understand by Design (UbD)\n❏\nModified UbD template\n❏\nSticking Points\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nWhat does this look\nlike for me?\nWeek 4\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nLearning\nObjectives for\nToday\n▫\nParticipants will consider if they want to modify\ntheir content, their practices or both!\n▫\nParticipants will use a modified backwards design\napproach to start the planning process to\n(re)vision their activities\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nWhat type of activity/lesson/course did you bring to work\non today? What do you want students to know and be\nable to do after your modifications?\nOpening\nActivity\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nWhere do I\nstart?\nCategories of Sustainability\nCompetencies\n▫\nSustainability\nKnowledge\n▫\nSystems Thinking\n▫\nSocial Justice\n▫\nFutures Thinking\n▫\nActive Citizenship\n▫\nContent\nKnowledge\nSustainability Instructional\nApproaches\n▫\nCollaborative, Small\nGroup Learning\n▫\nInquiry-based\nLearning\n▫\nExperiential Learning\n▫\nService Learning\n▫\nPlace-based Learning\n▫\nCulturally Sustained\nLearning\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nCategories of\nSustainability\nLiteracy\nCompetencies\nThese categories\nhelp us think\nabout the different\nways that\nsustainability is\npresent in the\ncourses we teach.\n▫\nNumerous different scholars have weighed in on the\nknowledge, skills, and dispositions necessary to be\nconsidered sustainability literate\n▫\nWide variety in what and how much is included in these lists\n▫\nEach of these lists start to fall into the following categories:\n▪\nSustainability Knowledge\n▪\nSystems Thinking\n▪\nSocial Justice\n▪\nFutures Thinking\n▪\nActive Citizenship\n▪\nContent Knowledge\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nSustainability Knowledge\nExplanation\n●\nAddresses the interconnection of environmental, social and\neconomic perspectives\n●\nBuilds past the tradition of an environmental or ecological way\nof knowing\n●\nEmbracing and including the interplay between the social and\neconomic perspectives.\nFocus of this\nCategory of\nCompetency\n●\nBuilds capacity for greater understanding of sustainability\nthrough environmental, social, human health, and/or economic\nperspectives\n●\nExplicit connection to course content and sustainability\nperspectives\nExamples\n●\nDrawdown\n●\nDiscussion Questions\n●\nReading Guide\n●\nHomework 1 & 2 in the list\nCategories of\nSustainability\nLiteracy\nCompetencies\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nSystems Thinking\nExplanation\n●\nEncourages a return to thinking about the \"whole\" instead of\nindividual \"parts\" of a system\n●\nLooks at the links between systems and how one decision affect\nanother system\nFocus of this\nCategory of\nCompetency\n●\nEmphasizes how the content being taught is part of a larger\nsystem\n●\nEncourages explanations or thinking about how the \"part\" is\nconnected to the whole\n●\nIncorporates at least two out of three perspectives of\nsustainability - environmental, social and/or economic\nExamples\n●\nPaper 1 & Paper 2\n●\nTechnology Critique\n●\nHometown Analysis\n●\nAssignment 1 & 3\nCategories of\nSustainability\nLiteracy\nCompetencies\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nCategories of\nSustainability\nLiteracy\nCompetencies\nSocial Justice\nExplanation\n●\nClearly articulates a need to provide equitable and inclusive\nopportunities to all\n●\nAcknowledgement of, and action towards dismantling the deeply\nembedded systems that support and perpetuate inequality\n●\nEmpowers learners who have been underrepresented\nFocus of this\nCategory of\nCompetency\n●\nRecognizes diversity within the context of the course material(s)\n●\nFocus is on equity and identifying existing social barriers that\nmay prevent equity\n●\nEquity can be broad from equitable distribution of resources to\ngender-equity in decision making\nExamples\n●\nAssignments 1, 2 & 4\n●\nReading Guide\n●\nWhat can a body do?\n●\nSite Probes\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nFutures Thinking\nExplanation\n●\nOften called anticipatory thinking or intergenerational thinking\n●\nEncourages instructors and learners to think about how current\nchoices will influence the long-term future\n●\nEncourages reflections on how current decisions impact future\ngenerations\nFocus of this\nCategory of\nCompetency\n●\nEmphasizes how choices now will impact future generations,\n150+ years from now\n●\nFocus is on meeting current needs without jeopardizing the\nneeds of future generations\n●\nCould use forecasting or backcasting to draw connections\nbetween here and then\nExamples\n●\nDream Project & Term Project\n●\nUrban Plans\n●\nProblem Set 1\nCategories of\nSustainability\nLiteracy\nCompetencies\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nActive Citizenship\nExplanation\n●\nPositions the learner to connect what they are learning to either\ntheir local place or as a global citizen\n●\nEncourages the connections between content and positive\naction within the defined community\nFocus of this\nCategory of\nCompetency\n●\nEmphasizes involvement in local and/or global community\n●\nInvolves learning about local and/or global community and ties\ncontent back to local/global community\n●\nLearning and/or action about governments, policies, laws, norms\netc\n●\nA reading or a lecture likely will not be active citizenship because\nstudents are not acting\nExamples\n●\nHealth Care Reform\n●\nFamine Relief\n●\nBig Plan\n●\nFinal Communication\nCategories of\nSustainability\nLiteracy\nCompetencies\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nSustainable\nInstructional\nApproaches\n▫\nHow we teach is almost as important as what we teach\n▫\nMake sure our method mirrors our message (Widhalm, 201\n▫\nSustainability Instructional Approaches (Nolet, 2016)\n▪\nCollaborative, Small Group Learning\n▪\nInquiry-based Learning\n▪\nExperiential Learning\n▪\nService Learning\n▪\nPlace-based Learning\n▪\nCulturally Sustained Learning\nThese approaches\nhelp us think\nabout the different\nways that our\nteaching practices\ncan embody\nsustainability\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nSustainable\nInstructional\nApproaches\nCollaborative, Small Group Learning\nExplanation\n●\nWorking in groups of 2-6, students engage in a learning\nexperience where the initial parameters are often defined by the\ninstructor\nExamples of\nthis type of\nLearning\n●\nThink-Pair-Share\n●\nJigsaw Activity\n●\nRoundtable\n●\nDiscussions\nExamples\n●\nDiscussion Prompts\n●\nCase Write-up Questions\n●\nProject of Change or Research Paper\n●\nFinal Project\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nSustainable\nInstructional\nApproaches\nInquiry -based Learning\nExplanation\n●\nStudents engage in authentic, self-directed learning.\n●\nOften, inquiry-based learning is collaborative\n●\nIn more guided inquiry experiences the instructor sets initial\nparameters and students follow a line of inquiry tied to the\nparameters\nExamples of\nthis type of\nLearning\n●\nProject-based learning\n●\nProblem-based learning\n●\nDesign-based learning\n●\nLabs\nExamples\n●\nPapers 1-4\n●\nTerm Project\n●\nTutorials; Drawdown; Dream Project Exercise; Dream Project\n●\nProject\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nSustainable\nInstructional\nApproaches\nExperiential Learning\nExplanation\n●\nProvides students with direct experiences, accompanied with\ncritical reflection\n●\nInstructors select experiences for students and then serve as the\nfacilitator while the experience is occurring\n●\nCommonly conducted in informal education settings, but also\nserve a valuable role in formal education settings\nExamples of\nthis type of\nLearning\n●\nField trips\n●\nField Work\n●\nInternships\n●\nHands-on Lessons\nExamples\n●\nShading Studies & Sun Path Diagrams\n●\nProblem Set 1\n●\nField Research and Report\n●\nPersonal Energy Consumption\n●\nField trip\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nSustainable\nInstructional\nApproaches\nService Learning\nExplanation\n●\nStudents engage in learning through community-based\nservice, where both the leaner and the community benefit\n●\nMore than just volunteering\n●\nOften has components of inquiry-based, experiential, and\ncollaborative learning\n●\nStages include: Investigation, Planning & Preparation; Action;\nReflection; Demonstration/Celebration\nExamples of\nthis type of\nLearning\n●\nExperiences vary greatly\n●\nEvent to support local community\n●\nTutoring in a local school/after school program\n●\nConducting research with community members\nExamples\n●\nGroup Response to a Proposal\n●\nService-Learning Standards for Quality Practice\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nSustainable\nInstructional\nApproaches\nPlace-based Learning\nExplanation\n●\nStudents interact with their local community\n●\nStudents are encouraged to ask questions and investigation\ntheir local place on topics of environmental, economic and or\nsocial equity\n●\nIncludes components of inquiry-based, experiential and/or\nservice learning\nExamples of\nthis type of\nLearning\n●\nField Trip\n●\nGuest Speaker\n●\nPrimary source documents from community\n●\nQuestions/Dialogue about community\nExamples\n●\nElemental Case Study\n●\nRe-designing Massachusetts Avenue\n●\nInvestigating a Site in the Past or Present Neighborhoods of MIT\n●\nHometown Analysis\n●\nNational Environmental Policy-making\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nSustainable\nInstructional\nApproaches\nCulturally Sustained Learning\nExplanation\n●\nAffirms and sustains students' cultural backgrounds\n●\nOften takes place behind the scenes in the development of\nlessons, experiences, and conscious awareness of teaching\nbehaviors\n●\nTakes place throughout all of the other practices, but as been\nintentionally identified as its own approach to signify its\nimportance\nExamples of\nthis type of\nLearning\n●\nReflection on one's own cultural lens\n●\nAddressing biases in systems\n●\nUtilization of students' culture to guide instruction\n●\nRemoving barriers to access instruction\nExamples\n●\nCulturally Sustaining Pedagogy: An Introduction\n●\nA Conversation about Instructional Equity by Zaretta Hammond\n●\nCulturally Sustaining Pedagogy from CA Dept. of Ed\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nWhere do I\nstart?\nBackwards\nDesign\n▫\nUnderstanding by Design (UbD) is a curriculum design process\ncommonly known as Backwards Design\n▫\nInstructors start with their learning goals for students and\ndesign experiences, where students build their understanding\nand demonstrate their knowledge, working backwards, to\nsupport those goals\n▫\nWorks to answer the questions\n▪\nWhat do I want my students to know and be able to do?\n▪\nHow will I support them in building the knowledge, skills and/or\ndispositions to accomplish those goals?\nBackwards Design Resources by Jay McTighe\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nWhere do I\nstart?\nCategories of Sustainability\nCompetencies\n▫\nSustainability\nKnowledge\n▫\nSystems Thinking\n▫\nSocial Justice\n▫\nFutures Thinking\n▫\nActive Citizenship\n▫\nContent\nKnowledge\nSustainability Instructional\nApproaches\n▫\nCollaborative, Small\nGroup Learning\n▫\nInquiry-based\nLearning\n▫\nExperiential Learning\n▫\nService Learning\n▫\nPlace-based Learning\n▫\nCulturally Sustained\nLearning\nStart here if you want to focus on\nthe content that is taught\nStart here if you want to focus on\nthe way you are teaching\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nWhere do I\nstart?\nTemplate\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nHow do you\nwant to\nwork?\n▫\nI want to work...\nA. individually.\nB. in a group, where discussions are frequent and we\ncan dialogue about the progress we're making, even\nif it is different.\nC. in a group for accountability; discussions are\ninfrequent but could occur.\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nWorkshop\nTime\nThe next 30 minutes are for you to workshop your ideas.\nWe'll be available to provide support if there are questions\nWhat do you hope to accomplish during your time?\nWe'll briefly share out what we did and/or what we're\nworking on after our workshop time has concluded.\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nSticking\nPoints\n▫\nYou're changing the norm for:\n▪\nStudents\n▫\nStudents are familiar with the status quo and they\nbecome more familiar the older they get. If you\nshake it up on them there is some inherent push\nback because they know the system and you're\nchanging the system.\n▪\nColleagues\n▫\nColleagues may bristle at you teaching differently\nthan you have in the past.\n▪\nYou\n▫\nNot everything you try will be a success the first\ntime. That doesn't mean you should give up!\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nArticles that address topics from class today:\n▫\nBrundiers, K., Barth, M., Cebrian, G., Cohen, M., Diaz, L., Douchette-Remington, S.,\nDripps, W., Habron, G., Harre, N., Jarchow, M., Losch, K., Michel, J., Mochizuki, Y.,\nRieckmann, M., Parnell, R., Walker, P., Zint, M., (2021). Key competencies in\nsustainability in higher education: Toward an agreed-upon reference framework.\nSustainability Science, 16, 13-29. https://doi.org/10.1007/s11625-020-00838-2\n▫\nWidhalm, B. (2011). Educators as architects of living systems: Designing vibrant learning\nexperiences beyond sustainability and systems thinking. Journal of\nSustainability Education, 2\n▫\nRedman, E., Murphy, C., Mancilla, Y., Mallon, B., Kater-Wettstaedt, L., Barth, M., Ortiz\nM.G., Smith, G., & Kelly, O. (2021). International scaling of sustainability continuing\nprofessional development for in-service teachers. Interdisciplinary Journal of Environmental\nand Science Education, 17(3), e2243.\nhttps://doi.org/10.21601/ijese/10936\nGoing\nFurther\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nReview of\nLearning\nObjectives\n▫\nParticipants will consider if they want to modify their\ncontent, their practices or both!\n▫\nParticipants will use a modified backwards design\napproach to start the planning process to (re)vision\ntheir activities\n1. What did you learn today?\n2. How will people you interact with know and benefit?\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nThank you!\nThank you for your time, energy and effort in our\nIAP course!\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nExcept where noted otherwise, the content on\nthis website is licensed under a Creative\nCommons Attribution -NonCommercial-\nShareAlike 4.0 International License (CC BY-NC-\nSA 4.0).\nPlease cite this work as:\nPotter-Nelson, E. & Meyers, S. (2022, January). Teaching with\nSustainability [MIT OpenCourseWare slides].\nCreative\nCommons\nLicensing\n\nPresentation template by SlidesCarnival\nCC BY-NC-SA 4.0\nMIT OpenCourseWare\nhttps://ocw.mit.edu\nRES.ENV-006 Teaching with Sustainability IAP 2022\nFor more information about citing these materials or our\nTerms of Use, visit https://ocw.mit.edu/terms."
        }
      ],
      "source_url": "https://ocw.mit.edu/courses/res-env-006-teaching-with-sustainability-january-iap-2022/",
      "course_info": "RES.ENV-006 | Non-Credit",
      "subject": "General"
    },
    {
      "course_name": "7.03x Genetics",
      "course_description": "In this course, you will learn the principles of genetics with application to the study of biological function at the level of molecules, cells, and multicellular organisms, including humans. We will cover structure and function of genes, chromosomes, and genomes; biological variation resulting from recombination, mutation, and selection; population genetics; and the use of genetic methods to modify genes and genomes and analyze protein function, gene regulation, and inherited disease.\nThis course, based on the MIT course 7.03 Genetics taken by enrolled MIT students, was organized as a three-part series on edX by MIT’s Department of Biology. It is self-paced and free as long as you enroll in the Audit Track option, which you can select after creating a free account on edX.",
      "topics": [
        "Science",
        "Biology",
        "Genetics",
        "Molecular Biology",
        "Science",
        "Biology",
        "Genetics",
        "Molecular Biology"
      ],
      "syllabus_content": "",
      "files": [],
      "source_url": "https://ocw.mit.edu/courses/res-7-006-7-03x-genetics/",
      "course_info": "RES.7-006 | Non-Credit",
      "subject": "General"
    },
    {
      "course_name": "Introduction to Computational Neuroscience with Neuroblox",
      "course_description": "In this course, you will learn the basics of computational neuroscience via hands-on model building in Neuroblox and Julia. You will simulate models from the literature, from single neurons to large circuits with synaptic plasticity, and fit them to neural data. By the end of the course, you will be able to model your data, build your own custom circuit “blox” that may be incorporated into the Neuroblox library, and explore how interventions such as drugs and stimulation probes affect neural circuits.\nComputational neuroscience aims to simulate the brain in silico, from single synapses to brain-wide networks. The field has matured in tandem with experimental neuroscience, to the point where computational modeling has become an indispensable tool for understanding neuroscience data and motivating future experiments. However, building such models can involve a painstaking process of translating concepts from the literature into working code, then optimizing it to run in a reasonable timeframe.\nNeuroblox is a new software platform for computational neuroscience that aims to break down these barriers. It is based on the Julia programming language, built with simplicity, modularity, and performance in mind. It consists of a library of modular computational building blocks (“blox”) that can be easily assembled to simulate brain dynamics in code or via an easy-to-use graphical interface. Our tools bridge scales from spiking neurons to brain waves and fMRI, and have applications to neurology and psychiatry. Moreover, the behavior of multiple model variants can be compared to discriminate between competing hypotheses.\nTo learn more about computational neuroscience and the team’s research, visit the Laboratory for Computational Neurodiagnostics website.\nCourse Audience: Anyone interested in exploring how the brain works, including how it leads to cognition. \nCourse Prerequisites: Prior coding experience is beneficial but not necessary.\nCourse Structure: Brief presentation of background material, followed by hands-on exercises and open-ended challenges.",
      "topics": [
        "Engineering",
        "Computer Science",
        "Health and Medicine",
        "Biomedical Signal and Image Processing",
        "Science",
        "Cognitive Science",
        "Engineering",
        "Computer Science",
        "Health and Medicine",
        "Biomedical Signal and Image Processing",
        "Science",
        "Cognitive Science"
      ],
      "syllabus_content": "",
      "files": [],
      "source_url": "https://ocw.mit.edu/courses/res-9-009-introduction-to-computational-neuroscience-with-neuroblox-january-iap-2025/",
      "course_info": "RES.9-009 | Graduate, Non-Credit",
      "subject": "General"
    },
    {
      "course_name": "MIT Governance Lab",
      "course_description": "The MIT Governance Lab (MIT GOV/LAB) is an applied research group and ideas incubator that aims to improve democracy and governance by changing practice around corruption, government accountability, and citizen voice. Our model combines behavioral political science, experimental social science, design thinking, and evaluation to iterate on governance solutions that support people’s ability to hold the government to account. \nWe partner with in-country practitioners, including government, civil society, and social enterprises, at every stage of the research and learning process, from theory building to theory testing, to critical reflections and adaptations in real time, with the goal of contributing to a solid evidence base to strengthen the overall field of practice for participatory governance. \nTo learn more about our work, check out our latest updates, tools, guides, and other resources, as well as published research, or be in touch mitgovlab@mit.edu.",
      "topics": [
        "Social Science",
        "Political Science",
        "Social Science",
        "Political Science"
      ],
      "syllabus_content": "",
      "files": [],
      "source_url": "https://ocw.mit.edu/courses/res-17-002-mit-governance-lab-spring-2023/",
      "course_info": "RES.17-002 | Non-Credit",
      "subject": "General"
    },
    {
      "course_name": "Climate Justice Instructional Toolkit",
      "course_description": "The primary goal of these resources and programming, created as part of a larger initiative to expand climate justice education at MIT, is to provide support to faculty members and instructors across disciplines in integrating climate justice content and related instructional approaches into their courses.\nFunded by the Alumni Class Funds Grant, the Toolkit houses a wide range of climate-justice-adaptable teaching modules, a starter guide for teaching climate justice, resources for students, and climate justice data sets that can serve as supportive tools to enhance teaching content and approaches.",
      "topics": [
        "Energy",
        "Climate",
        "Humanities",
        "Philosophy",
        "Political Philosophy",
        "Energy",
        "Climate",
        "Humanities",
        "Philosophy",
        "Political Philosophy"
      ],
      "syllabus_content": "",
      "files": [],
      "source_url": "https://ocw.mit.edu/courses/res-11-003-climate-justice-instructional-toolkit-fall-2023/",
      "course_info": "RES.11-003 | Non-Credit",
      "subject": "General"
    },
    {
      "course_name": "Business and Impact Planning for Social Enterprises (0.SolveX)",
      "course_description": "People in every corner of the world are innovating to solve social and environmental problems in their communities. In the past decade, new programs like MIT Solve have emerged to support those social entrepreneurs and drive partnerships to accelerate their impact. However, many startups find it difficult to develop business plans that clearly communicate their work and impact.\nThe main focus of this course is to help early-stage social impact startups define key aspects of their business by examining case studies from leading social entrepreneurs and both nonprofit and for-profit enterprises around the world.\nThe course was created by MIT Solve for MITx, and is now archived on the Open Learning Library (OLL), which is free to use. You have the option to sign up and enroll in each module if you want to track your progress, or you can view and use all the materials without enrolling.",
      "topics": [
        "Business",
        "Entrepreneurship",
        "Management",
        "Business",
        "Entrepreneurship",
        "Management"
      ],
      "syllabus_content": "",
      "files": [],
      "source_url": "https://ocw.mit.edu/courses/res-solvex-business-and-impact-planning-for-social-enterprises-0-solvex-summer-2021/",
      "course_info": "RES.SolveX | Non-Credit",
      "subject": "General"
    },
    {
      "course_name": "RAISE (Responsible AI for Social Empowerment and Education)",
      "course_description": "RAISE (Responsible AI for Social Empowerment and Education) is a new MIT-wide initiative headquartered in the MIT Media Lab and in collaboration with the MIT Schwarzman College of Computing and MIT Open Learning. MIT researchers continually develop curriculum modules and associated teaching materials that are available to all K-12 educators for free under a Creative Commons license.",
      "topics": [
        "Engineering",
        "Computer Science",
        "Artificial Intelligence",
        "Teaching and Education",
        "Curriculum and Teaching",
        "Engineering",
        "Computer Science",
        "Artificial Intelligence",
        "Teaching and Education",
        "Curriculum and Teaching"
      ],
      "syllabus_content": "",
      "files": [],
      "source_url": "https://ocw.mit.edu/courses/res-mas-001-raise-responsible-ai-for-social-empowerment-and-education-spring-2022/",
      "course_info": "RES.MAS-001 | Non-Credit",
      "subject": "General"
    },
    {
      "course_name": "Marguerite de Roberval: A Web-Based Approach to Teaching a Renaissance Heroine",
      "course_description": "This website is designed to introduce students to Marguerite de Roberval and the sixteenth-century texts she inspired. The site includes extensive bibliographies, teaching ideas, lists of modern and Renaissance versions of her story, information about Captain Roberval and his company, early exploration of Canada, images, and other media.\nThe Marguerite de Roberval website is published under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 (CC BY-NC-SA) International license.",
      "topics": [
        "Humanities",
        "Language",
        "French",
        "Literature",
        "International Literature",
        "Humanities",
        "Language",
        "French",
        "Literature",
        "International Literature"
      ],
      "syllabus_content": "",
      "files": [],
      "source_url": "https://ocw.mit.edu/courses/res-21g-3003-marguerite-de-roberval-a-web-based-approach-to-teaching-a-renaissance-heroine-fall-2023/",
      "course_info": "RES.21G-3003 | Non-Credit",
      "subject": "General"
    },
    {
      "course_name": "Angles",
      "course_description": "Angles is an annual online magazine of exemplary writing by MIT students. All of the works published in Angles since its first edition in 2008 were written by students in the introductory writing courses. These courses, designated as CI-HW (Communications-Intensive Humanities Writing) subjects, bring together students who love to write, students who struggle with writing, students who thrive in seminar-style classes, and students who just want a chance to develop their English skills. These students prosper together and produce some remarkable work. Angles has provided them with a public outlet for that work. It also provides the CI-HW instructors with material that inspires and guides their current students.\nIn these classes, students learn to read more critically, to address specific audiences for particular purposes, to construct effective arguments and narratives, and to use and cite source material properly. Students in these courses write a great deal; they prewrite, write, revise, and edit their work for content, clarity, tone, and grammar and receive detailed feedback from instructors and classmates. Assigned readings are related to the thematic focus of each course, and are used as demonstrations of writing techniques. The pieces in Angles may be used as teaching tools and practical examples for other students and self-learners to emulate.\nYou can find Angles Online.",
      "topics": [
        "Humanities",
        "Literature",
        "Academic Writing",
        "Creative Writing",
        "Nonfiction Prose",
        "Social Science",
        "Communication",
        "Humanities",
        "Literature",
        "Academic Writing",
        "Creative Writing",
        "Nonfiction Prose",
        "Social Science",
        "Communication"
      ],
      "syllabus_content": "",
      "files": [],
      "source_url": "https://ocw.mit.edu/courses/res-21w-01-angles-fall-2015/",
      "course_info": "RES.21W-01 | Non-Credit",
      "subject": "General"
    },
    {
      "course_name": "Introduction to R and Geographic Information Systems (GIS)",
      "course_description": "The goal of these videos is to provide students with tools and concepts for working with R, a free software environment for statistical computing and graphics. The students will learn the basics of R, how to navigate the R interface and deal with different data formats, how to run and interpret linear models with R, and how to use Geographic Information Systems (GIS) in R. These practical sessions were developed as part of the course 1.845 Terrestrial Carbon Cycle and Ecosystem Ecology but will be useful for anyone looking to learn about R and GIS.",
      "topics": [
        "Engineering",
        "Computer Science",
        "Graphics and Visualization",
        "Programming Languages",
        "Environmental Engineering",
        "Engineering",
        "Computer Science",
        "Graphics and Visualization",
        "Programming Languages",
        "Environmental Engineering"
      ],
      "syllabus_content": "",
      "files": [],
      "source_url": "https://ocw.mit.edu/courses/introduction-to-r-and-gis-fall-2023/",
      "course_info": "RES.1-002 | Non-Credit",
      "subject": "General"
    },
    {
      "course_name": "MIT Election Data + Science Lab",
      "course_description": "The MIT Election Data and Science Lab (MEDSL) supports advances in election science by collecting, analyzing, and sharing core data and findings. The lab also aims to build relationships with election officials and others to help apply new scientific research to the practice of democracy in the United States.\nBy applying scientific principles to how elections are studied and administered, MEDSL aims to improve the democratic experience for all U.S. voters.\nThe MIT Election Lab is a founding partner in the Stanford-MIT Healthy Elections Project, which was developed to ensure that the 2020 election can proceed with integrity, safety, and equal access. The project aims to do this by bringing together academics, civic organizations, election administrators, and election administration experts to assess and promote best practices.",
      "topics": [
        "Social Science",
        "Political Science",
        "American Politics",
        "Social Science",
        "Political Science",
        "American Politics"
      ],
      "syllabus_content": "",
      "files": [],
      "source_url": "https://ocw.mit.edu/courses/res-17-001-mit-election-data-science-lab-fall-2020/",
      "course_info": "RES.17-001 | Non-Credit",
      "subject": "General"
    },
    {
      "course_name": "Data Management",
      "course_description": "The MIT Libraries Data Management Group hosts a set of workshops during IAP  and throughout the year to assist MIT faculty and researchers with data set control, maintenance, and sharing. This resource contains a selection of presentations from those workshops. Topics include an introduction to data management, details on data sharing and storage, data management using the DMPTool, file organization, version control, and an overview of the open data requirements of various funding sources.",
      "topics": [
        "Business",
        "Information Technology",
        "Project Management",
        "Business",
        "Information Technology",
        "Project Management"
      ],
      "syllabus_content": "",
      "files": [],
      "source_url": "https://ocw.mit.edu/courses/res-str-002-data-management-spring-2016/",
      "course_info": "RES.STR-002 | Non-Credit",
      "subject": "General"
    },
    {
      "course_name": "LL EduCATE: Introduction to Engineering Concepts",
      "course_description": "Welcome to “Introduction to Engineering Concepts,\" a lesson that will introduce you to several STEM fields and help you build core skills that are helpful across many engineering disciplines. We also explain the engineering/research development process. This lesson assumes little to no prior engineering experience but does provide suggestions to increase the difficulty of the experiments should you desire to do so.\nThis course is provided by MIT Lincoln Laboratory, a research and development laboratory focusing on advanced technologies to meet critical national security needs.",
      "topics": [
        "Engineering",
        "Engineering"
      ],
      "syllabus_content": "",
      "files": [],
      "source_url": "https://ocw.mit.edu/courses/res.ll-004-ll-educate-introduction-to-engineering-concepts-spring-2022/",
      "course_info": "RES.LL-004 | Non-Credit",
      "subject": "General"
    },
    {
      "course_name": "Nuclear Weapons Education Project",
      "course_description": "No description found.",
      "topics": [
        "Energy",
        "Nuclear",
        "Humanities",
        "History",
        "History of Science and Technology",
        "Science",
        "Physics",
        "Atomic, Molecular, Optical Physics",
        "Energy",
        "Nuclear",
        "Humanities",
        "History",
        "History of Science and Technology",
        "Science",
        "Physics",
        "Atomic, Molecular, Optical Physics"
      ],
      "syllabus_content": "",
      "files": [],
      "source_url": "https://ocw.mit.edu/courses/res-8-008-nuclear-weapons-education-project-spring-2022/",
      "course_info": "RES.8-008 | Non-Credit",
      "subject": "General"
    },
    {
      "course_name": "7.InT: Inclusive Teaching Module",
      "course_description": "The Inclusive Teaching Module is both a standalone online resource for those looking to explore materials related to inclusive teaching as well as an integral part of a blended workshop available to use at your own institution. If you are looking to facilitate a blended workshop using this material, please download the Facilitation Guide and Appendix files to get started! \nAs part of the Open Learning Library (OLL), this course is free to use. You have the option to sign up and enroll if you want to track your progress, or you can view and use all the materials without enrolling. Resources on OLL allow learners to learn at their own pace while receiving immediate feedback through interactive content and exercises.",
      "topics": [
        "Teaching and Education",
        "Curriculum and Teaching",
        "Teaching and Education",
        "Curriculum and Teaching"
      ],
      "syllabus_content": "",
      "files": [
        {
          "category": "Resource",
          "title": "Blended Inclusive Teaching Workshop Facilitation Guide",
          "type": "PDF",
          "source_url": "https://ocw.mit.edu/courses/res-7-009-7-int-inclusive-teaching-module-fall-2022/mitres_7_009_f22_facilitation_guide_incl_teach.pdf",
          "content": "Blended Inclusive Teaching Workshop Facilitation Guide\nCreated by: Darcy G. Gordon, PhD\nOverview\nWhat this Workshop is About\nHow to Use the Materials\nLearning Goals and Objectives\nExpectations\nPlanning the Workshop\nPeople Power\nMaterials and Resources\nFormat and Timing Suggestions\nPreparing for the Workshop\nFacilitating the Workshop\nOverview and Introductions\nIntersectional Identity Activity\nConnecting Identity to Education\nReflective Teaching\nWrap Up Part 1/Homework Instructions\nOverview and Review of Inclusive Themes\nDiscussion of Homework/Online Scenario Group Work\nVideo Critiques\nGallery Showcase\nAction Plan\nAfterwards, Evaluation, and Additional Information\nWorkshop Feedback\nPost-Workshop Communication and Certification\nPotential Analyses\n\nOverview\nWhat this Workshop is About\nWe are so glad you are interested in facilitating a blended inclusive teaching workshop!\nThe intended audience for this workshop is anyone interested in inclusive education,\nincluding faculty, teaching staff, graduate teaching assistants, and postdoctoral fellows,\nespecially those in active teaching roles. This workshop uses a combination of in-person\nand online (i.e., blended) activities. These activities leverage the best that online and\nin-person active learning has to offer and encourage participant's ability to empathize\nwith students, evaluate instructional choices, and reflect on what inclusivity means in\ntheir teaching contexts. As a reflective, process-oriented workshop, facilitators and\nparticipants will spend time thinking about their own identities and experiences, how this\ninforms their teaching practices, as well as critically examine common pedagogical\npractices. This workshop is appropriate for folks just starting out in their inclusive\nteaching journey as well as for seasoned teachers. We designed activities so that\neveryone can benefit from the workshop materials and hope you enjoy it as much as we\ndo. Remember, have fun and learn a lot!\nHow to Use the Materials\nAside from this guide, which outlines the logistical and practical considerations for\nfacilitation, the Inclusive Teaching Module contains reflection opportunities,\napplication-based questions, and supporting materials to help guide participants through\nthe learning experience. In the blended workshop, some of the online activities found in\nthe Module will be used as is and others will be modified into an in-person activity or\nused in a different way than presented in the Module. In addition to fully reviewing this\nguide, we suggest going through the entire Module to familiarize yourself with the\ncontent and format of the sections before facilitating.\nLearning Goals and Objectives\nGoals\nThe learning goals for this workshop are:\n1. foster a reflective teaching style with a growth mindset toward improvement,\n2. empathize with how intersectional identities can inform experiences in education,\nand\n3. develop tools and strategies for inclusive practices.\n\nObjectives\nBy the end of this workshop, participants should be able to:\n1. articulate the intersectional identities you hold,\n2. identify how different teaching practices can be received by diverse audiences,\n3. assess strategies that promote inclusivity, and\n4. create an action plan to address inclusivity in your teaching environment.\nExpectations\nFor the Workshop\nAlthough educators vary in the degree of familiarity and comfort with discussions of\ndiversity, equity, and inclusion (DEI), we designed this workshop with the intention that\nthere is something for everyone. Even as the designers and facilitators of this workshop,\nwe learn something new each time it is offered. Because this is a dynamic field that\nconstantly is growing, this guide and the companion Inclusive Teaching Module are not\ntotally static resources. We have, and will continue to, edit and add to these materials as\nmore research and best practices are shared. Despite the significant shifts in\nself-reported attitudes and skills we measure as a result of offering this workshop, it is\nnot a cure-all. This workshop functions best when embedded into a larger institutional\neffort to increase DEI in your organization.\nFor Facilitators\nIt is vital that facilitators of this workshop model the inclusive practices and mindsets that\nwe encourage of our participants. Chief among them is humility. We all have something\nto learn and cannot expect that we will perfectly facilitate every time. Staying open with a\ngrowth mindset helps us navigate challenging situations and learn from those moments.\nAlong with modeling humility, we also want to model transparency. Be sure to describe to\nparticipants what is expected of them, how the activities are structured, and why they are\ndesigned that way (i.e., their alignment to specific learning outcomes).\nFor Participants\nWe know that talking about identity and teaching experiences can be emotional. That is\nwhy we strongly advocate for using ground rules/group agreements/community\nguidelines. These tenets not only set the tone for the workshop, but they clarify\nexpectations for participants and create a system for accountability. These are fairly\nnon-negotiable, we have had participants add to and clarify them, but we cannot abide\n\nby removing list items. This is in service of creating a space where folks feel welcome to\nparticipate. We introduce these ground rules after introductions, but before moving on to\nthe workshop content (Overview and Introduction section of this guide).\n1. Listen and speak with intention - You will get the most out of this workshop if you\nare present and attentive when listening, and mindful and deliberate when\nspeaking. Take a moment to relate your thoughts to today's objectives.\n2. Share time - Create space for others to be heard and take part in the\nconversation. Notice how much you are talking, and who else is participating.\nInvite others to share their thoughts.\n3. Ask questions - Test your assumptions by asking clarifying questions and\nrestating what you hear. Approach asking and answering questions with openness\nand the intention to increase understanding of all participants.\n4. Give the benefit of the doubt - We're all doing the best we can in the moment.\nStart from a place of positivity and give the benefit of the doubt to your\ncolleagues. We want to foster an environment where it is safe to be vulnerable\nand make mistakes.\n5. Hold yourself and others accountable - If you misstep, that is okay! Apologize,\nand correct the mistake if possible. We are all here to learn.\n6. Take the learning, but leave the stories- We want to create a space where folks\nfeel comfortable sharing their experiences. In that spirit, we want to take away\nideas and skills we build here, but leave specifics from others' stories.\nPlanning the Workshop\nPeople Power\nCo-Facilitation\nWe advocate that co-facilitation (at least 2 facilitators) is a best practice, but acknowledge\nthat is not always feasible. We typically offer this workshop with 2 facilitators. The\nbenefits of co-facilitation include representing diverse perspectives, demonstrating\ncollaboration, reducing reliance on a single person, and increasing capacity for workshop\nmanagement. The downside to co-facilitation is that it requires the coordination of more\npeople's schedules.\nParticipants\nWe typically will not facilitate this workshop with more than 25 people. It is an interactive,\nhighly participatory curriculum, so we want everyone to have a chance to be heard. More\n\npeople means there are fewer opportunities for folks to share out with the whole group\nand other time constraints. We find that the minimum number of participants required for\nthe activities and robust discussion is 8 people. Factor in some attrition into your\nrecruitment efforts to make sure you have 8-25 participants.\nMaterials and Resources\nIn each section of Facilitating the Workshop, we will note which of the supplies listed\nhere if any are needed. The physical space, technology, and files referenced in this\nsection are needed in each part of the workshop, whereas the supplies are only\nmentioned in the applicable activities.\nPhysical Space\n● Room for 25 participants maximum (room should hold ~30 people)\n● Enough tables with 5 chairs at each to accommodate all participants during small\ngroup work\n● AV equipment (see Technology)\n● Available walls for hanging at least 8 poster-sized sticky notes (see Supplies)\nTechnology\n● Facilitators:\n○ Laptop connected to internet, a projection screen, and speaker\n○ Audio and visual projection options for the room\n○ Inclusive Teaching Module\n● Participants:\n○ Laptop or tablet connected to internet with access to the Inclusive Teaching\nModule\nFiles\nWorkshop files are found in the Facilitation Guide and Appendix section of the Module.\n● Participants: Digital link sheet\n● Facilitators: All other files\nSupplies\n● Poster-sized sticky notes (~15 sheets)\n● 4 different shape and color combination sticky notes or stickers\n○ Each participant needs 2 of each shape/color combination\n\n● Large sticky notes\n○ Each participant should have 3-5\n● Name tags for each participant and facilitator\n● Large markers\n● Sign-in sheet\n● Table number signs\nFormat and Timing Suggestions\nOne All-Day Session\nThis workshop can be facilitated as a one-day intensive retreat. We suggest if you pursue\nthis option to provide meals/snacks as well as several breaks (noted).\n● Morning 1: Identity - (75 minutes total)\n○ Overview and introductions (in-person) - 30 minutes\n○ What is Inclusive Teaching? (in-person) - 5 minutes\n○ Intersectional identity activity (in-person) - 35 minutes\n○ Introduce Gallery Walk activity (in-person) - 5 minutes\n● Break (10 minutes)\n● Morning 2: Reflective Teaching (70 minutes total)\n○ Supporting under-represented students (in-person) - 5 minutes\n○ Connecting identity to education reflections (online) - 10 minutes\n○ Reflective teaching guided inquiry (online and in-person) - 40 minutes\n○ Wrap up and preview for next session (in-person) - 15 minutes\n● Lunch break (1 hour)\n● Afternoon 1: Distinguishing Inclusive Teaching Practices (60 minutes total)\n○ Overview, recap, review of inclusive themes (in-person)- 5 minutes\n○ Online work in small groups (online and in-person)- 30 minutes\n○ Scenario small group discussion (in-person) - 25 minutes\n● Break (10 min)\n● Afternoon 2- Critiquing Teaching Practices- (65 minutes total)\n○ Video critiques (online and in-person) - 60 minutes\n○ Debrief (in-person) - 5 minutes\n● Break (10 minutes)\n● Afternoon 3- Gallery Showcase and Action Plan- (80 minutes total)\n○ Gallery Showcase (in-person)- 30 minutes\n○ Action plan (online and in-person) - 50 minutes\n\nTwo-Session Format\nWe often run this workshop as two 2 hour sessions one week apart.\nSession 1: Identity and Reflective Teaching (2 hours total)\n○ Overview and introductions (in-person) - 25 minutes\n○ What is Inclusive Teaching? (in-person) - 5 minutes\n○ Intersectional identity activity (in-person) - 30 minutes\n○ Supporting under-represented students (in-person) - 5 minutes\n○ Connecting identity to education reflections (online) - 10 minutes\n○ Reflective teaching guided inquiry (online and in-person) - 30 minutes\n○ Wrap up and preview for next session (in-person)- 15 minutes\n● Homework (online in between sessions) (30 minutes)\n● Session 2: Distinguishing Inclusive Teaching Practices (2 hours total)\n○ Overview, recap, review of inclusive themes (in-person)- 15 minutes\n○ Scenario small group and large group discussions (in-person) - 20 minutes\n○ Video critiques (online and in-person) - 35 minutes\n○ Action plan (online and in person) - 45 minutes\nOther Possibilities\nOne of the intentions behind the design of this curriculum is that the activities build off\none another and are somewhat modular. Depending on time and interest, there are more\nformat variations possible. We have on occasion assigned the online version of the\nIntersectional Identity Activity as pre-work when time is limited. In those cases, we focus\nthe remaining synchronous activities on reflective teaching and/or discussions and\ncritiques of scenarios.\nPreparing for the Workshop\nTarget Audience\nWe offer this workshop to graduate students, postdoctoral fellows, teaching staff, and\nfaculty. We recommend extending invitations to graduate students and junior\npostdoctoral fellows together, or faculty, teaching staff, and senior postdoctoral fellows\ntogether. We believe a mixed group of graduate students and faculty has too many\ncomplicated power dynamics. Postdoctoral fellows pose a unique challenge as their\nexperience is typically the most variable, which is why we include them in both graduate\nstudent and faculty targeted workshops. If including postdoctoral fellows and faculty\ntogether, be mindful of potential conflicts (see Assign seating section).\n\nCommunications\nThis workshop is extremely participatory and we acknowledge folks have very busy\nschedules. That is why it is important to get an accurate headcount for the event. Our\nstrategy is to send out an interest form (see Appendix) 6-8 weeks ahead of the event and\nthen follow-up with folks who expressed interest to confirm registration (see Appendix)\nabout 1 month before the event. We find that this two-part interest/registration method\nminimizes attrition as it reinforces commitment. If it is an especially busy time of year and\nyou have some flexibility, we also have success including a rank choice date/time option\nin the interest form. That way you can find the date/time that works for both the\nfacilitators and prospective participants.\nAssign Seating\nWe find that assigning small groups for some activities works well. Based on the\nregistration information provided by participants, we like to compose groups with a mix\nof teaching experience, gender identities, and racial identities (if known). We typically\nassign 5-6 groups of 4-5 people. It is wise to try to have at least 2 people of a shared\ngender or racial identity (if known and if possible) in each small group, as the experience\nof being the only representative of a specific identity can trigger stereotype threat. If\nincluding folks of different roles (e.g., postdoctoral fellows and faculty), it is ideal to also\nhave 2 people of a similar role/work experience in each group. However, just make sure\nnot to assign a faculty member to the same group as the postdoctoral fellows in their lab.\nPrint out a sign-in sheet for the participants to initial (to indicate attendance at event) and\nfind their table as they enter the space (see Appendix). Due to some attrition on the day\nof the event, you may need to combine tables or rearrange the seating chart. We advise\ndoing this to maintain 3-5 people per group.\nReview All Materials\nThe most important thing you can do as a facilitator is be prepared! Be sure to review this\nguide, the online Inclusive Teaching Module, and all other materials thoroughly. Comfort\nwith the materials will help the workshop go smoothly and on schedule. Remember to\narrive at the workshop space at least 20 minutes before the workshop begins, as some\nset up is required.\n\nFacilitating the Workshop\nOverview and Introductions\nSynopsis\nIn-person and online. Introducing yourselves and the material can help set the tone for a\ntransparent, candid, and inviting workshop.\nSupplies\n● Name tags for each participant and facilitator\n● Large markers\n● Sign-in sheet (see Appendix)\n● Table number signs\nTiming: 25 minutes\nDetailed Guide\nAs folks enter the room, encourage them to:\n● sign in on the registration sheet\n● find their assigned table and fill out a name tag,\n● and complete Survey 1 as a pretest (for a hard copy see Appendix).\nThen introduce yourselves. We typically introduce ourselves by using our first names,\npronouns, role at the institute, and connection to the material. Sometimes, our workshop\nsessions are too large to have sufficient time for all participants to introduce themselves,\nin that case, we ask that participants introduce themselves before they speak for the first\ntime and in their small groups. However, you may want to include introductions as this\nhelps get participants comfortable.\nAfter introductions we move to outlining the Learning Goals and Objectives and the\nGround Rules (both described in detail in the Overview section of this guide).\nOnce these housekeeping tasks are completed we like to ask participants: what is\ninclusive teaching? We use PollEverywhere to compile anonymous open-ended short\ntext-based responses. However, you can set up a poll in whatever format you desire. We\nreview responses as they appear in real-time. After folks have responded, we define\n\ninclusive teaching as a collection of approaches that both invites and enables people\nthat embody diverse identities to successfully learn together.\nFacilitation Tips\nAssess agreement: Get an indication if folks agree to the ground rules. Ask participants\nto show a sign (thumbs up/down) of agreement. If someone does not agree, take a few\nminutes to discuss their concerns or suggested amendments (while keeping the existing\nrules in place).\nIntersectional Identity Activity\nSynopsis\nIn-person group activity. Participants indicate which categories of identity they feel are\nmost salient, less salient, powerful or privileged, and stigmatized or oppressed for\nthemselves and discuss in small and large groups. This activity aligns to:\n● Goal 2: empathize with how intersectional identities can inform experiences in\neducation\n● Objective 1: articulate the intersectional identities you hold\nSupplies\n● Poster-sized sticky notes (~8 sheets)\n● Large markers\n● 4 unique combinations of color and shape sticky notes or stickers (to ensure\nparticipants with impaired color vision can distinguish the different options)\n○ 2 of each shape/color combination per participant\nTiming: 35 minutes\n● Instructions overview: 5 minutes\n● Activity: 15 minutes\n● Discussion: 15 minutes\nDetailed Guide\nBefore the session starts, hang 8 poster-sized sticky notes (they should be spaced out)\naround the room with the following labels written on them:\n● Gender\n● Health and Ableness\n● Race and Ethnicity\n● Sexual Orientation\n\n● Socioeconomic Status\n● Immigration Status\n● Religion and Spirituality\n● Specify (a catchall for categories not\nalready mentioned)\nEach participant should have 2 of each of the 4 different color and shape combinations\nbefore the activity begins. We recommend placing these at each seat in the room when\nsetting up. We have found that unique color and shape combinations work best for\naccessibility.\nGive a brief overview of the whole process: We will go through 4 rounds of questions\ncorresponding to each of the different colors/shapes. In each round, place your 2 stickers\nin 2 categories that answer the question for you and then find a partner to discuss briefly.\nThen walk participants through the activity step by step. First, ask participants to place a\nsticker on the two identity categories in which they relate to most closely (are most\nsalient). After this placement, they should find someone at the same identity board to\nhave a short discussion. Repeat this process for identities that: do not relate to closely\n(less salient), feel the most oppressed or stigmatized, and have the most power or\nprivilege. Again, be sure to pause between each round for a brief partner discussion.\nAfter the 4 rounds of placement and partner discussion, engage in a large group\ndiscussion. You do not need to ask all of these questions, but we recommend some\ncombination of:\n● Which color/shape was the most challenging and which color/shape was the\neasiest for you to categorize? Why do you think this is the case?\n● Did you place multiple colors/shapes in the same category?\n● How do the different categories you identified in each round influence each\nother?\n● As a group, where are the different colors/shapes placed? How does this compare\nto your own categorization?\n● What patterns do you notice? What information is missing from these visuals?\nWe like to end with a final question: Why did we do this activity?\nWith the goal of helping participants make the following connections:\n● We all have multifaceted identities, many of which are not visible.\n● Educational settings are diverse places. Even if 2 people share an identity, it does\nnot mean their feelings about them are similar.\n\n● Awareness of our own identities, and how they relate to the identities of others, is\nthe first step to building empathy and an inclusive learning environment. This will\nultimately make it easier for us to communicate with, teach, and mentor others.\nFacilitation Tips\nBuild trust: this activity can be vulnerable and uncomfortable, so it might help to\nacknowledge this fact, remind folks of the ground rules, and provide your own examples\nduring the instructions for each round (especially of the Specify category). Also, be sure\nto mention that folks are welcome to participate at the level they feel safe doing so and\nto remember the difference between safety (required for learning) and comfort (not\nalways necessary to learn).\nConnecting Identity to Education\nSynopsis\nIndividual online reflection activity. In this section we will be bridging the\nidentity-focused work in the Intersectional Identity Activity with the upcoming activity\nexamining teaching practices. Briefly describe some strategies for supporting\nunderrepresented learners and then have participants reflect on their own experiences\nin education. This activity aligns to:\n● Goal 2: empathize with how intersectional identities can inform experiences in\neducation\n● Objective 1: articulate the intersectional identities you hold\n● Objective 2: identify how different teaching practices can be received by diverse\naudiences\nTiming: 15 minutes\n● Description of some supports for underrepresented learners: 5 minutes\n● Online reflection Connecting Identity and Education: 10 minutes\nDetailed Guide\nDescribe some broad strategies that are helpful for underrepresented learners. These\nare general practices that particularly help students feel supported in environments that\nmight otherwise feel unwelcoming.\n● Prepare ahead of time- know your resources and what you can provide to\nlearners. Are there resources at your institution that you can provide? This can be\n\nincluded in your syllabus. Examples include accessibility office, office for\nunderrepresented students, counseling services, etc.\n● Check in regularly- be willing to check in with students who might be struggling.\nTry to notice when someone seems like something is bothering them or if\nsomething is off.\n● Validate concerns- when someone comes to you, try to validate them instead of\ngiving excuses or explaining why they might be wrong\n● Provide community- if you cannot provide shared community and support to the\nlearner, can you connect them with people who can support them? Try not to\ndirectly connect them with a mentor/support based solely on shared background,\nbut instead provide them a menu of options to choose from so they can select the\nperson that is right for them.\n● Create psychological safety- create an environment where learners feel safe. This\ncan include providing options to step out, pass in group discussions, and\nrespecting pronouns.\nNext, invite participants to select 1 of the 3 questions found in the Connecting Identity\nand Education section to answer for their own reflective purposes. Remind participants\nthis will not be shared out. The three question options address themes of identity\naffirmation in education, identity as an asset to learning, and identity in teaching.\nFacilitation Tips\nParticipant signals: We like to ask participants to partially close their laptop/tablet when\nthey are done with the reflection to help us keep track of where participants are in the\nactivity.\nReflective Teaching\nSynopsis\nIn-person large group discussion and individual online reflection activity. The\nReflective Teaching cycle is introduced by the facilitators. Through a worked example,\nparticipants as a group answer a set of questions to demonstrate how to examine a focal\nteaching practice. After the worked example, participants are encouraged to try it out\nindividually. The purpose of this activity is to get participants in the habit of reflecting\nupon their teaching style, rather than following a prescriptive checklist. This activity aligns\nto:\n\n● Goal 1: foster a reflective teaching style with a growth mindset toward\nimprovement\n● Goal 2: empathize with how intersectional identities can inform experiences in\neducation\n● Objective 2: identify how different teaching practices can be received by diverse\naudiences\n● Objective 3: identify strategies that promote inclusivity\nSupplies\n● Poster board sticky notes (~2 sheets)\n● Large markers\nTiming: 30 minutes\n● Introduction and worked example: 10 minutes\n● Applying a Reflective Approach to a Teaching Practice online: 10 minutes\n● Debrief: 10 minutes\nDetailed Guide\nDescribe the process of reflective teaching: Being a reflective teacher means that you\nsystematically use self-reflection to critically examine your pedagogical choices, their\nimpact on students, and potential solutions to classroom challenges. Similar to the\nscientific method, a reflective teaching practice starts with a question and requires you to\ngather data from multiple sources, evaluate that information, and draw conclusions to\nrevise your teaching practices accordingly. Reflective teaching is an iterative approach to\ninstruction that is always in process.\nProvide an example of what this might look like:\n● Question: Am I grading assessments fairly?\n● Data: Look at student performance on assignments across time, feedback from\nstudents, invite a peer to talk about your grading scheme, and other observations\nyou or your colleagues make.\n● Evaluation: Is there a consistent pattern that emerges through the\ndata/observations? Are some of these sources more reliable or important than\nothers?\n● Conclusions: Does my current method produce results consistent with an\ninclusive teaching and learning environment?\n\n● Next Steps: Revise and iterate your practice. For example, add more detail to\nrubrics, modify exam formats, or institute more flexible deadlines.\nWe provide a set of questions that guide the process of examining focal teaching\npractices. If we examine the ways we teach, we can find areas for making our teaching\npractices more inclusive. When facilitating, we typically select the process of cold-calling\n(asking a student to contribute to class without them volunteering) as our worked\nexample. Some potential responses are indicated below.\nCold-calling\n● Why might I use this practice?\n○ The instructor wants to encourage participation or is uncomfortable with\nsilence.\n● What is implied about my values and expectations for students?\n○ The instructor values quick-thinking and frequent verbal contributions.\n○ Students are expected to answer quickly and correctly when called upon.\n● Which student behaviors are encouraged and which are discouraged by using this\npractice?\n○ Some students may be stressed or anxious, which could negatively\ninfluence their reception of material, reducing motivation to participate.\n○ Some students may find this motivating, or appreciate the opportunity to\nparticipate.\n○ This practice may encourage quick-thinking or second-guessing.\n○ This practice could discourage thoughtful responses.\n● Who is left out and who is welcomed to learn as a result of this practice?\n○ Socially anxious students may not feel comfortable in this classroom.\n○ Shy students may feel like they are given a dedicated opportunity to\nparticipate.\n● Is this practice more or less inclusive? What could be done to modify this practice\nto ensure inclusivity?\n○ Less inclusive. Bias in who the facilitator calls on can marginalize some\nparticipants. This practice takes away a sense of autonomy in participation.\nTo improve it, we could: randomize roll call using a roster/random number\ngenerator/etc., ask students ahead of time to indicate if they are willing to\nbe called upon, establish that this is an expectation of class from the first\nday, normalize \"passing\", and create a culture of respect and value for all\ncontributions.\n\nParticipants then have time to repeat this process by themselves by selecting a different\nfocal teaching practice of their own and working through Applying a Reflective Approach\nto a Teaching Practice. After that, try a \"go-around\" where each participant can share\nwhat focal practice they analyzed, an insight from that analysis, or pass.\nFacilitation Tips\nKeep it moving: Brainstorming responses to the guiding questions for the worked\nexample should go fairly quickly. We want participants to offer ideas, with one facilitator\nnavigating discussion, and the other taking notes on a poster-sized sticky note.\nWrap Up Part 1/Homework Instructions\nSynopsis\nIn-person and online. The content of this section will look slightly different depending on\nthe format of your workshop. The purpose of this activity is to transition out of the Identity\nand Reflective Teaching sections and into application of these principles.\nTiming: 15 minutes\n● Both formats- Complete Survey 1 as a post-test (for a hard copy see Appendix): 5\nminutes\n● If one all-day session- Share an insight or question from this session: 10 minutes\n● If two-session format- Preview of homework with instructions and demonstration:\n10 minutes\nDetailed Guide\nAfter the reflective teaching practice go-around, invite participants to fill out the Survey 1\nas a post-test from this part of the workshop (for a hard copy see Appendix)\nIf one all-day session: Share an insight or question you have from this session.\nIf you have time after the post-survey, you can do another go-around in the opposite\ndirection with every participant having an opportunity to share, or if time is tight, ask for a\nfew participants to offer questions and insights.\nIf two-session format: Review homework instructions and demonstrate course\nnavigation.\n\nInstruct participants to complete Survey 2 as a pre-test before starting the homework (for\na hard copy see Appendix). Demonstrate how to navigate the Scenario-Based Learning\nApplications section. Tell participants to use the link sheet to navigate to 3 different\nsections (Preparing Inclusive Materials, Designing Equitable Instructional Activities and\nAssessments, and Interacting with Diverse Students) of thematically-related scenarios\nthat will help guide them in distinguishing more inclusive practices from less inclusive\nones. For the homework, participants are invited to explore:\n● 1 scenario question from Preparing Inclusive Materials,\n● 2 scenario questions from Designing Equitable Instructional Activities and\nAssessments,\n● and 3 scenario questions from Interacting with Diverse Students.\nParticipants should not explore the video critiques as we will involve those in another\nactivity.\nFacilitation Tips\nElaborated explanations: Whether as part of homework or in small groups (see\nDiscussion of Homework/Online Scenario Group Work), it is very important to remind\nparticipants to click the Show Answer button after submitting an answer to learn more in\nthe online Module. There are incredibly detailed explanations that explain the logic and\nprovide references and resources for each assessment in the course.\nOverview and Review of Inclusive Themes\nSynopsis\nIn-person review. The purpose of introducing inclusive teaching themes is to provide a\nheuristic for identifying more inclusive practices by comparing these broad themes to\nspecific applications.\nTiming: 5-15 minutes\n● If two session format- Review of learning goals and objectives and ground rules:\n10 minutes\n● Both formats- Introduction of inclusive learning themes: 5 minutes\nDetailed Guide\nIn a two-session format, we encourage facilitators to take time to review the ground rules\nand learning goals and objectives before discussing the themes of inclusive teaching. In\n\none all-day session, you can skip the ground rules, learning goals, and objectives and go\nstraight into the discussion of inclusive teaching themes.\nIntroduction of inclusive learning themes:\n● Demonstrating respect and empathy for the whole student: Mutual respect and\nunderstanding is vital to interpersonal educational dynamics. If you extend\nkindness, understanding, and appreciation to your students you will see it return.\n● Encouraging autonomy and self-efficacy: By helping our students make\neducational decisions that are consistent with their values and instilling in them a\nbelief that they can succeed, they can become empowered in their educational\njourney.\n● Valuing open communication and transparent policies: By communicating with\nour students clearly and effectively, we can share a mutual understanding of not\nonly what is expected when and how, but why. By engaging in open, transparent\ncommunication, we also demonstrate respect and encourage autonomy.\n● Fostering belonging and personal connections: When we feel like we truly\nbelong to a group, like as scientists, researchers, academics, or artists- we are\nmore likely to persist in that group and make meaning out of our experiences. This\nprocess helps grow the network of our student's into a community where they feel\nat home.\n● Centering growth, accessibility, and flexibility: We all have something to learn, so\nremaining amenable to change both big and small is important to adapt and adjust\nto the unpredictability of life. To help with that uncertainty, we must also tirelessly\nwork to ensure that access - to educational content, instructor empathy,\nresources, and more - is preserved.\nFacilitation Tips\nWhat questions can I answer? Is an inviting way to normalize and encourage\nquestion-asking. Remember to pause for questions throughout the workshop, especially\nduring the more exposition-heavy sections.\nDiscussion of Homework/Online Scenario Group Work\nSynopsis\nSmall group work in person and/or online. The timing of this section will look slightly\ndifferent depending on the format of your workshop. The shared purpose of these\nactivities is to encourage participants to explore different teaching scenarios and\n\ndetermine more inclusive responses using the online Module and compare ideas in small\ngroups before sharing out more broadly. These activities align with:\n● Goal 1: foster a reflective teaching style with a growth mindset toward\nimprovement\n● Goal 3: develop tools and strategies for inclusive practices\n● Objective 2: identify how different teaching practices can be received by diverse\naudiences\n● Objective 3: identify strategies that promote inclusivity\nTiming: 50 minutes\n● If one all-day session- small group work of scenarios: 30 minutes\n● If two-session format- homework (described in Wrap Up Session 1/ Homework\nInstructions): 30 minutes\n○ Both formats include Survey 2 as a pre-test (for a hard copy see Appendix)\n● Both formats- Small group discussion of scenarios: 10 minutes\n● Both formats- Takeaways: 10 minutes\nDetailed Guide\nIf one all-day session: small group work\nFirst, instruct individuals to complete Survey 2 as a pre-test (for a hard copy see\nAppendix).\nThen, in groups of 3-5 (depending on final enrollment) instruct participants to complete\nthe Scenario-Based Learning Applications together. Each group should complete at least:\n● 1 scenario question from Preparing Inclusive Materials,\n● 2 scenario questions from Designing Equitable Instructional Activities and\nAssessments,\n● and 3 scenario questions from Interacting with Diverse Students.\nRemind participants to click Show Answer after submitting an answer for more\ninformation. After the end of this activity, instruct small groups to disassemble and reform\nwith different people.\nIf two-session format: individual computer work\nParticipants are expected to complete the Survey 2 as a pre-test (for a hard copy see\nAppendix) and homework (described in Wrap Up Session 1/ Homework Instructions) on\ntheir own before the start of the second session. You may want to open the workshop\nspace for 30 minutes before the workshop is scheduled to begin and let participants\nknow they can come early to finish the homework during that time.\n\nBoth formats: small and large group discussion of scenarios\nWhether one session or two, in the (new) small groups, encourage participants to discuss\nthe following:\n● Which scenarios did you explore previously?\n● Which theme(s) of inclusive teaching did each of these scenarios address?\n● Did anything surprise you? What did you learn?\n● How do you think your students will respond to the practices encouraged by\nthese scenarios?\n● What might be barriers to implementation? How could you resolve them?\nAfter small groups have time to discuss, invite a representative from each small group to\nsummarize what was discussed and any takeaways that emerged from their discussions.\nFacilitation Tips\nMonitor discussion: It helps to move around from small group to small group to listen in\non discussion to have a sense for how it is going and if you need to redirect any\nconversation.\nVideo Critiques\nSynopsis\nLarge group discussion with online resources. In this activity, participants watch short\npairs of video scenarios. There are 4 scenarios, each with 2 scenes. Scene A is a less\ninclusive way and Scene B is a more inclusive way of navigating the same situation. A\nlarge group discussion follows after each scene. This activity aligns to:\n● Goal 1: foster a reflective teaching style with a growth mindset toward\nimprovement\n● Goal 3: develop tools and strategies for inclusive practices\n● Objective 2: identify how different teaching practices can be received by diverse\naudiences\n● Objective 3: identify strategies that promote inclusivity\nTiming: 35-65 minutes\nVideos are found in the Video Critiques section of the Module\n● If one all-day session- watch all 4 scenarios and discuss: 60 minutes\n\n● If a two-session format- have participants vote on 2 scenarios they want to explore\nand discuss: 30 minutes\n● Both formats: Survey 2 as a post-test (for a hard copy see Appendix): 5 minutes\nDetailed Guide\nBefore you start watching videos it can help to provide some context for the activity:\nResponding in the moment is one of the most challenging parts of instruction. Our\nintentions to be supportive and mindful educators are a great place to start, but\nsometimes our intentions are not translated effectively into action or become muddled in\nmissteps and mistakes. Perfection is not a realistic expectation; we simply must try our\nbest, be thoughtful, and confront the impacts of our actions with humility, no matter our\nintention. The following video scenarios contain paired scenes grounded in real\nexperiences that are meant for you to practice critiquing responses based on what you\nhave learned about inclusive teaching so far. Each video contains two versions of the\nsame scenario, one scene that is less inclusive (Scene A), followed by another that is an\nimproved response (Scene B). We will critique and discuss each scene.\nIf you have limited time and cannot watch all 4 scenarios, have participants vote by a\nshow of hands which 2 scenarios they prefer. Regardless of whether or not you can\nexplore all scenarios, the following discussion questions can help guide the group\nconversation.\nAfter Scene A\n● What are some possible good intentions behind Scene A?\n● What are some criticisms you can make of Scene A? What are the potential\nnegative impacts?\nAfter Scene B\n● How does Scene B avoid or correct the criticisms and impacts from Scene A?\n● How else could you respond to this or a similar situation in your own teaching\ncontext?\nAfter discussion has ended, invite participants to complete Survey 2 as a post-test (for a\nhard copy see Appendix) before moving onto the next activity.\n\nFacilitation Tips\nVideo player: You may play the videos through the Video Critiques section of the online\nModule or download them locally and embed them into your slides for ease of\nfacilitation.\nGallery Showcase\nSynopsis\nIn-person small and large group activity. We typically only implement this activity during\nan all-day workshop when we have more time for participants to continually think and\nadd more ideas throughout the session. Participants brainstorm useful inclusive teaching\npractices in specific learning contexts and discuss implementation, including sharing their\nown inclusive teaching triumphs. This activity aligns to:\n● Goal 3: develop tools and strategies for inclusive practices\n● Objective 4: create an action plan to address inclusivity in your classroom.\nSupplies\n● Poster-sized sticky notes (with ~4 sheets)\n● Large sticky notes\n○ Each participant should have 3-5\nTiming: 30 minutes\n● Gallery debut: 10 minutes\n● Form small groups discussion: 10 minutes\n● Report out to large group: 10 minutes\nDetailed Guide\nSet up poster-sized sticky notes with four different types of teaching contexts around the\nroom (e.g., labs, large enrollment lecture, discussion-based, virtual) after the\nIntersectional Identity Activity. These can be any teaching contexts that are most relevant\nto your participants. Invite participants to add examples of inclusive strategies that fit\neach context throughout the day.\nWhen it comes time for the gallery debut portion, ask participants to move around the\nroom, take notes, and continue to add to the different boards. Then invite participants to\nassemble around a board that they want to explore in more depth (you may have to\n\nbreak groups up or ask to redistribute if too big). Remind participants this does not have\nto be a board that they personally added to. Encourage participants to discuss what\nimplementation of the strategies on the board would look like in that context. Finally,\nhave a representative of each board summarize what was discussed to the whole group.\nFacilitation Tips\nTime to think: This activity should be introduced early in the workshop, but will not\nactually take place until the end of the day. This gives participants time to add to the\nboards as they become more familiar with different inclusive teaching practices.\nAction Plan\nSynopsis\nIndividual online activity and partner discussion. In the final activity of the workshop,\ninvite participants to create a personal action plan to take the next step in their inclusive\nteaching journey and discuss it with a partner. This activity aligns to:\n● Goal 3: develop tools and strategies for inclusive practices\n● Objective 4: create an action plan to address inclusivity in your classroom.\nTiming: 45-50 minutes\n● Create a detailed plan for 1-3 inclusive practices with the Action Plan section of the\nModule: 20 minutes\n● Pair with a neighbor and share ideas: 10 minutes\n● Go around - share action plans/reflections: 15-20 minutes\nDetailed Guide\nParticipants have the opportunity to apply what they have learned throughout the\nworkshop and craft their next steps in implementing inclusive teaching practices.\nParticipants use the Action Plan section of the Module to identify 1-3 practices they want\nto try and answer questions that are designed to have them think through the\nimplementation considerations for each practice.\nAfter participants have the opportunity to answer this series of questions, they are asked\nto pair up and describe their plans. The workshop concludes with another go-around,\nwhere participants are invited to share 1 teaching practice they want to implement.\n\nFacilitation Tips\nRemind pairs to share: During the paired portion of the action plan, give a 5 minute\nwarning so that both members of the pair have ample time to share their ideas with each\nother. Typically the group share-out can go long, so be sure to leave plenty of time for\nthat final part of the activity.\nAfterwards, Evaluation, and Additional Information\nWorkshop Feedback\nWe want to continue to learn from our work as facilitators and offer the best possible\nlearning experience to participants. To that end, we ask participants to complete a simple\ndigital workshop evaluation form (see Appendix) at the very end of the workshop. This\nfeedback helps us determine how we may tweak our facilitation practices, materials, or\nworkshop format. It is very important to us that participants share honest feedback, so we\nlike to use an online form to collect responses anonymously.\nPost-Workshop Communication and Certification\nAfter our workshops, we distribute the slides as pdfs (see Appendix). This meets the\nneeds of participants for physical notes they can reference with our need as facilitators to\nkeep folks focused and attentive during the workshop activities. In addition to slides, we\nalso send out certificates (see Appendix) to the participants that complete all the\nworkshop activities. In our post-workshop email, we also thank participants and remind\nthem to complete the workshop evaluation form if they have not done so, yet. This is also\na good opportunity to follow up on any questions or requests for resources that you\ncould not attend to or answer during the workshop.\nPotential Analyses\nThere are built-in pre/post tests embedded in the course site, but we understand if it is\nimportant to your institution if you measure your own outcomes. We strongly suggest\nusing the same 8 questions on a seven-point Likert-like scale (1= Strongly Disagree, 4=\nNeutral, 7= Strongly Agree) we developed (see Appendix) that align to the learning goals\nand objectives, at the times stated in this guide. You can number each of your pre and\npost surveys with a de-identifying code to keep them anonymous, but also paired. After\ndata collection, we illustrate our results using histograms of pre/post responses and\nanalyze these data further (sample size permitting) using a paired Wilcoxon signed rank\ntest for each of the 8 questions with a Bonferroni correction for multiple tests.\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu/\nResource: Inclusive Teaching Module\nDarcy G. Gordon, Catherine Drennan\nThe following may not correspond to a particular course on MIT OpenCourseWare, but has been\nprovided by the author as an individual learning resource.\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms."
        }
      ],
      "source_url": "https://ocw.mit.edu/courses/res-7-009-7-int-inclusive-teaching-module-fall-2022/",
      "course_info": "RES.7-009 | Non-Credit",
      "subject": "General"
    },
    {
      "course_name": "Syllabus Checklist to Support Student Belonging & Achievement",
      "course_description": "The syllabus informs students’ first impressions of a class, the instructor, and their evaluation of whether they will succeed. Given the important role of the syllabus for students and for instructors’ intentional design of the course, this syllabus checklist is a tool to guide instructors in their construction and revision of course design, assessment descriptions, teaching practices, and policies in their syllabi. Many of the checklist items also apply beyond the syllabus to other communication channels in the course (e.g., Learning Management Systems, course wikis, classroom conversations).\nThe checklist is adapted from a comprehensive and detailed rubric developed by members of MIT’s Teaching + Learning Lab.",
      "topics": [
        "Teaching and Education",
        "Curriculum and Teaching",
        "Teaching and Education",
        "Curriculum and Teaching"
      ],
      "syllabus_content": "",
      "files": [],
      "source_url": "https://ocw.mit.edu/courses/res-tll-010-syllabus-checklist-to-support-student-belonging-achievement-spring-2025/",
      "course_info": "RES.TLL-010 | Non-Credit",
      "subject": "General"
    },
    {
      "course_name": "Heavy Metal 101",
      "course_description": "This is not a metallurgy class! Learn everything you ever wanted to know about heavy metal music. Topics of this video lecture series include musicology, history, metal culture, music theory, songwriting tropes, harsh vocal techniques, extreme metal, tech-based instruments, and how the genre tackles some of today’s biggest sociopolitical challenges. You’ll find out why metal bands exist in every country on Earth, and why you’re probably already a metalhead without even knowing it. This course has been rockin’ MIT’s Independent Activities Period (IAP)* since 2006!\n2025 Video Lectures:\n\nHeavy Metal 101: Music and Culture\nThe Physics Behind the Shred with Will Lunden\nWheels of Steel: The Influence of the New Wave of British Heavy Metal with Martin Popoff\nIs Heavy Metal Sacred? The Psychological Functions and Desecration of Heavy Metal with Kyle Messick\nHistory of Heavy Metal, Part I\nHistory of Heavy Metal, Part II\nMetal Aesthetics: A Rebel at the Core with Clara Wanning\nLeather and Heavy Metal: More Than Meets the Eye with Haydée Irizarry\nNeuroscience of Metal with Evgeny Gromovoy\nAll about Harsh Vocals: History, Application, and Technique with Paul Buckley\nHistory of Heavy Metal, Part III\nUnderstanding Black Metal: History, Sound, and Controversy with Lauren Crosser\nLife as a Modern Metal Drummer: Tech, Production, and Touring with Matt Zappa\nHistory of Heavy Metal, Part IV\n\nThe class video lectures from 2021 to the present are available on the site.\n*IAP is a 4-week term at MIT in January that allows members of the MIT community to organize, sponsor, and participate in activities and topics often outside of the regular MIT curriculum.",
      "topics": [
        "Fine Arts",
        "Music",
        "Music History",
        "Music Performance",
        "Fine Arts",
        "Music",
        "Music History",
        "Music Performance"
      ],
      "syllabus_content": "",
      "files": [],
      "source_url": "https://ocw.mit.edu/courses/res-21m-001-heavy-metal-101-january-iap-2025/",
      "course_info": "RES.21M-001 | Non-Credit",
      "subject": "General"
    },
    {
      "course_name": "Social and Ethical Responsibilities of Computing (SERC)",
      "course_description": "Social and Ethical Responsibilities of Computing (SERC), a cross-cutting initiative of the MIT Schwarzman College of Computing, works to train students and facilitate research to assess the broad challenges and opportunities associated with computing, and improve design, policy, implementation, and impacts.\nThis site is a resource for SERC pedagogical materials developed for use in MIT courses. SERC brings together cross-disciplinary teams of faculty, researchers, and students to develop original pedagogical materials that meet our goal of training students to practice responsible technology development through incorporation of insights and methods from the humanities and social sciences, including an emphasis on social responsibility.\nMaterials include the MIT Case Studies Series in Social and Ethical Responsibilities of Computing, original Active Learning Projects, and lecture materials that provide students hands-on practice and training in SERC, together with other resources and tools found useful in education at MIT. Original homework assignments and in-class demonstrations are specially created by multidisciplinary teams, to enable instructors to embed SERC-related material into a wide variety of existing courses.\nThe aim of SERC is to facilitate the development of responsible “habits of mind and action” for those who create and deploy computing technologies, and fostering the creation of technologies in the public interest.",
      "topics": [
        "Engineering",
        "Computer Science",
        "Artificial Intelligence",
        "Teaching and Education",
        "Curriculum and Teaching",
        "Higher Education",
        "Engineering",
        "Computer Science",
        "Artificial Intelligence",
        "Teaching and Education",
        "Curriculum and Teaching",
        "Higher Education"
      ],
      "syllabus_content": "",
      "files": [
        {
          "category": "Assignment",
          "title": "RES.TLL-008 Social and Ethical Responsibilities of Computing (SERC), 6.864 Assignment 2 Task A",
          "type": "PDF",
          "source_url": "https://ocw.mit.edu/courses/res-tll-008-social-and-ethical-responsibilities-of-computing-serc/0ae39a79ffc5fe4b546f9fd4d37f7e36_MITRES-TLL008F21-6864taska.pdf",
          "content": "6.804/6.864 HW2 TASK A: Comment Moderation\nSocial media platforms and other online forums are an increasingly common venue for\ndiscourse. But unfortunately, they have also created avenues for online harassment. A recent\nPew Research Center survey found \"41% of Americans have been personally subjected to\nharassing behavior online, and an even larger share (66%) has witnessed these behaviors\ndirected at others.\"1\nThe effects of online harassment on the victim can be severe: from compromising their privacy\nto threatening their physical safety. And there are also significant negative consequences on\nthe quality of these online platforms: both experiencing and simply witnessing harassment\nsilences users and can ultimately drive them off online spaces. In its \"milder\" forms, toxic\ndiscourse can still foster a negative and hostile environment.\nWhile employing moderators to read through and mark toxic comments is one potential\nmitigation, it's difficult to scale. Recent efforts have tried to utilize technology to help with\ncomment moderation efforts -- for example, by building machine learning models to identify\nabusive comments. These might be used in a variety of ways, from helping human moderators\nprioritize what to look at, to allowing readers to filter what comments they see.\nThese models are most likely trained on data consisting of past comments annotated by\nwhether or not they contained toxic speech (or how much). In this part of the assignment,\npretend you're on a research team at a new social media company that's collecting this data.\nYou have a set of comments scraped from Wikipedia, and now you want to label them. You\nhave a budget to hire annotators, but you need a labeling scheme and instructions to give\nthem.\nHere are some examples of what the comments look like:\n●\nYour comments on my discussion page are rude, arrogant, bullying and\ntotally inappropriate. Napoleon complex is a stub and you might learn\nsomething about yourself by improving it, little boy.\n●\nhello old and crazy man.....\n●\nPrick. Gimme some time to flesh things out. Stop being such a prick.\n●\nSo when is someone going to warn YOU about your toxic attitude then?\nTell me that. Tell me when someone's going to give you a block warning\nfor the bullshit you've pulled on Wikipedia, like getting into\narguments with people and issuing blocks to them when you don't like\nhearing the truth.\n●\nSurely concerns re: fossil fuels/alternative energy sources, pollution\nand other environmental concerns should be included with the mention of\nanimal rights.\n●\nI have restored material that was removed and added a substantial\nreference within the text and also tried to add some perspective and\nalso some copyediting. I would appreciate those of you who feel the\n1 https://www.pewresearch.org/internet/2017/07/11/online-harassment-2017/\n\ninformation restored is unfounded taking a look at the references at\nthe bottom of the page. With the opening of the KGB archives a flood of\nmaterial has become available.\n●\nStop being such a goddamn prick. The article will be sorted out in\ntime. Meanwhile spend some time away from wikipedia. And do normal\nthings. for instance leave your parent's basement.\n●\nYou are full of shit sir. You are clearly one of those racists who\nlurk all over the internet looking to shut down viewpoints that differ\nfrom yours and expose truths covered in fantasy. There is NO reason\nthat you should have blocked me or even said anything. What you should\nhave done is to reply to what was written with intelligence. Since you\ndid not, it is clear that you lack it. You are the prime reason why\nthe internet community is finally realizing that this site is a joke\nand is covered by clowns with agendas. That is, people who want to put\nforth propaganda.\n●\nUSA is #1 and we made the facebook, deal with it. Oh wait, all you\nkids on facebook do instead is cry about things on the facebook. Make\na stupid facebook group about it, why don't you.\n●\nNo! This is a GROUP EFFORT! Wikipedia is a collaborative COMMUNITY\nand there are no school essays here. The article needs to be more\nprofessional and adopt a better title besides the references. This is\nall that needs to be done, so get off your high horse and accomplish\nwhat you want to see done. If you have these goals, then put yourself\nto the test of solving this problem. That's what I do whenever\nsomething perturbs me. You're just looking for a fight about something\nyou admittedly care nothing about. How about I come by your house and\ncriticise your gardens? ``Why?`` You say. ``Because they are too ugly\nand I don't like the way they don't blend in with the neighbours'\nyards. So tacky, but I'm only passing by and I've never been down this\nroad before.``\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\nRES.TLL-008 Social and Ethical Responsibilities of Computing (SERC)\nFall 2021\nFor information about citing these materials or our Terms of Use, visit:\nhttps://ocw.mit.edu/terms"
        },
        {
          "category": "Resource",
          "title": "Active Learning Project Exploring the Functionalities, Data and Interfaces of a Modern Online Advertising System",
          "type": "DOCX",
          "source_url": "https://ocw.mit.edu/courses/res-tll-008-social-and-ethical-responsibilities-of-computing-serc/1ac96d823bf0485acf3d0aafabb52d43_RES-TLL008F21-ALP-ELO_Practice_Lab.docx",
          "content": "Active Learning Project Exploring the Functionalities, Data and Interfaces of a Modern Online Advertising System\nAuthored by: Grace Chuan, Emily Jiang, and Bhavik Nagda\n\nAssociated MIT SERC Case Study:\n\nIdentity, Advertising, and Algorithmic Targeting: Or How (Not) to Target Your \"Ideal User\"\n\nKant, T. (2021). Identity, Advertising, and Algorithmic Targeting: Or How (Not) to Target Your \"Ideal User.\" MIT Case Studies in Social and Ethical Responsibilities of Computing, (Summer 2021). https://doi.org/10.21428/2c646de5.929a7db6\n\nOverview:\n\nThe last two decades of digital transformation have revealed our broad societal dependence upon data-rich, \"Big Tech\" firms. From seemingly humble beginnings to present-day backlash and congressional scrutiny, these companies have weathered good and bad times alike. Facebook is, perhaps, the epitome of this Big Tech archetype. The company capitalizes on its users' time, selling advertising space for its Facebook, WhatsApp, and Instagram platforms. As you'll notice in the following lab, Facebook is relevant in digital advertising for many types of organizations, including small and medium-sized businesses, Fortune 500s, restaurants, and political campaigns.\n\nAs we explore the ethical implications of digital advertising, it's particularly helpful to concretely identify the functionalities, data, and interfaces driving ad systems in the modern era. The following lab focuses on Facebook's Ads Manager with this in mind.\n\nImagine, for the next hour, that you're the owner of Beurre Bakery, a bakery and cafe chain with multiple locations throughout Boston and Cambridge. As owner, you've been reticent to transform the local, grassroots marketing that has been so effective over the past decade; however, competition has been intensifying, so you've decided to explore Facebook's Ads offering. Explore the following lab, revamping Beurre's digital marketing with an eye toward the societal and ethical implications of the data platform.\n\nStep 1: Enter Facebook Business's Ads Manager with the following login information.\nWe can use one account for several different pages/businesses.\nUsername: XYZ\nPassword: ABC\n\nStep 2: Click on the \"Ads\" tab in the left-hand bar to reach the Ad Center.\n\nStep 3: Click \"Ads Manager.\"\n\nStep 4: Within Ads Manager, click the green \"Create\" button.\n\nStep 5: You will need to choose a campaign objective from one of three broad categories: Awareness, Consideration, and Conversion.\n\nQ1: What differentiates these three categories?\nQ2: In what situations would you select each category over the others?\nQ3: Under \"Awareness\", there are two objectives: \"Brand awareness\" and \"Reach.\" How might these two objectives target audiences differently?\n\nStep 6: Select \"Brand awareness\" as your campaign objective.\n\nStep 7: Name your campaign!\n\nStep 8: Scroll through the special ad categories. You will see four different options.\n\nQ4: What is the purpose of selecting a special ad category, and why might Facebook ask advertisers to do so if they have an ad that falls under one of these four categories?\nQ5: Choose two of the four categories, and provide real-world examples of how running an ad within each of them might lead to unintended social impacts.\nQ6: For ads that fall under the first three categories listed, some targeting features are disabled, such as \"Look-Alike audiences,\" which allows the user to target audiences by age, gender, ZIP code, or other demographic identifiers. Why do you think Facebook made this a choice for these three categories specifically?\nQ7: In addition to Look-Alike audiences, there also exists a \"Special Ad Audience\" feature that determines an audience based on similarities in online behavior and activity. Do you think this is a better alternative to a Look-Alike audience from an advertising and/or ethical standpoint? Why or why not?\nQ8: Refer to section \"Database Ethics: Targeting from the Developer's Perspective\" in the case study. Based on Kant's discussion of session-based recommendation vs. traditional identity profiling, what are the tradeoffs of an advertiser deciding to implement one over the other?\n\nStep 9: Click \"Next\" to reach the next page, \"New Ad Set.\"\nAn ad set is a specific ad you are designing for an ad campaign; therefore, one campaign can run multiple ad sets. Ad sets can target different audiences and be scheduled to appear on feeds at different times.\n\nStep 10: Name your ad set!\nStep 11: Click \"Learn More\" in the \"Dynamic Creative\" section, and read the article provided.\n\nQ9: The dynamic creative feature is still a form of targeting, but is less explicitly focused on identifying features such as race or gender. What are some possible drawbacks or limitations to this approach?\n\nStep 12: Within the \"Audience\" section, select \"Create New → Lookalike Audience.\"\n\nStep 13: Click on \"Create New Source → Custom Audience with LTV.\" A custom audience allows Facebook to construct an audience for your ad based on the customer dataset you provide and your choices about which features to optimize for. This audience will be composed of individuals outside your own customer list.\n\nStep 14: Upload the provided .csv as your customer list.\n\nQ10: What are the ethical implications of businesses being able to target audiences who resemble individuals described in this customer list by the features included?\n\nThe key feature in this dataset is the \"Customer Value\" column. The customer value is a numeric representation of the net profit you predict will be attributable to a given customer over the duration of your relationship with them. The Lookalike Audience feature will target more people who are similar to the individuals with the highest customer values.\n\nQ11: What are three different ways of potentially measuring customer value, and the ethical implications of each?\n\nStep 15: Select the \"Customer Value\" column and name the customer list to move on to the next page.\n\nStep 16: After clicking \"Next,\" be sure to assign the correct identifiers to each column of the dataset.\n\nStep 17: Upload the list. Facebook is now hashing the data.\n\nWhen you upload your customer list in Ads Manager to create a Custom Audience, the information in your list is hashed before it's sent to Facebook. Hashing is the application of cryptographic primitives to map data to representative numerical values. Facebook's hash functions are one-way functions: you cannot recover the original data from the hashed data.\n\nFacebook uses this hashed information and compares it to the company's own hashed information. Then, Facebook builds your audience by finding the Facebook profiles that match the specified criteria, and creates a Custom Audience from those matches. After your Custom Audience is created, the matched and unmatched hashed information is deleted.\n\nQ12: How does hashing individuals' data and then deleting it potentially preserve (or not preserve) people's privacy? Do you think hashing makes a difference in ameliorating the negative implications of targeting? Why or why not?\n\nStep 18: Complete the process of selecting your lookalike source.\n\nStep 19: Select an audience location based on where you think your ad would be most impactful given your business description.\n\nStep 20: Select an audience size -- the larger the percentage, the broader the audience.\nQ13: What are the equity implications of selecting a broader or narrower audience?\n\nStep 21: Finish creating your audience and exit the window.\n\nStep 22: Adjust age and gender group.\n\nStep 23: Open \"Detailed Targeting.\"\n\nThis feature includes and/or excludes certain audiences into tiers. For example, you could add vegetarians to \"Include/Exclude,\" and people who are interested in gardening to \"Narrow Audience.\" Doing so would result in the following setup:\nInclude/Exclude: Frequent travelers or vegetarians\nNarrow Audience: People interested in cooking or gardening\nNarrow Further: College grads\nOne criterion from each tier must be met for inclusion/exclusion; for example, a vegetarian college graduate who is interested in gardening would be in the audience, but a frequent traveler interested in cooking who isn't a college graduate would not be.\nQ14: How do you think the ethics of Detailed Targeting compare to the other targeting methods we've seen so far?\n\nStep 24: Save your ads, but do not hit publish!\n\nDone!\n\nDiscussion questions:\nWhat was your most surprising finding while performing the lab? How did the ad-targeting system compare to what you expected?\nDo you feel differently about the ethics of targeted advertising depending upon the type of ad being run (e.g., fashion, politics, housing)? If so, how and why?\nWhat benefits or drawbacks do you observe to Facebook's advertising model, for Facebook and/or society?\nIs there a need for the government to intervene? If so, what role should the government play? And if not, why not?\nWhat are the responsibilities of employees within an organization that commits ethical violations?\n\nFacebook screenshots (c) Facebook. All rights reserved. This content is excluded from our Creative Commons license. For more information, see https://ocw.mit.edu/help/faq-fair-use/\n\nWall Street Journal article excerpt (c) Wall Street Journal/Dow Jones & Company Inc. All rights reserved. This content is excluded from our Creative Commons license. For more information, see https://ocw.mit.edu/help/faq-fair-use/\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\n\nRES.TLL-008 Social and Ethical Responsibilities of Computing (SERC)\nFall 2021\n\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms"
        },
        {
          "category": "Resource",
          "title": "Active Learning Project on Developing Codes on Conduct",
          "type": "DOCX",
          "source_url": "https://ocw.mit.edu/courses/res-tll-008-social-and-ethical-responsibilities-of-computing-serc/0ddc2160f045ce3f896d53ad99980c2a_RES-TLL008F21-ALP_Open_Technologies_Open_Communities.docx",
          "content": "Active Learning Project on Developing Codes on Conduct\nAuthored by: Sohini Kar, Sarah Vu, and Jenny Cai\n\nAssociated MIT SERC Case Study:\nHacking Technology, Hacking Communities: Codes of Conduct and Community Standards in Open Source\nDunbar-Hester, C. (2021). Hacking Technology, Hacking Communities: Codes of Conduct and Community Standards in Open Source. MIT Case Studies in Social and Ethical Responsibilities of Computing, (Summer 2021). https://doi.org/10.21428/2c646de5.07bc6308\n\nTable of Contents\nIntroduction\nCreating a Github Code of Conduct\nOption 1: Using the Built-in Code of Conduct\nOption 2: Course Staff Design a Code of Conduct Template\nCode of Conduct Guidelines\nTeam Purpose and Pledge\nList of Standards\nUnacceptable Behavior\nEnforcement\nAdditional Sections\nProject Ethics\nConclusion\n\nIntroduction\n\nThis project guides students in the creation and design of codes of conduct (CoCs) for users of the technology they develop. Many MIT classes, including WebLab, 6.08, 6.031, 6.170, and BattleCode, all have \"final project\" team assignments where groups of students build applications and share a code base; students of these classes could benefit from this ALP.\n\nIn this document, we focus on creating CoCs for team-based projects in Github-hosted project repositories. README files are considered an essential and default aspect of repositories, and we believe a code of conduct should be equally essential for both developers and users. After creating the CoC, the team may choose to enforce the document passively, by only applying restorative justice when guidelines have been violated, or actively, by asking team members to periodically reflect on the document throughout the term.\n\nWhile writing the file, it might be helpful to bear in mind the following questions:\nWhy might creating a code of conduct be helpful? Do you feel it's necessary to do so? (Note: this may be circumstantial.)\nWhat is the goal of this team? Which values will be most salient to advancing this mission?\nWhat types of behavior will not be tolerated? If harassment is a prohibited behavior, how can you create specific guidelines that will identify what would be classified as harassment (even if unintentional)?\nHow can the team rigorously enforce this code of conduct? Who will benefit from adhering to the rules outlined in this document? Who is responsible for its passive and/or active enforcement?\n\nOur active learning project will guide users through the creation of codes of conduct for any Github-hosted team projects; however, the guiding questions and thought process can be applied to any team project.\n\nThis project directly connects to real-world applications and promotes best practices for computer science students at MIT. While the codes do not have to replace any team contracts already being used in classes, merging them with existing practices may encourage further use of codes of conduct in other projects, generally resulting in more open and inclusive communities. Below, we detail a guideline to creating a code of conduct, including a guide on how to create and add one to a Github repository.\n\nCreating a Github Code of Conduct\nThis active learning project uses Github as an example because it is a common classroom tool; however, note that codes of conduct can be adapted and applied to other code-sharing bases and team projects.\nOption 1: Using the built-in Code of Conduct feature\nGitHub already has code of conduct templates available; the video below demonstrates how one can be created. This option requires the least amount of work from course staff, but they should read through the template to ensure it aligns with their class goals before choosing this option.\n\nOption 2: Course Staff Design a Code of Conduct Template\nCodes of conduct may vary depending upon the context of the projects given to students. (For example, some projects may or may not be intended for the general public, so creating \"community\" guidelines can differ). However, at the very least, any code of conduct template given to students must contain the content within the guideline described in the \"Code of Conduct Guidelines\" section of this paper. Below are two demos from GitHub Classroom; course staff can create a template repo with an existing code of conduct for students to clone and create assignments from.\n\nCode of Conduct Guidelines\nIn this section, we guide users through important sections of a standard code of conduct applied to a classroom team project. We describe flexible guidelines and alternatives, so these sections may be adjusted as necessary.\nTeam Purpose and Pledge\nPresent a brief overview of team goals and the project description. Provide a purpose and motivation for the project, as well as an overview of the code of conduct.\nGenerally describe the goals for the code of conduct and which values the team considers important\nConsider including aspects from standard team contracts, such as timelines, deliverables, and general project goals.\nConsider including project rubric, work breakdown by member, and other project-related information.\n\nList of Standards\nList and describe best practices for maintaining a strong sense of community and inclusivity within the project.\nDetail behaviors that lead to an inclusive and positive project and team environment.\nOutline what respectful, positive, and considerate conversations look like, as well as general standards for detailing and signaling an open and accepting environment.\nMay include general team contract points, including which forms of communication to use or when/how often meetings occur, but the main goal should be to define respectful conduct.\nMay include examples of positive situations or successful conversations.\n\nUnacceptable Behavior\nDefine what actions or conversations are disallowed in order to maintain a positive working environment.\nProvide examples of behavior by team members that would be considered inappropriate for the project's setting.\nMay include threatening or bullying speech, spam, insulting comments, or actions that invade privacy.\nMay include any behavior specifically disallowed by the team through discussions and team meetings.\n\nEnforcement\nProvide a brief outline of what to do if the code of conduct is violated.\nWhat instances of negative or harmful behavior should be resolved by the group members, and how? Which situations should be resolved by the team, and which should be addressed by outside parties such as course staff?\nDescribe courses of action that could be taken in cases where a team member is not as active as required, or if a team member feels uncomfortable with any conversations or work related to the project.\n\nAdditional Sections\nHere, we provide examples of additional sections that may be included in a code of conduct. These may not be relevant for all projects, but incorporating these sections may serve to create productive conversations for the team and class.\nProject Ethics\nDiscussions addressing potential ethical problems related to the specific project. For example, describe the ethical pitfalls of models or datasets used for a machine learning project, or the problems related to data privacy or misuse for a security project.\nThis section allows course staff to integrate more discussions and conversations about the social and ethical responsibilities of computing into class projects. It may be used as an assignment in and of itself for classes focused on generating more conversations about ethics (e.g., 6.806, 6.036, or 6.170).\nReal-World Examples\nAs part of the assignment, groups can read a short article or case study about a real-world code of conduct before writing their own; this would both ground the assignment in reality and encourage students to think more critically about the reasons codes of conduct have been encouraged, such as the following.\nHacking Technology, Hacking Communities: Codes of Conduct and Community Standards in Open Source by Christina Dunbar-Hester\nAfter Working at Google, I'll Never Let Myself Love a Job Again, https://www.nytimes.com/2021/04/07/opinion/google-job-harassment.html\nScope\nDefine the scope of the code of conduct.\nDoes it apply both within project spaces and public spaces when an individual is representing the project or its community? Does it only apply within online settings, or does it apply to in-person conversations?\n\nRecommendations for CoC Discussions\nConversations about creating a code of conduct may reveal conflicting values between team members, so it is important for teaching staff to maintain discussion guidelines. One resource from the University of Michigan outlines the following set of guidelines for planned, high-stakes conversations:\n\nIdentify a clear purpose\nEstablish ground rules\nProvide a common basis for understanding\nCreate a framework for the discussion that maintains focus and flow\nInclude everyone\nBe an active facilitator\nSummarize discussion and gather student feedback\n\nOne difficulty we perceive in following this template is the ability of course staff to be present for every team's CoC discussion, especially in classes with few TAs and 100 or more students. Without an active, trained facilitator, the risk of CoC conversations ending poorly increases, so course staff should plan accordingly. One solution is to remove a lecture or recitation during one week of the semester to set aside time for team meetings with a course instructor/TA.\n\nAnother template for facilitating CoC discussions is \"SPECS\", developed by the University of Washington's Center of Neurotechnology (CNT) Neuroethics Trust. It involves an individual survey of ethics topics and a facilitated group discussion, and can be adapted to CoC discussions by providing students with a guiding survey to answer before taking part in a facilitated conversation. During this discussion, students would discuss their survey answers and motivations under the supervision of a course staff member. Benefits of this method include that it saves time (students take the survey and reflect on it before meeting), and that discussion is more controlled because it centers on specific cases and questions presented by the survey (which, we assume, has been created by course staff).\n\nCourse Staff Considerations\nHow will defining and resolving disputes play out among students?\nRetributive justice approaches to conflict -- will students feel about how this approach influences interpersonal dynamics? Will this resolution approach create too much reliance upon authority figures (course staff) when resolving issues? How will staff choose to handle instances where unacceptable behavior is reported?\nOnce behavior has been reported to course staff, the issue is out of students' hands and their code of conduct \"enforcement\" is no longer in play; this removes student autonomy and input.\nWill staff work with students as a group to decide what happens when behavior is reported? (This would be taking a more \"restorative justice\" type of approach.)\nRestorative justice approaches encourage students to figure out how to resolve conflicts amongst themselves.\nHave students talk to each other about issues, such as a member not putting in enough work. Why has this been an issue? How can the team accommodate members with extenuating circumstances?\nMake decisions based on shared values (which may differ from those of other groups or the course staff). For example, in a situation where someone is not meeting a deadline due to personal reasons, perhaps the value of care is more important than the value of achievement.\nNote that students should still be encouraged to work with course staff when they feel they are out of their depth. We do not want them to feel they have to handle everything.\nHow will the process of developing a code of conduct influence students' thinking of what is necessary to address DEI issues in open-source communities.\nIf students think that developing a code of conduct is all that needs to be done, then codes of conduct simply become \"security theater,\" in which actions taken give the feeling of improving the situation, while accomplishing little or nothing else.\n\nConclusion\nBy encouraging students and instructors to incorporate a code of conduct into team-based projects within an undergraduate curriculum, our active learning proposal is intended to promote a more inclusive environment for student teams working on Github-based projects, as well as to increase mindfulness with respect to the ethical implications of the technology the students create. To develop a CoC, instructors may either use the default CoC template provided or create a template repo with their own CoC (the latter is useful when the structure of the desired CoC deviates from GitHub's provided one).\n\nWhen writing the document, there are several sections students must fill out, including: a team purpose, list of standards, list of unacceptable behaviors, and mechanisms for enforcement. While these form the bare minimum for a code of conduct, we provide additional sections students may find useful: a discussion of project ethics, which allows students to dive into the ethical and social issues that may result from the use of their final product; a deep dive into real-world examples when a CoC was (or was not) effective; and a broader scoping that covers which spaces and conversations the CoC should apply to.\n\nOnce the CoC is finally drafted out, several more discussions should take place. The first deals with CoC enforcement: students should decide whether to let figures of higher authority handle CoC violations or resolve conflict amongst themselves. After that, it'd be useful for students to recognize and discuss the limitations of their CoC -- namely, that it won't address larger diversity, equity, or inclusion issues within open-source communities, as its scope is limited to the single community it's designed for.\n\nCreating a code of conduct is just the first step toward affecting change and making open-source communities more welcoming and transparent. By nudging students and instructors toward these essential conversations about behavior, community standards, and the implications their work may have on others, our project hopes to take the first step toward creating more self-aware and inclusive technology, as well as more just technology development communities.\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\n\nRES.TLL-008 Social and Ethical Responsibilities of Computing (SERC)\nFall 2021\n\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms"
        },
        {
          "category": "Resource",
          "title": "Cyber Crisis Scenario",
          "type": "DOCX",
          "source_url": "https://ocw.mit.edu/courses/res-tll-008-social-and-ethical-responsibilities-of-computing-serc/mitres_tll008_17_46_cybercrisis2.docx",
          "content": "Cyber Crisis Scenario\n\nInstructions for Implementation\n\nBackground\n\nThe cyber crisis scenario was originally designed as an end-of-semester exercise for an MIT undergraduate political science course, 17.46: U.S. National Security Policy. The scenario was intended to provide students with an opportunity to apply core class concepts, which included an understanding of the interagency process, the various actors involved in making and implementing national security policy, the law of armed conflict/international law, and the changing character of international crises.\n\nAlthough the scenario was designed to meet the teaching objectives of a specific class, instructors could also implement the scenario in courses on U.S. Foreign Policy, emerging technology and international security, the politics of cybersecurity, or U.S.-China relations. Instructors should feel free to modify elements of the scenario in order to tailor it to their teaching objectives.\n\nDevelopment of the crisis scenario was generously supported by MIT Schwarzman College of Computing's Social and Ethical Responsibilities of Computing (SERC) program.\n\nThe scenario was designed by Erik Lin-Greenberg (Assistant Professor, MIT Department of Political Science) and Lily Tsai (PhD Candidate, MIT Department of Electrical Engineering and Computer Science).\n\nImplementation\n\nThe crisis scenario was implemented over two class sessions (each 80 minutes long).\n\nPre-class Preparation\n\nTwo days prior to the first of these classes, the instructor randomly assigned students into five teams of approximately six members each: 1) Department of State; 2) Department of Defense; 3) Department of Homeland Security; 4) Department of Justice; 5) Office of the Director of National Intelligence. Groups larger than ~7 may be more difficult to manage and quieter students may feel less inclined to participate.\n\nStudents were not assigned to specific roles within these teams (i.e., there was no designated Secretary of Defense, etc.)\n\nThe instructor emailed the first page of the crisis scenario packet (\"The Road to Crisis\") to students two days prior to the first crisis scenario class.\n\nClass Session 1\n\nWhen students arrived in class, they sat at tables organized by their team assignment (e.g., one table for State Department, one for Defense Department etc.).\n\nThe instructor then handed all students a copy of the second page of the crisis scenario packet (\"Move 1\")\n\nStudents had 30 minutes to review the tasks for their team and to address responses. At the end of the 30 minutes, each team briefed the National Security Advisor on their recommendations (The National Security Advisor was played by a PhD student, but a course instructor could take on this role).\n\nThe teaching team member playing the National Security Advisor followed up with each team's briefer, asking questions 1) to ensure: the recommendations aligned with the president's objectives introduced in the Road to Crisis; 2) to assess whether students had given thought about how their recommended actions might be perceived by international actors (NB: this was intended to tie back to concepts of perceptions/misperceptions and inadvertent escalation covered in the assigned reading materials earlier in the semester); and 3) to assess whether students representing different departments and agencies were coordinating with other teams (NB: this was to help emphasize the role of the interagency process).\n\nStudents were given a short break and the instructor then distributed the third sheet of crisis scenario packet (\"Move 2\").\n\nThe National Security Advisor told the students that several days had transpired since the briefing and that president had implemented some of their recommendations (The instructor can select any/all of the recommendations put forward by students at the end of Move 1).\n\nStudents then had 35 minutes to work through Move 2. The teaching team then repeated the briefing procedure from Move 1. In Move 2, however, there is less direct guidance about the tasks for each team, allowing students to think about the role their organization would likely play in an actual contingency. This was an intentional design choice to help reinforce student learning about the rules and responsibilities of different government agencies.\n\nClass Session 2\n\nDuring the final class session of the semester, students worked through Move 3 and discussed what they had learned from the crisis scenario.\n\nFollowing the format used in Class session 1, the instructor provided students with page 4 of the crisis scenario packet (\"Move 3\"). This move was scheduled for 40 minutes as it 1) included several significant events and 2) did not provide students with defined tasks. The additional time was intended to allow students to process the events and to think about their department's role in providing a response.\n\nAt the end of the 40 minute period, each team then briefed the National Security Advisor, who asked students questions similar to those outlined above.\n\nAfter all teams had briefed, the class ended the exercise and held a facilitated discussion about lessons learned from the crisis scenario (and more broadly, on the use of scenarios as a learning tool). Potential discussion questions are on the next page.\n\nPotential Discussion Questions:\n\nHow has technology changed the character of international crises?\n\nWhat did the scenario teach you about the role of the strategic implications of technology on international security?\n\nWhat key challenges did your teams face when dealing with new technology in the crisis scenario? (e.g., trust in AI analysis, attributing blame for cyber actions, etc.)\n\nWhat key international relations theories did the crisis scenario help reinforce?\n\nWhat, if anything, did the scenario teach you about U.S.-China Relations?\n\nWhat, if anything, did the scenario teach you about crisis decision-making?\n\nWas it challenging to coordinate with other departments/agencies during the simulation? Why or why not?\n\nDid China always respond in the way you thought they would?\n\nWhat types of actors had an outsized influence in the scenario? Put differently, what actors had a bigger influence than you anticipated (e.g., protestors, hackers)? What actors had less of an impact/played less of a role?\n\nAre scenarios a useful tool for studying international relations? Why or why not?\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\n\nRES.TLL-008 Social and Ethical Responsibilities of Computing (SERC)\nFall 2022\n\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms"
        },
        {
          "category": "Resource",
          "title": "Design Decisions",
          "type": "DOCX",
          "source_url": "https://ocw.mit.edu/courses/res-tll-008-social-and-ethical-responsibilities-of-computing-serc/b89d2884415283f892633d8ab97dd456_MITRESTLL-008F21-6170designReflection.docx",
          "content": "Design Decisions\n\n1. Insert your short and compelling design decision title phrase\n\nBegin your design decision discussion with introducing the decision and the rationale behind why you chose it but be sure to discuss any limitations this choice still has.\n\nAlternatives Considered: Then go on to listing alternative design choices you may have considered and discuss why you didn't choose them, comparing them to the design you did choose.\n\n2. Insert your short and compelling design decision title phrase\n\nBegin your design decision discussion with introducing the decision and the rationale behind why you chose it but be sure to discuss any limitations this choice still has.\n\nAlternatives Considered: Then go on to listing alternative design choices you may have considered and discuss why you didn't choose them, comparing them to the design you did choose.\n\n3. Insert your short and compelling design decision title phrase\n\nBegin your design decision discussion with introducing the decision and the rationale behind why you chose it but be sure to discuss any limitations this choice still has.\n\nAlternatives Considered: Then go on to listing alternative design choices you may have considered and discuss why you didn't choose them, comparing them to the design you did choose.\n\n4. Insert your short and compelling design decision title phrase\n\nBegin your design decision discussion with introducing the decision and the rationale behind why you chose it but be sure to discuss any limitations this choice still has.\n\nAlternatives Considered: Then go on to listing alternative design choices you may have considered and discuss why you didn't choose them, comparing them to the design you did choose.\n\nEthical / Social Reflection\n\nDescribe how conducting the A4 reflection informed your design process in this assignment. In particular, has your interface design changed as a result - how, or why not? Also, are there other social/ethical implications that you encountered when translating your wireframes into a working implementation?\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\n\nRES.TLL-008 Social and Ethical Responsibilities of Computing (SERC)\nFall 2021\n\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms"
        },
        {
          "category": "Resource",
          "title": "Ethical Implications",
          "type": "DOCX",
          "source_url": "https://ocw.mit.edu/courses/res-tll-008-social-and-ethical-responsibilities-of-computing-serc/d9fd91777252a2cc082f4ff820c42b6b_MITRESTLL-008F21-6170ethical.docx",
          "content": "Ethical Implications\n\nAnswer the following questions. In your answers, please distinguish which implications follow from your conceptual design and which follow from your UI design.\n\nDid you make cultural or other assumptions about your users that affect how they interact with Fritter?\n\nWould an effective use of design heuristics to maximize engagement with Fritter be manipulative?\n\nHow would you adjust your design if your only goal were to: get children addicted to Fritter? or make it hard for older people to use Fritter? or stop fake news spreading? or prevent harassment? How, if at all, do your answers to these questions inform how you would actually design Fritter?\n\nYou have the option to allow users to see which other users have upvoted a Freet. What forms of engagement between users (positive or negative) would be encouraged by allowing this?\n\nIn A3, we asked about stakeholders who aren't your immediate users. Identify a design choice you faced that would benefit or harm such a stakeholder, and explain how.\n\nWhat are the accessibility implications of your design for people with different abilities?\n\nOne of the heuristics is to \"speak the user's language.\" In retrospect, assuming you followed this, can you identify what kind of user you had in mind?\nMIT OpenCourseWare\nhttps://ocw.mit.edu\n\nRES.TLL-008 Social and Ethical Responsibilities of Computing (SERC)\nFall 2021\n\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms"
        },
        {
          "category": "Resource",
          "title": "Fritter User Test",
          "type": "DOCX",
          "source_url": "https://ocw.mit.edu/courses/res-tll-008-social-and-ethical-responsibilities-of-computing-serc/16a11f2babb9f1c77c67da33a4a14054_MITRESTLL-008F21-6170user.docx",
          "content": "Fritter User Test\n\nSpecify Tasks for the User completed for your user test\nTask 1: User upvotes another user's freet, then removes their upvote\nTask 2: User follows another user, then checks their feed\n....\nTask n: User refreets another user's freet\n\nSummary of Observations\n\nDiscuss your observations you had as you observed your user go through the tasks you provided them.\n\nChanges in Responses to UI\n\nNote any changes you will make to your UI in response to what you observed from your user test.\nMIT OpenCourseWare\nhttps://ocw.mit.edu\n\nRES.TLL-008 Social and Ethical Responsibilities of Computing (SERC)\nFall 2021\n\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms"
        },
        {
          "category": "Resource",
          "title": "Heuristic Evaluation",
          "type": "DOCX",
          "source_url": "https://ocw.mit.edu/courses/res-tll-008-social-and-ethical-responsibilities-of-computing-serc/b91f260be72dba5c48c53d9bab5b5f61_MITRES-TLL-008F21-6170Heuristic.docx",
          "content": "Heuristic Evaluation\n\nFor each heuristic, you should cite one example in your wireframe either illustrating how the heuristic suggests an improvement, or pointing to a design decision you made that supports the heuristic.\n\nFitt's Law\n\nSpeak the User's Language\n\nConsistent Naming & Icons\n\nInformation Scent\n\nFollow Conventions\n\nShow Location & Structure\n\nAccelerators\n\nKeep Paths Short\n\nUndo & Cancel\n\nPerceptual Fusion\n\nGestalt Principle of Grouping\n\nRecognition vs. Recall\n\nAnticipation & Context\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\n\nRES.TLL-008 Social and Ethical Responsibilities of Computing (SERC)\nFall 2021\n\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms"
        },
        {
          "category": "Resource",
          "title": "Module: Big Data and Personal Privacy",
          "type": "DOCX",
          "source_url": "https://ocw.mit.edu/courses/res-tll-008-social-and-ethical-responsibilities-of-computing-serc/8283d95f3ec08827137334de3d3959ca_MITRES-TLL008F21-STS-012module.docx",
          "content": "Module: Big Data and Personal Privacy\n\nReadings:\n\nSarah Valentine, Impoverished Algorithms: Misguided Governments, Flawed Technologies, and Social Control. (2019). 46 Fordham Urb. L.J. 364.\n\nBoyd, Danah, and Kate Crawford. 2012. \"Critical Questions for Big Data.\" Information, Communication & Society 15(5): 662-679.\n\nAt home exercise:\n(Voluntary)\n\nLearn more about your data rights.\nhttps://www.dataprotection.ie/en/individuals/know-your-rights/right-access-information\nhttps://tapmydata.com/features/#superpower\nAccess your data from three websites/services you frequently use (Examples: Facebook, Twitter, Instagram, Google etc.)\nTip: Tapmydata is an application that makes it easy to send these requests. (Remember however that after a certain point in the process, they might ask you to use your data in a particular way.)\nWrite and post a short 200-word reflection on what you found and whether what you found surprised you. Think reflection should incorporate insights from the two readings for this week, particularly the sections on data triangulation and commercialization.\nRead your classmates posts.\n\nIn class:\n\nDiscussion of the key points of the articles and of the student responses.\n\nAims:\n\nTo find overlaps and differences in the experience of students learning about their right to privacy\nTo discuss whether they believe existing rights to be adequate\nTo examine whether current ethical standards (such as those instituted by the GDPR) sufficiently protect their rights (as they exist or as they believe should exist).\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\n\nRES.TLL-008 Social and Ethical Responsibilities of Computing (SERC)\nFall 2021\n\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms"
        },
        {
          "category": "Resource",
          "title": "RES.TLL-008 Social and Ethical Responsibilities of Computing (SERC), 6.036 Lab 1.pdf",
          "type": "PDF",
          "source_url": "https://ocw.mit.edu/courses/res-tll-008-social-and-ethical-responsibilities-of-computing-serc/a1509590b6e7e45cac07a269b11b3d75_RES-TLL008F21-6036_lab1.pdf",
          "content": "6.036 Spring 2021\nLab -- Separators\nInstructions\nThis lab is focused on getting you started in 6.036 and introducing you to some of the kinds of problems we will be thinking\nabout in this class.\nFor this first week only, the lab includes introductions by an instructor at the start of the lab section.\nIn 6.036 a large part of the learning happens by discussing lab questions with partners. You will be assigned to a breakout\nroom after introductions. Once you are in your breakout rooms, please complete this group self-partnering question with\nother people in your breakout room.\nGroup information\nCreate Your Group\nOnce you and your partner(s) are in a breakout room, you need to create a group.\nInstructions:\n(1) One of you should click here to create a group.\n(2) Everyone else should then enter the given new group name (including trailing numbers) into the box below\n(and press enter when done).\nName of group to join:\nReload this page anytime to refresh your group status (and to get a delete button, if you want to remove\nyourself from a group you've joined).\nGroups are limited to 3 persons max each, so that checkoff discussions can be inclusive.\nYou are not currently in any group\nThis 'Group Information' box will be similar to what you will see at the top of future labs as well.\n1/10\n\n6.036 Spring 2021\nNote: Write all your answers down somewhere you can share them with a staff member. Be prepared to discuss your\nanswers!\nCheckoff 1:\nCheck-in with a staff member, to confirm your attendance and that the setup is working for you.\nAsk for Help\nAsk for Checkoff\nNow let's get started!\n1) Finding Good Models\nMachine Learning is about using data that represent examples of a phenomenon in the world (such as how individual\nhumans respond to a medical treatment), in order to make predictions about new examples (how different humans will\nrespond to the same treatment).\nIn order to make predictions, however we must make the assumption that there is an underlying structure in the data and\nthat this structure extends to new, unseen data as well. But how can we know whether a prediction rule we have identified\nthat agrees with previous data, will be accurate on future data?\nIn this lab, we will practice making predictions from data and explore conceptual and more technical strategies for\nevaluating the effectiveness of prediction rules.\n1.1) Power in Numbers\nAcme Apparel is a company that has data from previous catalogs indicating which past customers ordered something from\nthe catalog and they are trying to decide which customers to mail catalogs to (yes, that's still a thing!) this holiday season.\nEach customer is represented in terms of two features (they could represent anything, such as age, address, previous buying\nhistory, etc.), so we can plot a point in 2D coordinates representing each person and label it according to whether they\nbought something last time: positive (shown as a green plus sign) and negative (shown as a red minus sign). We want to\npredict whether a brand new customer, characterized in terms of these same two features, will make a purchase.\nOur historical data looks like this:\nNote: Here we use x1 and x2 as axes instead of the typical x, y axis because as you'll see later, we use 'y' to denote\nsomething else!\n2/10\n\n6.036 Spring 2021\n1.1.1)\nSuppose there are 4 people who have not recieved a catalog. We collect information from them and represent them in the\nimage below using the four points marked as purple numbers. Which people do you predict will buy something? Why or why\nnot?\n1.1.2)\nAcme's marketing department studied the data and came up with a hypothesis about which potential customers will make a\npurchase, which is illustrated by the blue line below: points on one side are positive whereas points on the other side are\nnegative.\nhttps://introml.odl.mit.edu/cat-soop/6.036/labs/lab01\n3/10\n\n5/19/2021\n6.036 Spring 2021\nHow do you think this hypothesis will perform on future customers?\n1.1.3)\nThe Acme sales department comes up with a different hypothesis, shown in black below.\nHow do you think the black hypothesis will perform? If you had to choose between the blue and the black hypotheses, which\nwould you choose to use for future predictions? Why?\n1.1.4)\nMeanwhile, at Acme Apparel, the marketing department won the argument and so they mail out catalogs based on the first,\nsimple (blue) linear hypotheses. After the holiday rush, they make a plot of their new data and see this:\n4/10\n\n6.036 Spring 2021\nMarketing department (linear) hypothesis with both old and new data\nSales department (non-linear) hypothesis with both old and new data\n5/10\n\n6.036 Spring 2021\nDid using the simple,linear hypothesis to mail out catalogs result in a good outcome? Why or why not?\n1.1.5)\nWhich hypothesis should Acme use next holiday season? What might they have done differently to avoid mailing so many\ncatalogs to uninterested customers?\n1.1.6)\nThe engineering department decides they want to try their hand at developing a new hypothesis. The department collects\nboth new and old data from sales and marketing and divides it at random into two separate data sets, called A and B. They\nuse data set A to develop a new hypothesis and don't use data set B to develop the hypothesis.\nData set A (training) has 10,000 data points. Data set B (test) has 5,000 data points.\nThe engineers' hypothesis, when applied to data set A (training), makes wrong predictions on 5% of the data. When that\nsame hypothesis is applied to data set B (test set), it makes wrong predictions 10% of the time. What would you estimate\nthe error rate of applying this hypothesis to brand new data (neither A nor B) to be?\n1.1.7)\nFor the same setup as described above, how well do you think your hypothesis will perform in the real world if your data set\nB had 5 data points, versus if it had 5,000 data points?\n1.1.8)\nFor the same setup as described above, how well do you think your hypothesis will perform in the real world if your data set\nA had 10 points, versus if it had 10,000 points? Why? Note that the same setup as described above applies here.\n1.2) Comparing Apples to Oranges\nAcme Apparel (AA) is looking to expand to a new demographic (engineering college students), so they decide to use one of\nthe hypotheses their departments have developed (using data from existing AA college student customers) to determine\n6/10\n\n6.036 Spring 2021\nwhich college students to send their catalog to. AA also hires some consultants to gather some college student purchasing\npatterns data from a rival company specializing in engineering-themed apparel, Zenith Zapatos (ZZ).\n1.2.1)\nThey use a hypothesis developed by the engineering department which has a 5% error rate on the data set A and had 10%\nerror rate on data set B of existing Acme college student customers. They apply it to the college student customer data\nfrom ZZ and find it has a 35% error rate. What could account for this problem?\n1.2.2)\nHere is some actual data from AA current college student customers (left) and ZZ college-student customers (right). The\nengineering department finds another hypothesis, shown as the blue line below, that has the same error rate on both the\nAA data and the ZZ data. What do you think about this hypothesis? Should we use it for both populations? If not, what\nhypothesis or hypotheses would be better and why?\nCheckoff 2:\nHave a check-off conversation with a staff member, to discuss your answers until this point! While you're\nwaiting, please continue working on the lab.\nAsk for Help\nAsk for Checkoff\n2) A More Rigorous Evaluation\nAA and ZZ have merged to form A2Z and hired you as their chief data scientist! Luckily they have found a source of a huge\namount of data. Now, your job is to come up with some procedures for predicting how well classifiers you come up with will\nperform.\nNote the following notation and definitions, used throughout this problem:\n7/10\n\n6.036 Spring 2021\nA generator G is a function that takes as input n, the number of samples desired, and returns a (X , y) pair where X is\na d by n array of randomly sampled data points and y is a 1 by n array of their corresponding labels {+1, -1}.\ni\nA training dataset Dtrain is a set of labeled samples X , y generated by a generator G, where x represents the\ni\ni\nfeatures of an object to be classified (vector of real and/or discrete values), and y represents the label of x . (You can\nthink of i as the index for point xi.)\n2.1) Evaluating a classifier\nImagine that you have a generator G that pulls from a finite dataset of millions of points.\nLet's assume that Dtrain is one such output of the generator G.\nConsider the situation in which you have run a machine learning algorithm on some training dataset Dtrain, and it has\nreturned to you a specific classifier h. Your job is to design (but not implement yet!) a procedure for evaluating h's\neffectiveness as a classifier. (Want more on classifiers? Check the the notes on Linear Classifiers.)\nAssume we have a eval_classifier function that takes a classifier h, dataset D - a tuple of data and labels: (X, y) - and\nreturns the percentage of correctly classified data points as a decimal between 0 and 1. We'll package it as follows:\ndef eval_classifier(h, D):\ntest_X, test_y = D\nreturn score(h, test_X, test_y)\n2.1.1)\nPercy Eptron suggests reusing the training data to assess h:\neval_classifier(h, D_train)\nExplain why Percy's strategy might not be so good.\n2.1.2)\nNow write down a better approach for evaluating h (which may use h, G) and create a score function for h. The syntax is not\nimportant, but do write something down. Hint: How can you incorporate G?\n2.1.3)\nExplain why your method might be more desirable than Percy's. What problem does it fix?\n2.1.4)\n′\nHow would your method from 2.1.2 score the classifier h on a different dataset\nthat was generated from a different\nDtest\nunderlying distribution than Dtrain (i.e generated from a different generator)? Would the score be better, worse, or about\nthe same? For example, if we're trying to predict whether or not a certain medication works, how well would a classifier\ntrained on an adult population score on a population of children?\n8/10\n\n6.036 Spring 2021\nCheck and submit this box once you've finished this section:\nI've finished this section.\nSave\nSubmit\nClear Answer\nAsk for Help\nAs staff, you are always allowed to submit. If you were a student, you would see the following:\nYou have infinitely many submissions remaining.\nSolution:\nI've finished this section.\nExplanation:\nGood job! Keep going!\n3) Good Hypotheses: Beyond Accuracies\nSo far in this lab we have discussed the difficulties of evaluating a model and defined a slightly more rigorous process for\nevaluation. In all of the above cases, however, we made a few critical assumptions.\nWe assumed that we would always know with complete certainty whether a model made a correct or incorrect prediction on\nunobserved data. We also used accuracy as the ultimate quantitative metric of \"goodness\" of a model (albeit, accuracies on\ndifferent datasets). In the real world, however, there are other metrics we should care about beyond just accuracy, such as\nfairness and whether the model's decisions have any ethical implications that need to be considered while evaluating the\nmodel's performance. Thus, we must be careful in how we define the \"goodness\" of a particular model. To illustrate this,\nlet's look at a fictional case study.\nTo Loan or Not to Loan, that is the question\nFeirna Sinemel was recently hired to be director at a mortgage lender company, Loan Investing Team (LIT) Corporation. LIT\nwants to be competitive with other industry leaders in the mortgage lending space, but has had difficulty scaling due to the\nlimited speed at which humans can manually review loan applications.\nThe company is therefore interested in developing a machine learning model that can be used to determine whether or not\nto give someone a mortgage. They hope to use the model as an initial screening for the applications and reserve manual\nreviewing only for promising applicants.\nFeirna knows you are learning about machine learning and reaches out to seek your advice on how to start designing a\nmodel. She suggests, however, that you approach this role with caution and reminds you that the mortgage business has a\nlengthy history of systemic racism and sexism , including a form of discrimination known as \"redlining\", which continues to\nthis day.\nThe loan application assessment process is about assessing the likelihood that a person will be able to repay the loan in the\ngiven period of time.\n3.1)\n9/10\n\n6.036 Spring 2021\nOne of the first things to choose when developing a machine learning model is what inputs will be provided to the model\nand what the implications may be of including a particular input. For example, you may wish to include a person's current\nsalary. Presumably, the company is more willing to give loans to those who have well-paying jobs. An implication of including\na feature like \"salary\", however, is that historically certain demographic groups (ex. women, minorities, immigrants) have\nlower salaries, which may skew results of the model.\nOther example inputs may include work history and loan repayment/approval history. What are the implications for\nincluding work history and loan history as inputs to the model? What are other inputs you may want to use for the model\nand what are the implications of using those inputs?\n3.2)\nIn developing your model, would you opt to include sensitive inputs, like race or gender identity? What are the reasons you\nmight do so, and what are the reasons you might not?\n3.3)\nWhat are the differences (if any) between using a computation model and having a human make these decisions? What are\nthe benefits and drawbacks to each approach?\nFor next week's lab, we will delve deeper into this scenario and think about how to handle fairness in such situations.\nCheckoff 3:\nHave a check-off conversation with a staff member, to discuss your answers, and make sure you're setup for the\nrest of the week.\nAsk for Help\nAsk for Checkoff\n10/10\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\nRES.TLL-008 Social and Ethical Responsibilities of Computing (SERC)\nFall 2021\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms"
        },
        {
          "category": "Resource",
          "title": "RES.TLL-008 Social and Ethical Responsibilities of Computing (SERC), 6.036 Lab 2.pdf",
          "type": "PDF",
          "source_url": "https://ocw.mit.edu/courses/res-tll-008-social-and-ethical-responsibilities-of-computing-serc/e9a2abd7df63d1896e4c692c5b250f07_RES-TLL008F21-6036_lab2.pdf",
          "content": "6.036 Spring 2021\nLab -- Features; Train / Test\nInstructions\n1. If you haven't already, please create a group using the box below.\n2. Work through the lab assignment with your group, write your answers on paper, and ask questions while you're\nworking! Put yourself in the help queue to do so.\n3. When you're finished, put yourself in the queue for a checkoff. Only 1 person in the group needs to request the\ncheckoff (creating the group adds you all to the system together!)\n4. You should try to finish and get your checkoff done before the lab ends. If you don't finish, you can get the checkoff\nduring office hours. The lab checkoff is due as specified on the top of the page.\n5. After your checkoff, you're welcome to leave or stay to work on the homework.\nGroup information\nCreate Your Group\nOnce you and your partner(s) are in a breakout room, you need to create a group.\nInstructions:\n(1) One of you should click here to create a group.\n(2) Everyone else should then enter the given new group name (including trailing numbers) into the box below\n(and press enter when done).\nName of group to join:\nReload this page anytime to refresh your group status (and to get a delete button, if you want to remove\nyourself from a group you've joined).\nGroups are limited to 3 persons max each, so that checkoff discussions can be inclusive.\nYou are not currently in any group\n1/9\n\n6.036 Spring 2021\nLab 2\nWelcome to Lab 2, where will will discuss the evaluation of learning algorithms, and explore how to represent input features\nfor the model. We intend for you to begin thinking about these concepts, but please do not stress if you don't understand\neverything perfectly by the end. Use the lab session to build your understanding and clear up confusion, and explore the\ndifferent ways in which we can represent the features we input to the model. Come to office hours if you want to discuss lab\ntopics further. The staff are here to help you learn!\n1) Evaluating a learning algorithm\nNote the following notation and definitions, used in the problem:\nA generator G is a function that draws a random subset from a very large data set.\n(i)\nA training dataset Dtrain is a set of labeled samples X , y generated by a generator G, where x\nrepresents the\n(i)\n(i)\nfeatures of an object to be classified (vector of real and/or discrete values), and y\nrepresents the label of x . (You\n(i)\ncan think of i as the index for point x .)\nA binary classifier h is a function that takes a data point x (a d × 1 vector) as input and returns +1 or -1 as output.\nIn last week's lab, we explored the question of what makes a good hypothesis and the challenges involved with evaluating a\nhypothesis. This week, we explore how to evaluate the learning algorithms, which are used to generate hypotheses.\nA learning algorithm is a function L that takes as input the data set Dtrain as training data and returns a hypothesis (in this\nparticular question, our hypothesis is a classifier) h.\n1.1)\nWhat is the difference between a classifier and a learning algorithm? (Stuck? Check the notes on Linear Classifiers).\n1.2)\nLet Dtrain1 , Dtrain2 be different training datasets generated by G1, G2, respectively. Would running the learning algorithm L\non Dtrain1 and Dtrain2 produce the same classifier? In other words, would h1 = L(Dtrain1) be the same classifier as h2 =\nL(Dtrain2 )?\nWhat if Dtrain1 , Dtrain2 were generated by the same generator?\n1.3)\nNow, consider a situation in which someone is trying to sell you a new learning algorithm, and you want to know how good it\nis. There is an interesting theorem called the No Free Lunch Theorem, that says that without any assumptions about your\ndata there is no learning algorithm that, for all data sources, is better than every other learning algorithm. So, you'll need to\nassess the learning algorithm's performance in the context of a particular data source.\nAssume that you have a generator of labeled data, G, which will be suitable for your application. The learning algorithm's\nperformance on G-generated data will be a good predictor of the learning algorithm's performance on data from your\napplication. (You can review how to evaluate learning algorithms in the notes on Linear Classifiers.\nLinnea Separatoria wants to evaluate a learning algorithm, and suggests the following procedure:\n2/9\n\n6.036 Spring 2021\ndef eval_learning_alg(L, G, n):\n# draw a set of n training data points (points and labels)\ntrain_X, train_y = G(n)\n# run L\nh = L(train_X, train_y)\n# evaluate using your classifier scoring procedure, on some new labeled data\ntest_data = G(n) # draw new set of test data\nreturn eval_classifier(h, test_data)\nHow well or not well does Linnea's strategy evaluate the learning algorithm?\n1.4)\nNext, Linnea decides to generate one classifier h but evaluate that classifier with multiple (10) test sets in her\neval_learning_alg . More specifically, Linnea changed her code above into:\ndef eval_learning_alg(L, G, n):\n# draw a set of n training data points (points and labels)\ntrain_X, train_y = G(n)\n# run L\nh = L(train_X, train_y)\n# evaluate using your classifier scoring procedure, on some new labeled data\nscore = 0\nfor i in range(10):\ntest_data = G(n) # draw new set of test data\nscore += eval_classifier(h, test_data)\nreturn score/10\nIs Linnea's strategy better now? Explain why or why not.\nShow Hint\n1.5)\nNow design a better procedure, better_eval_learning_alg for evaluating L, that takes L, G and n and returns a score.\nWhat would the output score measure? What are the best and worst score values? Why is your method more desirable than\nLinnea's?\n1.6)\nIn reality, it's almost never possible to have a generator of all the data you want. In fact, in some domains, data is very\nexpensive to collect, and so, you are given a fixed, small set of samples. Now assume that you only have 100 labeled data\npoints to use for training and testing/evaluation.\nHow would you implement better_eval_learning_alg without G but instead with your 100 labeled data?\n3/9\n\n6.036 Spring 2021\nCheck and submit this box once you've finished this section:\nI've finished this section.\nSave\nSubmit\nView Answer\nAsk for Help\nAs staff, you are always allowed to submit. If you were a student, you would see the following:\nYou have infinitely many submissions remaining.\n2) Features Engineering\nThe performance of our hypotheses on the real world depends heavily on how we represent our data. In the next few\nquestions we will introduce you to several ways of representing data (from standard numerical data to text data and image\ndata!).\nPlease make sure you read the notes on Feature Representation for this lab.\n2.1) Feature engineering for car data\nOpen and view auto-mpg.tsv . You can also download a local version through the google sheets link or here. This file is in a\ncommon format, called \"tab separated values\". In the first line you will find the names of the columns. Each row is a data\npoint; the first column is the label for that point (1 or -1).\nThe original data came from the StatLib library from CMU. It was modified by Ross Quinlan to remove entries with unknown\nmpg (miles per gallon). We have modified it further by removing six entries with unknown horsepower. We have also\nbinarized the mpg column to turn this into a classification problem (later in the term, we will look at predicting continuous\nvalues, i.e. regression problems). Here are the nine columns in the dataset:\n1. mpg:\ncontinuous (modified by us to be -1 for mpg < 23, 1 for others)\n2. cylinders:\nmulti-valued discrete\n3. displacement:\ncontinuous\n4. horsepower:\ncontinuous\n5. weight:\ncontinuous\n6. acceleration:\ncontinuous\n7. model year:\nmulti-valued discrete\n8. origin:\nmulti-valued discrete\n9. car name:\nstring (many values)\nThere are 392 entries in the dataset, evenly split between positive and negative labels. The field names should be self-\nexplanatory except possibly displacement and origin . You can read about displacement here; in this data set\ndisplacement is in cubic inches. origin is 1=USA, 2=Europe, 3=Asia. We'll ignore car name in this assignment.\nA new student, Hiper Playne, suggests that we should just use all the numeric features in their raw form to predict whether\nthe car will get good or bad gas mileage. He will use the Perceptron algorithm to learn the classifier. Once he trains the\nmodel on this dataset, he wants to predict whether cars in 2021 will get good gas mileage.\n2.1.1)\nWhich of the following is a problem or may lead to problems when using the raw features directly?\n4/9\n\n6.036 Spring 2021\nBecause weight values and cylinders values are on different scales, perceptron might take many\niterations\ncylinders is a multi-valued discrete number feature\norigin is a multi-valued discrete number feature\nThere are too many features and the classifier will overfit\nmodel year is in the 70s, so a classifier based on this data might not perform well in 2021\nSave\nSubmit\nView Answer\nAsk for Help\nAs staff, you are always allowed to submit. If you were a student, you would see the following:\nYou have infinitely many submissions remaining.\n2.1.2)\nFor each feature from the following:\n[cylinders, displacement, horsepower, weight, acceleration, model_year, origin]\nindicate how you can represent it so as to make classification easier and get good generalization on unseen data, by\nchoosing one of:\n'drop' - leave the feature out,\n'raw' - use values as they are,\n'standard' - standardize values by subtracting out average value and dividing by standard deviation. Check the notes\non Feature Representation (Section: Hand-constructing features for real domains) for more details\n'one-hot' - use a one-hot encoding.\nThere could be multiple answers that make sense for each feature; please mention the tradeoffs between each answer. Be\nprepared to justify your choices (ex. why standardize instead of using raw features? why use one-hot encoding?)\nCheckoff 1:\nHave a check-off conversation with a staff member, to explain your answers.\nAsk for Help\nAsk for Checkoff\n2.2) Feature engineering for food reviews (text data)\nIn this part of the assignment, we are going to explore ways of defining features for textual data.\nOpen and view reviews.tsv . This file is in \"tab separated values\" (tsv) format, and it consists of 10,000 fine food reviews\nfrom Amazon. You can find additional information here. We will be focusing on the text field and use it to predict the\nsentiment field (-1 or 1).\nWe will convert review texts into fixed-length feature vectors using a bag-of-words (BOW) approach. We start by compiling\nall the words that appear in a training set of reviews into a list of d unique words.\n2.2.1)\n5/9\n\n6.036 Spring 2021\nFor instance, consider two simple documents \"Mary is selling apples.\" and \"Tom is buying apples to eat\". If we had only these\ntwo sentences in our training set of reviews, which option corresponds to the list of unique words that we build when using\nthe bag-of-words approach discussed above?\nSave\nSubmit\nView Answer\nAsk for Help\nAs staff, you are always allowed to submit. If you were a student, you would see the following:\nYou have infinitely many submissions remaining.\n(Mary, is, selling, apples, T om, is, buying, apples, to, eat)\n(Mary, is, selling, apples, T om, buying, to, eat)\n(Mary, is, selling, red, apples, T om, buying, blue, to, eat)\n2.2.2)\nith\nWe can now transform each of the reviews into a feature vector of length d by setting the\ncoordinate of the feature\nith\nvector to 1 if the\nword in the list of unique words appears in the review or 0 if it does not. Hence, how would we\nrepresent the sentence \"Tom is buying apples to eat\" as a feature vector using the bag-of-words approach and the list of\nunique words we found above?\nSave\nSubmit\nView Answer\nAsk for Help\nAs staff, you are always allowed to submit. If you were a student, you would see the following:\nYou have infinitely many submissions remaining.\n(1, 1, 0, 0, 1, 1, 1, 1)\n(0, 1, 0, 1, 1, 0, 1, 1)\n(0, 1, 0, 1, 1, 1, 1, 1)\n2.2.3)\nTalk with your group about the weaknesses of the bag-of-words approach seen above. For instance, how would you\ninterpret the feature vector (1, 1, 1, 1, 1, 0, 1, 0)?\n2.2.4)\nWords like \"the\", \"to\", \"a\", \"and\" and so on occur with very high frequency in English sentences. Do they help in detecting the\nsentiment in a review? Talk to your group about how to deal with these words, when building your list of unique words,\nusing the bag-of-words approach.\n2.3) Image features\nWe will be exploring in the homework how the perceptron algorithm might be applied to classify images of handwritten\ndigits, like those from a well-known (\"MNIST\") dataset, with items like these:\n6/9\n\n6.036 Spring 2021\nFor today, assume we only have images of digits '1' and '3' and we would like to find a linear classifier which can classify\nthese images correctly, giving label +1 for the digit '1' and label -1 for the digit '3'.\nFor simplicity, assume each image provided is a 5-pixel wide and 5-pixel tall (5x5) black and white image.\n2.3.1)\nAssume images from the MNIST dataset are provided to you as 5x5 matrices. An image is represented as a matrix, say A,\nith\njth\nith\njth\nwith the entry of the\nrow and\ncolumn (Ai,j ) representing the image pixel found at the\nrow and\ncolumn of\npixels. Black pixels have value 0 while white pixels have value 1 in the matrix.\nWith the help of your group, write down the matrix corresponding to the image shown here:\n2.3.2)\nImagine we want to use the perceptron algorithm to perform the task of distinguishing between images of digits '1' and '3'.\nEach image is a data point, which we need in vector form, to feed to the perceptron algorithm. One approach is to take the\ntwo-dimensional matrix representation of an image and concatenate the rows one after the other, into a one-dimensional\nvector of the form [A1,1 , A1,2 , A1,3 , A1,4 , A1,5 , A2,1 , A2,2 , ..., A5,5 ]\nFor the image shown above, what will be the last\nentries of the one-dimensional vector representing that\nimage? Reminder that 0 represents black and 1 represents white. Enter a python list of length\nfor your\nanswer:\nSave\nSubmit\nView Answer\nAsk for Help\nAs staff, you are always allowed to submit. If you were a student, you would see the following:\nYou have infinitely many submissions remaining.\n2.3.3)\nHow well would you expect the perceptron algorithm to work on classifying images if you simply represented them as 1D\nvectors (if you do not reliably know the width and length of the image)?\n2.3.4)\n7/9\n\n6.036 Spring 2021\nWhat approaches might you suggest to extract more meaningful features from the images, such that the perceptron\nalgorithm might do a good job of classification? (Hint: What makes the image of the digit '1' different compared to the\nimage of the digit '3'?)\nDiscuss these questions with your group, and write down your answers. Be prepared to discuss these with the staff for your\nlab checkoff.\nIn the homework for this week we will investigate these datasets in more detail. And later in the semester, we'll explore\nother algorithms, including neural networks and convolutional neural networks, which can essentially do feature extraction\non their own.\n3) Fairness in ML\nLast week, Feirna Sinamel introduced the problem of using machine learning to predict whether or not to give someone a\nloan. We saw how even the seemingly simple decision of choosing input features has several ethical and societal\nimplications (and having done this lab, you can probably imagine that the way we represent features also has ethical\nimplications).\nAfter we have thoroughly thought through the implications of certain technical decisions (like, choosing features and their\nrepresentation), we will need some way of evaluating the impact of our choices (presumably based on the performance of\nthe model).\nSo this raises the question -- how do we evaluate the fairness of a model?\nTo get started thinking about this, let's take a look at some past data that Feirna gave you, and for the sake of concreteness,\nlet's focus specifically on \"fairness\" across genders.\nYou notice that only 30% of the applicants for loan applications come from women, and of the applications that get\napproved, 10% are from women. So, you ask Feirna how gender has been used in the application assessment process in the\npast. She finds that though applications do contain information on gender, the application readers cannot view these fields.\nThis brings up the interesting question: What would a \"fair\" outcome by an application screening model look like when it\ncomes to the gender distribution? More generally, what does it mean for a model to be \"fair\"?\nLIT Company's Definition of Fairness (Group Unaware): The company believes that a fair process and, therefore, a fair\nmodel, would not account for gender or race at all.\nAdvocacy Group's Definition (Demographic parity): An advocacy group believes that a model is fair if the distribution of\noutcomes for each demographic, gender, or other subgroup is the same among those that applied and those that were\naccepted. For example, in the example above, 30% of the applicants for loan applications come from women. In the\ndemographic parity definition of fairness, this means 30% of the approved loan applications should come from women.\nNote: The list of definitions of fairness mentioned above is not exhaustive (scroll down for some more examples).\nNote also that questions about a model's \"fairness\" are not strictly questions about statistical distribution of the\nmodel's outputs. Questions of fairness may also concern assumptions about the model's data. This also brings up the\nquestion of whether the application of machine learning itself is discriminatory or socially unjust ( See here for some\ninteresting reading on this).\n3.1)\nWhat are the merits and drawbacks of these particular definitions. What situations do those definitions account for? What\ndo they not account for?\n8/9\n\n6.036 Spring 2021\n3.2)\nHow might we implement and evaluate these two fairness standards?\n3.3)\nNow of course, gender discrimination is not the only form of discrimination, and one could argue that race-based\ndiscrimination is far more prevalent in loan approval processes. In general, as machine learning engineers, how can we make\nsure fairness (across all different demographic groups) is considered when we formulate and test hypotheses?\nWhile you're waiting for the checkoff, some further food for thought...\nIf you want to learn more about ML fairness in loan applications, check out this paper (Black Loans Matter) that discusses\nthis exact problem! If you're interested in more definitions of fairness in ML, here is an article from Google about 5 common\ndefinitions (including the two discussed above).\nFinally many researchers have identified major ethical limitations in attempts to formalize fairness in ML, arguing that those\nattempts overlook deeper patterns of inequality and injustice. See this article in The Lancet for limitations of algorithmic\nfairness in healthcare. For longer technical articles offering different positions on this debate, see here and here.\nCheckoff 2:\nHave a check-off conversation with a staff member, to explain your answers.\nAsk for Help\nAsk for Checkoff\n9/9\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\nRES.TLL-008 Social and Ethical Responsibilities of Computing (SERC)\nFall 2021\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms"
        },
        {
          "category": "Resource",
          "title": "RES.TLL-008 Social and Ethical Responsibilities of Computing (SERC), 6.036 Lab 5.pdf",
          "type": "PDF",
          "source_url": "https://ocw.mit.edu/courses/res-tll-008-social-and-ethical-responsibilities-of-computing-serc/5ae324ceb0dffba0c6637b0c378c3e0e_RES-TLL008F21-6036_lab5.pdf",
          "content": "6.036 Spring 2021\nLab -- Neural Networks\nGroup information\nCreate Your Group\nOnce you and your partner(s) are in a breakout room, you need to create a group.\nInstructions:\n(1) One of you should click here to create a group.\n(2) Everyone else should then enter the given new group name (including trailing numbers) into the box below\n(and press enter when done).\nName of group to join:\nReload this page anytime to refresh your group status (and to get a delete button, if you want to remove\nyourself from a group you've joined).\nGroups are limited to 3 persons max each, so that checkoff discussions can be inclusive.\nYou are not currently in any group\nNeural Networks\nFor this lab, you will need to understand the material in the notes on Neural Networks up through and including section 6 on\nloss functions.\n1) Exploring neural networks\nNotes on the functions in the code boxes below:\nThe initialization of weights in a neural network is random, so subsequent runs might produce different results.\niters indicates how many single steps of SGD to run, each using one training point.\nPay attention to the decision boundaries, shown in the answers after you run the code. Also note that the accuracy of\nthe network on the training data is printed above the graph.\n1/8\n\n6.036 Spring 2021\n1.1) Simple separable data set\nHere's a very simple data set.\nX = np.array([[2, 3, 9, 12],\n[5, 2, 6, 5]])\nY = np.array([[1, 0, 1, 0]])\nThe code below runs a very simple neural network composed of a single sigmoid unit with two inputs, using negative log\nlikelihood (NLL) loss:\nThe function sigmoid_nn in the code box below plots the classifier found after training for the specified number of\niterations with the specified \"learning rate\" (step size). The classifier predicts label +1 if the output of the sigmoid, a, is\ngreater than 0.5 and label 0 otherwise -- remember that the range of the sigmoid function is (0, 1).\n1.1.A) What is the shape of the separator produced by this network? Explain.\n1.1.B) Are you able to get relatively consistent 100% accuracy with some combination of iters and learning rate lr ?\nRun Code\nSave\nSubmit\nView Answer\nAsk for Help\nAs staff, you are always allowed to submit. If you were a student, you would see the following:\nYou have infinitely many submissions remaining.\ndef run():\nreturn sigmoid_nn(iters=100, lr=0.05)\n1.2) Not-XOR\nThe XOR dataset is a classic example showing the need for more than one layer of non-linear units. Here, we will consider a\nfunction outputting the negation of XOR, Not-XOR:\nX = np.array([[0, 1, 0, 1],\n[0, 1, 1, 0]])\nY = np.array([[1, 1, 0, 0]])\n1.2.A) Draw a plot showing the locations of these data points in x1, x2 coordinate space, with the corresponding labels.\nNow consider a network with no hidden layers as in part 1.1 above, which just has input units connected (via weights) to an\noutput sigmoid unit. Can this network learn a separator for the given dataset? Explain.\n2/8\n\n6.036 Spring 2021\n1.2.B) Consider the following truth table representing the logical AND and OR operators. We would like to represent the\nAND function as a neural network, using the same structure as from Problem 1.1. Find weights w1 , w2 , and w0 that\nrepresent the (i) AND operation and (ii) OR operation.\n1.2.C) We can express Not-XOR using only AND, OR, and NOT operations. Which expression corresponds to x1 Not-XOR x2?\n(\nAND\n) AND (NOT\nAND NOT\n)\n(\nOR\n) AND (NOT\nOR NOT\n)\n(\nAND\n) OR (NOT\nAND NOT\n)\n(\nOR\n) OR (NOT\nOR NOT\n)\nSave\nSubmit\nView Answer\nAsk for Help\nAs staff, you are always allowed to submit. If you were a student, you would see the following:\nYou have infinitely many submissions remaining.\nx1\nx2\nx1\nx2\nx1\nx2\nx1\nx2\nx1\nx2\nx1\nx2\nx1\nx2\nx1\nx2\n1.2.D) Consider the following network with the hidden layer of Sigmoid (σ) units, where f is a sigmoid unit and\nw0,1 ... w0,n , w0,Σ are the offsets.\nWe can use this network to represent the Not-XOR function. What is the minimal number of units we need in the hidden\nlayer?\n3/8\n\n6.036 Spring 2021\nEnter the minimal number of units we need in the hidden layer:\nSave\nSubmit\nClear Answer\nAsk for Help\nAs staff, you are always allowed to submit. If you were a student, you would see the following:\nYou have infinitely many submissions remaining.\nSolution: 2\nExplanation:\nDiscuss in checkoff\n1.2.E) Now that we have our architecture, find the weights and offsets corresponding to the units.\nExplain how the network works with reference to your earlier drawing of the Not-XOR data in x1 and x2 space. (Try to spend\njust 10 minutes on this, then ask for tips!)\n1.2.F) In the run box below, first try to see if you can get a network of the size you found above to separate the data reliably\n(several times in a row, keeping randomInit = True ). If not, try larger networks. Try each value of hidden units a few\ndifferent times. Experiment with different learning rates and iterations as well. Explain what's going on. Keep in mind that\nthe network is being trained using batch gradient descent.\nNow, change randomInit = False . Try different values of hidden units. Try these values a few different times. Comment on\nhow the behavior is different.\nThe single_layer_nn function in the code below runs on the dataset using a network with a single hidden layer of ReLU\nunits, a sigmoid output layer, and NLL loss. You can specify the number of hidden units, the number of iterations, and the\nlearning rate.\nRun Code\nSave\nSubmit\nView Answer\nAsk for Help\nAs staff, you are always allowed to submit. If you were a student, you would see the following:\nYou have infinitely many submissions remaining.\ndef run():\nreturn single_layer_nn(hidden_units=1, iters=1000, lr=0.05, randomInit=True)\n1.3) Hard data set\nIn this next example we use a much harder data set that is barely separable (although not linearly). We'll try a two-layer\nnetwork architecture.\n1.3.A) Running the code below, can you get this architecture to separate the data set with at least 95% accuracy? How about\n100% accuracy (Don't spend too long looking for 100%)? If you can't, explain why not. If you can, explain why. Make sure\nyour accuracy is reliable by running the code several times.\n1.3.B) Do you think it's a good idea to try to find a \"perfect\" separator for this data? Explain.\n4/8\n\n6.036 Spring 2021\nThe network here has two hidden layers of ReLU units and a sigmoid output unit with NLL loss. In the two_layer_nn\nfunction call below, you can play around with the number of hidden units in each hidden layer, the number of iterations, and\nthe learning rate.\nRun Code\nSave\nSubmit\nView Answer\nAsk for Help\nAs staff, you are always allowed to submit. If you were a student, you would see the following:\nYou have infinitely many submissions remaining.\ndef run():\nreturn two_layer_nn(hidden_units=2, iters=100, lr=0.05)\n2) Checkoff\nCheckoff 1:\nHave a check-off conversation with a staff member, to explain your answers.\nAsk for Help\nAsk for Checkoff\n3) Activation and Loss Function Applications\nOne important part of designing a neural network application is understanding the problem domain and choosing\nA representation for the input\nThe number of output units and what range of values they can take on\nThe loss function to try to minimize, based on actual and desired outputs\nWe have studied input representation (featurization) in a previous lab, so in this problem we will concentrate on the number\nof output units, activation function on the output units, and loss function. These should generally be chosen jointly.\nJust as a reminder, among different loss functions and activation functions (see Sections 3 and 6 of the Chapter 8 notes), we\nhave studied:\nActivation functions: linear, ReLU, sigmoid, softmax\nLoss functions: negative log likelihood (NLL a.k.a. cross-entropy), quadratic (mean squared)\nFor each of the following application domains, specify good choices for the number of units in the output layer, the\nactivation function(s) on the output layer, and the loss function. When you choose to use multiple output units, be very clear\non the details of how you are applying the activation and the loss. Please write your answers down!\n3.A) Map the words on the front page of the New York Times to the predicted (numerical) change in the stock market\naverage.\n3.B) Map a satellite image centered on a particular location to a value that can be interpreted as the probability it will rain at\nthat location sometime in the next 4 hours.\n3.C) Map the words in an email message to which one of a user's fixed set of email folders it should be filed in.\n3.D) Map the words of a document into a vector of outputs, where each index represents a topic, and has value 1 if the\ndocument addresses that topic and 0 otherwise. Each document may contain multiple topics, so in the training data, the\n5/8\n\n6.036 Spring 2021\noutput vectors may have multiple 1 values.\n4) Social Utility\nOver the last several labs, we've explored different forms of biases with problematic outcomes: historical bias,\nrepresentation bias, aggregation bias. This week, we'll start discussing potential benefits and drawbacks of intentionally\nbiasing your model, and how this can affect the model's utility.\nDr. Niyu Ralnette's research group is investigating the use of machine learning to support radiologists.\n2% of the population have a rare, deadly disease which can be detected with x-rays. The research group built a model that\nachieves 98% accuracy on the test set of 100,000 people and a 99% accuracy on the training set of 1 million individuals.\nThe Ralnette group starts to test the model in the wild, but when Dr. Ralnette takes a look at the results, she finds that the\nmodel never produces a positive diagnosis of the disease. Dr. Ralnette is confused by this since the model seemed to\nperform well on both the training data and test data.\n4.A) Can you think of a possible explanation for why the model had high accuracies on the training data and test data, but\nseems to be unable to correctly diagnose the disease in the wild?\nWe now introduce another evaluation tool, used in addition to accuracy measurements, called confusion matrices. A\nconfusion matrix is a table used to provide more detailed information on the performance of a classification model.\nOur model that achieved a 98% accuracy on the test set, had the following confusion matrix.\n6/8\n\n6.036 Spring 2021\nIt seems the model learned to always predict \"False\" for the diagnosis! Dr. Ralnette's group trains a few more models to see\nif we get different performance\n4.B) The confusion matrices of the developed models are below. Calculate the accuracy of each model.\n4.C) Which of the following models would you prefer to deploy, and why? In the case of diagnosing this rare, deadly disease,\ndo you prefer false negatives, false positives, or do you not have a preference for the type of failures? Why?\nNote: In case you are curious, one way achieve models with different combinations of false positive and false negative rates\nis to use an asymmetric loss (as seen in the Chapter 1 notes).\n4.D) This disease can be treated if detected, but the treatment has extremely harsh, non-lethal side effects. Does this\nknowledge change the model you would choose? Would you choose a different model if the model were going to diagnose\nthe patient without a radiologist making the final recommendation?\n7/8\n\n6.036 Spring 2021\n5) Checkoff\nCheckoff 2:\nHave a check-off conversation with a staff member, to explain your answers.\nAsk for Help\nAsk for Checkoff\n8/8\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\nRES.TLL-008 Social and Ethical Responsibilities of Computing (SERC)\nFall 2021\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms"
        },
        {
          "category": "Resource",
          "title": "RES.TLL-008 Social and Ethical Responsibilities of Computing (SERC), 6.036 Lab 9.pdf",
          "type": "PDF",
          "source_url": "https://ocw.mit.edu/courses/res-tll-008-social-and-ethical-responsibilities-of-computing-serc/7a3c3be8168d0e427cc41f74a9e1e72a_RES-TLL008F21-6036_lab9.pdf",
          "content": "6.036 Spring 2021\nLab -- Recurrent Neural\nNetworks\nGroup information\nCreate Your Group\nOnce you and your partner(s) are in a breakout room, you need to create a group.\nInstructions:\n(1) One of you should click here to create a group.\n(2) Everyone else should then enter the given new group name (including trailing numbers) into the box below (and press\nenter when done).\nName of group to join:\nReload this page anytime to refresh your group status (and to get a delete button, if you want to remove yourself from a\ngroup you've joined).\nGroups are limited to 3 persons max each, so that checkoff discussions can be inclusive.\nYou are not currently in any group\nFor this lab:\nYou will need to understand the material in the notes on recurrent neural networks.\nWe have prepared a Colab notebook that is essential for doing this lab that can be found here. We recommend using the colab but\ncode files can be found here. You can download this to your computer if you prefer.\nRNNs\n1) Applications of RNNs\n1.1) Examples\nIn this section, we'll consider examples of RNN applications with respect to the forms of inputs and outputs.\n1/9\n\n6.036 Spring 2021\n1.2) Choose a structure\nChoose an RNN structure from one-to-many, many-to-one, and many-to-many, to address each of the problems below. For each, describe\nhow you would structure the input to the RNN (which has to be a fixed-length vector at each time step), and what kind of output unit(s) you\nwould use.\nNote that yellow nodes stand for inputs, blue nodes stand for hidden units, and red nodes stand for outputs.\n1.2.1)\nGiven a review for a new product on a shopping website, detect whether the text's sentiment is positive or negative, that is, whether the\nwriter writes positively or negatively about the new product.\n1.2.2)\nAssign a part-of-speech tag to each word in an English sentence: \"The old man will man the boat.\" -> [\"determiner\", \"adjective\", \"noun\",\n\"modal\", \"verb\", \"determiner\", \"noun\", \"punctuation\"]\n1.2.3)\nGiven a picture (encoded as a vector of features computed by a CNN), generate a caption, for example: \"A cat is sitting on a rock\" or \"Dogs\nplaying at the park\".\n1.2.4)\nTranslate a sentence from Spanish to English: \"Quiero aprender mas algebra lineal.\" -> \"I want to learn more linear algebra.\" As you can see,\nhere we have different sequence lengths and words might be in different order (algebra lineal vs. linear algebra). What architecture (or\ncombination of architectures), from the above described, would you use to address this problem? Be ready to discuss some challenges of\nthese architectures.\nCheck this box and submit when you have finished all parts of this question.\nSave\nSubmit\nView Answer\nAsk for Help\nAs staff, you are always allowed to submit. If you were a student, you would see the following:\nYou have infinitely many submissions remaining.\n2) Generating sequences\nIn this question, we will look into using an RNN model to predict the next element in a sequence. We will focus on sequences of text\ncharacters (this is sometimes referred to as a \"language\" model). We will want to train on one or more sequences and then, given an initial\ncharacter or sequence of characters, we want the RNN to predict what characters should come next. An example sequence might be the\nfollowing:\nc = ['m', 'i', 't']\n2/9\n\n6.036 Spring 2021\nThis sequence will be used both as input to an RNN and as desired output (offset by one time step), since we are training the RNN to\nproduce the next character in the sequence.\n2.1) RNN structure\nSince the input to an RNN at each time step is encoded as a fixed-length vector, we will first encode each character of the sequence using a\none-hot encoding. Let φ(ct) represent the one-hot encoding of character ct. Recall that if we have V possible characters, then φ(ct) will be\na vector of size V where each element corresponds to one of the possible characters.\nThe inputs to the RNN, x, will consist of the encoded characters with a special start character. The output sequence of the RNN, y, will also\nconsist of the encoded characters but have a special end character. In this lab, we will use '.' and '\\n' as the start and end character\nrespectively. This format will allow us to train an RNN to do character prediction (at time t, the RNN will have seen c1, ... , ct-1 and will try\nto predict ct).\nx = [<start>, φ(c1), φ(c2), ... , φ(cn )]\ny = [φ(c1), φ(c2), ... , φ(cn ), <end>]\nNote that x and y are shifted by one time step.\nThe following diagram unravels the RNN and shows what x and y would be for the sequence c=['m','i','t'] :\nThe particular form of the RNN that we will look at is:\nNote that this in the same form as the Continuous State Machines in Lab 8.\n2.1.1)\nBe prepared to discuss these points during checkoff:\nWhen the symbols are all the lowercase letters in the English alphabet, what is the size of V ?\nWhich time step of x should the output yt match?\nWhat is the role of st?\nHow is pt related to st?\nTraining: We will first describe how to train this RNN given a dataset of sequences. For each sequence in the dataset:\nFormat the input and output for the RNN as described above (add start/end characters to the sequence for the input/output\nrespectively).\nFeed each character of the input into the RNN (at time t, this will be ct-1 from the original sequence).\n3/9\n\n6.036 Spring 2021\nUse the NLL between the predictions pt and the true character encodings yt and perform backpropagation to update the weights in\nthe matrices.\nGeneration: Once the RNN is trained, we can use it to generate new text based on its own predictions.\nStarting with the start symbol ('.'), it predicts a next character by sampling it from the softmax distribution on the output pt in the\ntrained model, then it feeds that character as the next input into the model and repeats until an end symbol ('\\n') is generated.\nAn alternative generation approach picks the most likely character at pt instead of sampling from the softmax distribution.\nWe visualize this process below where we use y^ t to represent the encoding of the character the network predicted at time t. Notice how the\nnetwork uses its own predictions as inputs. This differs from training where we always used the characters from the sequence in our dataset\nas inputs (see the training diagram above).\n2.1.2)\nBe prepared to discuss these points during checkoff:\nHow are the training sequences used in the training phase?\nHow are multiple sequences produces in the generation phase?\n2.2) Memorizing a Sequence\nWe will first see how well these models can learn to produce a single sequence. Let's consider generating a sequence of 10 a characters. We\nwill train the RNN and then call the generation method 11 times. The first time we give it '.' as input and then the following 10 times we\ngive it the output of the RNN at the previous time step. We want the outputs to be:\n['a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', '\\n']\n2.2.1)\nWhat does the RNN need to learn in order to perform this task? Mark all that are true.\nA linear classifier that predicts 'a' versus `\\n' depending on the hidden state\nA state machine that encodes a count of the number of characters seen so far in the hidden state\nSave\nSubmit\nView Answer\nAsk for Help\nAs staff, you are always allowed to submit. If you were a student, you would see the following:\nYou have infinitely many submissions remaining.\n4/9\n\n6.036 Spring 2021\nNext, assume that the one-hot encoding of 'a' is [[1], [0]] and the encoding of '\\n' is [[0], [1]] . For now, assume that the encoding of '.'\nis also [[0], [1]] .\nPicking the dimension of the hidden state, m, to be 1 and training an RNN with this sequence for 10000 iterations of SGD, we obtain the\nfollowing RNN matrices:\nWss = [[2.66555941]] Wsx = [[-0.75865931,\n2.91783285]] Wss0 = [[-0.37149935]]\nWo = [[ 9.63304408], [-9.63296282]]\nWo0 = [[ 2.64391274], [-2.64382701]]\nIf we now call the RNN generation function repeatedly, we get the following output (approximately). Note that state is st-1 , x is xt,\nnew_state is st and p is pt.\nt= 1 state [[0.]]\nx [[0] [1]] new_state [[0.98779174]] p [[1.0], [0.0]]\nt= 2 state [[0.98779174]] x [[1] [0]] new_state [[0.90566354]] p [[1.0], [0.0]]\nt= 3 state [[0.90566354]] x [[1] [0]] new_state [[0.85753147]] p [[1.0], [0.0]]\nt= 4 state [[0.85753147]] x [[1] [0]] new_state [[0.81961469]] p [[1.0], [0.0]]\nt= 5 state [[0.81961469]] x [[1] [0]] new_state [[0.78357789]] p [[1.0], [0.0]]\nt= 6 state [[0.78357789]] x [[1] [0]] new_state [[0.74361363]] p [[1.0], [0.0]]\nt= 7 state [[0.74361363]] x [[1] [0]] new_state [[0.69210644]] p [[1.0], [0.0]]\nt= 8 state [[0.69210644]] x [[1] [0]] new_state [[0.61361073]] p [[1.0], [0.0]]\nt= 9 state [[0.61361073]] x [[1] [0]] new_state [[0.46639812]] p [[1.0], [0.0]]\nt=10 state [[0.46639812]] x [[1] [0]] new_state [[0.11257404]] p [[1.0], [0.0]]\nt=11 state [[0.11257404]] x [[1] [0]] new_state [[-0.68052211]]\np [[0.0], [1.0]]\n2.2.2)\nFor what values of\nis the output character '\\n'?\npositive values\nnegative values\nSave\nSubmit\nView Answer\nAsk for Help\nAs staff, you are always allowed to submit. If you were a student, you would see the following:\nYou have infinitely many submissions remaining.\nst\n2.2.3)\nBe prepared to discuss these points during checkoff:\nNote that the state starts with value 0, how does it get be close to 1 at the first step?\nAt what time step does the new_state (st) go below 0?\nHow does the change in sign of st affect the output? (Think about how softmax works)\n2.2.4)\nThe sequence above had a fixed length, but what if we didn't include a termination character and wanted to generate repeating strings?\nWhat if we wanted to train a language model to generate the sequence ['m', 'i', 't', 'm', 'i', 't', ....] forever? What\nwould the state need to encode?\nWhat about ['m', 'm', 'i', 'i', 't', 't', 'm', 'm', 'i', 'i', ...] What would the state need to encode?\nWhat about ['m', 'm', 'm', 'm', ....] What would the state need to encode?\n2.3) Hard Sequences\nSome sequences are harder to memorize than others. As a measure of difficulty of learning, let's consider two factors:\n5/9\n\n6.036 Spring 2021\nnum_hidden : The dimension of the hidden state (referred to as m above),\nnum_steps : The number of steps to run the optimizer for.\nWe will focus on the first of these - the dimension of the hidden state.\nThe RNN will first be trained on a dataset of a single sequence. We will then use the trained RNN to generate a new sequence as described\nabove (see the generation section). Our goal is to have the RNN reproduce the training sequence reliably during generation (including\nstopping at the right place).\nWe'll consider these sequences (note we visualize them as strings instead of list of characters):\n(1)\n\"aaaaaaaaaa\"\n\"aabaaabbaaaababaabaa\"\n\"abcdefghijklmnopqrstuvwxyz\"\n\"abcabcabcabcabc\"\nWhich sequence do you think will be most difficult for the RNN to learn? Recall that the vocabulary includes all the letters in\nthe input, but we're not using size of V as indicating difficulty. Here, \"difficult\" just consists of needing larger hidden\ndimension.\n--\nSave\nSubmit\nView Answer\nAsk for Help\nAs staff, you are always allowed to submit. If you were a student, you would see the following:\nYou have infinitely many submissions remaining.\nc\n=\nc\n=\n(2)\nc\n=\n(3)\nc\n=\n(4)\nBe prepared to explain your reasoning during the checkoff.\n2.4) Running the code\nWe will now try training an RNN on these single-sequence datasets. We have provided code to do this for you. In the Colab you will find\ndefinitions of a procedure for training and using models of sequential data (you can also use code_for_lab9.py from the downloadable\nfiles).\ntest_word(word, interactive=False, num_hidden=1, num_steps=10000, step_size=0.005)\nword is a string representing the sequence of characters. These will be converted into a training set of sequence pairs for a language\nmodel as described above.\nnum_hidden indicates the number of units in the hidden layer (the dimension of the states),\nnum_steps indicates steps of (stochastic) gradient descent,\nstep_size the magnitude of the gradient descent steps,\ninteractive indicates, when False, to generate 100 random sequences from learned model, when True, it asks for a partial sequence\nand then completes it in the most likely way given the learned model. Note: input sequences can only include characters present in the\nword (or the start character . )\nNote that test_word(word=\"aaaaaaaaaa\") uses as both training and test set only the input word (i.e. the model is literally only trying to\nlearn how to represent that sequence).\nTry using different values of each of the following parameters:.\nnum_hidden : The dimension of the hidden state,\nnum_steps : The number of steps. Try num_steps in [1000, 5000, 10000, 15000, 20000].\nNote that the initial weights are chosen randomly, so results will vary for each run. You can set the random seed if you can't get consistent\nresults.\n2.4.1)\n6/9\n\n6.036 Spring 2021\nTry learning each of the above sequences, using the test_word function for different values of num_hidden and num_steps ; pay attention to\nthe training error value printed by the code. The output of test_word is 100 sequences generated from a trained model, that is, sampling\nfrom the softmax distribution on the output pt. Find the difficulty of each string (the minimum size of hidden layer and number of steps\nrequired to consistently reproduce the string, where we prioritize minimizing hidden layer size (i.e. num_hidden ). Comment on your results.\nCheckoff 1:\nHave a check-off conversation with a staff member, to explain your results.\nAsk for Help\nAsk for Checkoff\n3) Language Modeling\n3.1) Larger datasets\nWe will now try training the RNN using larger datasets with more realistic sequences. We will specifically look at different strategies to\ngenerate sequences with a trained model.\ninteractive=True : You will be prompted to enter the start of a sequence. We will use the RNN to complete the sequence (taking the\nmost likely character at each prediction).\ninteractive_top5=True : Similar to interactive=True but instead of choosing the most likely character at each time step, you will be\nshown the top 5 most likely characters and asked to choose one.\nThe test_food function uses the file food.txt of recipe names.\nRun test_food with interactive=True .\nRun test_food with interactive_top5=True .\n3.1.1)\nWhat is the mechanism by which these RNNs generate the top 5 characters? More specifically, what characters do the trained RNN seem to\npropose for you to choose at each location?\n3.1.2)\nWithout having you manually choose the next character, what would be a mechanism by which these RNNs should generate their output?\nWould that produce diverse sequences (i.e., if you run the generation multiple times with the same start-of-sequence string, would you get\ndifferent outputs)?\nNote: If your installation of Python has trouble finding the data files, try setting the dirname in the code_for_lab9.py file to the pathname\nfor the folder where the data can be found.\n4) Word Embeddings\nRNNs are often used to process language, for example to map from one sequence of words to another sequence of words.\nRNNs, like other NNs, take vectors as input, so to get them to process words we need some way of turning words into vectors. One way to\ndo this is with a one-hot encoding (as in the previous lab problems). But there are lots of lower dimensional but more informative\nrepresentations of words called \"word embeddings\".\nOne popular technique for producing word embeddings is called word2vec. It assigns each word a vector embedding such that words that\nappear in similar sentence contexts have embeddings that are close in vector space. Typically, we create these embedding vectors through\nmachine learning techniques (i.e. an embedding weight matrix of size [number of words x embedding size] is learned).\n4.1) Exploring embeddings\n7/9\n\n6.036 Spring 2021\nHere, we investigate a phenomenon that will affect any RNN that uses these embeddings. We've trained embeddings for all the words that\nappeared in a large dataset of news articles. Instead of loading embeddings for every word in this set (together they take up about 3 GB!),\nwe have pre-selected several words whose embeddings have interesting properties.\nwords = [\"woman\", \"man\", \"boy\", \"girl\", \"doctor\", \"nurse\", \"programmer\", \"homemaker\", \"queen\", \"king\", \"receptionist\",\n\"librarian\", \"socialite\", \"hairdresser\", \"nanny\", \"bookkeeper\", \"stylist\", \"maestro\", \"protege\", \"philosopher\",\n\"captain\", \"architect\", \"surgeon\", \"brilliant\", \"mother\", \"father\"]\nThe function below takes two lists and computes the cosine distance between corresponding elements of the lists:\nw1 ⋅ w2\nd(w1, w2) = 1 - ∣∣w1∣∣∣∣w2∣∣\n[We can see that with cosine distance, the magnitude of the involved vectors is irrelevant; distance is dependent on the angle between the\ntwo vectors. Smaller angles correspond to closer vectors. Using cosine distance, we also know that distances will range between 0 and 1.]\nUse the function below to find the distances between various pairs of words from the above list. Compare the distances to each other. What\ndo the relative distances seem to reflect? What unexpected distances do you notice?\nRun Code\nSave\nSubmit\nView Answer\nAsk for Help\nAs staff, you are always allowed to submit. If you were a student, you would see the following:\nYou have infinitely many submissions remaining.\ndef run():\nreturn t1(w1list=[\"woman\", \"man\"], w2list=[\"mother\", \"father\"])\n4.2)\nNow let's take a look at some of the problems that arise when we use these embeddings in the wild. Please go to Google Translate and\ntranslate the following into Hungarian: \"She is an engineer. He is beautiful\". What do you get?\nNow take the Hungarian translation above and translate it back into English using Google Translate. Please note that Hungarian is a gender\nneutral language (so there are no gendered pronouns). What do you get? Why might this be happening? How does this relate to the\nunexpected distances we saw in the previous problem? And where do these unexpected distances come from?\n4.3)\nWhat are some applications where using biased word embeddings may have a negative impact?\nCheckoff 2:\nHave a check-off conversation with a staff member, to explain your results.\nAsk for Help\nAsk for Checkoff\nWhile you wait for a checkoff...\nDe-biasing these translations is ongoing process. Here's an example from 2019. And here is their fix as of today, but as illustrated in the\nabove examples, it is still far from perfect. If you are curious to read more on the Hungarian translation example, see this blog post. There is\nalso a lot of research in this space. Here's a paper that works on debiasing such embeddings\nAs of November 20, 2019\nvs. November 1, 2020\n8/9\n\n6.036 Spring 2021\n(c) Google. All rights reserved. This content is excluded from\nour Creative Commons license. For more information, see\nhttps://ocw.mit.edu/help/faq-fair-use/\n5) More Food for Thought\nIn the past few years, another model architecture, the transformer, has replaced the RNNs as the model of choice for language processing\ntasks. Generative Pre-trained transformer (GPT-3) is one such language model developed by Open-AI. Many developers have come up with\nmany different applications that are often indistinugishable from human generated texts.\nThis is an application where GPT-3 is used to generate tweets given any word as the theme. For example, here's a tweet generated with mit\nas the theme word: \"MIT slaps you across the face with reality and drags you to Mars. That's why it's the best.\" We'll look at the transformer\nmodel in next week's lab.\n9/9\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\nRES.TLL-008 Social and Ethical Responsibilities of Computing (SERC)\nFall 2021\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms"
        },
        {
          "category": "Resource",
          "title": "RES.TLL-008 Social and Ethical Responsibilities of Computing (SERC), 6.390: Introduction to Machine Learning, Markov Lab",
          "type": "PDF",
          "source_url": "https://ocw.mit.edu/courses/res-tll-008-social-and-ethical-responsibilities-of-computing-serc/mitres-tll008s23_6039_markov.pdf",
          "content": "Introduction to Machine Learning\n(Fall 2022)\nLab attendance check\nType in your section passcode to get attendance credit (within the first fifteen minutes of your scheduled section).\nPasscode:\nEnter\nGroup information\nCreate/join a group\n1. One person (and only one) should create a group.\n2. Everyone else should enter the group name below (in the form groupname_0000 ).\nJoin group:\nSubmit\nTo join another group or leave your current group, reload the page.\nYou are not in a group.\nFor this lab:\nYou will need to understand the material in the course notes on Markov decision processes.\nDon't spend too long on any one question - use the help queue if you are stuck!\n1) Deterministic Wash & Paint MDP\nWe will model aspects of a very simple wash and paint machine as a Markov decision process (MDP). An agent controls the actions taken, while the\nenvironment responds with the transition to the next state.\nOur simple machine has three possible operations: \"wash\", \"paint\", and \"eject\" (each with a corresponding button). Objects are put into the machine.\nEach time you push a button, something is done to the object. The machine has a camera inside that can clearly detect what is going on with the\nobject and will output the state of the object: dirty, clean, painted, or ejected.\nIn this question, you will devise a policy that will take the state of an object as input and select a button to press until finally you press the eject\nbutton. You get reward +10 for the \"eject\" action on a painted object, reward 0 for \"eject\" action on an object that is dirty or clean, reward 0 for any\naction on an ejected object, and reward -3 otherwise.\nWe start out with a brand-new machine that operates reliably and deterministically, as illustrated in the state diagram below. Here state transition arcs\nare labeled with the action responsible for the transition. Specifically, when we \"wash\" a dirty or painted object, it becomes clean; and when we\n\"paint\" a clean object it becomes painted. If we \"eject\" a dirty, clean, or painted object, it becomes ejected. An ejected object stays ejected, for any\naction.\n\n1.1)\nYou will formulate the brand-new machine as an MDP, but with a deterministic transition function. It will be useful to write out and save\ntables/diagrams of your answers and show them to staff during the checkoff.\nWrite out a specification of the state space and action space.\nThe transition model is specified by the diagram above, where an arc from state to state\nunder action indicates a transition probability\n, and lack of an arc from to\nindicates a transition probability\n.\nThe reward function,\n, needs your definition. Given\nstates and actions, the reward matrix should be\nby , and will look something\nlike:\nwash paint eject\ndirty\n--\n--\n--\nclean\n--\n--\n--\npainted --\n--\n--\nejected --\n--\n--\nFor the matrix in the response below, order the states as \"dirty\", \"clean\", \"painted\", and \"ejected\": and the actions as \"wash\", \"paint\", \"eject\".\nEnter the reward matrix as a list of lists:\nCheck Formatting\nSubmit\nView Answer\nAsk for Help\nAs staff, you are always allowed to submit. If you were a student, you would see the following:\nYou have infinitely many submissions remaining.\n1.2)\nSuppose we have an infinite horizon and discount factor 1. That means you can take as many steps as you want to, and all rewards are weighted\nequally whether they happen at the beginning or end of the action sequence. What would be the optimal action to take in each state? What would\nyour total sum of rewards be (under the optimal policy) if you started in state dirty?\n1.3)\nSuppose we have a horizon of 2 and discount factor 1. That means you could only take two steps in total. Would the policy from the previous\nquestion change? Why, or why not? What would your total sum of rewards be (under the optimal policy) if you started in state dirty?\n1.4)\nSuppose we have an infinite horizon and discount factor 0.5. Let's also assume that under our action policy, we always \"paint\" an object if it is clean,\nand always \"eject\" an object if it is painted. What would be the sum of discounted future rewards if you start with a dirty object in each of the policies\nlisted next:\nYour policy is to \"eject\" an object whenever it is dirty?\ns\ns′\na\nT(s, a, s ) =\n′\ns\ns′\nT(s, a, s ) =\n′\nR(s, a)\nm\nn\nm\nn\n\nYour policy is to \"wash\" an object whenever it is dirty, followed by optimal actions after that?\nWhich is the better policy?\n2) Stochastic Wash & Paint MDP\nOur wash and paint machine has gotten old, and is no longer so reliable. Now, many of its state transitions are stochastic in response to specific\nactions:\nWash:\nIf you perform the \"wash\" operation on any object, whether it's dirty, clean, or painted, it will end up clean with probability 0.9 and dirty\notherwise.\nPaint:\nIf you perform the \"paint\" operation on a clean object, it will become nicely painted with probability 0.8. With probability 0.1, the paint misses\nbut the object stays clean, and also with probability 0.1, the machine dumps rusty dust all over the object and it becomes dirty.\nIf you perform the \"paint\" operation on a painted object, it stays painted with probability 1.0.\nIf you perform the \"paint\" operation on a dirty object, it stays dirty with probability 1.0.\nEject:\nIf you perform an \"eject\" operation on any object, the object comes out of the machine and this fun game is over. The object remains ejected\nregardless of any further action.\nHere is an example state diagram for the \"wash\" operation, now with arcs labeling the probability\n, for action being \"wash\".\n2.1)\nIn order to visualize the stochastic machine MDP, draw the state diagrams for the \"paint\" and \"eject\" operations.\n2.2)\nThe state space, action space, and reward function remain the same as for our deterministic machine, but now our transition model has changed.\nWrite out the transition matrices for the \"wash\", \"paint\", and \"eject\" actions. Specifically, provide three transition matrices (rows should sum to one,\nwith the conventions used in this class), one transition matrix for each of the \"wash\", \"paint\", and \"eject\" actions.\nGiven\nstates, each transition matrix should be\nby\n, corresponding to\nwith row indicating and column\n. Thus, a transition matrix\nfor a given action will look something like:\nT(s, a, s )\n′\na\nm\nm\nm\nT(s, a, s )\n′\ns\ns′\na\n\ndirty clean painted ejected\ndirty\n--\n--\n--\n--\nclean\n--\n--\n--\n--\npainted --\n--\n--\n--\nejected --\n--\n--\n--\nFor the prompt just below, order the rows and columns as dirty, clean, painted, ejected.\nEnter the transition matrix as a list of lists for \"wash\" action:\nCheck Formatting\nSubmit\nView Answer\nAsk for Help\nAs staff, you are always allowed to submit. If you were a student, you would see the following:\nYou have infinitely many submissions remaining.\n2.3)\nWe next consider some finite horizon scenarios (and with discount factor\n), but now with our stochastic wash & paint MDP.\n2.3.1)\nFirst, assume horizon\nWhat is our optimal action\nif you are in a painted state? What is the optimal action-value function\nfor this case,\n?\n2.3.2)\nIf we instead have a finite horizon of\n, what is our optimal action\nif we are in a painted state with two steps to go? Why is this different than\n(or the same as)\n? What is\n; how does this compare to\nand why?\n2.3.3)\nStill with a finite horizon of\n, now we start in state clean. In the deterministic (brand new) wash & paint machine, we saw that the optimal action\nwas to paint, then eject, for a total reward of 7.\nNow, with horizon\nin our stochastic wash & paint machine, we still hope to paint then eject. Will this\nhave a\nreward of 7, more than 7, or less than 7? Why?\n2.4)\nWe switch to an infinite-horizon scenario. For our stochastic machine, here is the infinite-horizon\nfunction (computed via value iteration) for near\n1.\nwash paint eject\ndirty [[ 2.32274541 -0.70048204 0.\n]\nclean [ 2.32274541 5.71581775 0.\n]\npainted [ 2.32274541 6.9 10.\n]\nejected [ 0. 0. 0.\n]]\nWhat is the optimal thing to do with a clean object?\nWhat will you do if it becomes dirty?\nDoes this optimal policy make intuitive sense?\n2.5)\nγ = 1\nh = 1.\na1\nQh\nQ (s =\npainted, a )\nh = 2\na2\na1\nQ (s =\npainted, a )\nQ (s =\npainted, a )\nh = 2\nh = 2\nQ (s =\nclean, a =\npaint)\nQ\nγ\n\nIf the machine became much less reliable (i.e., washing and painting only achieve the desired transition, say, 20% of the time), how do you think the\noptimal policy would change?\nCheckoff 1:\nHave a check-off conversation with a staff member, to explain your answers.\nAsk for Help\nAsk for Checkoff\n3) Grid-World -- Finite Horizon Q Values\nIn the previous problem, we only had four states: dirty, clean, painted, and ejected. In this problem, we use a two-dimensional \"grid-world\" with a\nrobot in it; we have a state for every square on the grid, representing the robot's location.\nOur four possible actions are moving North, South, East or West (note that the robot cannot move off the board, so some states have fewer possible\nactions). The transitions are also substantially noisy; when commanding a move to a target state, there is a 50% probability of moving to the target\nstate, and a\nprobability of landing instead at one of the vertical or horizontal neighbor states of the target state. In most cases, will\nbe four, but at the boundaries of our grid-world, and the available transitions will include only the neighboring squares that are within grid-world.\nWe want to identify the best action that the robot can take in each state (i.e., the best policy), if it had a specific horizon of remaining moves. We do\nnot have any discount for future moves: the discount factor\nConsider a grid world with its \"floor plan\" represented as a list of strings of characters:\n['..........',\n'........*.',\n'..........',\n'..........',\n'..........',\n'..........',\n'..........',\n'..........',\n'.$........',\n'..........']\nEach character corresponds to a square in the grid. The meanings of the characters are:\n'.' : a normally habitable square, from which the robot can move.\n'$' : a terminal state. Reward is 100 for any action from this state, and then the game immediately ends.\n'*' : a teleporter state. Reward is 50 for any action from this state, and the next state is chosen uniformly at random from all occupiable\nstates, including $ and *. This reward can be claimed multiple times.\nBelow are plots of the\nvalues of the states as we consider horizons from 0 to 99. The color for each square represents\n, where\nis the optimal finite-horizon action to take at horizon , i.e.,\nThe arrows represent the optimal move,\n, pointing N, S,\nE, or W.\n(50/g)%\ng\ng\ng\nh\nγ = 1.\nQh\nh\ns\nQ (s, a\n)\nh\nopt\naopt\nh\na\n=\nopt\narg max\nQ (s, a).\na\nh\naopt\nNote: Before proceeding, confirm that you understand what these diagrams mean, and how they relate to Qh in the finite-horizon set up in the\ncourse notes on MDPs. What equations in the notes apply to this scenario? Ask for help if you're not sure!\n\n99 (note scale change!)\n3.1)\nIn the first picture all the values are zero, and with a default \"best\" action, N. Why?\nThe second picture considers an horizon\nscenario. In this case, we have two states with non-zero Q values. What states are they? What values\ndo they reflect?\n3.2)\nWhat is new in the horizon 2 scenario?\nHow is it possible that there are non-zero\nfor states that do not neighbor $ and *?\n3.3)\nWhat happens for horizons roughly in the range of 3 to 7? What do you observe about the upper right and lower left portions of the grid?\n3.4)\nLook at the horizon 11 scenario. Why does the upper right teleporter state * now have higher\nvalue than the lower left terminal state, $?\n3.5)\nh = 1\nQ2\nQ11\n\nWhat's happening to the arrows in the pictures corresponding to horizon values near\n?\n3.6)\nWhat's happening around horizon 19?\nThe value of being near the \"teleporter\" is about 150. Why? Give an informal description of how an optimal policy plays out for states near the\nteleporter, with the estimated\nvalues at this point.\n3.7)\nThe last picture is for\n(note the change in scale for the color bar!). If we were to consider scenarios well beyond horizon 99, what would the\nvalue function look like for large ?\nFor very long horizons, do we expect the game to eventually terminate?\n3.8)\nIn thinking through each successive horizon above, we built our\nvalue based on knowing our\nvalue. If we were to run the infinite horizon\n, and were to plot the estimate of\nand\nafter each\nis the change in distance traveled in meters along the shortest path from start to goal, regularly calculated using the car's current position;\nis the change in speed in km/h;\nis the change in collision damage, expressed in range [0, 1], where 0 is no damage and 1 is damage when the car crashes.\nWhat information do you need to encode your state? Does this reward function align with your preferences, and why?\nHint: think about how you might compare a successful trajectory, a motionless trajectory where the car does not move, and/or an unsuccessful\ntrajectory where the car crashes\n.\n4.3)\nh = 16\nQh\nh = 99\nQh\nh\nQh\nQh-1\nvalue iteration algorithm (in pseudocode at the end of the chapter on MDPs) with γ = 1\niteration, what would those plots look like?\n4) Reward Hacking\nQ\na′\nReward functions and discount factors define a task and the optimal solutions to this task. We introduce the \"Value Alignment Problem\", which\nconcerns the challenge of aligning the preferences encoded by reward functions (and discount factors) with human preferences.\n4.1)\nCoastRunners is a boat racing game. This video shows how the game should be played.\nOpenAI added this game to their internal testing suite for reinforcement learning algorithms, and they used the game's score as the reward function.\nThey found their learned agents achieved scores ~20% higher than human players; a success. This video shows an example gameplay for their agent.\nHow is it possible that an agent which scores better than humans repeatedly crashes into targets, and does not make progress toward the goal?\n4.2)\nCarla is an open source urban driving simulator that aims to support the development, training, and validation of autonomous driving systems. This\nsimulator formulates driving as an MDP, and has the following (simplified) reward function and discount factor:\nr = (1)Δd + (0.05)Δv + (-0.00002)Δc\nγ = 0.99\nΔd\nΔv\nΔc\n(∆c = 1)\n\nLet's suppose we wanted an autonomous vehicle to observe speed limits. Is this a good idea? How might we add something like this into our RL\nsystem?\n4.4)\nRecall that our reward functions in their general form depend only on state s and action a. This means that the reward function does not depend on\nthe history of states. Do you think alignment (say, to a specific individual's preferences) is always possible with a reward that depends only on the\ncurrent state? Does this limitation affect what aspects of the situation you'd want to include in the problem state?\nCheckoff 2:\nHave a check-off conversation with a staff member, to explain your answers.\nAsk for Help\nAsk for Checkoff\nFurther Reading\nYou can read more about the (common!) problem of reward mis-design in autonomous driving in this recent paper. (You might also ask: should we\neven be trying to formulate the autonomous driving task this way in the first place?)\nWe will continue to explore this topic of value alignment next week. In the meantime, if you're interested in learning more about misspecification of\nreward functions, these academic papers are a good place to start!\nConcrete Problems in AI Safety\nThe Effects of Reward Misspecification: Mapping and Mitigating Misaligned Models\nHere is a long un-curated list of \"objective-hacking\" in a variety of learning contexts.\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\nRES.TLL-008 Social and Ethical Responsibilities of Computing\nSpring 2023\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\nRES.TLL-008 Social and Ethical Responsibilities of Computing\nSpring 2023\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms"
        },
        {
          "category": "Resource",
          "title": "RES.TLL-008 Social and Ethical Responsibilities of Computing (SERC), 6.390: Introduction to Machine Learning, Regression Lab",
          "type": "PDF",
          "source_url": "https://ocw.mit.edu/courses/res-tll-008-social-and-ethical-responsibilities-of-computing-serc/mitres-tll008s23_6039_regression.pdf",
          "content": "Introduction to Machine Learning\n(Fall 2022)\nLab attendance check\nType in your section passcode to get attendance credit (within the first fifteen minutes of your scheduled section).\nPasscode:\nEnter\nInstructions\nIn 6.390 a large part of the learning happens by discussing lab questions with partners. Please complete this group self-partnering question then begin the\nlab.\nGroup information\nCreate/join a group\n1. One person (and only one) should create a group.\n2. Everyone else should enter the group name below (in the form groupname_0000 ).\nJoin group:\nSubmit\nTo join another group or leave your current group, reload the page.\nYou are not in a group.\nPlease refer to the course notes on Regression for definitions and explanations of basic concepts.\nLab 2\n1) Warm up\nAs a warm-up, discuss the following questions with your lab partner(s) and be ready to share your reasoning with your instructor:\n1.1)\nWhat is the difference between a learning algorithm and a hypothesis? Write down one possible hypothesis for a linear regression problem in which the\ninput dimension is d = 3. Name two learning algorithms that you know for linear regression.\n1.2)\nWe often use squared error as a loss function in regression. Can you think of a situation in which that might not be a good idea or other loss functions\nwould be better? (What would be a good loss function if you were trying to throw a ball of radius r into a circular hole of radius R?)\n\n2) Least-squares regression on a real data set\nIn this problem we will use linear regression to study the relationship between variables in a real public health dataset. Each data-point represents a U.S.\ncity, and it is characterized by a number of features characterizing aspects of the health of its population, each of which constitutes a dimension of the input\nassociated with that city. In this exercise, we will try to predict the attribute Percent_Person_Obesity based on the following other attributes:\nCount_Person\nMedian_Income_Person (k$)\nPercent_NoHealthInsurance(%)\nPercent_Person_PhysicalInactivity (%)\nPercent_Person_SleepLessThan7Hours (%)\nCommute_Time (min)\nPercent_Person_WithHighBloodPressure (%)\nPercent_Person_WithMentalHealthNotGood (%)\nPercent_Person_WithHighCholesterol (%)\nThe data we will be using contain the above information from 500 U.S. cities and is acquired from Data Commons, a free API combining publicly available\ndata from open sources.\nAs a simple illustration of the dataset, see below a plot of Percent_Person_Obesity vs Percent_Person_PhysicalInactivity using data from 50 random\ncities. (Does it look linear? What do you think linear regression will do on the data in this plot?)\nWe first separate the original 500 cities dataset into three training datasets\nTrain_small contains data from 10 large cities (SF, NYC, Atlanta, etc.)\nTrain_big contains data from 200 cities\nTrain_tiny contains data from 5 cities\nand one test dataset Test_data of 50 cities (different from those in the training sets).\nBecause these attributes are described in very different units (percentages, thousands of dollars, minutes, etc.) learning will work best if we pre-process\nthem so they are all roughly in the same range. (We'll study this process more in a few weeks.) Below, we will be using a black-box function that does linear\nregression on the processed data, then \"unprocesses\" the data and computes the error as well as plots the learned regression fits alongside the original\ndata. The processed datasets, together with the normalization coefficients used for scaling, are viewable at this online spreadsheet.\nOur goal is to learn a linear regression model using the training data such that it can make good predictions on the cities in Test_data .\nx\n\nIn ordinary least squares regression problems, we assume that our objective function\ncomes without a regularization term and only has a mean\nsquare error loss. In other words,\nwhere\nis the prediction made by the hypothesis, and\nis the actual sample output value. For our ordinary least squares case,\nis the squared loss\n, where we have made explicit that the hypothesis depends on both input data\n, and model parameters and\n. Recall that it is possible to solve an\nordinary least-squares regression problem directly via the matrix algebra expression for the optimal parameter vector in terms of the input data\nand\ndesired output vector\n:\nNote that above we have already added a row of all ones into\nand concatenated and\ntogether, making the hypothesis\n(so that the\nanalytic formula gives us both and\n!). We have written the expression for above in terms of our\nand\nmatrices where data-points correspond to\ncolumns; to make it match the notes and many other descriptions of regression (in which data points correspond to rows), you can use the\nversion of\nthe solution, which just works with the transposes of\nand\n. In the rest of the lab, we will implicitly use this \"augmented\" version of\nand ,\nunless otherwise specified.\nIn this section, we will explore the solutions that this analytic strategy produces. In the homework, we will actually implement this analytic strategy.\n1-D Regression\nWe start with a 1-dimensional regression first, so we can visualize the data by a 2D plot.\n2.1)\nWith the Train_small dataset and exactly one of the features above, what are the sizes of\n, , and\n?\nReminder: For labs, all members of a group should enter their answers in the answer checkers in order to get credit for those questions.\nEnter the size of\nas a list of [number_of_rows, number_of_columns]:\nCheck Formatting\nSubmit\nView Answer\nAsk for Help\nAs staff, you are always allowed to submit. If you were a student, you would see the following:\nYou have infinitely many submissions remaining.\nEnter the size of as a list of [number_of_rows, number_of_columns]:\nCheck Formatting\nSubmit\nView Answer\nAsk for Help\nAs staff, you are always allowed to submit. If you were a student, you would see the following:\nYou have infinitely many submissions remaining.\nEnter the size of\nas a list of [number_of_rows, number_of_columns]:\nCheck Formatting\nSubmit\nView Answer\nAsk for Help\nAs staff, you are always allowed to submit. If you were a student, you would see the following:\nYou have infinitely many submissions remaining.\nThe function test_analytic_regress below takes in the training dataset name (e.g., Train_small) and a list of feature names (from those listed above),\nfinds the parameters using the analytic regression formula, then evaluates the mean squared loss on Test_data and returns the test set loss as well as a\nplot of data alongside the learned predictor.\nTo answer the questions below, you should modify the arguments to test_analytic_regress as needed and then run the codebox by hitting\nSubmit.\nJ(θ, θ\n)\nJ(θ, θ\n) =\nL(g\n, a\n) =\nn\ni=1\n∑\nn\n(i)\n(i)\nL\n(h(x\n; θ, θ\n), y\n) ,\nn\ni=1\n∑\nn\ns\n(i)\n(i)\ng(i)\na(i)\nL\nL\ns\nx(i)\nθ\nθ\nθ\nX\nY\nθ = (XX )\nY .\nT -1\n(d+1)×n\nX\nT\nX\nθ\nθ\nY = θ X\nT\nθ\nθ\nθ\nX\nY\n,\nX~ Y~\nX\nY\nX\nθ\nθ\nX θ\nY\nX\nθ\nY\nθ\n\nRun Code\nSubmit\nView Answer\nAsk for Help\nAs staff, you are always allowed to submit. If you were a student, you would see the following:\nYou have infinitely many submissions remaining.\n2.2)\nRun the codebox above, using the Train_small dataset and the Count_Person feature. Do you think the fit or linear hypothesis is reasonable or helpful for\nthis case?\nUsing the Train_small dataset and exactly one of the features listed below, find the feature that gives you the lowest test set error.\nCount_Person\nPercent_Person_WithHighBloodPressure\nPercent_NoHealthInsurance\nMedian_Income_Person\nCommute_Time\nDoes this result make sense to you?\n2.3)\nNow use the feature you found in the previous problem (the one with the lowest test error) and train on Train_big. What do you observe and why? You\nshould use the codebox in the previous problem.\n2-D Regression\nNow let's make it more interesting with a 2-dimensional regression (so that the data is visualized by a 3D plot)!\n2.4)\nWith the Train_big dataset and exactly two features, what are the sizes of\n, , and\n?\nEnter the size of\nas a list of [number_of_rows, number_of_columns]:\nCheck Formatting\nSubmit\nView Answer\nAsk for Help\nAs staff, you are always allowed to submit. If you were a student, you would see the following:\nYou have infinitely many submissions remaining.\nEnter the size of as a list of [number_of_rows, number_of_columns]:\nCheck Formatting\nSubmit\nView Answer\nAsk for Help\nAs staff, you are always allowed to submit. If you were a student, you would see the following:\nYou have infinitely many submissions remaining.\nX θ\nY\nX\nθ\n# train_data can be 'Train_small', 'Train_big', 'Train_tiny'\n# features should be a list of strings. E.g ['Count_Person','Commute_Time']\ndef run():\nreturn test_analytic_regress(\ntrain_data = \"Train_small\",\nfeatures = [\"Count_Person\"]\n)\n\n3 ▾\n4 ▾\n\nEnter the size of\nas a list of [number_of_rows, number_of_columns]:\nCheck Formatting\nSubmit\nView Answer\nAsk for Help\nAs staff, you are always allowed to submit. If you were a student, you would see the following:\nYou have infinitely many submissions remaining.\n2.5)\nUsing the Train_big dataset and one of the feature pairs below, find the pair that gives you the lowest test set error. We've provided another codebox\nbelow for convenience; modify arguments as needed and hit the Submit button to run.\nCount_Person and Percent_Person_SleepLessThan7Hours\nPercent_NoHealthInsurance and Percent_Person_PhysicalInactivity\nPercent_Person_SleepLessThan7Hours and Median_Income_Person\nCommute_Time and Percent_Person_WithHighBloodPressure\nDoes the result agree with your intuition?\nRun Code\nSubmit\nView Answer\nAsk for Help\nAs staff, you are always allowed to submit. If you were a student, you would see the following:\nYou have infinitely many submissions remaining.\n2.6)\nCompare the lowest test set errors you got when using two features versus when using one feature.\n9-D Regression\nLet's now use all of the nine features. Unfortunately we can't easily visualize a 10D space, so we'll only see mean square error as output when running the\ncodebox below.\n2.7)\nRun the codebox below, where test_analytic_regress queries all nine features, and compare the test set losses when using Train_small vs. Train_big.\nY\n# train_data can be 'Train_small', 'Train_big', 'Train_tiny'\n# features should be a list of strings. E.g ['Count_Person','Commute_Time']\ndef run():\nreturn test_analytic_regress(\ntrain_data = \"Train_big\",\nfeatures = [\"Count_Person\",\n\"Percent_Person_SleepLessThan7Hours\"]\n)\n\n3 ▾\n4 ▾\n6 ▾\n\nRun Code\nSubmit\nView Answer\nAsk for Help\nAs staff, you are always allowed to submit. If you were a student, you would see the following:\nYou have infinitely many submissions remaining.\n2.8)\nIn our example, the size of the training set is at most 200 samples. Do you see any problems with our analytic regression if you were to attempt regression\nwith a very large training set size, e.g., as big as the population of the US (about 332 million)?\nWhat if we had a very large training set (again, perhaps 332 million samples), but now with many features per sample (e.g., 2 million features per each\nindividual)? Any problems with analytic regression in this case?\n2.9)\nIn the other extreme, let's try running analytic regression on the Train_tiny, which contains five cities, and use 'all_features'. You should use the\nprevious codebox. What do you see when you run the code? Can you explain why that is the case?\nCheckoff1:\nHave a check-off conversation with a staff member, to explain your answers.\nAsk for Help\nAsk for Checkoff\n3) A taste of regularization\nRecall the form of the regularized ridge regression objective:\n3.1)\nWhat happens to the learned regression line and what would you expect to happen to\n, with very large and very small (e.g., 0) values of ?\n3.2)\nIf our goal is to solely minimize\non the training dataset, what would be the best value of ?\n3.3)\nWhat purpose does adding the regularization term serve?\n3.4)\nJ\n(θ, θ\n) =\nridge\nL\n(h(x\n; θ, θ\n), y\n) +\nn\ni=1\n∑\nn\ns\n(i)\n(i)\nλ∥θ∥2\nJ\n(θ, θ\n)\nridge\nλ\n\nL\n(h(x\n; θ, θ\n), y\n)\nn\n1 ∑i=1\nn\ns\n(i)\n(i)\nλ\n#train_data can be 'Train_small', 'Train_big', 'Train_tiny'\n# features is a string: 'all_features'. (Do not change this)\ndef run():\nreturn test_analytic_regress(\ntrain_data = \"Train_small\",\nfeatures = 'all_features'\n)\n\n3 ▾\n4 ▾\n\nWhy don't we regularize the offset\nin ridge regression?\n3.5)\nCross validation\nCross-validation is a method that lets us estimate the performance of a learning algorithm on a data set. (Not a hypothesis! Make sure you are clear on\nthis point. Ask if not!)\nYou can think of changing a hyperparameter (like ) as changing the algorithm. So, we can use cross-validation to evaluate a choice of . For example,\nshown below is a validation curve obtained by doing leave-one-out cross-validation on a simple dataset, where we vary from 0.01 to 0.3.\nWhy is this the shape of the graph? What is the best value of , in terms of generalization performance, based on this data? Is it the same as the best value\nfor for performance on the training set, discussed in question 3.2 above?\nθ\nλ\nλ\nλ\nλ\nλ\nk\nIn this week's homework, you will actually implement -fold cross validation to select λ on the public health data!\n4) Bands of Bands\nIn many of our 6.390 labs, we will explore a variety of potential biases affecting machine learning. This week, we introduce aggregation bias.\nAggregation bias arises during model construction, when distinct populations are inappropriately combined. In many applications, the population of\ninterest is heterogeneous (i.e., consisting of dissimilar sub-populations) and a single model is unlikely to suit all subgroups.\nTo illustrate this, we look at a particular phenomenon called Simpson's paradox, which arises due to a form of aggregation bias.\n4.1)\nYou continue your foray into exploring Data Commons, and you make an interesting discovery about the relationship between age and blood pressure, as\nshown in the graph below! The blue line is produced from a linear regression on this data. What does this regression line indicate about the relationship\nbetween median age and high blood pressure?\n\n4.2)\nThis data is drawn from two different states: Mississippi (orange stars) and Vermont (green circles). If we plot separate regression lines for these different\ngroups as below, what does the graph tell us about the relationship between median age and high blood pressure? Why might aggregation of these two\ngroups reverse the relationship between age and high blood pressure?\n4.3)\nSimpson's paradox is a phenomenon in which a trend appears in multiple groups of data but disappears or is reversed when data is aggregated. Can you\nthink of a situation in which aggregating data could be harmful? Does this paradox mean we should not aggregate data, for risk of combining subgroups\ninappropriately? Can aggregating data ever be a good idea?\nCheckoff2:\nHave a check-off conversation with a staff member, to explain your answers.\nAsk for Help\nAsk for Checkoff\nFood for thought:\nRegression was first devised by Francis Galton, a Victorian scientist who is known as the \"father of eugenics.\" Galton's discovery of regression was motivated\nby his interest in applying heredity to \"improve the human race.\" He made the first regression line by plotting the diameter of sweet pea parental seeds\nagainst progeny seeds to examine whether exceptional physical traits were inheritable (see Figure). Galton subsequently introduced the idea of \"regression\ntowards mediocrity,\" in which he observed that extreme characteristics regress towards the mean of a distribution. Galton used these ideas to advocate for\n\"selective breeding.\"\nWhile Galton and other statisticians used their creations to advocate inhumane policies, this history does not invalidate the usefulness of regression. But,\nwhen you apply a statistical technique, consider: what are the limitations of this technique? How can your use of this technique create, perpetuate, or\namplify societal harms?\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\nRES.TLL-008 Social and Ethical Responsibilities of Computing\nSpring 2023\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms"
        },
        {
          "category": "Resource",
          "title": "RES.TLL-008 Social and Ethical Responsibilities of Computing (SERC), 6.390: Introduction to Machine Learning, Reinforcement Learning Lab",
          "type": "PDF",
          "source_url": "https://ocw.mit.edu/courses/res-tll-008-social-and-ethical-responsibilities-of-computing-serc/mitres-tll008s23_6039_reinforcement.pdf",
          "content": "Introduction to Machine Learning\n(Fall 2022)\nLab attendance check\nType in your section passcode to get attendance credit (within the first fifteen minutes of your scheduled section).\nPasscode:\nEnter\nGroup information\nCreate/join a group\n1. One person (and only one) should create a group.\n2. Everyone else should enter the group name below (in the form groupname_0000 ).\nJoin group:\nSubmit\nTo join another group or leave your current group, reload the page.\nYou are not in a group.\nReinforcement Learning\nDue: Monday, December 05, 2022 at 11:00 PM\nFor this lab:\nYou may find it useful to refer to the notes on Reinforcement Learning.\nDon't spend too long on any one question - use the help queue if you are stuck!\n1) Q-Learning Warmup\nIn this week's lab, we explore the Q-learning algorithm with different methods of setting up rewards.\n1.1) Q-Learning vs. Value-Iteration\nBefore proceeding, it is important to note the differences between the value iteration (VI) algorithm in the MDP notes versus the Q-learning (QL)\nalgorithm in the Reinforcement Learning notes to be explored in this week's lab.\n1.1.1)\nWhat is the principal difference between VI and QL algorithms?\n\nPick one:\ni) VI computes and outputs a value function; QL learns and outputs a policy.\nii) VI computes and outputs a policy; QL learns and outputs a value function.\niii) While running, VI has access to the true state transition function T and reward function R of the MDP, while QL does not.\niv) While running, QL has access to the true state transition function T but not the reward function R of the MDP, while VI has\naccess to both.\nSubmit\nView Answer\n100.00%\nAs staff, you are always allowed to submit. If you were a student, you would see the following:\nYou have infinitely many submissions remaining.\n1.1.2)\nIn which of these settings would you use QL, because VI is not applicable? Assume that the sizes of the state space for all of these are small enough\nso that tabular VI and QL are in principle applicable.\nChoose the Q-learning applications:\ni) Finding shortest paths to a goal for a robot in a grid with perfect transitions (perfect in the sense the exact probability is\ncompletely known).\nii) Finding paths to a goal with shortest expected length for a robot in a grid with noisy transitions with known transition\nprobabilities, given the state at each time step.\niii) Finding paths to a goal with shortest expected length for a robot in a grid with unknown noisy transition probabilities, given\nthe state at each time step.\niv) Playing a single-person video game, where we know the transition probabilities of the game at each time step given the state\nof the game and a score\nv) Playing a single-person video game, whose transition probabilities we don't know, given at each time step the state of the\ngame and a score.\nSubmit\nView Answer\n100.00%\nAs staff, you are always allowed to submit. If you were a student, you would see the following:\nYou have infinitely many submissions remaining.\n1.2) Q-Learning algorithm with different reward functions\nWe explore the Q-learning algorithm using a deterministic MDP with two possible actions (b and c) and four states (s0, s1, s2, s3). The transition\nmodel is\nT (s0, b, s1) = 1\nT (s0, c, s2) = 1\nT (s1, ∗, s0) = 1\nT (s2, ∗, s3) = 1\nT (s3, ∗, s3) = 1\nwhere ∗ represents either b or c.\nSome notes:\n1. All other transitions have probability 0.\n2. The goal state is s2, and s3 is a terminal state (similar to $ in the grid-world question we have looked at).\n3. Assume that if there are ties in the Q function for actions b and c in a state, then we pick action b.\n4. Assume the Q function is initialized to 0 for every state-action pair and that, after every episode (sequence of actions) of length 10, the agent is\nrestarted in state s0.\n5. Assume a learning rate (α) of 0.5.\n\n6. Assume an ε-greedy strategy with ε = 0.\n7. Assume a discount factor of 1.\nNote that we restart the agent in state s0 after every 10 steps because otherwise it may reach s3 and stay there forever.\n1.2.1)\nDraw a state transition diagram, like you drew in the MDP lab.\nNext, we will see two typical schemes for setting up rewards in domains with a goal state: Goal-reward based, and Stochastic-shortest-path (SSP)\nbased, and we will study how each scheme affects the exploration of the state space.\nGoal-reward\nIn the goal-reward case, every action taken from the goal state s2 gives an immediate positive reward of 1, and leads to a zero-reward next state (in\nfact terminal state) s3 that can never be escaped. Taking any action from any state other than the goal state provides zero reward. In other words, we\nhave a reward function which outputs 0 for every state-action pair, except for R(s2, ∗) = 1.\n1.2.2)\nWhat action will be selected the first time the agent encounters\n? And why (explain why during the checkoff)?\nb\nc\nSubmit\nView Answer\n100.00%\nAs staff, you are always allowed to submit. If you were a student, you would see the following:\nYou have infinitely many submissions remaining.\ns0\n1.2.3)\nWhat action will be selected the second time the agent encounters\n? And why (explain why during the checkoff)?\nb\nc\nSubmit\nView Answer\n100.00%\nAs staff, you are always allowed to submit. If you were a student, you would see the following:\nYou have infinitely many submissions remaining.\ns0\n1.2.4)\nWhat action will be selected the hundredth time the agent encounters\n? And why (explain why during the checkoff)?\nb\nc\nSubmit\nView Answer\n100.00%\nAs staff, you are always allowed to submit. If you were a student, you would see the following:\nYou have infinitely many submissions remaining.\ns0\nStochastic shortest path\nIn the stochastic shortest path (SSP) case, we put zero reward on taking any action from the goal state. Every action taken from the goal state s2\nleads to a zero-reward terminal state s3 that can never be escaped. We put -1 in rewards everywhere else. In other words, we have a reward\n\nfunction which outputs -1 for every state-action pair except R(s2, ∗) = R(s3, ∗) = 0.\n1.2.5)\nWhat action will be selected the first time the agent encounters\n? And why (explain why during the checkoff)?\nb\nc\nSubmit\nView Answer\nAsk for Help\nAs staff, you are always allowed to submit. If you were a student, you would see the following:\nYou have infinitely many submissions remaining.\ns0\n1.2.6)\nWhat action will be selected the second time the agent encounters\n? And why (explain why during the checkoff)?\nb\nc\nSubmit\nView Answer\nAsk for Help\nAs staff, you are always allowed to submit. If you were a student, you would see the following:\nYou have infinitely many submissions remaining.\ns0\n1.2.7)\nWhat action will be selected the hundredth time the agent encounters\n? And why (explain why during the checkoff)?\nb\nc\nSubmit\nView Answer\nAsk for Help\nAs staff, you are always allowed to submit. If you were a student, you would see the following:\nYou have infinitely many submissions remaining.\ns0\n2) Q-Learning in a 2D grid\nNow, we'll take a look at Q-learning in a simple 2D grid setting but with a single goal location. We'll adopt the same state space and action space as\nin MDP lab.\nSpecifically, our state space is a 10-by-10 grid, with the bottom-left state indexed as state (0, 0), and our four possible actions are moving North,\nSouth, East or West (note that if the robot tries to move off the board, it cannot; it just stays in the same state). Our single goal is at state (3, 6).\nRemember that for Q-learning, the transition probabilities and reward values are not known in advance by the method--the agent just gets to\nobserve state, action, and reward values as it moves through the domain.\nSome notes (please read!):\nA new episode is started by sampling the first state uniformly at random.\nThe agent follows an epsilon-greedy policy with ε = 0.1.\nEvery action taken from the goal state leads to a zero-reward state that can never be escaped. Thus, to continue learning, we repeat the steps\nabove. Note that we start a new/reset episode only after the agent reaches the goal state.\nIn the case of a tie in the value max Q(s, a) across actions a, we choose the \"best\" action randomly.\na\nAll transitions are noisy; that is, there is some non-zero probability of the agent moving somewhere different from its desired destination. For\nexample, say the agent in in state (0,0) and takes a \"North\" action, there is a non-zero chance that it actually ends up in state (1,1).\nOur γ (discount factor) is set to 0.9 and our α (learning rate) is set to 0.5.\n\nNote that the scale of the colors changes across the different plots, per the bar on the right of each plot.\n2.1) Goal reward\n2.1.1)\nRecall that we are interested in learning the value of taking the best actions starting at a given state. In Q learning, we try to learn these values. But for\nthe moment in this sub-question, suppose we actually knew these \"true\" max Q(s, a) values exactly. Also suppose that taking an action in the goal\na\nstate yields a reward of 100. What is the highest value (a number) for the function maxa Q(s, a) among all state-action input pairs? Roughly what is\nthe max Q(s, a) value when s is a direct neighbor of the goal state (to answer this, ignore the error probabilities and imagine that the actions\na\nalways take the robot to the intended location)?\n2.1.2)\nNow let's go back to Q-learning (where we don't know the true values of states and want to learn them).\nBelow are plots of the maximum Q values max Q(s, a) at different points during an execution of Q learning, with the iteration number shown in\na\nthe title.\n\nWhat has been happening for the first 100 steps of Q-learning?\n2.1.3)\nAt iteration 500, why does the state at (3, 6) have value 50?\n2.1.4)\nAt iteration 1000, how many more times do you think the agent reached the goal state?\n2.1.5)\nAt iteration 10,000, how close are the values plotted (our estimates of the true value of taking the best actions starting at the given state) to the actual\nvalue of taking the best actions starting from the given state?\nIn particular, what should the value of the bottom-right corner be? (To make this easier to think about, you can assume that the transitions are\ndeterministic; that is, the robot always moves in the direction it is \"aiming\".)\n2.2) Stochastic shortest path\nThese are plots of the maximum Q values of the states max Q(s, a) using the SSP formulation as we run 10,000 iterations of Q-value learning,\na\nplotting at specific iterations. Note that the scale of the colors changes across the different plots, per the bar on the right of each plot.\n\n2.2.1)\nAt iteration 100, this is a pretty strange picture. At first we thought we had bugs! Remember that the squares are colored according to the maximum\nof Q(s, a) over all actions in that state, and that they are all initialized to 0. What can we say about the squares that are colored yellow? What about\nthe squares colored blue?\n2.2.2)\nAt iteration 100, how can it be possible for (6, 6) to be colored blue, when all its neighbors are yellow?\n2.2.3)\nAt iteration 100, is there a state where we have tried all the actions twice?\n2.2.4)\nAt iteration 1000, there is a yellow block in the upper left and lots of the policy arrows are pushing the agent to go up there. Why? Is that desirable\nbehavior in this problem? What if there is more than one goal state?\n2.2.5)\nAt iteration 10,000, how close are the values plotted (our estimates of the true value of taking the best actions starting at the given state) to the actual\nvalue of taking the best actions starting from the given state? Roughly what should the value in the bottom right corner be? (Assume that the\ntransitions are deterministic.)\nCheckoff 1:\nHave a check-off conversation with a staff member, to explain your answers.\nAsk for Help\nAsk for Checkoff\n3) No Exit\nRecall that the hyperparameter epsilon ( ) characterizes a trade-off between exploration and exploitation in reinforcement learning. When we use an \"\nε\nε-greedy\" strategy in Q learning, we take a completely random action with probability ε; and with probability 1 - ε, we take the action that'd lead to\nthe highest Q value, i.e. we take arg max Q(s, a).\na\nWe'll explore how choosing the value of epsilon affects the performance of Q learning in a very simple game.\n3.1) Intuition\n\nThe choice of epsilon can affect the overall behavior of Q-learning. Let's consider three possible values for epsilon: 0.0, 0.5, and 1.0.\n3.1.1)\nWhich of these epsilon values risks never finding the optimal policy? --\nSubmit\nView Answer\nAsk for Help\nAs staff, you are always allowed to submit. If you were a student, you would see the following:\nYou have infinitely many submissions remaining.\n3.1.2)\nWhich of these epsilon values has the highest risk of spending way too much time exploring parts of the space that are unlikely to be\nuseful? --\nSubmit\nView Answer\nAsk for Help\nAs staff, you are always allowed to submit. If you were a student, you would see the following:\nYou have infinitely many submissions remaining.\n3.1.3)\nWhich of these epsilon values is guaranteed to cause optimal behavior during learning? --\nSubmit\nView Answer\nAsk for Help\nAs staff, you are always allowed to submit. If you were a student, you would see the following:\nYou have infinitely many submissions remaining.\n3.2) Experience\nFor this part, you will use a Colab notebook we have prepared for you. You can find the Colab notebook here.\nOnce you run the code, wait patiently until you see a yellow and purple square on a teal background (you may need to scroll down from the \"score\"\nand \"reward\" text lines printed out). Ignore everything else for now. Click play in the button right below the square. This is a movie of a policy playing\nthe game No Exit. It's kind of like Pong: the purple square is the \"ball\" and the yellow square is your \"paddle\". The actions are to move the paddle up,\ndown, or keep it still.\nThe state is specified by the positions and velocities of the ball and paddle, with a special added \"game over\" state.\nThe transition model is a very approximate physics model of the ball reflecting off walls and the paddle, except if the ball gets past the paddle in the\npositive x direction, the game is over.\nThe agent gets a reward of +1 on every step it manages to survive.\nWhen watching the game play out, you'll sometimes see that the purple square gets near the right-hand border and then suddenly it changes to a\nstate with the purple square in the bottom left and the yellow one in the upper right -- this means that the game terminated and then reset to the\ninitial state.\nNow we can go back and look at the other output in the notebook:\nFirst, we print what happens during learning in the format (number of iterations, average score): after every 10 iterations of batch Q learning, we\ntake the current greedy policy and run it to see what its average score is. This score represents how long the episode ran before the ball ran off\nthe map, or 100 if it lasted for that long.\nNext is a plot of the score as a function of number of iterations.\nFinally, we run the greedy policy with respect to the last Q-value function for 10 games and report the rewards achieved on each game. We also\nshow a movie clip from a handful of these 10 games.\n\n3.2.1)\nWhat is the maximum possible score in the game? What is the minimum possible score?\n3.2.2)\nRun the code given on the notebook for values of ε in the set 0, 0.5, 1. Does your observation match your answers from 3.1?\nRemember that this is a small instance, so sometimes the random noise of the environment might prevent you from seeing any useful information.\nRun the notebook two or three times if something doesn't line up with your expectation, and then ask for help.\n4) Value Alignment\nLast week we first learned about the problem of \"value alignment\", which aims to ensure the values embedded in AI agents are aligned with human\nvalues.\n4.1)\nIf a reward function is value-aligned (to a specific individual's values), is an agent which used this reward function to learn necessarily also aligned?\nWhy or why not?\n4.2)\nPhilosophers argue over how AI agents should be aligned to human values. Assume, again, that we only want to create an agent which is aligned to a\nspecific person's values. Should this agent be aligned to:\nThe human's instructions?\nThe human's intentions?\nThe human's expressed behaviors?\nBehaviors which are in the 'best interest' for the human?\nAnd why?\nTo make this concrete, you might want to think about recommendations - like those of Netflix. Think about a person who aspires to watch more\n\"good\" films. This person might search for Oscar-winning films (their instructions). But perhaps they're really looking for Cannes-winning films (their\nintent), but they often spend their time watching reality TV instead (their expressed behaviors). Perhaps Netflix thinks it is actually in their best interest\nto watch more documentaries.\n(An article from Iason Gabriel at DeepMind has some nice discussions and formalization of this topic: Goal Misgeneralization)\n4.3)\nIn our consideration of the value alignment problem thus far, we have made a big assumption: that we only want to create agents which align with a\nspecific individual's values. In practice, agents will inevitably interact with many people with different value systems, and from different cultures and\nreligions with different values.\nHow might you try to design a reward function or agent in the face of conflict across different value systems? What are the pros and cons of your\nproposal?\nConsider, for example, writing a reward function for an autonomous vehicle. In a terrible scenario, an autonomous vehicle might have to choose\nbetween saving one of two people: one an elder and one a child. Research has shown that people from Western cultures often express a preference\nfor saving the child, while Eastern cultures express a preference for saving the elder. How might we think about reconciling these preferences? This is\nan open question, so we're not looking for 'correct' answers. Instead, we're looking for thoughtful, creative answers!\nCheckoff 2:\nHave a check-off conversation with a staff member, to explain your answers.\nAsk for Help\nAsk for Checkoff\n\nFurther discussions of these questions:\nThis study of moral preferences for autonomous vehicles is based off of research from MIT!\nMoral Machines\nHow East and West Differ on Who a Self Driving Car Should Save\nFurther reading:\nArtificial Intelligence, Values, and Alignment\nAI Alignment, Philosophical Pluralism, and the Relevance of Non-Western Philosophy - LessWrong (A talk transcript by MIT PhD student Tan Zhi\nXuan)\nFood for (lighter) thought\nThis blog post includes a little game that illustrates multi-armed bandits, which are non-sequential (environment resets after each action)\nreinforcement-learning problems. You can compare how well you do against some classic approaches to solving these problems. And, you can help\nsave the world from Bieber.\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\nRES.TLL-008 Social and Ethical Responsibilities of Computing\nSpring 2023\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms"
        },
        {
          "category": "Lecture Notes",
          "title": "RES.TLL-008  Social and Ethical Responsibilities of Computing (SERC), STS.047 Quantifying People: A History of Social Science Lecture",
          "type": "PDF",
          "source_url": "https://ocw.mit.edu/courses/res-tll-008-social-and-ethical-responsibilities-of-computing-serc/9fd9e6dd436baf1b7d0be9ff0011d48c_RES-TLL-008F21-STS047.pdf",
          "content": "STS.047\nQuantify and Punish:\nData, Race, and Policing\nFrom the Burgess Method to Big Data\nModule 11\n(c) NYPD. All rights reserved. This content is excluded from our Creative Commons license. For more information, see https://ocw.mit.edu/help/faq-fair-use/\n\nLogistics\n▪\nFor next Thursday: come\nprepared to give a brief\n(3/5 minute) presentation\non an empowering work\nof recent social science\n▪\nIndividually or in pairs (if\nin pairs, both partners\nshould talk, presentation\nshould be proportionally\nlonger)\n▪\nSlides/visuals optional...\n▪\nPost links on Canvas\nboard\n(c) NYPD. All rights reserved. This content is excluded from our\nCreative Commons license. For more information, see\nhttps://ocw.mit.edu/help/faq-fair-use/\n\nToday's Plan\nI.\nStatistics, policing, and\nracial injustice: an overview\nII. Crime statistics and the\n\"condemnation of\nblackness,\" c. 1890-1940\nIII. Risk assessment and the\n\"actuarial\" approach to\npolicing and punishment,\nfrom the Burgess Method\n(1928) to AI\nIV. \"Data-driven\" policing from\nCompStat (1990s) to Big\nData\n(c) NYPD. All rights reserved. This content is excluded from our\nCreative Commons license. For more information, see\nhttps://ocw.mit.edu/help/faq-fair-use/\n\nQuantify and Punish: Overview\n▪\nModule 11 considers: what role have\nquantitative data, computational methods,\nand social science played in the\nconstruction of modern systems of\ncriminal justice?\n▪\nHow has quantification contributed to the\ninjustices of modern policing and\npunishment - to the creation and\nmaintenance of a system that\ndisproportionately and unjustly targets,\npunishes, incarcerates, and kills people\nof color, especially Black citizens?\n▪\nWhat can history tell us about the role that\ndata and computation should - or should\nnot - play in efforts to create a more just\nsystem of justice in the future?\n(c) Chicago Police Department. All\nrights reserved. This content is\nexcluded from our Creative Commons\nlicense. For more information, see\nhttps://ocw.mit.edu/help/faq-fair-use/\n\nQuantification-Race-Policing: Big Themes\n▪\nTurn to data and quantification\noften driven by desire to create\nfairer, more accountable, less\nbiased systems - often in\nresponse to crisis, calls for reform\n▪\nWhile quantitative turn has\nbrought some positive effects and\nreforms, it has also brought harms\n▪\nEfforts to quantify policing and\npunishment rely on historical\ndata, which reflect biases of\nprevious system - histories of data\nshape their futures\n▪\nData is always already mediated\nthrough previous criminal justice\napparatus - the crime data\" is in\nfact always \"policing data\"\n(c) NYPD. All rights reserved. This content is excluded\nfrom our Creative Commons license. For more\ninformation, see https://ocw.mit.edu/help/faq-fair-use/\n\nQuantification-Race-Policing: Big Themes\n▪\nIn fact, data has played a central\nrole in the historical construction\nof ideas about criminality that\nundergird structural racism of\nmodern criminal justice system\n▪\nComputational tools can obscure,\nlaunder, and exacerbate existing\npatterns of discrimination -\nbehind veil of \"objectivity\"\n▪\nThe establishment of quantitative\nsystems for guiding and\nevaluating policing can reshape\npolicing behaviors in detrimental\nways:\n▪\n\"Ratchet effects\"\n▪\n\"Juking the stats\"\n(c) NYPD. All rights reserved. This content is excluded\nfrom our Creative Commons license. For more\ninformation, see https://ocw.mit.edu/help/faq-fair-use/\n\nCrime, Numbers, and Social Science\n\"Cartes figurative: Crimes contre les proprietes / Crimes contre les personnes.\" Two\nlithograph maps within one border, 21.5 × 33 cm. From Quetelet's Sur l'homme et le\ndeveloppement de ses facultes; ou, Essai de physique sociale, 2 vols. in 1 (Brussels: Louis\nHauman, 1836) [Historic Maps Collection]. (Princeton Historical Maps Collection)\nImage is in the public domain.\n\nThree Episodes\n▪\nCrime statistics and the\n\"condemnation of\nblackness,\" c. 1890-1940\n▪\nRisk assessment and the\n\"actuarial\" approach to\npolicing and punishment,\nfrom the Burgess Method\n(1928) to AI\n▪\n\"Data-driven\" policing from\nCompStat (1990s) to Big\nData\n(c) Northpointe, NYPD. All rights reserved. This content is\nexcluded from our Creative Commons license. For more\ninformation, see https://ocw.mit.edu/help/faq-fair-use/\nImage is in the public domain.\n\nCrime statistics and the \"condemnation of\nblackness,\" c. 1890-1940\n\nThe Statistical Condemnation of Blackness\n▪\nIn 2011 book, Khalil Gibran\nMuhammad argues that\nstatistics played a crucial role\nin the establishing a link\nbetween Blackness and\ncriminality\n▪\nNotion that criminality was a\nfeature of Black Americans as a\ngroup, while crime by white\nAmericans was masked as\nindividual failure\n▪\n\"Black criminality [became] the\nmost significant and durable\nsignifier of black inferiority in\nwhite people's minds\" (p. 3)\n▪\nGibran argues this link was\nforged in the Jim Crow era\n(1890-1940)\n(c) Khalil Gibran Muhammad/Harvard University Press. All rights\nreserved. This content is excluded from our Creative Commons license.\nFor more information, see https://ocw.mit.edu/help/faq-fair-use/\n\nThe 1890 Census\n▪\n1890 Census was a watershed\nmoment\n▪\nContext: 25 years after\nemancipation; more than a\ndecade after end of\nReconstruction - question of\nstatus and future of African\nAmericans in American society\n▪\n1890 census publicized data\nabout prison populations by\nrace: Black Americans were\n12% of population and 30% of\nprisoners\n▪\nStatistical racists like Frederick\nT. Hoffman (Module 7) drew\nheavily on 1890\nImage is in the public domain.\n\nComparing Black and Foreign-Born\n▪\nCrucial to the creation of what\nMuhammad calls the \"statistical\nghetto\" was comparison\nbetween Black and foreign-born\nwhite Americans\n▪\nProgressive era social scientists\ninterpreted (or dismissed)\nstatistics on crime by European\nimmigrants as evidence that\nIrish, Italians, Poles, etc. could\nbe assimilated into US culture\n▪\nCharles R. Henderson, U.\nChicago sociologist, 1901: \"the\n[evil of immigrant crime] is not\nso great as statistics carelessly\ninterpreted might prove...\"\n(c) Khalil Gibran Muhammad/Harvard University Press. All rights\nreserved. This content is excluded from our Creative Commons license.\nFor more information, see https://ocw.mit.edu/help/faq-fair-use/\n\nComparing Black and Foreign-Born\n▪\nHenderson (1901), cont'd: But\nwhere the \"Negro factor\" is\nconcerned, \"racial inheritance,\nphysical and mental inferiority,\nbarbarian and slave ancestry\nand culture...\" were among the\n\"most serious factors in crime\nstatistics.\"\n(c) Khalil Gibran Muhammad/Harvard University Press. All rights\nreserved. This content is excluded from our Creative Commons license.\nFor more information, see https://ocw.mit.edu/help/faq-fair-use/\n\nRisk assessment and the \"actuarial\"\napproach to policing and punishment, from\nthe Burgess Method (1928) to AI\n\n\"Positive Criminology\" & \"Individualization\"\n▪\nKey finding of 19th c. quantitative\nsoc. sci. was regularity of \"laws\"\nof crime - Quetelet's \"budget of\nthe scaffold\"\n▪\nCrime was not random, but\npredictably steady\n▪\nAdvocates of \"positive\ncriminology\" like Cesare\nLombroso (1835-1909) and\nCharles Goring (1870-1919)\nheld criminals were not\nrandomly chosen from\npopulation\n▪\nCriminality seen to be correlated\nwith home conditions, physical\ntraits, genetic makeup,\nneighborhood, and race\nThis image is in the public domain.\n\n\"Positive Criminology\" & \"Individualization\"\n▪\nCirca 1900: international interest\nin the \"individualization of penal\ntreatment\"\n▪\nNational Conference on Criminal\nLaw and Criminology, 1909: U.\nChicago law profs. Ernst Freund\nand Roscoe Pound set agenda:\n▪\n\"Modern science recognizes that\npenal or remedial treatment\ncannot possibly be\nindiscriminate and machine-like,\nbut must be adapted to the\ncauses, and to the man as\naffected by those causes\"\nThis image is in the public domain.\n\nErnest Burgess and Parole Prediction\n▪\nGoal of \"Individualization\"\nencouraged move toward\nindeterminate sentencing for\ncrimes: local parole boards to\ndetermine length of sentence\n▪\n1920s: researchers like Hornell\nHart (Iowa Child Research\nStation) argue that statistics\nmight make it possible to\ncreate a \"prognostic score for\neach man coming up for\nparole\"\n▪\nRobert Burgess (1886-1966):\nPhD in Sociology from U.\nChicago in 1913; faculty 1916\n▪\nCo-wrote Introduction to the\nScience of Sociology w. Chicago\nmentor Robert Park (1921)\nErnest W. Burgess photographed by\nStephen Deutch, University of Chicago\nPhotographic Archive, apf1-02325, Special\nCollections Research Center, University of\nChicago Library.\n(c) University of Chicago. All rights reserved. This\ncontent is excluded from our Creative Commons\nlicense. For more information, see\nhttps://ocw.mit.edu/help/faq-fair-use/\n\nErnest Burgess and Parole Prediction\n▪\nBurgess emphasized quant.\nmethods over \"ecological\"\napproach dominant at Chicago\n▪\nBurgess: \"Prediction is the aim\nof the social sciences as it is of\nthe physical sciences.\" (1929)\n▪\n1927-28: Burgess and four\ncolleagues requested by\nchairman of Illinois parole\nboard to study Ill. procedures\n▪\nUnderstaffed, overworked\nparole officials in Ill. had been\nunable to give much attention\nor deliberation to parole cases\n▪\nBurgess conducts study of 3,000\nparole cases in Illinois ~1920-\nErnest W. Burgess photographed by\nStephen Deutch, University of Chicago\nPhotographic Archive, apf1-02325, Special\nCollections Research Center, University of\nChicago Library.\n(c) University of Chicago. All rights reserved. This\ncontent is excluded from our Creative Commons\nlicense. For more information, see\nhttps://ocw.mit.edu/help/faq-fair-use/\n\nErnest Burgess and Parole Prediction\n▪\nBurgess attempted to find a\nstatistical relationship between\nwho did/did not violate terms\nof parole and 22 other\nindependent factors\n▪\nFactors included: racial and\nethnic categorization, social &\npersonality type, mental age,\ncircumstances of crime, and\nprior criminal record\n▪\nBurgess develops 21-factor test:\nthose with high scores (16-21)\nhad low parole-offense rates\n(1.5%); those with low scores\n(2-4) had highest offending\nrates (76%)\n▪\nReading for this module...\nErnest W. Burgess photographed by\nStephen Deutch, University of Chicago\nPhotographic Archive, apf1-02325, Special\nCollections Research Center, University of\nChicago Library.\n(c) University of Chicago. All rights reserved. This\ncontent is excluded from our Creative Commons\nlicense. For more information, see\nhttps://ocw.mit.edu/help/faq-fair-use/\n\nThe Burgess Method Takes Hold\n▪\nBurgess Method implemented\nquickly at Joliet Penitentiary,\n1932-33\n▪\n1932 election: Democratic wave\nleads to Dem. Governor elected\nin IL; appoints John Landesco,\nBurgess's research assistant, to\nState Parole Board\n▪\nLandesco urges IL legislature to\npass bill to hire sociologists and\nactuaries to \"make analyses and\npredictions in the cases of all men\nbeing considered for parole\"\n▪\n1930s-40s: Adoption of Burgess\nMethod in IL triggers outpouring\nof academic research\nIllinois State Penitentiary, Joliet\n(Source)\n(c) Source unknown. All rights reserved. This content is\nexcluded from our Creative Commons license. For\nmore information, see https://ocw.mit.edu/help/faq-fair-\nuse/\n\nThe Burgess Method Takes Hold\n▪\nOthers seek to critique, improve\nBurgess Method through more\ndata and development of new\nrisk-assessment tools using\ndifferent variables and weighting\ndifferent variables more/less\n▪\nSome explored more\nsophisticated statistical\ntechniques (e.g. multiple\nregression) to develop\nassessment tools\n▪\nResearchers studying Burgess\nMethod found prominent\npositions at top institutions like U.\nChicago, Harvard Law School,\nUniversity of Southern California,\nand University of Minnesota\nIllinois State Penitentiary, Joliet\n(Source)\n(c) Source unknown. All rights reserved. This content is\nexcluded from our Creative Commons license. For\nmore information, see https://ocw.mit.edu/help/faq-fair-\nuse/\n\n▪\nFor the first few decades,\napplication actuarial parole\nmethods confined to Illinois\n▪\nOther states begin to adopt\nsimilar tools in 1960s\n▪\nPrior to 1970s, race and\nnationality were common\nfactors in these tools\n▪\nEarly 1970s: federal gov't\nadopts slim, 7-factor \"Salient\nFactor Score\"\n▪\nFederal adoption stimulates\nwidespread interest in\nparole prediction tools - first\nin California, then wave of\nother states in the 1980s-90s\nFrom Harcourt, Against Prediction: Policing,\nPunishing, and Profiling in an Actuarial Age\n(Chicago, 2007), p. 9.\nThe Actuarial Approach Takes Off\n(c) Bernard Harcourt. All rights reserved. This content\nis excluded from our Creative Commons license. For\nmore information, see https://ocw.mit.edu/help/faq-\nfair-use/\n\nFrom Harcourt, Against Prediction: Policing, Punishing, and Profiling in an Actuarial Age (Chicago, 2007), p. 9.\nThe Actuarial Approach Takes Off\n(c) Bernard Harcourt. All rights reserved. This content is excluded from our Creative Commons license. For more information, see\nhttps://ocw.mit.edu/help/faq-fair-use/\n\nExample of a criminal sentencing\nworksheet from the Virginia\nCriminal Sentencing Commission\n(Source)\n(c) Commonwealth of Virginia. Virginia Criminal\nSentencing Commission.. All rights reserved. This\ncontent is excluded from our Creative Commons\nlicense. For more information, see\nhttps://ocw.mit.edu/help/faq-fair-use/\n\nFrom Parole Prediction to Profiling\n▪\nBy 1951, Burgess argued\nactuarial risk assessment\ncould be applied much more\nwidely than parole selection\n▪\nLater part of the 20th century\nsaw adoption of risk-\nassessment methods to\npolicing potential crimes as\nwell (\"profiling\")\n▪\n1968: Federal Aviation\nAdministration implements\n\"airline-highjacker\" profile -\n25 characteristics\n▪\n1970s+: increasing use of\nprofiles for specific crimes\n\"drug-courier\"\nImage from hijacking of TWA flight 847, 1985\n(CNN)\n(c) JOEL ROBINE/AFP/Getty Images. All rights reserved.\nThis content is excluded from our Creative Commons\nlicense. For more information, see\nhttps://ocw.mit.edu/help/faq-fair-use/\n\n▪\nStarting in 1969, IRS began\nto use computerized\nassessment of past income\ntax returns to develop\npredictive tools (secret\n\"Discriminant Index\nFunction\") to flag income tax\nreturn for audit\nFrom Parole Prediction to Profiling\nImage from hijacking of TWA flight 847, 1985\n(CNN)\n(c) JOEL ROBINE/AFP/Getty Images. All rights reserved.\nThis content is excluded from our Creative Commons\nlicense. For more information, see\nhttps://ocw.mit.edu/help/faq-fair-use/\n\nSocial Costs of Prediction: the \"Ratchet\"\n▪\nLegal scholar Bernard Harcourt\nand others have identified\ncrucial social costs to the\nactuarial, predictive approach\nto criminal justice\n▪\nUsing statistical techniques to\ntarget policing/ punishment\nwill increase success rate of\nsearches, audits, parole\ndecisions, etc.\n▪\nMore searches (of specific\ngroup) will find more\ncontraband...\n▪\nMore parole denials (of\nspecific group) will prevent\nre-offenses...\n(c) Bernard Harcourt, University of Chicago Press. All rights reserved. This content is excluded from our Creative Commons license. For more information, see\nhttps://ocw.mit.edu/help/faq-fair-use/\n\nSocial Costs of Prediction: the \"Ratchet\"\n▪\nIf the actuarial methods\ndisproportionately target a\nspecific group - e.g. drywall\ncontractors for tax audits,\nyoung Black men for street\nfrisks - then over time the extra\npolicing attention will produce\nmore infractions from that\ngroup\n▪\nThis may be taken as\nconfirmatory evidence that the\nspecific group offends at a\nhigher rate (not that the group\nis under heightened attention)\n▪\nThis creates a \"ratchet\":\nincreased police attention more evidence of infractions increased police attention ...\n(c) Bernard Harcourt, University of Chicago Press. All rights reserved.\nThis content is excluded from our Creative Commons license. For more\ninformation, see https://ocw.mit.edu/help/faq-fair-use/\n\nSocial Costs of Prediction: the \"Ratchet\"\n▪\nsubject to police contacts, even with\nsmall/no punishment or for minor\ninfractions, can have significant social\ncosts\n▪\nHarcourt: \"Disproportionate criminal\nsupervision and incarceration reduces\nwork opportunities, breaks down families\nand communities, and disrupts\neducation.\" (161)\np.\n(c) Bernard Harcourt, University of Chicago Press. All rights reserved. This content is excluded from our Creative Commons license. For more information, see\nhttps://ocw.mit.edu/help/faq-fair-use/\n\nAlgorithmic Predictions and Their Biases\n▪\nToday, \"risk assessment\" for\ncriminal sentencing and parole are\nincreasingly conducted by\nalgorithms\n▪\nE.g. the COMPAS -- Correctional\nOffender Management Profiling for\nAlternative Sanctions - algorithm\nfrom for-profit company\nNorthpointe\n▪\nAlgorithmic risk scores widely\nused in assigning bail, criminal\nsentencing, and parole decisions\n▪\nAs of 2016, risk scores given\ndirectly to judges during\nsentencing in at least 11 states\n▪\nCOMPAS algorithm based on 137\nquestions/data points; not race\n(c) Northpointe. All rights reserved. This content is\nexcluded from our Creative Commons license. For more\ninformation, see https://ocw.mit.edu/help/faq-fair-use/\n\nAlgorithmic Predictions and Their Biases\n'The survey asks defendants such\nthings as: \"Was one of your parents\never sent to jail or prison?\" \"How\nmany of your friends/acquaintances\nare taking drugs illegally?\" and\n\"How often did you get in fights\nwhile at school?\" The questionnaire\nalso asks people to agree or\ndisagree with statements such as \"A\nhungry person has a right to steal\"\nand \"If people make me angry or\nlose my temper, I can be\ndangerous.\"'\nJulia Angwin, Jeff Larson, Surya Mattu\nand Lauren Kirchner, \"Machine\nBias,\" ProPublica (May 23, 2016).\n(c) Northpointe. All rights reserved. This content\nis excluded from our Creative Commons\nlicense. For more information, see\nhttps://ocw.mit.edu/help/faq-fair-use/\n\nAlgorithmic Predictions and Their Biases\n▪\n2016 study by ProPublica found\nthat COMPAS algorithm was...\n▪\n...very bad at predicting violent\ncrime: 20% of those predicted to\ncommit future violent crime did\n▪\n...only moderately good at\npredicting all crime (including\nmisdemeanor): 61% of those\ndeemed likely recidivists\ncommitted future crimes\n▪\n...racially biased: Black\ndefendants much more likely to\nbe flagged incorrectly as likely\nre-offenders (false positive), and\nwhite defendants more likely to\nbe mislabeled as low risk (false\nnegative)\n(c) Northpointe. All rights reserved. This content is\nexcluded from our Creative Commons license. For more\ninformation, see https://ocw.mit.edu/help/faq-fair-use/\n(c) Julia Angwin, Jeff Larson, Surya Mattu and Lauren\nKirchner, ProPublica. All rights reserved. This content is\nexcluded from our Creative Commons license. For more\ninformation, see https://ocw.mit.edu/help/faq-fair-use/\n\nAlgorithmic Predictions and Their Biases\n(c) Julia Angwin, Jeff Larson, Surya Mattu and Lauren Kirchner, ProPublica. All rights reserved. This content is excluded from our\nCreative Commons license. For more information, see https://ocw.mit.edu/help/faq-fair-use/\n\n\"Data-driven\" policing from CompStat\n(1990s) to Big Data\n\nBill Bratton and Data-Driven Policing\n▪\nNo single individual more\nresponsible for expansion of\n\"data-driven policing\" than\nBill Bratton\n▪\nAcross two stints as police\nchief in NYC and one in LA,\nBratton led three major\nexpansions of use of data\nand computation\n▪\nCritically: in all three cases,\nBratton was brought in to\nreform police depts. in crisis\n▪\nIn each case, Bratton turned\nto data and computation as a\nremedy for corruption, mal-\npractice, and bias\n(c) TIME. All rights reserved. This content is excluded from\nour Creative Commons license. For more information, see\nhttps://ocw.mit.edu/help/faq-fair-use/\n\nCompstat: Quantitative Policing in the '90s\n▪\nEarly 1990s, NYC experiencing\nhigh crime and raft of police\ncorruption\n▪\nMollen Commission (created\n1992) revealed widespread,\nunchecked corruption in NYPD:\n\"characterized by brutality,\ntheft, abuse of authority, and\nactive police criminality.\"\n▪\n1994: Mayor Rudolph Giuliani\nappoints Bratton new Police\nCommissioner; previously\nBoston police chief and head of\nNYC Transit Police\n▪\nAs head of Transit Police,\nBratton had overseen work of\nJack Maple\nhttps://www.innovations.harvard.edu/compst\nat-crime-reduction-management-tool\n(c) Harvard. All rights reserved. This content is excluded\nfrom our Creative Commons license. For more information,\nsee https://ocw.mit.edu/help/faq-fair-use/\n\nJack Maple's \"Charts of the Future\"\n▪\nJack Maple started in NYPD in 1970;\nbecame a transit police officer, inc.\nundercover Times Square / 42nd\nStreet Station\n▪\nIn 1970s-80s, subways major sites\nof crime, esp. violent robberies\n▪\nAs detective, Maple took to\nmapping patterns of subway crime\nwith pushpins on wall maps -\n\"Chart of the Future\"\n▪\nCharts allowed Maple to observe\nrepeated patterns in subways\ncrimes - large %age of crimes from\nserial offenders tracing set routes\n▪\nTargeting policing to key locations\ndisrupted these patterns; led to\n27% reduction in subway crime\nJack Maple (Source)\n(c) unknown. All rights reserved. This content is excluded from our\nCreative Commons license. For more information, see\nhttps://ocw.mit.edu/help/faq-fair-use/\n\nCompStat in Practice\n▪\nWhen appointed Commissioner\nin 1994, Bratton promoted Maple\nfrom lieutenant to Deputy Chief\n▪\nMaple and Bratton institute new\nCOMPuterized STATistics\nprogram\n▪\nCompStat required personnel\nfrom each of city's 77 precincts\nand other units to submit weekly\nreport on complaints, arrests,\nsummons, open crimes, etc.\n▪\nNYPD CompStat system\nproduced regular reports\nshowing weekly, monthly, annual\ntrends\nhttps://www.innovations.harvard.edu/c\nompstat-crime-reduction-management-\ntool\n(c) Harvard. All rights reserved. This content is excluded\nfrom our Creative Commons license. For more information,\nsee https://ocw.mit.edu/help/faq-fair-use/\n\nCompStat in Practice\n▪\nSystems of regular meetings with\nleading NYPD officials and\nprecinct/unit commanders\nenabled sharing of data,\ndiscussion of crime control\nstrategies, and oversight of units\n▪\nOne key objective of CompStat\nincluding improving accountability\nand professionalism of local force\nwhile giving more responsibility to\nlocal commanders\n▪\nAlso sought to address problems\nof inadequate police attention in\ncertain areas: e.g. major crimes in\npoor, predominantly Black and\nLatinx areas outside Manhattan\ncore went routinely unsolved\nhttps://www.innovations.harvard.edu/c\nompstat-crime-reduction-management-\ntool\n(c) Harvard. All rights reserved. This content is excluded\nfrom our Creative Commons license. For more information,\nsee https://ocw.mit.edu/help/faq-fair-use/\n\nThe \"Marvel\" of CompStat\n▪\nInstitution of CompStat coincided\nwith notable decline in crime in\nNew York City - inc. stark\ndecline in murders, from record\n2,245 in 1990 to 673 in 2000 (and\n289 in 2018)\n▪\nBratton publicly targeted 10%+\nreductions in crime; achieved\n12% in first CompStat years\n▪\nNYT called results under Bratton\n\"marvel of modern law\nenforcement\"; \"simply\nbreathtaking\"\n▪\nBut debate over role of CompStat\nin decline in crime (decline\nbegan in 1990, before CompStat,\nand occurred across major\ncities)\n(c) TIME. All rights reserved. This content is excluded from\nour Creative Commons license. For more information, see\nhttps://ocw.mit.edu/help/faq-fair-use/\n\nThe \"Marvel\" of CompStat\n▪\nApparent successes of CompStat\nin New York led to widespread\nuptake of data-driven methods\nacross other US police\ndepartments over early 2000s,\ninc. Philadelphia, Miami,\nChicago, Baltimore, DC, San\nFrancisco, etc.\n▪\n2002: Bratton recruited to lead\nLos Angeles PD; wracked by\nlongstanding abuses, poor\ncommunity relations, poor\nmorale, and major corruption\nscandal in anti-gang unit\n(\"Rampart Scandal\")\n▪\nBratton instituted CompStat in LA\n(c) TIME. All rights reserved. This content is excluded from\nour Creative Commons license. For more information, see\nhttps://ocw.mit.edu/help/faq-fair-use/\n\nThe \"Marvel\" of CompStat\n▪\nFor opposing perspectives on\nthe role of CompStat in crime\ndecline:\nLauren-Brooke Eisen, Oliver\nRoeder, and Julia Bowling, \"What\nCaused the Crime Decline?\" The\nBrennan Center for Justice (Feb. 12,\n2015)\nSteven D. Levitt, \"Understanding\nWhy Crime Fell in the 1990s: Four\nFactors that Explain the Decline and\nSix That Do Not,\" Journal of\nEconomic Perspectives 18, no. 1\n(Winter 2004): 163-190.\n(c) TIME. All rights reserved. This content is excluded from\nour Creative Commons license. For more information, see\nhttps://ocw.mit.edu/help/faq-fair-use/\n\n\"Juking the Stats\": Critiques of CompStat\n▪\nIntroduction of CompStat had\nmajor effects on practice and\nculture of policing\n▪\nIncreasing political, managerial\nemphasis on reducing CompStat\nnumbers created pressure on\ncommanders and officers to make\nit appear crime was falling\n▪\nEmphasis on measurable stats\ndistracted from public safety\ngoals, community relationships\n▪\n\"Juking the Stats\": statistical\nmanipulation designed to make\nCompStat figures appear better:\ne.g. through reclassifying crimes\ninto lesser categories (aggravated\nassaults assaults)\nMayor Rudolph W. Giuliani, right, and\nPolice Commissioner William Bratton at a\n1995 news conference reporting a decline\nin crime statistics.James Estrin for The New\nYork Times.\nhttps://archive.nytimes.com/www.nytimes.\ncom/interactive/2013/12/06/nyregion/bratt\non-on-the-issues.html - /\n(c) James Estrin/The New York Times. All rights\nreserved. This content is excluded from our Creative\nCommons license. For more information, see\nhttps://ocw.mit.edu/help/faq-fair-use/\n\n\"Juking the Stats\": Critiques of CompStat\n▪\nRewarding measurable indicators of\npolice activity - e.g. arrests and\ntickets - incentivized officers to\nincrease punishment for minor\noffenses (e.g. transit fare evasion,\nvandalism, loitering)\n▪\nEspecially combined with \"broken\nwindows\" theory (as in Bratton in the\n90s): theory that rigorously policing\nminor \"anti-social\" crimes creates\nenvironment of order, lawfulness that\nprevents more serious crime\n▪\nBlack and Latino citizens dis-\nproportionately targets of minor-\ncrime enforcement: 2001-2013, Blacks\nand Latinos in NY (57% of population)\nwere 80% of misdemeanor arrests\nand summonses\n(c) James Estrin/The New York Times. All rights\nreserved. This content is excluded from our Creative\nCommons license. For more information, see\nhttps://ocw.mit.edu/help/faq-fair-use/\n\n\"Juking the Stats\"\nThe Wire, Season 4, Episode 9\n(2006).\n\nThe Rise of Big Data Policing in the 2000s\n▪\nBratton returned as NYPD\nchief Jan. 1, 2014 - in wake of\nwidespread anger about\n\"stop-and-frisk\" and legal\nruling declaring it\nunconstitutional\n▪\nBratton oversees\nconstruction of real-time\ncrime-command center in\nManhattan; orders tens of\nthousands of crime mapping\ntablet computers\n▪\n\"Intelligence-led policing\"\npurported to go beyond\n\"hunches,\" offer alternative\nto stop and frisk\nNYPD Joint Operations Center (City Journal)\n(c) Victor Milsoslvsky/NYPD. All rights reserved. This content\nis excluded from our Creative Commons license. For more\ninformation, see https://ocw.mit.edu/help/faq-fair-use/\n\nData & the Who/Where/When/How of Policing\n▪\nWhom...\n▪\nIn 2012, Kansas City PD used\nsocial-network analysis to\nidentify 884 people deemed\nlikely to commit homicides \"focused deterrence\"\n▪\nChicago developed\nalgorithmic \"heat list\" to\nidentify likely perpetrators and\nvictims of gum violence\n▪\nWhere...\n▪\nJeff Brantingham (UCLA) uses\nearthquake-prediction\ntechniques to develop PredPol\nalgorithm for identifying likely\nsites of crime implemented\nby LAPD in 2011 (25%\nreduction in burglaries)\n\nData & the Who/Where/When/How of Policing\n▪\nWhen...\n▪\nNetworks of surveillance\ndevices (cameras, license\nplate readers, etc.) used for\nreal-time tracking and alerts;\ne.g. NYPD-Microsoft \"Domain\nAwareness system\" monitoring\nsouthern Manhattan\n▪\nHow...\n▪\nData mining to search\n\"cellular, digital, and\nbiological data trails\"\n▪\nFacial recognition\n▪\nNotably, much of this done in\nconcert with private for-profit\ncompanies - as in Palantir and\nLAPD Real-Time Analysis Critical\nResponse section\n\nThe Future of Big Data and Policing?\n▪\nAndrew Guthrie Ferguson\nproposes five-point checklist for\nsafe application of big data\ntechniques:\n1.\nCan you identify the risks your\ntechnology is trying to address?\n2.\nCan you defend the inputs into\nthe system?\n3.\nCan you defend the outputs\n(how they will impact policing\npractice/community)?\n4.\nCan you test the technology\n(transparency/accountability)?\n5.\nIs police use of the technology\nrespectful of the autonomy of the\npeople it will impact?\n▪\nOr, abolish big data? (Data for\nBlack Lives)\n(c) Data for Black Lives. All rights reserved. This content\nis excluded from our Creative Commons license. For\nmore information, see https://ocw.mit.edu/help/faq-fair-\nuse/\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\nRES.TLL-008 Social and Ethical Responsibilities of Computing (SERC)\nFall 2021\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms"
        },
        {
          "category": "Resource",
          "title": "RES.TLL-008 Social and Ethical Responsibilities of Computing (SERC), 17.64 The Road to Crisis",
          "type": "PDF",
          "source_url": "https://ocw.mit.edu/courses/res-tll-008-social-and-ethical-responsibilities-of-computing-serc/mitres_tll008_17-64_crisis2.pdf",
          "content": "The Road to Crisis\nDuring a press conference in mid-December 2021, President Biden announced plans to provide Taiwan with\nadditional Patriot air defense systems, two-dozen new F-16 fighter jets, eight surplus P-3 maritime patrol\naircraft, and five naval destroyers equipped with Aegis Combat Systems. Biden explained that the arms deal--\none of the largest in Taiwan's history--was intended to bolster Taiwan's ability to defend itself and its\ndemocratic way of life. In response to questions from reporters, President Biden also reiterated a pledge that\nhe had made in October: \"If China attacks Taiwan, the United States will take steps to defend Taiwan.\"\nThat evening, China's Foreign Minister Wang Yi issued an official statement criticizing the arms deal and\naccused the United States of \"meddling in regional affairs\" and \"dangerously and unnecessarily escalating\ntensions.\"\nIn the days following Biden's press conference, the People's Liberation Army (PLA) significantly increased\nmilitary flights through Taiwan's Air Defense Identification Zone. In a 72-hour period from December 20\nDecember 23, the PLA Air Force (PLAAF) and PLA Navy (PLAN) flew more than 180 aircraft in the airspace\nsurrounding Taiwan. Taiwan's government responded by scrambling fighter jets to intercept many of these\nPLAAF and PLAN aircraft.\nOn December 24, a PLAAF Su-27 fighter jet collided with a Taiwan Air Force F-16 fighter jet, leading to the\ndeaths of both pilots. The domestic public in China takes to the streets demanding harsh action against Taiwan\nto avenge the death of the PLAAF pilot.\nPresident Biden and Secretary of State Blinken urge calm, but also warn China--both privately and publicly--\nto not attempt to forcefully change the status of Taiwan.\nOn December 25, Christmas celebrations in the Taiwanese cities of Taipei and Kaoshiung are interrupted by\nextensive blackouts. More than a million people are left without power, and 279 Taiwanese citizens die as a\nresult of the power outages (e.g., life support failures, etc.).\nRecorded Futures, the Somerville, Massachusetts-based company that identified the Chinese malware behind\npower outages that plagued Indian cities during the Sino-Indian conflict of 2020, make a similar discovery in\nthis case: the Taiwan backouts are almost certainly triggered by Chinese malware. The discovery was made\npossible by advances in machine learning that allowed Recorded Futures to find common patterns between the\ntimings of sequential cyber-intrusion attacks in India and Taiwan. Recorded Futures identified a record of\nattempts to connect to the same infrastructure registered to Tsinghua University that was implicated in the\nIndian outages. In the China-India incident, analysts believed China was signaling its ability to cause significant\ndamage if India escalated the border conflict. The U.S. intelligence community has yet to confirm that the\nblackout is the result of a Chinese cyberattack, and some AI/ML scholars have raised doubts about the accuracy\nof the Recorded Futures machine learning algorithms.\nPresident Biden schedules an emergency National Security Council Principals Committee meeting for this\nafternoon. You've been called into the office to help your organization prepare for this meeting. You open\nyour email to find President Biden's strategic objectives for dealing with the crisis:\n1. Maintain status quo (i.e., no change to the status of Taiwan).\n2. Protect U.S. citizens and interests in the People's Republic of China (PRC) and Taiwan.\n3. Prevent further escalation between the PRC and Taiwan.\n4. Should the PRC and Taiwan escalate, minimize direct U.S. combat involvement in conflict.\n\nMove 1:\nDecember 26, 2021\n(30 minutes followed by 15 minute \"report back\")\nAs the death toll in Taipei and Kaoshiung continues to climb, your teams begin formulating the initial U.S.\nresponse. The FBI and NSA also reports increased evidence of Chinese intelligence collection in the United\nStates. Specifically, Chinese \"consular\" officials have been started taking photos of U.S. military and port\nfacilities in Hawaii, Alaska, California, and Washington, and there have been increased phishing attempts against\nsenior U.S. military officers.\nThe list below includes tasks for each team.\nDepartment of State:\n-\nWhat actions, if any, should the United States take to protect American citizens and interests in\nChina/Taiwan?\n-\nWhat coordination, if any, should the United States take with allies and partners within the Asia-Pacific\nregion and beyond?\n-\nPrepare talking points for the Secretary of State that he can use to offer brief comments on the situation\nif asked by reporters. Ensure these are aligned with the whole of government position.\nDepartment of Defense:\n-\nWhat military measures, if any, should the United States take at this point? These measures could\ninclude mobilization/deployment of forces, kinetic/non-kinetic action, etc.\n-\nPrepare talking points for the Secretary of Defense and Chairman of the Joint Chiefs that they can use\nto offer brief comments on the situation if asked by reporters. Ensure these are aligned with the whole\nof government position.\nOffice of the Director of National Intelligence:\n-\nWhat additional information does your team (and the other Executive Branch agencies) need?\n-\nHow will you obtain this information (i.e., which intelligence disciplines are best suited to collect this)?\nDepartment of Homeland Security:\n-\nWhat steps should the United States take to protect the U.S. homeland from kinetic and non-kinetic\nattacks?\nDepartment of Justice:\n-\nWhat actions should the Department of Justice take to mitigate the risk of espionage against the United\nStates during this period of heightened tensions? Which organizations will DOJ need to coordinate\nwith?\nWhen formulating your recommendations, ensure you respond to the defined tasks/questions and ensure your recommendations are\nin line with President Biden's objections. You are encouraged to coordinate with the other Executive branch agencies when developing\nyour response.\n\nMove 2:\nDecember 28, 2021\n(35 minutes followed by 15 minute \"report back\")\nOn December 27th, Taiwan's President Tsai Ing-Wen declares a state of emergency in Taipei and Kaoshiung,\nwhere power still remains out. She also orders a limited mobilization of Taiwan's reserve forces (including 3000\ninfantry personnel) and puts 40 civilian fishing vessels and 8 civilian Boeing airliners from China Airlines under\nthe operational control of the Ministry of Defense. Tsai publicly states these measures are to \"support\nhumanitarian relief operations,\" but also makes a secret call to President Biden in which she expresses fear that\nChina may attempt to use military force to seize Taiwan in the coming weeks.\nAlthough large numbers of PLA ground, naval, and air forces continue to flow into China's Eastern Theater\nCommand, U.S. intelligence has no specific indication of an impending attack. China's defense minister,\nhowever, issues the warning that \"outside nations should not meddle in China's internal affairs. Unnecessary\nmeddling will risk a significant heightening of tensions.\"\nIn the early morning hours of December 28th, Guam--a U.S. territory that is home to Anderson Air Force\nBase and several key U.S. naval facilities--suffers a significant cyberattack that significantly degrades operations\nat Anderson and kills 3 Americans at Guam Medical Center in the city of Tamuning. Intelligence assessments\nsuggest with high confidence that China's military is behind the data breach and cyberattack on Guam\nAt the same time, ransomware locks down systems at sea and airport facilities in Long Beach, Los Angeles,\nOakland, San Francisco, and Seattle--all facilities that would be used to deploy material into the Pacific Theater.\nAn unknown actor demands $500 million to unlock the systems. Security analysis identifies the attack as Conti\nransomware deployed via a spearphishing attack that compromised employee accounts lacking multi-factor\nauthentication. The Conti Ransomware Gang is known to perform ruthless attacks on life-critical systems, but\nin this case, the NSA and DHS are unable to attribute the ransomware attack's initiator.\nEvents also continue to unfold in Asia. The identities of U.S. diplomatic and intelligence personnel stationed\nat diplomatic posts throughout Asia are posted on Chinese social media sites, which urge \"loyal Chinese\npatriots\" to track down and hold these individuals accountable for \"aggression against China.\" Intelligence\nanalysis of Chinese operations reveals that information about these personnel were likely obtained through the\nSolarWinds leak in early 2020.\nOn top of actions in the cyber domain, China has detained four U.S. citizens working for Ford in Shanghai,\naccusing them of espionage.\nIn this move, teams do not have specific tasks. Instead, determine what actions you believe your agency is responsible for and develop\na set of policy recommendations. Again, ensure the recommendations are in line with the president's objectives and are coordinated\nwith the other agencies. President Biden, however, has tasked the NSC to address three specific points (ensure, however, that you\nconsider all events that have transpired):\n-\nThe president seeks advice on retaliation for the cyberattack on Guam. Specifically, he asks for legal\nand military/intelligence guidance on 1) the legality of a retaliatory cyberattack and 2) an assessment\nof the risks of spillover effects that impact non-military actors in China (he is concerned about the\nlegal, political, and ethical implications of harming civilians)\n-\nHow to address the ransomware incident?\n-\nWhat actions can the United States take to deter further aggression against the U.S. homeland and\nTaiwan without significantly escalating tensions?\n\nMove 3:\nJanuary 5, 2021\n(40 minutes, followed by 20 minute brief)\nIn the days following the cyberattack on Guam, PLA forces continued to flow into the mainland areas near\nTaiwan. In response, Taiwan ordered a full mobilization of its reserve forces and heightened its military alert\nlevel on December 29th. That evening, President Biden issued a public statement again urging calm in the\nTaiwan Strait Crisis of 2021, and reiterated Washington's support for Taiwan's democratic system.\nEfforts to remove the ransomware have been largely ineffective and the port facilities remain closed. The port\nclosure has had several follow-on effects. First, the inability to load/un-load ships has led to a back-up of\nshipping vessels both off the western U.S. coast and in key chokepoints, including the Panama Canal. Shipping\nanalysts have described the port closures as having the potential to generate a larger impact on global trade than\nthe 2021 Ever Given incident. The U.S. Chief of Naval Operations has voiced concerns that delays at the\nPanama Canal could make it difficult to reposition naval vessels in the event of conflict. Closer to home, fears\nthat the port closure will exacerbate global supply chain issues has led to Americans to begin stockpiling\nhousehold goods. In Los Angeles, large scale protests erupt as port workers take to the streets criticizing the\nU.S. government of its inability to resolve the ransomware incidents. Other actors take advantage of the protests\nto loot homes and businesses around the city. Amid the chaos, protestors set the Chinese Consulate in Los\nAngeles ablaze, resulting in the death of two Chinese consular officials. The governor of California activates\nthe National Guard to restore calm. Governors in several other states including Washington, Texas, Florida,\nand New York follow suit as a preemptive measure.\nChina's foreign minister condemns \"the violent attack\" on its Los Angeles Consulate and publicly lambasts the\nUnited States for failing to uphold its responsibilities under the Vienna Convention on Consular Relations. As\nprotests outside of U.S. diplomatic and consular facilities in China mount, the Chinese foreign ministry\nannounces they are no longer able to ensure the security of U.S. consulates in China and orders the immediate\nclosure of U.S. consulates in Shanghai, Nanjing, and Guangzhou. These facilities support some of the largest\npopulations of American citizens in China.\nU.S. intelligence indicates that a U.S.- based Taiwan-activist group is taking advantage of the protests to\ndeliberately target Chinese diplomatic facilities and may be planning to attack Chinese diplomats and consular\nofficials in major U.S. cities. While some officials in the DHS and DOJ push for search warrants (and forced\nnondisclosure, to keep the search under wraps) to inspect electronic communications of protest attendees, they\nface pushback from internal groups that believe the warrant would grossly violate the privacy of innocent\ncitizens exercising their protest rights.\nOn January 3rd, a U.S. Air Force RQ-4 unmanned reconnaissance aircraft flying 50 miles north of Taiwan\ncrashes into the East China Sea after U.S. operators lose contact with the aircraft. Initial reports suggest that\nChinese disturbance signals jammed the drone signal and disrupted communication with its operators. A frigate\nfrom Taiwan's Navy sailing to the crash site to help recover wreckage suffers an explosion, killing 17 Taiwanese\nsailors. Although it is too soon to assess the cause of the explosion, members of Taiwan's public are calling for\nmilitary retaliation against China.\nAt home, American pundits and politicians are calling on President Biden to resolve the situation. Hawks are\ncalling for action to punish China for causing the incident; some doves have demanded that Biden cut back\nelements of the arms deal as an olive branch to China; while others simply hope the U.S. stays out of the rapidly\nescalating conflict in Taiwan.\nDetermine how your agency can best respond to the events that have transpired in this move and develop a set of policy\nrecommendations. What are the most important issues that your agency must wrestle with? Again, ensure your recommendations\nare in line with the president's objectives and are coordinated with the other agencies.\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\nRES.TLL-008 Social and Ethical Responsibilities of Computing (SERC)\nFall 2022\nFor information about citing these materials or our Terms of Use, visit:\nhttps://ocw.mit.edu/terms"
        },
        {
          "category": "Resource",
          "title": "RES.TLL-008 Social and Ethical Responsibilities of Computing (SERC), 6.031 Moral Lenses",
          "type": "PDF",
          "source_url": "https://ocw.mit.edu/courses/res-tll-008-social-and-ethical-responsibilities-of-computing-serc/mit_restll008_6-031_moral.pdf",
          "content": "Moral Lenses\nAbby Everett Jaques\nMIT\nWhen you make something, your efforts may go well or badly in many ways.\nThings may go well in that you may benefit yourself, by furthering your career, or\nenjoying the feeling of using your skills, or creating something people admire. You\nmay benefit others--your company, your family, your users, or even society at\nlarge. Or things may go badly, so that your project is a stain on your career or\nyour reputation, a harm to others, even a danger to the world. Often, things will\ngo well in some ways, and less well in others. Sometimes there are tradeoffs, even\npainful ones.\nEvaluating your project ethically is about understanding all the ways it goes well\nand badly. It's about tallying up all the things your project does--not just in the\nnarrow sense in which you might conceive it at first, but in as much richness and\ndimension as you possibly can--and then thinking through the ways in which\nwhat it does is good and bad (sometimes both at once!), and for whom.\nTo assess your project ethically, you'll use four moral lenses, each of which offers\nyou a way of looking at a project in order to see what's good or bad about it.\nThe lenses complement each other: each one gives you a different perspective.\nSome change the scale at which you're considering the project, as a microscope or\ntelescope does. Some make particular features visible and obscure others, as\nlenses that filter certain wavelengths do. The lenses provide goals and guardrails:\nthings to aim for and things to avoid.\nSometimes the lenses will agree; other times something that seems fine when\nviewed with one lens will seem worrying or even egregious with another. When\nthat happens, you need to think about how the people affected would weigh\nvarious harms and benefits--and remember that others may weigh things\ndifferently than you do.\n\nA Process for Ethical Engineering\nTo use the lenses, you first need to think about everything that will be different if\nyour project exists and operates. When you make things, you change things; the\nworld is altered. In what ways? Some are small: you may check something off\nyour to-do list; your boss may add something to your list of accomplishments for\nyour performance review; users may gain a new feature in a familiar app. But\nothers are larger: you may get funding for your startup; users may change how\nthey perform an important activity in their lives; old ways of doing things may\ndie off, so that some people lose their jobs, economies both regional and national\nsuffer or thrive; and so on.\nOnce you've thought of as many ways a project will and may change things as\nyou can, notice all the different people and groups who are affected, and how the\neffects are similar or different depending on who you're talking about.\nNext, use the lenses to get clear about the ways in which particular effects on\nparticular groups are good and bad. The same thing may be good for one group\nbut bad for another, or good in one way and bad in another way for a single\ngroup, and so on.\nFinally, revisit your project's design: How can you maximize the good and\nminimize the bad features you've identified? How will you justify your choices to\nthe people and groups affected by them? Maybe your project needs to be quite\ndifferent. Maybe you shouldn't pursue it at all, because something else would be\nbetter.\nYou can think of this process as involving four steps:\n1.Differences: Think through all the things your project does, all the ways\nthe world is different with your project in it.\n2.Players: Catalog the people and groups who are affected by those\nchanges.\n3.Values: Use the lenses to understand how the differences your project\nmakes for each person or group are good and bad.\n4.Design: Think about which of your design choices affects the good and\nbad aspects of your project overall. How can your decisions shape the\nbalance and distribution of harms and benefits? Iterate your project in\nlight of steps 1-3 and your new understanding of how your engineering\nchoices are also ethical choices. Then repeat this process with the new\nMoral Lenses\nJaques\n\nproject, until you arrive at a version that seems to achieve the best\nbalance of benefits and harms for all the affected groups.\nStep 1: Finding Differences\nYou make things because you want to change things. You want to provide a\nbetter way to do something, or enable something never possible before. You can\nthink of the changes your project makes in layers of nested systems:\n- Layer 1: changes in the system that includes you, your team, your\norganization\n- Layer 2: changes in the systems that contain your users, your\ncompetitors, the activities your software performs/replaces/changes\n- Layer 3+: changes in the systems that enclose the first 2 layers: the\nlarger business or institution that contains the activities from layer 2, the\nindustry of which that business or institution is a part; the larger\neconomy of which that industry is a part; and so on.\nIn each layer, think of as many changes, or potential changes, as you can. Make a\nlist, and when you think of a change in one layer, ask yourself how it would affect\nthe others. The idea is to understand all the changes that will or may happen--\nbig or small; good, bad, or in between--as a result of the existence and operation\nof your project.\nOne way to tackle this step is to work forward, starting from what you expect\nyour project to do and imagining how those things will cause further effects.\nAnother way is to work backward: look at similar projects that you or others\nhave created, where you know what (some) of their effects were, and see if or how\nthose effects map to your project, given its similarities and differences compared\nto the previous one.\nYou can also consult the work of experts in other fields: each layer involves\nsystems, from companies and other organizations to the health care system, the\ngovernment, and the economy. Social scientists know a lot about how those\nsystems work, and have important insights to offer. Depending on the specifics of\nyour project, there may be various kinds of experts who've already developed the\ninsights you need. Don't hesitate to seek them out.\nA combination of these approaches is often the best bet.\nMoral Lenses\nJaques\n\nExample: Suppose you make a new app that can perform the tasks of a\nroutine medical checkup. Layer 1 changes may include completing a\nproject you've been assigned by your boss; your organization's being able\nto go public; etc. Layer 2 changes may include enabling people without\neasy access to medical care to get checkups outside of doctors' offices or\nenabling nurses to administer checkups without MDs (one or both of those\nmay have been a design goal from the start, but one may not have been\nthe original plan). Layer 3 changes may include medical practices reducing\ntheir number of primary care physicians; higher up we may see insurers\nrequiring the use of the app instead of in-person appointments; medical\nstudents shifting away from primary care specialties; changes to the\nfederal budget because of cost savings on Medicare and other federally\nfunded programs, unemployment and/or retraining needs among primary\ncare physicians, etc.\nStep 2: Identifying Players\nImagine all the changes you identified in Step 1 were parts of a story, a movie.\nWho would be in the cast? Notice all the people and groups you've identified--\nyou and your boss, your users and your competitors, and so on. Don't just think\nabout who'd have starring roles; remember that the extras matter too: sometimes\nvery important ethical effects are those that are small at the individual level but\nmatter because they involve so many people, even if those people might initially\nseem far from the center of the action.\nNotice too that sometimes you'll need to subdivide groups: your software may\nwork differently for some subsets of users; it may affect some non-users more than\nothers, etc. Again you can think in layers: at each layer from Step 1, who is\naffected? Remember to capture secondary effects, too: if some parents are directly\naffected, there may be important indirect effects on their children, for example.\nOr if primary care doctors are directly affected, the nurses and other employees in\ntheir practices may be indirectly affected.\nAdd the relevant people and groups, subdivided as needed, to each change on\nyour list from Step 1.\nExample: Keep thinking about the medical checkup app. Lots of people\nand groups came up in describing the changes in each layer: you, people in\nyour company, patients, doctors, medical students, hospital\nMoral Lenses\nJaques\n\nadministrators, insurers, and more. And some of those groups will need to\nbe subdivided: we imagined patients being required to use the app instead\nof in-person appointments, but that might be true only for less affluent\npatients; people with very high-end insurance might not be subject to the\nrequirement, for example.\nStep 3: Using the Four Lenses\nNow that you know how your project makes a difference, and for whom, it's time\nto get clear on which of those differences are good and bad, and in what ways.\n(Some differences will be good in one way, and bad in another.) That's what the\nlenses are for.\nI. The Outcomes Lens: When we make something, the state of the world is\naltered. What changes when your project is created/used/maintained? In what\nway(s) do things turn out better or worse vs the starting state?\n‣ Ask: What good or bad thing, tangible or intangible, does each person or\ngroup have more or less of? (health, wealth, power, freedom, security,\ntime, burritos?)\n‣ This lens is about costs and benefits.\nExample: Users of the checkup app may save time and money by using it:\nthose are outcome benefits to them. (Though if the app is less good than\na doctor at detecting some medical conditions, your users may also lose\nhealth by using it. This would be an outcome harm.) Given the problems\nin the US health care system, an app like yours might be very valuable:\nyou and your company might well make a lot of money. That would be an\noutcome benefit. On the other hand, some primary care doctors might\nlose their jobs; that would be an outcome harm.\nII. The Process Lens: it's not just what happens, but how. Even if the\noutcome is good, it can still be that something has gone wrong. How is each\nperson or group treated by, and in, this process? Are rules followed? Rights\nrespected? Duties fulfilled?\n‣ Ask: Did people have a chance to consent or refuse? (Note that EULAs\nthat are too long to read and too full of jargon to understand do not yield\nmeaningful consent.) Were they deceived (which undermines their ability\nto meaningfully consent)? Was someone used in ways they might object\nMoral Lenses\nJaques\n\nto? Was their privacy violated? Did people have the kinds of control they\nare entitled to, or were important things out of their hands? Were\nprocedures/rules/etc. followed as people reasonably expect?\n‣ This lens is about the means by which outcomes are produced.\nExample: Think about our checkup app again. If many people would\nprefer to talk to a human doctor rather than using the app, but their\ninsurer won't allow it, then the existence of the app reduces those people's\ncontrol of how they receive medical care. This is a process harm to those\npeople, even though to other people the additional option may be a\nprocess benefit.\nNow imagine the app can monitor people's health without their knowing\nit (thanks to some fancy hardware/peripherals that check vital signs at a\ndistance using radio waves, plus some data collection about people's\nactivities from their phone accelerometers, calendars, etc, plus more data\ncollection from the Alexas in people's homes that hear what they talk\nabout, their tone of voice, whether they sneeze and cough...).\nEven if people can gain important health information this way--an\noutcome benefit--it is nonetheless a process harm. Individuals are\nsupposed to get to decide what medical care they get, generally speaking,\nbecause control of what happens to your own body is important. Having\nthis app collect data about everyone could also provide important\noutcome benefits to the population as a whole--say, by supporting\nmedical research, enabling early intervention with outbreaks of infectious\ndiseases, and so on. But again, if people do not have the opportunity to\nconsent or deny consent, there is a process harm. And of course, if you\nwere monetizing all this health data, you or your company might gain\nthat outcome benefit. But that does not negate the process harm.\nIII. The Structure Lens: how are outcomes distributed among people and\ngroups? what are the differences in how people and groups are treated in the\nprocess? what are the patterns of harm and benefit?\n‣ Ask: Is everyone treated equally? If not, what is the basis for the\ninequality? Do the patterns of harm and benefit track historical patterns\nof advantage and disadvantage, for example by privileging people of a\ncertain race or gender, or do they mitigate historical patterns? Does the\ndistribution of harms and benefits look fair, or unfair?\nMoral Lenses\nJaques\n\n‣ Remember to consider both outcomes and process when you're thinking\nabout the distribution of harms and benefits: in other words, you want to\npay attention not only to the patterns in who ends up better and worse\noff, but also the patterns in who was treated well or badly as a means to\nthose outcomes.\n‣ This lens is about things like patterns, distribution, fairness, and bias.\nExample: Recall the insurers forcing people to use the app instead of\nseeing a doctor. This may only happen to people who are poor, with\ninexpensive insurance. The wealthiest people, who have excellent\ninsurance or don't need insurance at all, may have more options. This\npattern, where the app gives additional flexibility to people who are\nalready the best off, and limits the control of people who are already\ndisadvantaged, is a structural harm.\nWhat's more, if the app is better at diagnosing medical problems for some\npeople than others, especially if those differences map to important\ncategories like race or gender, there will be a structural problem even if\nthe app is better than a doctor for many people.\nIV. The Character Lens: what kind of 'person' is this project? does it\nmanifest virtue or vice? would a good person create, use, and/or support this\nproject, or not?\n‣ Ask: What are the character traits of this project? Does the\nproject (its development, use, operation) manifest virtues like\ncourage, kindness, impartiality, consideration, generosity, and\naltruism, or vices like cowardice, greed, bias, and selfishness?\n‣ This lens is a bit different from the others. But sometimes it's the\nmost intuitive way to understand ways in which a project can be\ngood or bad.\nExample: What is the character of the checkup app, and those who\nwould create, support, or use it? We can imagine that its\ndevelopers' goal was to increase access to medical care for those\nwho need it; that would be generous. Even so, if the app is\ndeployed by insurers just to cut costs, without benefiting patients,\nthat's greedy. If the app only works well for certain groups, then\nit's biased. Sometimes virtuous efforts are exploited by actors\noperating from vice; sometimes a project can itself seem to\nMoral Lenses\nJaques\n\nmanifest both virtues and vices. Thinking about how your project\ncan support virtuous uses and resist vicious ones can be a good\nway of working through its ethical dimensions.\nStep 4: Make it Ethical by Design\nYou now know a lot more about what your project is and does, and to and for\nwhom, and the ways in which that's good and bad. Your final step is to think\nabout which features of your project make a difference to the balance and\ndistribution of benefits and harms. What design choices maximize benefits,\nminimize harms, and do the best job of making sure both are distributed fairly?\nAt this stage, it's a good idea to think about how you would justify your choices\nto the people and groups affected by them--especially when there are significant\ntradeoffs. If one of your design choices benefits some people at others' expense,\nwhat would you say to those who are bearing the burden? What would they say\nin reply? One very good way to work through this stage--and the earlier ones,\ntoo!--is to talk to as many people from the relevant groups as you can. You don't\nneed to guess; you can ask.\nOnce you've mapped the changes your project produces to particular design\nchoices, and thought through which way to go with those choices by thinking\nabout what you can justify to those affected, you may find you need to rethink\nyour project. Do that, then work through the process again with the new version;\nkeep going till you have a version that doesn't seem to call for more changes.\n(And of course, the version that turns out to be best could be the one that means\nabandoning the project: you always need to be able to explain why your project\nis better than the alternatives, where those alternatives include the status quo.)\nExample: One important set of choices for the checkup app has to\ndo with what role actual doctors play in the process. Is the app\ndesigned to replace in-person checkups, or is it designed to speed\nup the checkup process without eliminating the in-person\ncomponent? If it's the latter, doctors may be in favor of your app;\nif it's the latter; expect them to object--because the former looks\nlike an outcome benefit to them, since it saves them time and thus\nallows them either to fit more appointments into their workday or\nto spend more time communicating with their patients, but the\nlatter is an outcome harm to them, threatening their income and\nMoral Lenses\nJaques\n\neven jobs. Of course, insurers will see different benefits and harms,\nand so deciding which way to design the app will involve balancing\nthe needs of each--along with patients and everyone else from\nStep 2.\nPractice Exercises\n1. Think of a piece of software you'd like to create. Work through the four steps,\nusing the moral lenses, and think about what the ethical issues are for your\nproject.\n‣ What are the main benefits it will or may provide, and to whom?\n‣ What are the main harms it will or may cause, and to whom?\n‣ How could you maximize the benefits and minimize the harms, and ensure\nthat they are distributed fairly?\n2. You've been practicing evaluating the software you create in terms of three\nimportant properties: correctness, clarity, and changeability. Correctness is about\nensuring that your code does what it's supposed to do. Clarity is about ensuring\nthat those who work with your code understand what they're getting, what\nthey're doing if they use it. And changeability is about ensuring that as\ncircumstances evolve, your code is able to adapt--so that it continues to do what\nit's supposed to do, and what people expect.\nAll of these properties are important to writing good software, and they often\nreinforce each other. Working on clarity can help with correctness; ensuring\ncorrectness can contribute to changeability; and so on. These properties can also\naffect the ethical import of a project: that is, failures of correctness, clarity, or\nchangeability can also be failures of outcomes, process, structure, or character.\nThis is because the 3 Cs affect what your project does, whether it does what\nothers expect, and so on.\n‣ How can a failure of correctness become an ethical problem?\nUse the moral lenses to answer.\n‣ Then do the same for failures of clarity and changeability.\nMoral Lenses\nJaques\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\nRES.TLL-008 Social and Ethical Responsibilities of Computing (SERC)\nFall 2022\nFor information about citing these materials or our Terms of Use, visit: https://\nocw.mit.edu/terms"
        },
        {
          "category": "Resource",
          "title": "RES.TLL-008 Social and Ethical Responsibilities of Computing (SERC), 6.031 Moral Lenses case study",
          "type": "PDF",
          "source_url": "https://ocw.mit.edu/courses/res-tll-008-social-and-ethical-responsibilities-of-computing-serc/mit_restll008_6-031_moralslides.pdf",
          "content": "Moral Lenses case study\n\nWarmup\n- Read the problem and the proposed design change\n- With your partner, brainstorm:\n- differences that might happen as a result\n- stakeholders affected by or interested in those differences\n- Write your answers in case-study.txt\n\nMoral Lenses review\n- What are the three moral lenses?\n- let's imagine them in the context of a game show\n\nFacebook in 2017\n- Problem: people are still using FB, but more passively\n- reading posts and watching videos, but not commenting or liking as much as before\n- \"We have an ethical duty not to turn Facebook users into zombies\"\n- Proposal: rank posts by meaningful social interaction (MSI)\n- MSI = actions on a post (comment >> react-emoji/reshare >> like) made by your own friends\n- With your partner:\n- apply the moral lenses for the stakeholder group of your section of the room\n- write your answers in case-study.txt\n- Working with the other pairs in your section:\n- put your Outcomes/Process/Structure points in the slides\n- consolidate similar points\n- vote for 1-2 points per slide (e.g. important or nonobvious)\n- boldface those key points\n\nAction\n- After moral lens analysis, what do we have that we may not have had\nbefore?\n- What can we do with that new knowledge?\nFor more about this case study:\nWall Street Journal Facebook Files podcast series\n(c) WSJ. All rights reserved. This content is excluded from our Creative Commons\nlicense. For more information, see https://ocw.mit.edu/help/faq-fair-use/\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu/\nRES.TLL-008 Social and Ethical Responsibilities of Computing (SERC)\nFall 2022\nFor information about citing these materials or our Terms of Use, visit: https://\nocw.mit.edu/terms"
        },
        {
          "category": "Lecture Notes",
          "title": "RES.TLL-008 Social and Ethical Responsibilities of Computing (SERC), 6.170 Ethics Protocol Lecture",
          "type": "PDF",
          "source_url": "https://ocw.mit.edu/courses/res-tll-008-social-and-ethical-responsibilities-of-computing-serc/9a221dbe4d169781cb4cd9df4fced3e8_MITRESTLL-008F21-6170lec.pdf",
          "content": "Ethics Protocol:\nA method for designing responsibly\n6.170 Fall 2020\nSerena Booth\nContent: Milo Phillips-Brown and Abby Jaques\n\nResponsibility\n\nResponsibility\nSome Choices\nA. Happy to do it\nB.\nReluctant but would do it\nC. Object to doing it and ask for an\nalternative task, but would do it if I had to\nD. Leak information to the public, but don't\nresign from my job\nE.\nKeep your job, but organize with others to\nstand up to leadership in the future.\nF.\nResign from my job rather than do it\nG. Resign from my job and leak information\nto the public\nCite: Abeba Birhane\nYou're an engineer at change.org.\nYour users have been learning that your\ncompany is for-profit, and that your petitions\nare never presented to government in an official\ncapacity. They're starting to leave your platform.\nYour manager asks you to design an alternative\nchange.org website to look and feel exactly like\nreal government petitions using their newly\npurchased change.whitehouse.org domain.\nWhat do you do?\n\nResponsibility\nSome Choices\nA. Happy to do it\nB.\nReluctant but would do it\nC. Object to doing it and ask for an\nalternative task, but would do it if I had to\nD. Leak information to the public, but don't\nresign from my job\nE.\nKeep your job, but organize with others to\nstand up to leadership in the future.\nF.\nResign from my job rather than do it\nG. Resign from my job and leak information\nto the public\nCite: Abeba Birhane\nYou're a UROP. You're interested in going to\ngrad school, and you had a hard time getting\nthis position. You're hoping for a good letter.\nYour grad student mentor works on a method\nfor explaining the decisions of autonomous\nsystems. Your grad student recently realized\ntheir system could also work for drones.\nThey task you with creating a website to help\nmilitary personnel assess UAV decisions. They\nsay, \"they're already using the drones, this will\njust increase accountability.\"\nWhat do you do?\n\nEthics: why should I care?\n\nEthics: why should I care?\nWe claim: exploring ethics and assessing your values now will\nhelp you make better decisions in the future.\nNow: less pressure, less stress, fewer sources of conflict.\nThe ethics protocol is a tool to help you with such decisions.\n\nEthics: why should I care?\nWe claim: exploring ethics and assessing your values now will\nhelp you make better decisions in the future.\nNow: less pressure, less stress, fewer sources of conflict.\nThe ethics protocol is a tool to help you with such decisions.\nYou will use the ethics protocol for your final projects.\n\nEthics Protocol Goals\n● Make more informed decisions\n● Justifying existing/past decisions\n\nEthics Protocol Goals\n● Make more informed decisions\n● Justifying existing/past decisions\n● Assess priorities, compromise\n● Search for a simple \"right\" answer\n\nEthics Protocol Goals\n● Make more informed decisions\n● Justifying existing/past decisions\n● Assess priorities, compromise\n● Search for a simple \"right\" answer\n● Avoid thoughtless blunders\n● Replacing participatory design\n\nEthics Protocol Overview\nEnvision\nPossible\nFutures\n\nEthics Protocol Overview\nEnvision\nPossible\nFutures\nIdentify\nStakeholder\ns\n\nEthics Protocol Overview\nEnvision\nPossible\nFutures\nIdentify\nStakeholder\ns\nIdentify\nValues at\nPlay\n\nEthics Protocol Overview\nEnvision\nPossible\nFutures\nIdentify\nStakeholder\ns\nIdentify\nValues at\nPlay\nIdentify\nValue-Laden\nDesign\nChoices\n\nEthics Protocol Overview\nEnvision\nPossible\nFutures\nIdentify\nStakeholder\ns\nIdentify\nValues at\nPlay\nIdentify\nValue-Laden\nDesign\nChoices\nChoose &\nJustify\n\nEthics Protocol Overview\nEnvision\nPossible\nFutures\nIdentify\nStakeholder\ns\nIdentify\nValues at\nPlay\nIdentify\nValue-Laden\nDesign\nChoices\nChoose &\nJustify\nBuild\n\ncw: COVID-19\n\nRunning Example: Digital Contact Tracing\nTwo main features:\n1. Contact Identification\npeople who have been exposed are identified\n1. Contact Notification\npeople are notified of their potential exposure\n\nPreliminary design choices\n1.Is contact tracing always \"on,\" or is it just used\nat certain establishments (e.g., restaurants)?\n2.Does the app use phone-to-phone\ncommunication, or do we add additional\nhardware beacons?\n3.Do we use bluetooth or GPS or neither?\n4.How is the app distributed?\n5....\n\nEthics Protocol Overview\nEnvision\nPossible\nFutures\n\nContact Tracing Imagined Futures\nThe government releases a contact tracing app.\nWithin two months, there were zero COVID-19\ncases in the country. Hundreds of thousands of\nlives were saved. Schools reopened, businesses\nflourished, and the roaring twenties kicked off.\nThe government preemptively decided to stop\ncollecting data from users, but maintained the\napp for in case of future pandemics.\n\nContact Tracing Imagined Futures\n< Room X: Add your imagined futures>\n\nContact Tracing Imagined Futures\n5 minutes\n\nContact Tracing Imagined Futures\nPOSITIVE\n-\nFaster\npandemic\nNEGATIVE\nrecovery\n-\nTrack certain\ngroups movements\nthrough the app\n(e.g. criminals)\n-\nOverreach for\nother examples\nthat don't\nrequire...\n-\nMake assumptions about\nmovement of certain groups\nNEUTRAL\n-\nWhat happens to data\nafter contact tracing is\nknow longer needed?\n-\nIncreased Legislation for\nreusing the app\n-\nData used for future\nresearch\n\nContact Tracing Imagined Futures\n-\nSurveillance state\n-\nDisproportionately harms marginalized communities\n-\nProtestors/whistleblowers at risk (one person traced can lead to\ntracking others)\n-\nBuggy App\n-\nLoses User's Trust, causes mass panic, doesn't prevent spread\n-\nApp is hacked/compromised\n-\nCan be used for ransom/stalking/blackmail\n\nContact Tracing Imagined Futures\n-\nPrivacy issues: creators of the app have access to other users'\nlocations and may use users' information for financial gain (e.g.\nselling to companies), could be used in turn for individual\nmarketing\n-\nOverconfidence issue: users' behavior becomes more risky as\nthey underestimate exposure and reduce testing frequency\n-\nGovernment abuse: using the app to track groups of people /\nhow they interact, potentially voter suppression\n\nContact Tracing Imagined Futures\n< Room 4: Add your imagined futures>\nGood:\n● Limited only for pandemic\nBad:\n● Using for other domains\n● Collected data unintentionally leaks sensitive information or is\nmisused/sold\n\nContact Tracing Imagined Futures\nSocial media could be transformed if this contact\ntracing app takes off. Something like proximity-\nbased socialization and connecting to others.\nSurveillance from government and corporations\nincreases. What if our location data is all sold?\n\nEthics Protocol Overview\nEnvision\nPossible\nFutures\nIdentify\nStakeholder\ns\n\nWhat is a stakeholder?\n\nWhat is a stakeholder?\nA stakeholder is anyone or any thing that\ncan affect or be affected by your project.\n\nStakeholders are not (just):\nYou & your institution\nFinancial backers (shareholders)\nUsers\n\nWhy define stakeholder so broadly?\n\nWhy define stakeholder so broadly?\nThere are no ethical externalities.\n\nThat doesn't mean you're responsible for\neverything.\n\nBut, to make things ethically,\nyou need to know\nwhat all the ethical elements are!\n\nStakeholder subgroups matter.\n\nContact Tracing Stakeholders\nSmartphone users\nNot-smartphone users\n\nContact Tracing Stakeholders\nSmartphone users\nNot-smartphone users\nBlack people\nHispanic or Latino people\n\nContact Tracing Stakeholders\nTask: Brainstorm as many stakeholders as you can\n5 minutes\n\nContact Tracing Stakeholders\n● Coronavirus(?)\n● Low income communities\n● Developers\n● Governments\n● Different Age Groups\n● People in areas with worse connectivity\n● People who are benefiting from the\npandemic.\n\nContact Tracing Stakeholders\n< Room 2: Add your stakeholders>\n-\nHealthcare workers\n-\nEssential workers\n-\nBusinesses/potential hubs for\ntransmission\n-\nMaker of app\n\nContact Tracing Stakeholders\n● Homeless & low-income\n● Healthcare workers\n● BIPOC\n● Non-smartphone owners\n● Elderly\n● Disabled\n● Children\n● Essential workers\n● Public transportation users\n● Government (all levels)\n\nContact Tracing Stakeholders\n● Users\n● Non-Users: Elderly (non-smartphone users)\n● Government\n● Hospitals\n● Testing Centers\n● Academia\n● Big pharma\n● Inter-Country Tracing Systems\n\nContact Tracing Stakeholders\n< Room 5: Add your stakeholders>\n● Lower-income, anyone without a phone or areas with\npoor connectivity\n● Rural vs. urban?\n○ Proximity to other people (tracing you through\nother people's devices)\n● Older vs younger\n○ People\n○ Tech\n■ New tech - less hackable but built in\nhardware\n● BIPOC\n\nEthics Protocol Overview\nEnvision\nPossible\nFutures\nIdentify\nStakeholder\ns\nIdentify\nValues at\nPlay\n\nMoral Lenses\nDifferent ways of looking at effects\non stakeholders that reveal different\nkinds of ethical significance.\n\nOutcome Lens\nIn what ways does what you're\nmaking turn out better or worse\nfor your stakeholders?\n\nProcess Lens\nHow did the process treat\nstakeholders?\nThink: autonomy, consent,\ntransparency, participation, etc.\n\nStructure Lens\nHow are the outcomes distributed\namong different stakeholders? What\nare the differences in how different\nstakeholders were treated by the\nprocess?\nCould be called 'Justice Lens'\n\nOutcome, Process, Structure\nWhat's missing?\nWhat are your values?\n\nEthics Protocol Overview\nEnvision\nPossible\nFutures\nIdentify\nStakeholder\ns\nIdentify\nValues at\nPlay\nIdentify\nValue-Laden\nDesign\nChoices\n\nTwo ways to identify value-\nladen design choices\n\nTwo ways to identify value-\nladen design choices\n1. Work forward:\nTake a choice you know you'd have to make and\ntrace out the value-laden implications\n\nPreliminary design choices\n1. How are COVID-19 cases identified?\n\nValues promoted\nValues demoted\nPossible Choice\n(and for whom?)\n(and for whom?)\nOption A\nOption B\nOption C\n\nValues promoted\nValues demoted\nPossible Choice\n(and for whom?)\n(and for whom?)\nUsers post their COVID-19\nstatus without proof\nOption B\nOption C\n\nValues promoted\nValues demoted\nPossible Choice\n(and for whom?)\n(and for whom?)\nUsers post their COVID-19\nstatus without proof\nUsers post their COVID-19\nstatus with doctor's note\nOption C\n\nPossible Choice\nValues promoted\n(and for whom?)\nValues demoted\n(and for whom?)\nUsers post their COVID-19\nstatus without proof\nUsers post their COVID-19\nstatus with doctor's note\nWe identify COVID-19\nstatus by monitoring vocal\npatterns [src]\n\nPossible Choice\nUsers post their COVID-19\nstatus without proof\nUsers post their COVID-19\nstatus with doctor's note\nWe identify COVID-19\nstatus by monitoring vocal\npatterns [src]\nValues promoted\n(and for whom?)\nStructure Lens: users don't\nhave to see a doctor\nProcess Lens: the process is\nentirely transparent\nValues demoted\n(and for whom?)\nOutcome Lens: bad actors\ncan prank the system\n\nPossible Choice\nUsers post their COVID-19\nstatus without proof\nUsers post their COVID-19\nstatus with doctor's note\nWe identify COVID-19\nstatus by monitoring vocal\nValues promoted\n(and for whom?)\nStructure Lens: users don't\nhave to see a doctor\nProcess Lens: the process is\nentirely transparent\nOutcome Lens: the least\nfalse positives\nOutcome Lens: we're able\nto identify the most cases\nValues demoted\n(and for whom?)\nOutcome Lens: bad actors\ncan prank the system\nStructure Lens: high\nbarrier to use\nProcess Lens: compromises\nprivacy\nProcess Lens: users didn't\nconsent to this data\ncollection\nStructure Lens: the model\npatterns [src]\nusing this technology\nonly uses English data.\n\nTwo ways to identify value-\nladen design choices\n1. Work forward:\nTake a choice you know you'd have to make and\ntrace out the value-laden implications\n2. Work backward:\nYou've identified futures and their ethical\ndimensions. Which choices result in which\noutcomes?\n\nWorking backward\nOne envisioned future is that there are so many\nfalse positives, the system is incredibly ineffective\nand we give up using it.\nOne contributing design decision could be this\nquestion of how positive cases are communicated.\n\nPreliminary design choices\n1. How are COVID-19 cases identified?\n2. GPS vs Phone-to-Phone Bluetooth\n3. Opt-in vs opt-out?\n4. Distribution mechanism?\n5. Always on, or only used in certain locations?\n6. ...\n\nPossible Choice\nGPS\nBluetooth\nValues promoted\n(and for whom?)\nOutcomes: we can remove\noutdoors\nJustice: works anywhere in\nthe world\nOutcomes: we're more\nconfident you were in close\nproximity\nValues demoted\n(and for whom?)\nOutcomes: generally worse\nprotocol\nProcess: collecting a lot\nmore data\nOption C\nRoom 1\n\nValues promoted\nValues demoted\nPossible Choice\n(and for whom?)\n(and for whom?)\nOption A\nOption B\nOption C\nRoom 2\n\nEthics Protocol Overview\nEnvision\nPossible\nFutures\nIdentify\nStakeholder\ns\nIdentify\nValues at\nPlay\nIdentify\nValue-Laden\nDesign\nChoices\nChoose &\nJustify\n\n1. How are COVID-19 cases identified?\nChoice: Users post their COVID-19 Status by acquiring\nan authorization code from their doctor.\n● This prevents bad actors from manipulating\nthe system, forcing unnecessary self-isolation,\nunlike without requiring authorization codes.\n● Users consent, unlike with the voice\nmonitoring solution.\n● Fewer users report, since this requires the\nfinancial means/feelings of security needed to\nsee a doctor in the US.\n● Privacy is compromised since users can be\nassociated with a specific doctor's visit.\n\nContact Tracing Choose & Justify\n5 minutes\n\n1. Question?\nChoice\nJustification\nRoom 1\n\nEthics Protocol Overview\nEnvision\nPossible\nFutures\nIdentify\nStakeholder\ns\nIdentify\nValues at\nPlay\nIdentify\nValue-Laden\nDesign\nChoices\nChoose &\nJustify\nBuild\n\nChoose &\nJustify\nBuild\n\"Minor\" technical\ndecisions can have\nethical consequences.\n\nChoose &\nJustify\nBuild\nImmediate\nNotifications?\n\nDon't forget to ask:\n\"Should I build this?\"\nFin!\nReminder: You'll use the ethics protocol\nin your final projects.\n\nLearn More Ethics!\nClasses (Spring `21):\n● 24.191 Being, Thinking, Doing (or not): Ethics in Your Life\n● 24.03 Good Food: The Ethics and Politics of Food\n● 24.231 Ethics: Systematic study of central theories in ethics\n● 24.237(J) Feminist Thought\nOther:\n● PKG Center - internships, colloquia, funding for your ideas, lots of\nopportunities!\n● AI Ethics Reading Group, AI Alignment Reading Group, & more\n\nQ&A\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\nRES.TLL-008 Social and Ethical Responsibilities of Computing (SERC)\nFall 2021\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms"
        },
        {
          "category": "Resource",
          "title": "Design Decisions",
          "type": "DOCX",
          "source_url": "https://ocw.mit.edu/courses/res-tll-008-social-and-ethical-responsibilities-of-computing-serc/b89d2884415283f892633d8ab97dd456_MITRESTLL-008F21-6170designReflection.docx",
          "content": "Design Decisions\n\n1. Insert your short and compelling design decision title phrase\n\nBegin your design decision discussion with introducing the decision and the rationale behind why you chose it but be sure to discuss any limitations this choice still has.\n\nAlternatives Considered: Then go on to listing alternative design choices you may have considered and discuss why you didn't choose them, comparing them to the design you did choose.\n\n2. Insert your short and compelling design decision title phrase\n\nBegin your design decision discussion with introducing the decision and the rationale behind why you chose it but be sure to discuss any limitations this choice still has.\n\nAlternatives Considered: Then go on to listing alternative design choices you may have considered and discuss why you didn't choose them, comparing them to the design you did choose.\n\n3. Insert your short and compelling design decision title phrase\n\nBegin your design decision discussion with introducing the decision and the rationale behind why you chose it but be sure to discuss any limitations this choice still has.\n\nAlternatives Considered: Then go on to listing alternative design choices you may have considered and discuss why you didn't choose them, comparing them to the design you did choose.\n\n4. Insert your short and compelling design decision title phrase\n\nBegin your design decision discussion with introducing the decision and the rationale behind why you chose it but be sure to discuss any limitations this choice still has.\n\nAlternatives Considered: Then go on to listing alternative design choices you may have considered and discuss why you didn't choose them, comparing them to the design you did choose.\n\nEthical / Social Reflection\n\nDescribe how conducting the A4 reflection informed your design process in this assignment. In particular, has your interface design changed as a result - how, or why not? Also, are there other social/ethical implications that you encountered when translating your wireframes into a working implementation?\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\n\nRES.TLL-008 Social and Ethical Responsibilities of Computing (SERC)\nFall 2021\n\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms"
        },
        {
          "category": "Resource",
          "title": "Ethical Implications",
          "type": "DOCX",
          "source_url": "https://ocw.mit.edu/courses/res-tll-008-social-and-ethical-responsibilities-of-computing-serc/d9fd91777252a2cc082f4ff820c42b6b_MITRESTLL-008F21-6170ethical.docx",
          "content": "Ethical Implications\n\nAnswer the following questions. In your answers, please distinguish which implications follow from your conceptual design and which follow from your UI design.\n\nDid you make cultural or other assumptions about your users that affect how they interact with Fritter?\n\nWould an effective use of design heuristics to maximize engagement with Fritter be manipulative?\n\nHow would you adjust your design if your only goal were to: get children addicted to Fritter? or make it hard for older people to use Fritter? or stop fake news spreading? or prevent harassment? How, if at all, do your answers to these questions inform how you would actually design Fritter?\n\nYou have the option to allow users to see which other users have upvoted a Freet. What forms of engagement between users (positive or negative) would be encouraged by allowing this?\n\nIn A3, we asked about stakeholders who aren't your immediate users. Identify a design choice you faced that would benefit or harm such a stakeholder, and explain how.\n\nWhat are the accessibility implications of your design for people with different abilities?\n\nOne of the heuristics is to \"speak the user's language.\" In retrospect, assuming you followed this, can you identify what kind of user you had in mind?\nMIT OpenCourseWare\nhttps://ocw.mit.edu\n\nRES.TLL-008 Social and Ethical Responsibilities of Computing (SERC)\nFall 2021\n\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms"
        },
        {
          "category": "Resource",
          "title": "Fritter User Test",
          "type": "DOCX",
          "source_url": "https://ocw.mit.edu/courses/res-tll-008-social-and-ethical-responsibilities-of-computing-serc/16a11f2babb9f1c77c67da33a4a14054_MITRESTLL-008F21-6170user.docx",
          "content": "Fritter User Test\n\nSpecify Tasks for the User completed for your user test\nTask 1: User upvotes another user's freet, then removes their upvote\nTask 2: User follows another user, then checks their feed\n....\nTask n: User refreets another user's freet\n\nSummary of Observations\n\nDiscuss your observations you had as you observed your user go through the tasks you provided them.\n\nChanges in Responses to UI\n\nNote any changes you will make to your UI in response to what you observed from your user test.\nMIT OpenCourseWare\nhttps://ocw.mit.edu\n\nRES.TLL-008 Social and Ethical Responsibilities of Computing (SERC)\nFall 2021\n\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms"
        },
        {
          "category": "Resource",
          "title": "Heuristic Evaluation",
          "type": "DOCX",
          "source_url": "https://ocw.mit.edu/courses/res-tll-008-social-and-ethical-responsibilities-of-computing-serc/b91f260be72dba5c48c53d9bab5b5f61_MITRES-TLL-008F21-6170Heuristic.docx",
          "content": "Heuristic Evaluation\n\nFor each heuristic, you should cite one example in your wireframe either illustrating how the heuristic suggests an improvement, or pointing to a design decision you made that supports the heuristic.\n\nFitt's Law\n\nSpeak the User's Language\n\nConsistent Naming & Icons\n\nInformation Scent\n\nFollow Conventions\n\nShow Location & Structure\n\nAccelerators\n\nKeep Paths Short\n\nUndo & Cancel\n\nPerceptual Fusion\n\nGestalt Principle of Grouping\n\nRecognition vs. Recall\n\nAnticipation & Context\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\n\nRES.TLL-008 Social and Ethical Responsibilities of Computing (SERC)\nFall 2021\n\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms"
        },
        {
          "category": "Resource",
          "title": "Module: Big Data and Personal Privacy",
          "type": "DOCX",
          "source_url": "https://ocw.mit.edu/courses/res-tll-008-social-and-ethical-responsibilities-of-computing-serc/8283d95f3ec08827137334de3d3959ca_MITRES-TLL008F21-STS-012module.docx",
          "content": "Module: Big Data and Personal Privacy\n\nReadings:\n\nSarah Valentine, Impoverished Algorithms: Misguided Governments, Flawed Technologies, and Social Control. (2019). 46 Fordham Urb. L.J. 364.\n\nBoyd, Danah, and Kate Crawford. 2012. \"Critical Questions for Big Data.\" Information, Communication & Society 15(5): 662-679.\n\nAt home exercise:\n(Voluntary)\n\nLearn more about your data rights.\nhttps://www.dataprotection.ie/en/individuals/know-your-rights/right-access-information\nhttps://tapmydata.com/features/#superpower\nAccess your data from three websites/services you frequently use (Examples: Facebook, Twitter, Instagram, Google etc.)\nTip: Tapmydata is an application that makes it easy to send these requests. (Remember however that after a certain point in the process, they might ask you to use your data in a particular way.)\nWrite and post a short 200-word reflection on what you found and whether what you found surprised you. Think reflection should incorporate insights from the two readings for this week, particularly the sections on data triangulation and commercialization.\nRead your classmates posts.\n\nIn class:\n\nDiscussion of the key points of the articles and of the student responses.\n\nAims:\n\nTo find overlaps and differences in the experience of students learning about their right to privacy\nTo discuss whether they believe existing rights to be adequate\nTo examine whether current ethical standards (such as those instituted by the GDPR) sufficiently protect their rights (as they exist or as they believe should exist).\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\n\nRES.TLL-008 Social and Ethical Responsibilities of Computing (SERC)\nFall 2021\n\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms"
        },
        {
          "category": "Resource",
          "title": "Social / Ethical Implications",
          "type": "DOCX",
          "source_url": "https://ocw.mit.edu/courses/res-tll-008-social-and-ethical-responsibilities-of-computing-serc/6798d7403276605c3f41b5a84eb2e433_MITRESTLL-008F21-6170social.docx",
          "content": "Social / Ethical Implications\n\n1. Insert your short and compelling social / ethical implication title phrase\n\nYou should explain why the decision you made has particular implications, and, if those are negative, how they might be mitigated.\n\n2. Insert your short and compelling social / ethical implication title phrase\n\nYou should explain why the decision you made has particular implications, and, if those are negative, how they might be mitigated.\n\n3. Insert your short and compelling social / ethical implication title phrase\n\nYou should explain why the decision you made has particular implications, and, if those are negative, how they might be mitigated.\nMIT OpenCourseWare\nhttps://ocw.mit.edu\n\nRES.TLL-008 Social and Ethical Responsibilities of Computing (SERC)\nFall 2021\n\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms"
        },
        {
          "category": "Assignment",
          "title": "Assignment Part 0",
          "type": "PDF",
          "source_url": "https://ocw.mit.edu/courses/res-tll-008-social-and-ethical-responsibilities-of-computing-serc/62162d4f97741c381b492697930242ed_MITRES-TLL008F21_6864pt0.pdf",
          "content": "Assignment Part 0:\nFirst read the assignment background & overview. Then, consider the following scenarios, and\nbriefly describe any problem(s) you think could arise (~1 paragraph or a few bullet points).\n1. Your friend works in the admissions office of a nearby university. They mention that\nthere's a proposal to build an ML model to help filter applications, using features like\nthe applicant's extracurricular activities and test scores. They're planning to train the\nmodel on data from past students at the school. To label this data, they propose using\nthese past students' college GPA -- if the GPA is above 2.75, the label will be positive\n(i.e., should be admitted) and if not, the label will be negative (i.e., should not be\nadmitted).\n2. The company you work for is prototyping a model to sift resumes and recommend\nwhich applicants to follow up with for interviews. Over a period of a few months, they\npull out the text from all the applications that come in, and have employees across the\ncompany annotate whether they are qualified candidates. Now, they want to use this as\nthe dataset to train a model to predict whether a new candidate is qualified (and if so,\nextend an interview).\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\nRES.TLL-008 Social and Ethical Responsibilities of Computing (SERC)\nFall 2021\nFor information about citing these materials or our Terms of Use, visit:\nhttps://ocw.mit.edu/terms"
        },
        {
          "category": "Resource",
          "title": "A1 Problem Statement",
          "type": "DOCX",
          "source_url": "https://ocw.mit.edu/courses/res-tll-008-social-and-ethical-responsibilities-of-computing-serc/bfc14b2cbbe688c89a9901034e027e52_MITRESTLL-008F21-6170hw1.docx",
          "content": "A1 Problem Statement\nOverview & Objectives\nThe Game. In this assignment, you'll build a browser-based version of John Conway's Game of Life, a cellular automaton that simulates the evolution of an organism using a simple deterministic rule.\nWriting code in JavaScript. The main purpose of the assignment is to give you practice writing high-quality code in JavaScript. This includes not only the superficial aspects of coding (such as neat formatting, judicious commenting, having functions of reasonable size, and so on) but also the more subtle aspects that have a major impact on how easy the code is to understand and modify, and which tend to require more sophisticated techniques.\nIdioms. In particular, you should use the idioms you've learned in class, notably abstracting iteration with functionals and using closures to control access to state.\nLocalizing design decisions and avoiding repetition. A good check that your code is well structured is to consider whether each of the key design decisions (such as the shape of the board, or the rules for playing the game) is expressed at a single point in the code. Also, you should avoid repetition and redundancy so that changes even to small features (such as the dimensions of the board) can be made in just one place.\nDesign Reflection. Although this assignment is focused on coding, the theme of the class as a whole is design. Each assignment will therefore involve conducting some design reflection, and this assignment will give you your first experience doing this.\nSpecification\nYour pair's (or individually) task is to build a browser-based version of John Conway's Game of Life. Users should be able to select one of a collection of preset starting states, or create an arbitrary starting configuration, and start and stop an instance of the animation while it is running.\nProvided code. To spare you the effort of implementing a user interface (which we will cover later in the class), we are providing you with some starter code that sets up the visual board and controls for you. Your task is to write the code that maintains the internal representation of the game, applies the rules, and sends updates to the visual board. Implementing this code involves providing the bodies of some functions in a given file. Of course, you should not constrain your code to be entirely within those functions; they will likely make calls to other functions that you will declare. To open & manually test your implementation in the browser in Chrome go to File > Open File... > Select & open index.html from finder and this will show you the game of life UI.\nClient side code only. Your implementation will be loaded as a web page, and run without a server. This project requires client-side code only. You should only be writing JavaScript that runs in a web browser, and there is no need to provide any server-side code to generate these pages.\nCommenting and testing. Your code should include succinct specifications of functions and classes, should be commented appropriately. Testing graphical behavior is hard, and we don't expect you to do this automatically -- eyeballing the output is enough.\nDesign Reflection. (max 1000 words) In your design reflection, you & your partner should describe:\nThe key design decisions you made, and how you achieved localization and avoided repetition.\nHow you exploited functionals in your code, and why they improved the design.\nSome alternatives you considered to your design and why they were not chosen.\nSome limitations of your design and how they might be addressed.\nSome comments on the ethical implications of the project (see hints below).\nDeliverables\n\nThe entire code of your project, comprising the starter code with your code inserted in the file internal.js (which provides several skeletal functions that you should complete).\nA file called reflection.md, in the top-level directory of the repo, that contains the design, ethical reflections. Give each section a header and in the header, put the partner responsible for that section in parenthesis\nIf you worked with a partner, each partner must fill out the prompts of the Assignment repo's critiques.md file.\nIf you worked individually, fill out the sections for Partner 1 in critiques.md except the Partner Critique & Authorship sections.\nCollaboration Policy for Partner Assignments\nPlease review and follow the collaboration policy for partner assignments on the course syllabus.\n\nRemember that both partner's should engage with all parts of the assignment (code implementation, design, and reflections) and divide the work equally.\nGrading\nSee the accompanying rubric.\n\nHints\nDesign Reflection. Keep your discussion succinct, clear and to the point. Including irrelevant comments or repeating yourself will lead to a lower grade. Some design decisions to consider (also called \"dimensions\" or \"axes\" of a design) include: what data structures you used to represent the game board; how you chose to iterate over cells; how the board was updated or replaced at each step; how presets were represented and loaded.\nEthical Implications. The last part of the design reflection asks you to comment on some of the ethical implications of your project. You are free to consider any moral or ethical issue that you think is relevant, so long as what you write is coherent, thoughtful and to the point. Recognizing that the Game of Life has been taken by many computer scientists as a metaphor for biological and evolutionary processes, or even for population control, you might consider how this metaphor influences, positively or negatively the way we view the real world and our role in it. Or you might examine to what extent you just implemented the rules without considering their meaning, and whether this is typical of how programmers operate in corporate settings.\nDocumentation of Public Interfaces: You are not required to use any particular JavaScript annotation tool (if you'd like to, JSDoc is a popular tool), nor any particular styling of comments. Recall from 6.031 that to document your interfaces, you wrote brief, stylized comments for each function and, for each module, a very brief summary of what the module provides.\nUse of Functionals: This assignment provides many opportunities to use functionals, as taught in lecture, to eliminate duplication in the code and to make it more succinct and more elegant. In particular, you may want to think about how you iterate over the neighbors of a cell, and whether this can be abstracted. One of the former 6.170 TAs (Harihar Subramanyam) made a guide about common misuses of functionals. It's highly recommended that you read it before starting the pset.\nAdditional References: The Wikipedia article on Game of Life; an implementation using an external graphics library, with simple source code (but you can do better!); a video of Conway talking about the game; a longer discussion of the game, its properties, as well as different objects and their properties (including stationary, oscillating, and gliding objects).\nEdge Behavior: When live cells reach the edge of the grid, there are a number of ways they could behave, including: cells off the board could simply all be \"dead\" cells, or \"live\" cells could wrap around the edge of the board. Any behavior is acceptable, so long as your implementation is consistent and reasonable.\nMarkdown: When writing your reflection.md file, check out this cheat sheet for information on how to style markdown.\nTesting: Although you will not be assessed on writing tests (graders will not run them), if you choose to write tests, we suggest using Jest.\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\n\nRES.TLL-008 Social and Ethical Responsibilities of Computing (SERC)\nFall 2021\n\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms"
        },
        {
          "category": "Resource",
          "title": "A1 Rubric",
          "type": "DOCX",
          "source_url": "https://ocw.mit.edu/courses/res-tll-008-social-and-ethical-responsibilities-of-computing-serc/c37d9a4ef3bc3c3c6b6b06612fe2ba3e_MITRESTLL-008F21-6170hw1rubric.docx",
          "content": "A1 Rubric\n(50 points) Functionality\n30 points for correct rule implementation\n10 points for creating a collection of preset starting states (at least 3)\n10 points for being able to create an arbitrary starting configuration\n\n(5 points) Presentation\n5 points for presenting code neatly, well formatted and judiciously documented.\n\n(45 points) Design reflection (max 1000 words)\n15 points for describing key design decisions:\n2 points for describing what design decisions were identified.\n5 points for describing how the decisions were resolved, and localized.\n3 points for describing why those decisions were made.\n5 points for describing what alternatives were considered and why they were not taken.\n10 points for describing functionals:\n5 points for describing how functionals were used (point to places in the code).\n5 points for describing why these functionals were used (that is, what was gained).\n10 points for analyzing limitations:\n5 points for describing design limitations (not bugs in the implementation).\n5 points for describing how they may be addressed in the future.\n10 points for discussing ethical implications in a compelling and coherent way.\nMIT OpenCourseWare\nhttps://ocw.mit.edu\n\nRES.TLL-008 Social and Ethical Responsibilities of Computing (SERC)\nFall 2021\n\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms"
        },
        {
          "category": "Resource",
          "title": "Part 1 HW2",
          "type": "DOCX",
          "source_url": "https://ocw.mit.edu/courses/res-tll-008-social-and-ethical-responsibilities-of-computing-serc/4008487bbeb088b18e99a15727f1dec5_MITRES-TLL008F21-6864pt1.docx",
          "content": "Part 1:\n\nThis part of HW2 is a group assignment. Look through the Task A and Task B descriptions, and then discuss & submit answers for the following questions with your group. Only one group member needs to submit answers but you should work collaboratively (e.g., maybe draft answers together in a google doc).\n\nCome up with a labeling scheme. How many labels do you want to have? Are they binary, or multi-class? It might help to think about / decide how you want to use the resulting model. Write a few sentences on how you came to your decision.\n\nYou have a budget to hire people to annotate the comments according to your labeling scheme. Write a set of instructions to give to the annotators.\nThe format of your instructions is flexible, but as a guide you can consider the following parts:\nBrief task description including what they will see & be asked to do (~1 paragraph)\nStep-by-step instructions for how to label each example\nTips for reading the examples (~1 paragraph): For example, are there specific factors they should consider/look out for? Should they go with their first reaction or look up additional information?\nYour labeling scheme (~1-2 paragraphs or several bullet points): Make sure you describe your labeling scheme precisely--you don't want people to be labeling examples with different terms, since that will make it hard to reconcile the labels from different annotators. Define terms that are not clear, and maybe include guidelines for what people should do if they're not sure (Should they go with their best guess? Or are you going to include a \"Not Sure\" label in your scheme?).\nSample labeled examples according to your labeling scheme (e.g. use the examples in your task description doc)\n\nWrite a few sentences about how you might integrate the annotations into the dataset. Will you average labels of multiple annotators for each example or use some other aggregation? What do you do with examples where there's disagreement among annotators? It's okay if you're not sure, just try to write about what the tradeoffs might be.\n\nAre there concerns you have about using technology to address this problem?\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\n\nRES.TLL-008 Social and Ethical Responsibilities of Computing (SERC)\nFall 2021\n\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms"
        },
        {
          "category": "Assignment",
          "title": "RES.TLL-008 Social and Ethical Responsibilities of Computing (SERC), 17.806 Problem Set 1 Questions",
          "type": "PDF",
          "source_url": "https://ocw.mit.edu/courses/res-tll-008-social-and-ethical-responsibilities-of-computing-serc/mit_restll008_17-806_pset1.pdf",
          "content": "17.806: Problem Set 1\nProfessor: In Song Kim\nPlease submit both your write-up and your code electronically to the Learning Modules.1 This should\nbe completed before class begins at 3 pm (late submissions will not be accepted).\nAnalyzing the impact of police stopping on politcal behavior\nIn the lecture, we have learned that an increase in the availability of (unstructured) data would advance\nempirical analysis in political science. In this problem set, you will explore how/whether policing against\ncitizens and against racial minorities a ects political behavior of citizens by leveraging a variety of data\nsources online. In recent years, micro-level administrative data on policing is readily available, which\nallows us to conduct more reliable analysis from observational data. This problem set particularly focuses\non the stop-question-and-frisk (SQF) by the New York Police Department (NYPD).\nNYPD discloses geo-located data on all SQF, which o ers us a unique opportunity to study the\nrelationship between policing and voting behavior at the ne-grained level. Some critics have argued\nthat SQF is a racially discriminatory policy because people being stopped are overwhelmingly Black\nand Latino.2 In particular, more than 50% of SQF are conducted against black people while they only\naccount for a quarter of the population in NYC. Since policy toward policing has been one of the salient\nissues in recent elections, this problem set will examine how/whether SQF in a community a ects voting\nbehavior. Speci cally, we will analyze the impact of police stopping on the electoral outcomes using the\nNYPD SQF data and election data from the 2016 and 2020 presidential elections. For the purpose of\nthis course, these problems will help us practice various skills to collect new data and make use of regex.\n1. As the rst step, we will practice automatically downloading data and structuring the downloaded\ndata. Although the number of les that we download in this question does not require us to develop\na pipeline to download the data automatically, researchers often encounter websites with thousands\nor millions of target data that makes it impossible to download manually. Therefore, this exercise\nwill get you started on this process while you think about your own data collection e orts.\nThe NYPD discloses the SQF data at their website (https://www1.nyc.gov/site/nypd/stats/\nreports-analysis/stopfrisk.page) from years 2003 to 2019.\nWrite codes to automatically\ndownload the SQF data from the website. In your codes, create a directory named data rst,\nthen create a subdirectory named nypd_stop_data inside data, and store the downloaded data\ninto nypd_stop_data (i.e., write a script to automatically create the folders and subfolders and\nstore the downloaded data rather than manually do so).\nPlease follow these steps:\n1 Site is unavailable to OCW users.\n2 Milner, Adrienne N., Brandon J. George, and David B. Allison. 2016. Black and Hispanic men perceived to be large\nare at increased risk for police frisk, search, and force. PloS One 11.1.\n\n‹ Identify the URL that contains data\n‹ Analyze the html by extracting tags and attributes that contain data\n‹ Create folders/directories to store data\n‹ Download data (Make sure to wait a bit between downloads because too much tra°c may\ncause a website to crash, and/or the website could identify you as a bot and block you from\naccessing it. To do so, try using the Sys.sleep function.)\nThe directory to contain the data should look like this.\nPset1\npset1_solution.Rmd\ndata\nnypd_stop_data\nsqf-2019.xlsx\n...\nHint\n‹ Use the rvest package to analyze html\n‹ Use download.file function in the base R to download les\n‹ Use regex to identify les to download. Closely examine the html le of the website and make\nsure not to download irrelevant les. You can check the source code with the web browser\n(e.g., go to View/Developer/View Source in Google Chrome).\n2. The downloaded SQF data span multiple years and contain more than one hundred variables that\nmay not be relevant to our analysis. The natural next step is to clean and structure our data.\nIn this problem, we will practice cleaning data programmatically, while the tools we learn can\nbe applied to many settings. The goal is to construct one standard data frame nypd_data that\ncontains four variables year, race, xcoord, and ycoord from years 2014 to 2019. This data frame\nwill then be used to identify election districts for our empirical analysis.\nHint: Use regex to identify targeted years and unzip corresponding les. For further information\nabout the dataset, refer to the code books available at the NYPD website (https://www1.nyc.\ngov/site/nypd/stats/reports-analysis/stopfrisk.page).\n3. Extra Credit. Follow the hint below to map the location of each SQF to corresponding election\ndistrict based on xcoord and ycoord. 3 Since cleaning this data requires some knowledge in GIS\nsystem, we provide the cleaned version of the data (nypd_sqf_2014_2019.csv) for later analysis\non the Canvas website.\nHint\n‹ NYC publicizes GIS data of election district, which is also available on Canvas.\n‹ The geographic coordination system used in the SQF data is not based on longitude and\nlatitude.\nproject function in the proj4 package will be useful to convert its geographic\ncoordination system to longitude/latitude rst. You may nd the following website helpful:\nhttps://spatialreference.org/ref/epsg/nad83-new-york-long-island-ftus/proj4/.\n3 Note that election district is an administrative border created within each electoral district.\n\n‹ To match the election district with each SQF location, st_intersects function in the sf\npackage would be useful.\n4. In this question, we will analyze the impact of SQF on the electoral outcomes using the collected\nNYPD data (nypd_sqf_2014_2019.csv on Canvas).\nWe apply the Di erence-in-Di erences strategy to estimate the e ect of the changes in SQF on the\nchanges in the vote share for the Democratic candidate (We will learn more about the Di erence\nin-Di erences strategy later in the course). In our regression analysis, the outcome variable is the\nproportion of votes for the Democratic candidate in the 2016 and 2020 presidential elections, Yit,\nwhere i denotes the election district and t denotes one of the two time periods. The explanatory\nvariable, Dit, is the average number of SQF in 20142016 and 20172019. We de ne Tt as the\nbinary indicator that will be equal to one for the second period and zero for the rst period. We\nwill also include a vector of Xit as our control variables. Formally, we estimate the regression\nmodel:\nYit = β0 + β1Dit + β2Tt + β3DitTt + γ0Xit + εit\nLoad the election result data from the 2016 and 2020 presidential election (pres_res.csv). The\ndata is measured at election district level, which is much more granular than any other adminis\ntrative district.4\nFollowing variables are contained in the data:\n‹ year: year of election, either 2016 or 2020\n‹ election_type: type of election\n‹ district: electoral district\n‹ elect_dist: election district\n‹ vote_dem: the proportion of votes for the Democratic candidate received in the election district\nThe election district control variables are available in demographic_df.csv on Canvas.\nThose\ncontrol variables are total_pop, black, unemploy_rate, and median_income.\nEstimate the model with an ordinary least square regression. Plot all the estimates along with\n95% con dence intervals. In your plot, make sure to adjust for your standard error and highlight\nthe quantity of interest with a di erent color. Finally, brie y interpret the results and explain the\nrationale of this modeling strategy and necessary assumptions for causal identi cation.\n5. One potential confounder in our analysis is neighborhood safety. That is, whether the neighborhood\nis safe or not might a ect both votes toward Democrats and SQF. To address this concern, we will\ncollect crime report data in NYC while practicing using API. Follow the steps below to obtain the\nAPI token and download this dataset.\n‹ Sign up for API token at https://data.cityofnewyork.us/signup (Using App Tokens\nwill be enough).\n‹ Access crime report data at https://data.cityofnewyork.us/resource/qgea-i56i.json.\n4 You can check election districts in NYC at this website: https://vote.nyc/page/nyc-district-maps\n\n‹ Write codes to download the crime report data from years 2017 to 2019 and extract variables\nrpt_dt, law_cat_cd, latitude, longitude, x_coord_cd, y_coord_cd. You may nd the\nhttr package useful.\n‹ Limit your download per query to 5000. Note that over-tra°c can crash the server and other\npeople might not be able to use the API. $offset and $limit would be useful to control the\nnumber of query.\n‹ Construct the data frame and lter for felony and violation in the crime category.\nOnce you nish downloading the data, create a data frame to store the data. First ve rows should\nlook like this:\nrpt_dt\nlaw_cat_cd\nlatitude\nlongitude\nx_coord_cd\ny_coord_cd\n2017-01-01T00:00:00.000\nFELONY\n40.872037533\n-73.83784794\n2017-01-01T00:00:00.000\nFELONY\n40.830911443\n-73.866137497\n2017-01-01T00:00:00.000\nFELONY\n40.67109684\n-73.906209401\n2017-01-01T00:00:00.000\nFELONY\n40.837436665\n-73.944159423\n2017-01-01T00:00:00.000\nVIOLATION\n40.627248134\n-73.942627681\nAlthough you can click and download the entire data from 2006, it is an extremely huge le (larger\nthan 1GB) and would be di°cult to load in R even if you directly download the data manually\nfrom the website. Therefore, it is necessary to download just relevant observations and columns by\ncommunicating with API. The New York City API is constructed based on the Socrata Open Data\nAPI, which is widely used in governments, non-pro ts, and NGOs around the world. Once you\ncomplete this task, you will be able to deal with any datasets that use the Socrata's\nsystem at http://www.opendatanetwork.com/.\n6. Extra Credit. Now follow the same steps in Question 3 to map the crime report data to election\ndistricts. Calculate the number of crime reports from 2014 to 2016 and from 2017 to 2019 for each\nelection district. Include this additional control variable in our Di erence-in-Di erences analysis.\nAre our results robust?\n7. Another way to strengthen our analysis is to test the mechanism through which SQF a ects voting\nbehaviors. One possible mechanism is that Democratic politicians have introduced more or fewer\nbills on police reforms as a response to increasing concerns over law enforcement. To start on\nthis analysis and practice parsing PDF les, download the meeting agenda for NYC Committee\non Public Safety from years 2014 to 2019 (available on Canvas).5 Read in PDF les and apply\nregex to extract bill, bill number, committee chair, and date of introduction. For this question,\nyou should focus on bills with Int as the pre x and can approximate the date of introduction as\nthe printed date (See Figure below). Construct a dataset with the rst few rows as:\nbill\nbill number\nchair\ndate\nInt 1234-2018\n1234-2018\nDonovan J. Richards\n1/ 18/19\nInt 1261-2018\n1261-2018\nDonovan J. Richards\n1/ 18/19\nInt 1105-2018\n1105-2018\nDonovan J. Richards\n2/ 6/19\nInt 1309-2018\n1309-2018\nDonovan J. Richards\n2/ 6/19\n5 The\noriginal\nles\nare\navailable\nat\nhttps://legistar.council.nyc.gov/DepartmentDetail.aspx?ID=6913&GUID=\nBCE87221-FD8F-40B5-94D4-66C5F4F643E7\n\nWhat do you observe about the number of reform bills across two periods of study (i.e., 2014-2016\nand 2017-2019)? Given our goal, can you think of a way to improve this data collection strategy?\n(c) New York City Council. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see https://ocw.mit.edu/help/faq-fair-use/\nFigure 1: Sample Meeting Agenda for NYC Committee on Public Safety. The highlighted\nparts represent the key information we would like to extract for our analysis.\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\nRES.TLL-008 Social and Ethical Responsibilities of Computing (SERC)\nFall 2022\nFor information about citing these materials or our Terms of Use, visit: https://\nocw.mit.edu/terms"
        }
      ],
      "source_url": "https://ocw.mit.edu/courses/res-tll-008-social-and-ethical-responsibilities-of-computing-serc/",
      "course_info": "RES.TLL-008 | Non-Credit",
      "subject": "General"
    },
    {
      "course_name": "Geographic Information System (GIS) Tutorial",
      "course_description": "No description found.",
      "topics": [
        "Social Science",
        "Geography",
        "Social Science",
        "Geography"
      ],
      "syllabus_content": "",
      "files": [
        {
          "category": "Resource",
          "title": "GIS Level 1 ArcGIS Pro Take-Home Exercises (PDF)",
          "type": "PDF",
          "source_url": "https://ocw.mit.edu/courses/res-str-001-geographic-information-system-gis-tutorial-january-iap-2022/mitres_str001iap22_level1_arcgis_takehome.pdf",
          "content": "Introduction to GIS & Mapping: ArcGIS\nDesktop\nYour task in this exercise is to determine the best place to build a mixed use facility in Hudson County, NJ. In\norder to revitalize the community and take advantage of special loans, you want to build your facility in an area\nwith at least 1.5 times the national unemployment rate (It was 4.4% as of August 2017, which is the year of our\ndata). You will also explore what sort of railroad transit is available in this area.\nOpen ArcGIS Pro\n1. Before you begin, decide where you will be storing the GIS files that you will be downloading and\ncreating in this exercise. You can create a working folder on the desktop or in the Documents folder. The\nexercise data is in the folder you downloaded before the workshop in the folder Data\\Final Exercise.\n2. Open ArcGIS Pro (Start (Windows icon)) > All Programs > ArcGIS > ArcGIS Pro). You will see an open\nscreen where you can create a new map from a blank template. Click on \"Map\" to do so.\n3. You will see a new form where you will name your project and where it will be located:\n4. Uncheck the \"Create a new folder for this project\" checkbox and select the folder where you\ndownloaded the data to (and not the folder that actually contains the data).\nMIT Libraries, GIS Services, Updated 1/6/2022\n\nArcgis Pro is designed like most Windows programs. All of the menus are context sensitive. In the top area (the\ntoolbar), you see a number of tools. Those tools change with the selection of tabs and depending on what data\nlayers you have highlighted.\nAdd a basemap from ArcGIS Online\nNotice that the map you created is not blank, but includes a default basemap. You can change the basemap if\nyou choose:\n1. Click the Map tab and Basemap.\n2. Click on Imagery.\nNote that the layer is served over the web so it may take some time to draw (and you have to be connected to\nthe internet for it to continue drawing). What you see depends on the scale you are working in on your map - as\nyou zoom in closer you will typically find more detailed information. Your scale is displayed below the map and\nautomatically adjusts as you zoom in and out.\nTo navigate your data, you will primarily use these buttons in the Map tab:\nMIT Libraries, GIS Services, Updated 1/6/2022\n\nFrom left to right, top row first, they are used to Zoom to the extent of all layers in the map, zoom to selected\ndata, fixed zoom in, and fixed zoom. You can use the scroll button on your mouse to zoom in and out and you\ncan left click and hold the click to pan around the map.\nFind and add data\nAs you learned, there are many sources for GIS data. We will first find transportation data for New Jersey.\n1. Go to: http://njogis-newjersey.opendata.arcgis.com/datasets?t=Transportation. This shows all the open\ntransportation data for New Jersey. We found this site by doing an internet search for \"new jersey gis\ndata.\"\n2. Search for \"railroad\" in the top search box. Options should drop down from the search box. View the\nPassenger Rail Stations data layer by clicking on its name.\n3. A page opens that previews the data on a map. Click the download icon to the left of the map.\n4. A download pane opens on the left side of the screen. Click Download under Shapefile.\n5. While the file downloads, click the information icon.\nBrief metadata is provided in the sidebar. Click the View Full Details button to see more.\n6. Return to the search box and repeat this process to locate and download the Railroads Network. If you\nwant to explore any other data from this area, feel free to download it.\n7. Move the data to your working folder and unzip each file by right clicking and selecting 7-zip > Extract\nhere (or use whatever data extraction tool you have installed on your computer).\n8. Click the Add Data button on the Map tab and navigate to your working folder where you unzipped the\ndata and add it to the map. One is called Railroads_Network and one has a long code name.\n9. Right click on each layer name and select Properties. In the General tab rename Railroads_Network to\nRailroad_Stations and the long code name to Railroad_Lines.\n10. In addition to the transportation data you just downloaded, add census unemployment data from the\nworkshop materials. It can be found in GIS_Level1_Data\\takehome_exercise.\n11. Right click on Hudson_tracts and select Zoom to Layer.\nThe US Census divides the country into continuous polygons and aggregates census data for these polygons\nbefore releasing the data to the public so that individual responses cannot be identified. Our data is for\ncensus tracts, which contain between 1200 and 8000 people total.\n12. In the Table of Contents of ArcGIS (where all layer names are listed) turn the layers on or off using the\ncheckboxes located to the left of each layer name. Leave the basemap layer unchecked for now so that\nthe next few steps will go more quickly.\nMIT Libraries, GIS Services, Updated 1/6/2022\n\n13. Adjust which layer draws on top by dragging layers above or below one another. You will want your rail\nstations and rail lines on top so they won't be covered by the census tracts polygons. If your layers will\nnot drag, click the List by Drawing Order button at the top of the table of contents.\nExplore the attribute table\n1. Right click on each layer and select Attribute Table.\nEvery point, line, or polygon file has an attribute table. Any data in the attribute table can be used for displaying\nand labeling on the map and making queries. You can also create new columns in the table and add data or\ncalculations. Metadata can be key to understanding attribute tables that use codes and abbreviations.\n2. Leave the attribute table for the tract unemployment data open.\nCan you tell what any of the column headings mean? It's unlikely, so you will need to look at the metadata.\n3. Open the text file (outside of ArcGIS Pro) that is in your Data\\Final_Exercise folder. You now see the\ndefinition for each column. This data was downloaded from a database called Social Explorer, and joined\nto a polygon file from the US Census.\nVariable A17005_003 is the number of unemployed people in the civilian population. Is this what we want to\nmap? Why or why not?\nMapping raw numbers is usually not useful because the total population in one census tract may be more or less\nthan another. One way to \"normalize\" the data is to take into account the total population and calculate a rate.\n4. At the top of the Attribute Table, click the Add field button.\n5. Name the variable Unemp_rate and choose the type as double (you may need to double click on the\nData Type box in order to select it with the cursor). Close the Fields window with the \"X\" and save your\nchanges.\nMIT Libraries, GIS Services, Updated 1/6/2022\n\n6. Right click on the new column that was added and select Calculate Field.\nWe want to divide the number of people unemployed by the total number of people in each tract. Based on the\nmetadata, which columns will you use?\n7. Add fields to the equation by double clicking on them in the list. Make sure your equation matches this\none: A17005_003! / !A17005_001! and click Run. Be patient, it will take a few seconds.\nMIT Libraries, GIS Services, Updated 1/6/2022\n\nWe want to find tracts that are 1.5 times the national unemployment rate. This is equal to .066 or greater.\n8. Click the Table tab at the top of the window, then Select By Attributes. Keep all of the defaults and then\nclick Add (+) New Expression then Create a new expression.\n9. In the Where clause of the expression, you will notice three fields:\na. In the left field, change the column that you want to work with from FID to Unemp_rate in the\ndropdown list.\nb. In the middle field, change \"is equal to\" to \"is greater than or equal to\".\nc. In the last field, enter 0.066. Click Run to select the tracts that have an unemployment rate\ngreater than 0.066.\nAll rows that correspond to a tract with a higher than average unemployment rate are highlighted and the\ncorresponding tracts are highlighted on the map.\n10. Close the Attribute Table.\nExport to a new file\nWe will export the selected tracts to a new data layer so that we can more easily visualize which tracts have high\nunemployment. Exporting a smaller area of data is the easiest way to subset a dataset to only the desired\nrecords or keep your file sizes smaller and more manageable.\n1. Make sure the Hudson_tracts is highlighted in the table of contents.\n2. Click the Data tab and Layer from Selection. Note that this layer is temporary until we export it.\n3. Right click on the new layer created from the selection and select Data > Export Features.\n4. Click on the folder icon to view and edit the save location. Select the folder where you want to save the\nfile (you'll name the layer in the next step).\n5. In the Output Feature Class box name the layer unemp_high.\nNote that file names and locations can be very important when working on projects. GIS software tends to\ngenerate many files, so you want to make sure to use file names that are descriptive and easy to remember in\nthe future.\nMIT Libraries, GIS Services, Updated 1/6/2022\n\n6. Click Run.\n7. Clear the selected features by selecting the Clear button in the Map tab.\n8. Save your map document.\nSymbolize data\nChange a single symbol\nRather than completely covering the unemployment polygon layer with the one for high unemployment, we can\nchange the symbology of the high unemployment layer so that we can still see the tracts for the entire county\nunderneath.\n1. In the table of contents, double click the colored rectangle below the high unemployment layer\n(unemp_high) and change the fill to a pattern, such as 10% simple hatch (you will have to scroll down to\nfind it). That way we can still see the unemployment tract data layer underneath.\n2. Close the Symbology box.\nExplore data distribution\nBefore we make a choropleth map of the unemployment rate, we need to examine our data in order to create\nthe most appropriate map. A quick way to explore the distribution of our data in ArcMap is to make a graph. For\nfuture projects, you will likely want to explore your data outside of ArcGIS in statistical or data visualization\nsoftware in order to better understand it.\n1. Click on the Hudson_tracts_unemp_2017 layer in the Table of Contents.\nMIT Libraries, GIS Services, Updated 1/6/2022\n\n2. At the top of the window under Feature Layer, select the Data tab.\n3. Click Create Chart, choose Histogram.\n4. Choose Unemp_rate as the Number. Feel free to change the number of bins and see how the histogram\nchanges.\nThis histogram is showing the number of tracts (y axis) that fall into each unemployment range (x axis). Not all\nranges are shown because of size constraints on the axis, but this still gives you an idea of the general shape of\nyour data. We see that unemployment rate is relatively low, but that there are some outlying tracts with a high\nemployment rate.\n5. Close the Chart Properties box and the chart itself.\nMIT Libraries, GIS Services, Updated 1/6/2022\n\nMake a choropleth map\n1. Make sure the Hudson_tracts_unemp_2017 layer is highlighted in the table of contents. At the top of\nwindow, click the Appearance tab. Click on the dropdown triangle below Symbology and select\nGraduated Colors. This will open the Layer Properties window.\n2. Select \"Unemp_rate\" as the Field.\n3. Symbolize the data in whatever way you think is best. Map symbology can be used to alter the way\npeople view and understand information, just like statistics. It is important to understand what you want\nto express in your map and how to best symbolize your data.\na. Chose a classification method and number of classes. In order to help you choose a classification\nmethod. Here is more information about each method: https://pro.arcgis.com/en/pro\napp/help/mapping/layer-properties/data-classification-methods.htm\nb. Pick a color scheme from the drop down menu.\nc. You can adjust the number of decimals shown by clicking the Advanced symbol options button\nand adjusting the Rounding options.\n4. Close the window when you are finished.\n5. Save your map document.\nDo you have an idea about where you might build based on the unemployment rate? Obviously many factors go\ninto selecting a building site. We will examine one more: train access.\nFind tracts that have railroad stations\nYou will use the Select by Location tool to select all tracts that contain a railroad station.\nMIT Libraries, GIS Services, Updated 1/6/2022\n\n1. Click on the Map tab. In the Selection menu at the top, click \"Select By Location\".\na. For the Input Features, choose Hudson_tracts_unemp_2017.\nb. Change Relationship to Contains.\nc. For the Selecting Features, choose Railroad_Stations_in_NJ.\n2. Click Run. Now all tracts that contain a railroad station are highlighted in blue. This is temporary until\nyou clear the selection.\n3. Make these into a temporary layer again in the Data tab using the Layer from Selection button. We don't\nhave to export them to a permanent layer this time.\nChoose a tract for building\n1. With the Hudson_tracts_unemp_2017 layer selected in the Table of Contents click the Map tab and the\nClear button.\n2. Now choose the Select button in the tab. Click on the tract that you want to build in, based on the\nvisualization you have made. You can select more than one tract by holding the Shift key as you make\nyour selection.\n3. Again, create a layer from the selected data. Export the data using the method in the Export to\nA New File section of the exercise.\n4. Clear the selection once you have exported the layer and change the symbology of the layer to show it is\nthe one you selected for building.\n5. Wondering what area was actually chosen for this building? Add Bay_street_building from\nData\\Final_Exercise. You may need to double click on the point symbol and adjust the size to see it.\nRead the article here.\n6. Make final changes to the color of any of the data layers and zoom and center your map to prepare for\ncreating a layout.\nMIT Libraries, GIS Services, Updated 1/6/2022\n\nCreate a layout of your map\n1. At the top of the window, in the Insert tab select New Layout.\n2. Select 8.5\" x 11\" Letter under ANSI Landscape.\n3. You should have an empty page. Click the Insert tab and Map Frame. Select the image of your map.\nDraw a box where you would like the map placed. Drag the corner of the map to fill most of the page\nbut leave room for a title, scale bar etc. If you need to adjust the scale once the map frame has been\ninserted, select or type in a value in the scale bar at the bottom of the screen (the smaller the number,\nthe more zoomed in the map).\n4. Click on the Insert tab and Legend. You need to drag the box big enough to see all of the entries. Only\nthe visible layers in your map will be included in the legend.\n5. Using the same procedure, insert a North arrow.\n6. From the Text dropdown (it will say rectangle now), choose Text and place it on your map. Write a title.\nExport your map\n1. Click on the Share tab.\n2. Click Export Layout from the Output section.\n3. Choose PDF in File Type and select the location to save to.\n4. Click on the Export button.\nNote that if you save as an AI (Adobe Illustrator), the layers will remain as separate, editable layers in\nIllustrator. If you save as JPEG or TIFF, you can adjust the resolution of the exported file.\n5. Open your map in Adobe Acrobat to see what it looks like.\nSave your ArcMap document\n1. Click Save button.\nNote that when you save an ArcGIS Pro document, you are only saving a link to the layers in your project. If you\nmove your project to a new location, you will need to move all the files linked to your project with\nit. Each shapefile has multiple files associated together, and they need to stay together to work properly! It is\nbest to save all files in the project folder so they are more transportable with the project.\nMIT Libraries, GIS Services, Updated 1/6/2022\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\nRES.STR-001 Geographic Information System (GIS) Tutorial\nIAP 2022\nFor information about citing these materials or our Terms of Use, visit:\nhttps://ocw.mit.edu/terms\nMIT Libraries, GIS Services, Updated 1/6/2022"
        },
        {
          "category": "Resource",
          "title": "GIS Level 1 ArcGIS Pro Workshop Exercises (PDF)",
          "type": "PDF",
          "source_url": "https://ocw.mit.edu/courses/res-str-001-geographic-information-system-gis-tutorial-january-iap-2022/mitres_str001iap22_level1_arcgispro.pdf",
          "content": "GIS Level 1: ArcGIS Pro Workshop Exercises\nExercise 1\nOpen software\n1.\nOpen ArcGIS Pro on your computer. Select Map from the Blank Templates area.\n2.\nName your Project GIS_Level1 and select a location for saving it. A blank map will now open.\nAdd data\n1.\nClick the Map tab and the Add Data button.\n2.\nNavigate to the workshop folder and select GIS_Level1_Data\\workshop_exercises.\n3.\nAdd all the data layers:\na.\nMBTA_NODE\nb.\nMBTA_ARC\nc.\ncambridge_demographics\nd.\ncambridge_DEM\ne.\ncambridge_restaurants\nIt may take a minute for the data to load.\nReview interface & organize data\n-\nThe center of the screen contains a basemap that has been automatically loaded. It is there to\nprovide context for the data that we added.\n-\nYou can move around the map using the pan and zoom buttons in the Map tab of the top menu\nbar.\n-\nData layer names are shown in the Contents pane on the left. You can right click on any layer\nand select Zoom to Layer to center it on the screen.\n1.\nDrag the layers up or down so that they do not cover each other.\n2.\nYou can turn layers on and off by checking/unchecking the box next to each name. Uncheck the\ncambridge_DEM for now so it is easier to see the other data layers (we will change its\nappearance later in the exercise).\n\nClicking the menus at the top of the screen will show various tools you can use to edit, visualize and\nanalyze your data. The toolbox in the Analysis tab will open the full list of analysis tools, which we will\nexplore more in GIS Level 2.\nIdentify types of data & explore attributes\n1. Look at the data layers in the Contents pane. Are they vector or raster data? If they are vector,\nare they point, line or polygon?\n2. To see the underlying data of each layer, right click on it and select Attribute Table.\na. What columns are included with the MBTA_ARC data?\nb. What about the cambridge_DEM? Why are they different?\n3. The cambridge_restaurants data layer is currently not in a shapefile format so it is not displaying\non the map, however we can convert it to point data by plotting the coordinates included in the\ntable.\na. Right click on the cambridge_restaurants table in the Contents pane and select Display\nXY Data.\nb. Click the folder next to Output Feature Class to select a location to save the data and\nchoose a file name.\nc. The X Field should already be filled in with Longitude and the Y field with Latitude. Keep\nthe Coordinate System as GCS_WGS_1984.\nd. Click OK.\n4. Save your map project and keep your map open.\n\nExercise 2\nData can be symbolized in a variety of ways, depending on the data format and available attributes.\nChange a single symbol\n1. Double click on the point symbol below the Cambridge_restaurants layer in the Contents pane.\n2. Choose a symbol to represent the restaurants. You can make additional modifications to the\nsymbol in the Properties tab.\n3. Close the Symbol window when you are finished.\nSymbolize categories\nYou want to change the color of the mbta lines (MBTA_ARC) so they correspond to the correct color.\n1. Right click on MBTA_ARC and select Symbology.\n2. Choose Unique Values under Primary symbology, which means that each value will be assigned\na unique color, pattern, etc.\n3. Look at the metadata (https://www.mass.gov/info-details/massgis-data-mbta-rapid-transit) to\ndetermine which column contains information about the name of the rapid transit line. Choose\nthe appropriate column from the dropdown menu in Field 1.\n4. Click the Add all Values button to add all unique values found in the LINE column.\n5. Click on the line symbol in the Symbol column to select an appropriate color. Click Apply and the\nback arrow after selecting each color.\n6. Close the Symbology window when you are finished.\nMake a choropleth map\n1. Select the Cambridge_demographics layer in the Contents pane by clicking on it so it is\nhighlighted.\n2. Click the Appearances menu and Symbology.\n3. Select Graduated Colors from the Primary symbology dropdown menu to create a choropleth\nmap.\n4. Open the metadata for this layer outside of ArcGIS Pro. It is in the workshop_exercise data\nfolder and called Cambridge_demographics_variable_names.txt. Choose which data you would\nlike to symbolize and choose the corresponding column from the Field dropdown menu.\n5. Experiment with different break methods, classes, and color schemes from the dropdown\nmenus until you are happy with your map.\n6. Click the Advanced symbology options tab and expand Format labels.\n7. Click the Category dropdown to select the appropriate numeric display for your data and alter\nthe number of decimal places if needed.\n8. Close the symbology window when you are finished.\n\nSymbolize a raster\n1. Right click on Cambridge_DEM and select Symbology.\n2. There are different options for symbolizing raster data versus vector data. The DEM is currently\nsymbolized as Unique values which are most appropriate for values that each represent a\ndifferent data category, such as land use so you should choose a different symbology. Feel free\nto experiment with other options from the dropdown menu:\na. Stretch: assigns a continuous color scheme from the minimum to the maximum value of\neach raster cell\nb. Discrete: you choose a specific number of colors to use when symbolizing data\nc. Classify: data value are grouped into classes, similar to when creating a choropleth map.\n3. When you are happy with your raster symbolization, close the Symbology window.\nSee the take home exercise for information on how to create a layout for printing or exporting your\nmap.\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\nRES.STR-001 Geographic Information System (GIS) Tutorial\nIAP 2022\nFor information about citing these materials or our Terms of Use, visit:\nhttps://ocw.mit.edu/terms"
        },
        {
          "category": "Resource",
          "title": "GIS Level 1 GIS Workshop Exercises (PDF)",
          "type": "PDF",
          "source_url": "https://ocw.mit.edu/courses/res-str-001-geographic-information-system-gis-tutorial-january-iap-2022/mitres_str001iap22_level1_qgis.pdf",
          "content": "GIS Level 1: QGIS Workshop Exercises\nExercise 1\nOpen software\n1. Open QGIS on your computer. Select the new Project icon.\n2. A blank map will now open. Click the Save icon to name and save your project.\nAdd data\n1. Click the top Layer Tab > Data Source Manager button.\n2. Click the Vector icon on the left.\n3. To the right of the 'Vector Dataset(s)' box, click the ... icon. Navigate to the workshop folder and\nGIS_Level1_Data/workshop_exercises.\n4. Hold Ctrl and select the .shp files for each of the following layers:\na. cambridge_demographics.shp\nb. MBTA_ARC.shp\nc. MBTA_NODE.shp\nWhen done selecting > click Open > and then click Add > and follow the instructions below.\n5. A coordinate reference system window may appear because our project has a different\ncoordinate system than our data layers. This tool will change the project coordinate reference\nsystem to that of the data layers so they appear less distorted on screen. We will discuss map\nprojections more in GIS Level 2. You can select OK to close this window for now.\n6. Now we will add raster data. Click the raster icon on the far left-hand side of the Data Source\nManager window.\na. Click the ... icon to the right of the Raster dataset(s) box and select cambridge_dem.tif\nfrom the data folder.\nb. Click Add and then close the window.\nNote: if you accidentally added duplicate layers you can right click them and select to remove.\n\n7. Make sure the Quick map plugin is installed by clicking Plugins > Manage and Install Plugins >\nand searching for QuickMapServices. Click the Install Plugin button. (This button will only be\nvisible if the plugin is not installed.) Close the plugin window.\n8. Add a basemap by clicking Web > QuickMapServices > OSM > OSM Standard.\nReview the interface & organize data\n-\nThe center of the screen displays any data that we added.\n-\nThe names of data layers are shown in the Layers pane on the left.\n-\nMove around the map using the pan and zoom buttons in the top menu bar.\n-\nRight click on any layer and select Zoom to Layer to center it on the screen\n-\nTurn layers on and off by checking/unchecking the box next to each name.\n1. Drag the layers up or down in the Layers box so that they do not cover each other.\nThe menus at the top of the screen show various tools you can use to analyze vector or raster data. New\nmenus may appear when you load additional plugins using the Plugins menu.\nIdentify types of data & explore attributes\n1. Look at the data layers in the Layers pane. Are they vector or raster data? If they are vector, are\nthey point, line or polygon?\n2. To see the underlying data table for a layer, right click and select Open Attribute Table.\na. What columns are included with the MBTA_ARC data?\nb. Is there an attribute table for cambridge_dem? Why might that be?\nCreating geographic data from tabular data\nThe cambridge_restaurants data layer is currently not in a shapefile format so it was not added to the\nmap, however we can convert it from a .csv to point data by plotting the coordinates included in the\ntable.\n1. Open the Layer > Data Source Manager again and select the Delimited Text tab.\n2. Next to File Name > click the ... menu and navigate to the .csv in the data folder.\n3. In the Geometry Definition section (click the arrow to extend the dropdown) select Point\ncoordinates with the X Field as Longitude and the Y field as Latitude.\n4. In the same section, for Geometry CRS, select EPSG:4326 - WGS 84 from the dropdown menu. If you\ndon't see it listed, click the Select CRS button next to the dropdown menu to search for it.\n5. Click Add and Close. Now see where the cambridge_restaurants show up as points.\n6. Save your project and keep it open.\n\nExercise 2\nData can be symbolized in a variety of ways, depending on the data format and available attributes.\nChange a single symbol\n1. Double click on the cambridge_restaurants layer in the Layers pane.\n2. Click the Symbology tab.\n3. Click on the text, Simple marker. Down below, choose a symbol to represent the restaurants.\nYou can make additional modifications to the symbol using the various dropdown menus.\n4. Click Ok and close the Properties window when you are finished.\nSymbolize categories\nNow change the color of the mbta lines (MBTA_ARC) so they correspond to the correct color.\n1. Right click on MBTA_ARC and select Properties. Select the Symbology tab.\n2. From the dropdown menu at the top, choose the styling to be Categorized, which means that\neach value will be assigned a unique color, pattern, etc.\n3. Look at the metadata (https://www.mass.gov/info-details/massgis-data-mbta-rapid-transit) to\ndetermine which column contains information about the name of the rapid transit line. Choose\nthe appropriate column from the dropdown menu in the Value box.\n4. Click the Classify button, at the bottom, to add all unique values found in the LINE column.\n5. Double click on the line symbol in the Symbol column to select an appropriate color.\n6. Click OK when you are finished.\nMake a choropleth map\n1. Double click the cambridge_demographics layer and select the Symbology menu.\n2. Select Graduated from the dropdown menu at the top to create a choropleth map.\n3. Open the metadata for this layer outside of QGIS. It is in workshop_exercise data folder and\ncalled cambridge_demographics_variable_names.txt.\n4. Choose which data you would like to symbolize and choose the corresponding column from the\nValue dropdown menu.\n5. Click the Classify button at the bottom of the window. Experiment with different break\nmethods, classes, and color schemes from the dropdown menus until you are happy with your\nmap.\n6. Use the precision dropdown menu to alter the number of decimal places if needed.\nClick Ok when you are finished.\n\nSymbolize a raster\n1. Double click on cambridge_dem and select the Symbology tab.\n2. Notice that there are different options for symbolizing raster data versus vector data.\na. The data are currently symbolized as Singleband gray, which assigns a continuous color\nscheme from the minimum to the maximum value of each raster cell.\nb. Another option that could be appropriate for this data is Singleband pseudocolor, in\nwhich data value are grouped into classes, similar to when creating a choropleth map.\nChoose a color ramp to see the options for this rendering. Note: Paletted/Unique values\nwould be the most appropriate for values that each represent a different data category,\nsuch as land use.\nc. Experiment with the symbolization. When you are happy with your raster click OK.\nSee the take home exercise to learn how to create a layout for printing or how to export your map.\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\nRES.STR-001 Geographic Information System (GIS) Tutorial\nIAP 2022\nFor information about citing these materials or our Terms of Use, visit:\nhttps://ocw.mit.edu/terms"
        },
        {
          "category": "Resource",
          "title": "GIS Level 1 Instructions (PDF)",
          "type": "PDF",
          "source_url": "https://ocw.mit.edu/courses/res-str-001-geographic-information-system-gis-tutorial-january-iap-2022/mitres_str001iap22_level1_instructions.pdf",
          "content": "GIS Level 1 Setup Instructions\nNote: This activity uses online resources that may not be freely available to OCW users.\nThank you for registering for GIS Level 1. Before the workshop, please do the following:\n1.\nDownload and install either ArcGIS Pro or QGIS\n2.\nInstall 7-zip if necessary\n3.\nDownload all workshop materials\n4.\nUpdate and setup Zoom\nDownload and install ArcGIS Pro or QGIS\nQGIS is a free, open source software program that will work on any operating system and doesn't take\nup much space on your computer. While it has many of the same capabilities as ArcGIS Pro, there are\nsome analyses you can't do in QGIS and it tends to have more bugs.\nArcGIS Pro is a commercial software from ESRI that we have a subscription for at MIT. It only runs on\nWindows and requires an account or a connection to the MIT license server to run. It includes a full\nsuite of GIS tools, but may not run well if you have a slower computer.\nIf you are not sure which software to use, this website has a lot of additional information:\nhttps://gisgeography.com/qgis-arcgis-differences/\nNote: This workshop will NOT use ArcGIS Desktop/ArcMap, only ArcGIS Pro, the newest GIS software\nfrom ESRI.\nArcGIS Pro installation\n1. Create an ArcGIS Online (AGOL) account: https://libguides.mit.edu/gis/webmap#s-lg-box-wrapper\n2. If you have not already downloaded Pro, log into your AGOL account. From your account page, click\nyour name in the upper right and select My settings > Licenses and click download next to ArcGIS Pro.\n3. After installing Pro, choose the Named User License type and select ArcGIS Online. You'll then see the\nsame login screen that you used to create your account.\nQGIS Installation\nFull instructions and links for installing QGIS for a number of different operating systems can be found\nhere: http://qgis.org/en/site/forusers/download.html\nWindows users should download QGIS Standalone Installer. (Mac users only have one option.)\nDownload QGIS 3.16 or higher. If you already have QGIS installed, we have tested the workshop\nexercises with versions 3.16 and higher so we recommend upgrading if you are using an older version.\n\n7-zip installation\nWorkshop files (and most GIS data) are in zipped folders. Most Windows computers have the option to\nextract data by right clicking and most Macs will automatically extract data. Occasionally your computer\nmay not have a built-in data extraction tool. In this case we recommend installing 7-zip:\nhttps://www.7-zip.org/\nWorkshop materials\nDownload all workshop materials.\nMaterials include the presentation, workshop exercises, take-home exercise, and all required data.\nZoom setup\n1.\nMake sure your Zoom app is up-to-date using these instructions. You may have difficulty\ncompleting exercises in breakout rooms if your Zoom is not updated:\nhttps://support.zoom.us/hc/en-us/articles/201362233-Upgrade-update-to-the-latest-version\n2.\nIf you have access to a second monitor (or a second \"smart\" device that can connect to a Zoom\nsession) it may greatly improve your workshop experience and make it easier to follow the\ninstructor and complete the exercises simultaneously. If not, it is still doable, for example, by\norganizing your screen in this way:\nhttps://raw.githubusercontent.com/hbctraining/bioinformatics_online/master/guidelines/img/S\ncreenshot%202020-03-23%2015.21.10.png\n3.\nWe encourage participation during the session and kindly ask you to use your video, if possible.\n4.\nMute audio except when talking (Tip: you can temporarily unmute yourself by pressing and\nholding a space bar. When it is released, Zoom goes back to the mute mode).\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\nRES.STR-001 Geographic Information System (GIS) Tutorial\nIAP 2022\nFor information about citing these materials or our Terms of Use, visit:\nhttps://ocw.mit.edu/terms"
        },
        {
          "category": "Resource",
          "title": "GIS Level 1 QGIS Take-Home Exercises (PDF)",
          "type": "PDF",
          "source_url": "https://ocw.mit.edu/courses/res-str-001-geographic-information-system-gis-tutorial-january-iap-2022/mitres_str001iap22_level1_qgis_takehome.pdf",
          "content": "Introduction to GIS & Mapping: QGIS Desktop\nYour task in this exercise is to determine the best place to build a mixed use facility in Hudson County, NJ.\nIn order to revitalize the community and take advantage of special loans, you want to build your facility in an\narea with at least 1.5 times the national unemployment rate (4.4% as of August 2017, the year of our data). You\nwill also explore what sort of railroad transit is available in this area.\nOpen QGIS Desktop\nThis exercise has been tested with QGIS versions 3.16 and higher, though previous releases will likely work as\nwell.\n1. Decide what folder you will use to store your map and data. We recommend using the folder where you\ndownloaded the workshop materials.\n2. Open QGIS (Start (Windows icon)) > All Programs > QGIS > QGIS Desktop 3.X). Note: if this is the\ncomputer's first time opening the new version it may present window with a welcome message; click\n\"Let's get started!\" Now, open a new map by clicking on the Project tab in the top menu and then the\n'New' project icon in the upper left corner of the QGIS Desktop window.\na. If you do not see this icon it may be due to what toolbars are turned on. Go to the View tab in\nthe top menu > Toolbars (at bottom) > and make sure the following toolbars are checked:\nAttributes, Map Navigation, and Project. You can also access the panel and toolbar menu by\nright clicking anywhere in the grey of the top menu.\nNote: the QGIS Project file is a record of the layers that have been added to a map display, along with\nthe map display itself. This allows users to recover a map display including the layers in the map,\nsymbolization, visibility, units of measurement, and other display settings (similar to other software).\n3. Click Project > 'Save As...' to save your project in the folder you set up. We recommend saving frequently\nwith any GIS software as there can be crashes when running tools.\nAdd a basemap\nAdding a basemap is a quick and easy way to provide context to spatial data you are displaying or analyzing.\n1. Look for the Web menu at the top of the screen and QuickMapServices. If you do not see it, follow the\ninstructions below. If it is there, continue to step 2.\nMIT Libraries, GIS Services, Updated 1/6/2022\n\na.\nIf you cannot see the QuickMapServices plugin, click 'Plugins' in the top menu > 'Manage and\nInstall Plugins...'\nb.\nSelect 'QuickMapServices' from the list of plugins.\nc.\nClick 'Install Plugin' > and 'Close' the window.\n2.\nClick the Web tab in the top menu, and hover over the QuickMapServices Plugin until the dropdown\nmenu shows. Click on OSM Standard.\n3.\nNote that the layer is served over the web so it may take some time to \"draw\" (you must be connected\nto the internet to use this plugin). What you see depends on the scale you are working in on your map\nas you zoom in closer (see methods below) you will typically find more detailed information. Your scale\nis displayed in the Standard toolbar and automatically adjusts as you zoom in and out.\n4.\nTo navigate your data you will primarily use these buttons:\nFrom left to right, they are used to pan, pan to selection, zoom in, zoom out, and zoom to the full extent\nof all visible data. Take a moment to explore these options as you will use them often. Note that the\nicons may vary slightly depending on the version of QGIS that you have. You can hover over an icon to\nsee its name.\n5.\nThe coordinate of your mouse pointer and zoom scale are shown along the bottom right of the map:\nFind and add data\nAs you learned, there are many sources for GIS data. We will first find transportation data for New Jersey.\n1.\nGo to: http://njogis-newjersey.opendata.arcgis.com/datasets?t=Transportation. This shows all the open\ntransportation data for New Jersey. We found this site by doing an internet search for \"new jersey gis\ndata.\"\n2.\nSearch for \"railroad\" in the top search box. Options should drop down from the search box. View the\nPassenger Rail Stations data layer by clicking on its name.\nMIT Libraries, GIS Services, Updated 1/6/2022\n\n3. A page opens that previews the data on a map. Click the download icon on the left side of the map.\n4. A download pane opens on the left side of the screen. Click Download under Shapefile.\n5. While the file downloads, click the information icon. Brief metadata is provided in the sidebar. Click the\nView Full Details button to see more.\n6. Return to the search box and repeat this process to locate and download Railroads Network. If you\nwant to explore any other data from this area, feel free to download it.\n7. Move the files to your folder and unzip the files by right clicking on file and selecting 7-Zip > Extract Here\n(or use the data extraction software installed on your computer).\n8. Go back to QGIS. In the top menu select Layer > Add Layer > Add Vector Layer...\n9. Navigate to your working folder by clicking on ... to the right of the Source box.\na. Select the two shapefiles by selecting the file with the .shp extension. Hold ctrl to select multiple\nfiles. One is called Railroads_Network and one has a long code name.\nb. Click Open > Add (if a projection warning comes up, hit OK for now) > close window when done.\nc. Note that even though you selected the .shp files, QGIS is using all the files that make up the\nshapefile in order to place the data in the proper position on the map.\nd. If the box appears for converting coordinate reference systems, click Ok and Ok again if\nprompted. We will work with coordinate reference systems in GIS Level 2.\ne. Right click on the layer name and select, \"Zoom to layer.\" Note depending on the random color\nassigned to the railroad lines they may be hard to see.\nf.\nRight click on each layer name and select Rename Layer. Rename Railroads_Network to\nRailroad_Stations and the long code name to Railroad_Lines.\n10. In addition to the transportation data you just downloaded, add census unemployment data to the map.\nThis data can be found in the folder Data\\Final_Exercise. Repeat the process of adding a vector layer:\n\"Hudson_tracts_unemp_2017.shp\". Close the Add Vector data box and Zoom to this layer to hone in on\nthe project site.\nThe US Census divides the country into continuous polygons and aggregates census data for these polygons\nbefore releasing the data to the public so that individual responses cannot be identified. Our data is for\ncensus tracts, which contain between 1200 and 8000 people.\nMIT Libraries, GIS Services, Updated 1/6/2022\n\n11. In the Table of Contents of QGIS (where all layer names are listed) turn the layers on or off using the\ncheckboxes located to the left of each layer name. Leave the basemap layer unchecked for now so that\nthe next few steps will go more quickly (basemaps can slow down the drawing of other layers).\n12. Adjust which layer draws on top by dragging layers above or below one another. Note: You will want to\nend up with your rail stations and rail lines on top so they won't be covered by census tract polygons.\nExplore the attribute table\n1. Right click on each layer's name > select Open Attribute Table... This is the data associated with each\nlayer, and what that layer's symbolization will be based upon.\nEvery point, line, or polygon file has an attribute table. Any data in the attribute table can be used for displaying\nand labeling that layer as well as make queries from. You can also create new columns in the table and add data\nor calculations. Note: metadata can be key to understanding attribute tables that use codes and abbreviations.\n2. Leave the attribute table for the tract unemployment data open.\nCan you tell what any of the column headings mean? It's unlikely, so you will need to look at the metadata.\nOpen the text file (outside of QGIS) in Data\\Final Exercise. You now see the definition for each column. Note:\nthis data was downloaded from a web based GIS, Social Explorer, and joined to a polygon file from the US\nCensus.\nQ: Variable A17005_003 is the number of unemployed people in the civilian population. Is this what we want to\nmap? Why or why not?\nA: Mapping raw numbers is not often useful because the total population in one census tract may be more\nor less than another, and so the counts are not meaningful to compare between geometries. One way to\n\"normalize\" data is to divide the counts by the total population to calculate a rate.\n3. Click the Open Field Calculator icon\na. Note, in some versions of QGIS this may be greyed out until you click the Toggle edit icon\n4. Make the Output field name Unemp_rate and make the Output field type Decimal number.\na. In some versions of QGIS, you may need to specify the field length (if these options are greyed\nout, ignore this step). In this case, make Output field length 11 (number of characters) and\nprecision (number of decimal places) 11.\nQ: Since we want to divide the number of people unemployed by the total number of people in each tract. What\ncolumns would you use to do this, (remember you can look at metadata to know what each column is)?\nA: To create the expression that will calculate the unemployment rate:\n-\nClick in the Expression box\n-\nOpen the Fields and Values menu in the box to the right (under the search line)\n-\nDouble click on the fields to add them to the expression box (you can also type them in directly)\n-\nUse the divide by function button between fields to create the expression shown.\nMIT Libraries, GIS Services, Updated 1/6/2022\n\n5. Click OK.\n6. If you turned on editing, click the Save edits icon in the table's menu\nAnd click the Toggle edit ( ) to stop editing.\nIf you did not turn on editing, proceed to the next step.\nNext, based on the original problem statement we know that we want to find tracts that are 1.5 times the\nnational unemployment rate. This is equal to .066 or greater. Click the Select features using an expression\nbutton at the top of the table's menu window.\n7. Open the Fields and Values menu. Double click on Unemp_rate in the list. This will add it to the\nexpression box on the left. Finish the expression by setting it greater than or equal to .066\n(\"Unemp_rate\" >= .066). You will find >= in the Operators menu (below the Fields and Values menu).\nClick Select Features and close the Select by expression window, to see the rows that were selected.\nMIT Libraries, GIS Services, Updated 1/6/2022\n\nAll rows that correspond to a tract with a higher than average unemployment rate are highlighted and the\ncorresponding tracts are highlighted on the map.\n8. Without clicking anywhere within the table or map (will alter the selection), close the Attribute Table.\nExport to a new file\nWe will now export the selected tracts to a new data layer so that we can more easily visualize which tracts have\nhigh unemployment. Exporting a smaller area of data is the easiest way to subset a dataset to only the desired\nrecords or keep your file sizes smaller and more manageable.\n1. Right click the unemployment layer in the table of contents > Export > Save Selected Features As...\n2. Make the Format ESRI Shapefile. Click the ... next to the File name box and navigate to your folder.\nName the file \"Unemp_ratehigh\" in your folder. Keep the CRS (EPSG,4269, NAD83). Click OK.\nNote: file names and locations can be very important when working on projects. GIS software tends to generate\nmany files, so you want to make sure to use file names that are descriptive and easy to remember.\n3. Clear the selected features by clicking the \"Deselect features from all layers\" icon in the top menu.\n4. Now try turning on/off this new layer and the original unemployment data. What do you notice?\n5. Save your map document to your working folder on your local drive using the Save icon.\nSo far you have learned how to open and navigate the software, use plugins to add a basemap, find, download,\nand add data, explore and select from the attribute table based on information in the metadata, perform a\nselection, and export your new dataset. You have completed many parts of getting started in a GIS and are half\nway through the exercise. Feel free to take a short break before continuing on to symbolization, decision\nmaking, and creating and exporting your final map.\nMIT Libraries, GIS Services, Updated 1/6/2022\n\nSymbolize data\nChange a single symbol\nRather than completely covering the unemployment polygon layer with the one for high unemployment, we can\nchange the symbology of the high unemployment layer so that we can still see the tracts for the entire county\nunderneath.\n1. In the table of contents, double click the high unemployment layer (Unemp_ratehigh) name.\n2. Click on the Symbology tab\n3. Click on the words, \"Simple fill\" to bring up the options.\n4. In Fill Style, change the Simple fill style to a pattern, such as Diagonal X. That way we can still see the\nunemployment tract data layer underneath.\n5. Adjust the color (using the drop down menu in the 'Fill' box) and click OK when done.\nNote: Your help screen may look slightly different depending your version of QGIS.\nMIT Libraries, GIS Services, Updated 1/6/2022\n\nExplore data distribution\nBefore we make a choropleth map of the unemployment rate, we need to examine our data in order to create\nthe most appropriate map. A quick way to explore the distribution of our data in QGIS is to make a graph.\n1. Double Click hudson_tracts_unemp_2017 in the Layers Panel.\n2. Choose Symbology from the left column.\n3. Select Graduated from the top dropdown menu.\n4. Choose Unemp_rate as your Value/Column.\n5. Select a color ramp of your choosing.\n6. Click Classify to load that field's values.\nMIT Libraries, GIS Services, Updated 1/6/2022\n\n7. Now select the Histogram tab (next to Classes). Click on Load values and see how the frequency of\ndifferent values are being symbolized based on the method, number of classes, & color ramp.\nWe see that unemployment rate is relatively low, but that there are some outliers with a high employment rate.\nMake a choropleth map\n1. Symbolize the data in whatever way you think is best. Map symbology can be used to alter the way\npeople view and understand information, just like statistics. It is important to understand what you want\nto express in your map and think carefully about how best to symbolize your data. Note: you can click\napply when finished instead of OK to test options, without leaving the Layer Properties window.\na. Pick a color ramp from the drop down menu.\nb. Choose the mode and number of classes (options below the classes box)\nc. Here is brief information about some of the available classification methods. For a more in\ndepth analysis check out our mini-tutorial on choropleth mapping.\ni. Equal Interval: classes are all the same size.\nii. Quantile - number of values in each class is the same. If there are 100 values and we\nwant 4 classes, quantile method will make it such that each class will have 25 values.\niii. Natural Breaks (Jenks) - algorithm finds natural groupings of data to create classes. It\nmaximizes the variance between individual classes and min. variance within each class.\niv. Standard Deviation - creates classes based on standard deviations from the mean.\nv. Pretty Breaks - This is based on the statistical package R's pretty algorithm. It is a bit\ncomplex, but the pretty in the name means it creates classes with round numbers.\nd.\nTo reduce the number of decimals shown in the legend, use the Precision options in the upper\nright part of the Symbology window.\n2. Click Ok when you are finished.\n3. Save your map document.\nDo you have an idea about where you might build based on the unemployment rate?\nObviously many factors go into selecting a building site. We will examine one more: train access.\nFind tracts that have railroad stations\nYou will use the Spatial Query tool to select all tracts that contain a railroad station.\n1. From the top menu, click Vector > Research Tools > Select by Location.\n2. Select features from the hudson_tracts_unemp_2017 data layer, where the features \"contain\" features\nfrom the Railroad_Stations_in_NJ.\n3. Click Run > then Close.\nMIT Libraries, GIS Services, Updated 1/6/2022\n\nNow all tracts that contain a railroad station are highlighted. Based where there is high unemployment (1.5\ntimes the national unemployment rate, use 'Unemp_ratehigh' layer) and access to transportation, where might\nyou want to build?\nRemember you can repeat the process of exporting your selection to its own layer, which you can symbolize in\nsuch a way (e.g. hollow with dots) that it can be seen alongside other layers. You may also want to turn off\nrailroad lines and stations once you have performed the prior steps.\nOnce you have finished this step, clear the selection.\nChoose a tract for building\n1. Click the selection button at the top of the screen and click on the tract that you want to build in, based\non the visualization you have made. You can select more than one tract by holding down the Ctrl button.\n2. Save the selected feature(s) using the same method you used above so that you know which location(s)\nyou selected to build on.\n3. Clear the selection once you have exported the layer.\n4. Wondering what area was actually chosen for this building? Add Bay_street_building from\nData\\Final_Exercise. You may need to double click on the point symbol and adjust the size to see it.\nRead the article here.\nMIT Libraries, GIS Services, Updated 1/6/2022\n\n5. Make final changes to the color of any of the data layers.\nLayout and export your map\n1. In QGIS, you can create a map to export and print in the Map Layout.\na. On the main toolbar menu at the top of QGIS click Project > Layout Manager.\nb. In the Layout manager window, click Create... and name your new layout something like \"New\nJersey Building Tract\".\nc. Click OK.\n2. A new window will open where you can work on the layout your map. If you close the new layout, you\ncan re-open it by clicking Project > Layouts, and choosing your layout from the list.\nThe menus on the left of the layout window are tools that help you move around and add things to your\nmap. The menus across the top are tools that allow you to save and export, zoom in and out and more.\nHover over the symbols to read what they do.\n3. On the left-hand menu, click on the Add Map icon.\n4. Click and drag a box on the blank page. Your map will appear in the box you've drawn. You can click and\ndrag the map around and resize it to make the margins work the way you want.\n5. Use the select/move item icon to select and move your map around on the page.\n6. Use the move item content icon to adjust the placement of your map.\n7. Right click the map itself > Page Properties to test switching between portrait or landscape orientation.\nMIT Libraries, GIS Services, Updated 1/6/2022\n\n8. Use the Add Label button and click on the page to add a title box.\n9. On the right side of the Layout window, click on the Item properties tab and type your title in the Main\nProperties box. Change font (click right dropdown arrow), margins, position, size and background the\nway you think it should be.\n10. Insert a legend using the Insert legend button, then click and drag a box for the legend placement. Use\nthe Item properties tab to modify your legend.\n11. Insert a scale bar and/or North arrow (click once to start line, again to end it, & right click to finish).\nNote these are the least important features you need to add so do not pick distracting formats.\n12. Use again the Add New Label icon to create a text box for your name, date, and sources for your data. If\nyou do not like the default settings for any item, use the item properties to edit its display.\n13. Save your layout.\nExport your map\n1. In the top menu go to Layout > and look at the different export options:\nExport as Image, Export as SVG..., Export as PDF... You can also use the icons to save your map in any of\nthese ways. Note: if you save as a JPEG or TIFF, you can adjust the resolution of the file.\nIf you receive a \"Project Contains WMS Layers\" warning, this means that the owner of the basemap\nwon't allow large areas to be exported. Our area is small enough to ignore this warning so feel free to\nhave your basemap on when exporting (you can move layout view to the side to edit what layers are on\nin original data view window).\n2. Save your exported map.\n3. Click close (if needed after export).\n4. Open your map to see what it looks like.\n5. Close the Layout window & then the Layout Manager window\nSave your QGIS document\n1. Click the Save icon.\nNote that when you save a QGIS document, you are only saving the links to the layers in your project and how\nyou have symbolized them, not the actual datasets. If you move your project to a new location, you will need to\nMIT Libraries, GIS Services, Updated 1/6/2022\n\nmove all the files linked to your project. Note: also keep in mind that each shapefile has multiple files associated\nwith it, and they need to stay together to work properly.\nBy default, QGIS stores the full path name to each layer in the QGIS document. This means that if you move your\nfiles around, your path name will change and you will need to redirect QGIS to the new file location for each\nfolder of data. If you will be moving files around, it is recommended that you save a relative path to the data\nfiles in your project. QGIS does this by default.\n2. To be sure the default is set that way, go to Project > Properties.\n3. Click on the General tab.\n4. Check that the dropdown menu next to Save paths is set to relative, not absolute. Click OK to close the\nwindow.\nCongratulations!\n1. You should now be familiar with the following:\n2. Opening a QGIS Desktop Project\n3. Adding basemaps & data\n4. Exploring attribute tables\n5. Selecting & exporting data\n6. Symbolizing data\n7. Performing selections & analyses\n8. Exporting & Saving a map\nFor more information, check out the QGIS Documentation.\nMIT Libraries, GIS Services, Updated 1/6/2022\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\nRES.STR-001 Geographic Information System (GIS) Tutorial\nIAP 2022\nFor information about citing these materials or our Terms of Use, visit:\nhttps://ocw.mit.edu/terms\nMIT Libraries, GIS Services, Updated 1/6/2022"
        },
        {
          "category": "Resource",
          "title": "GIS Level 2 ArcGIS Pro Take-Home Exercises (PDF)",
          "type": "PDF",
          "source_url": "https://ocw.mit.edu/courses/res-str-001-geographic-information-system-gis-tutorial-january-iap-2022/mitres_str001iap22_level2_arcgispro_takehome2.pdf",
          "content": "GIS Level 2\nIn the Introduction to GIS workshop we filtered data and visually examined it to determine where to\npotentially build a new mixed-use facility. In order to get a low interest loan, the building needs to be\nlocated in an area with high unemployment. You also want to consider access to public transportation\n(for people who may be living at the building and commuting to the city or commuting to the building\nfor work) and the terrain of the area.\nIn this exercise we will learn how to use the analysis tools in ArcGIS Pro with vector and raster data to\nfurther examine potential building sites.\nUse Spatial Autocorrelation to Determine Areas of High Unemployment\nChange a projection\nBecause spatial autocorrelation uses distance among features as part of the calculation, we will first\nconvert the census data from a geographic coordinate system to one that is projected.\n1. Open ArcGIS Pro and select the Map option and create a new project.\n2. Click the Map tab and use the Add Data button to add Hudson_tracts_unemp_2017 (the\nunemployment rate by census tract) from the folder Data\\Final Exercise.\n3. Right click on the name of the data layer and select Properties > Source > Spatial Reference. We\ncan see that the coordinate system is NAD 1983 and the unit is a Degree so we'll want to change\nthis to a projected coordinate system that uses a linear unit like meters.\n4. Open the Geoprocessing pane if it is not already open (View > Geoprocessing).\n5. Search for the project tool. Click the Project tool that is part of the Data Management Tools.\n6. Complete the information specified below.\na. Input: Hudson_tracts_unemp_2017\nb. Output: Save the output dataset to your working folder.\nc. Output Coordinate System: Click the button to the right of the text box and search for\n'new jersey' as shown.\nMIT Libraries, GIS Services, Updated 1/6/2022\n\nd. We could choose from any number of map projections. Expand the folders: Projected\nCoordinate Systems > State Plane > NAD 1983 (US Feet). Select the NAD 1983\nStatePlane New Jersey FIPS 2900 (US Feet) projection. Since it is specific for New Jersey,\ndistance will be fairly accurate in this area.\n7. Click OK to close the Coordinate System box and then Run. The new data layer should be\nautomatically added to your map. It will look identical to the old layer but have a different\ninternal projection. ArcMap automatically aligns data with different projections.\n8. Remove the original data layer.\nSpatial Autocorrelation\nSpatial Autocorrelation is a statistical technique that identifies clusters of low or high values by\ncomparing the value of each feature to that of its neighbors.\n1. Click the back arrow to return to the Geoprocessing search box. Search for the Cluster and\nOutlier Analysis tool. Open it.\n2. Fill in the information as below:\na. Input: projected unemployment data layer\nb. Input Field: Unemp_rate\nc. Output: working folder\nd. Conceptualization: Inverse Distance (assumes that closer features are more influential\nthan ones further away)\ne. Distance method: Euclidean\nf.\nStandardization: Row\n3. Click Run.\n4. After you run the tool you should see results similar to these. You may also see a warning that\ntells you the distance used to define neighborhoods. To make the map look less distorted, right\nclick on Map in the Contents pane and select Properties > Coordinate Systems. Scroll up and\nexpand Layers and select the NJ state plane coordinate system. Click Ok.\nMIT Libraries, GIS Services, Updated 1/6/2022\n\n_____________________________________________________________________________________\n_____________________________________________________________________________________\n_____________________________________________________________________________________\n5. Look at the legend in the Contents pane.\na. Where is there statistically significant clustering of high unemployment? Low\nunemployment?\nb. Is this what you expect based on the original data? You can change the symbology in the\nProperties menu of this layer to visualize the unemployment rate.\n6. Save your project using the save icon in the upper left.\nBased on this information, where might you build?\nExamine proximity to transportation\nMake a Multiple Ring Buffer\nIn this part of the exercise, you will be looking at proximity to the PATH station on the line that runs to\nthe World Trade Center in Manhattan.\n1. Turn off all the data layers.\n2. Add the following data layers from Data\\Final Exercise:\na. PathStation\nb. Streets\n3. Notice the point that shows where the PATH station is. Feel free to change the color or make it\nlarger so it is easier to see. The street network is also on the map.\n4. Search for and open the Multiple Ring Buffer tool in the Geoprocessing pane.\nMIT Libraries, GIS Services, Updated 1/6/2022\n\n5. Enter the information specified below. Notice the 5280, 10560, 15840, and 21120 values are 1,\n2, 3, and 4 miles as the path station is projected in a New Jersey State Plane projection in feet.\nClick Run.\n6. Click on the new layer to highlight it in the Contents pane once it is added to the map. Click the\nAppearance tab at the top of the screen and move the transparency slider in the Effects group\nto about 50%.\nApproximately how much of Jersey City are within 1 miles of the station? 3 miles? Is this an accurate\nrepresentation of distance from the Path Station?\n7. Turn off the street data to better see what is within each of the distance rings.\nYou can use the Network Analyst tools in ArcGIS Pro to create buffers (called service areas) based on a\nroad or other networks to increase the accuracy of your estimates. This tools will take into account the\nroads you will need to travel on to get from one place to another. To save time we won't do that as part\nof this exercise, but you can learn more here:\nMIT Libraries, GIS Services, Updated 1/6/2022\n\n_____________________________________________________________________________________\n_____________________________________________________________________________________\nhttps://pro.arcgis.com/en/pro-app/tool-reference/ready-to-use/itemdesc-generate-service-areas.htm\nhttps://pro.arcgis.com/en/pro-app/help/analysis/networks/service-area-tutorial.htm\n8. We previously created a service are for you. Add the network_buffer data layer to your map.\n9. To show the different service area distances, we'll change the symbology. Right click on the\nnetwork_buffer layer name and select Symbology.\n10. Choose Unique Values from the dropdown menu.\n11. In the Field 1 drop down menu, select ToBreak, which indicates the furthest distance covered by\nthe service area.\n12. Click the Color scheme drop down menu and select a color scheme.\nHow do the buffer and service area differ? If you wanted this new building to be close to the train\nstation, where might you choose to build?\nExamine Terrain\nAdd Raster Data\nYou have now explored some of the tools available for analysis of vector data. Now let's explore what\ncan be done with different types of the raster data.\nThis section will use elevation data which is developed from satellite imagery. If you are interested in\nlearning more about satellite imagery and image processing see the Introduction to Satellite Remote\nSensing Workshop.\nProject Raster\nBefore performing analyses it's always a good idea to make sure the data is in a projected coordinate\nsystem if it may be necessary to use the tools.\n1. Add Elevation from the Final Exercise folder. It may take a minute to load. Elevation represents\nelevation from the ASTER sensor aboard the Terra satellite. Turn off any data layers that you do\nnot need.\n2. Go back to the Geoprocessing search pane and find the tool \"Project Raster\".\n3. Use the Elevation layer as your Input Raster.\n4. Save the output raster to your working folder using an intuitive name. In many cases rasters\nneed names that are 13 characters or less when working in Pro.\n5. From the Output Coordinate System dropdown menu, select the projected unemployment data\nto convert the raster to the same projection. Click Run.\n6. Remove the old elevation data from the map.\nMIT Libraries, GIS Services, Updated 1/6/2022\n\nExtract by Mask (aka clip raster)\nBackground Information:\nWhoever named this tool, decided against \"clip for raster\" which arguably would have been more\nintuitive to the majority of people. Alas, the name \"extract by mask\" while less intuitive, draws upon\nimage processing terminology and also hints at an interesting underlying process taking place. As you\nwould have learned in Introduction to GIS, vectors and rasters have some key differences. Vectors have\ndefined coordinate boundaries, while rasters use cell values in a grid of rows and columns. When you\nclip a vector, you are in a way moving the coordinates to new locations. However, when you try to clip a\nraster it must remain as a rectangular grid. To have it appear as though you have \"clipped\" out certain\nsections, \"extract by mask\" replaces pixels/cells that fall outside the boundary used (aka \"mask\") with\nNoData values, visualized using NoColor and therefore making the raster appear clipped. To check that\nthis is the case after running the tool, click on a pixel and see its values.\n1. Right click the projected elevation raster and select Zoom to Layer to see its full extent. As you\ncan see, satellite imagery is often provided at large scales, which can be reduced to be easier to\nwork with.\n2. Search for and open the \"Extract by Mask\" tool.\n3. We will use the tracts as the mask, so input the following:\na. Input raster: projected elevation raster\nb. Input raster or feature mask data: projected Hudson unemployment tracts\nc. Output raster: Save your output raster to your folder using an intuitive name.\n4. Click Run. The resulting layer has been masked so that all pixels outside the tracts have no value\nand those inside are symbolized with a black and white color ramp stretched from the min to\nmax values.\nCreate Contour Lines\nContour abstracts a digital elevation surface into lines representing different elevations. Lines can be\neasier to overlay on top of other datasets without covering them up as a raster surface would. They can\nalso help clarify visual trends in a way that a surface can be difficult to observe.\n1. Search for and open the Contour (Spatial Analyst) tool.\n2. Use the following inputs:\na. Input raster: the clipped/masked elevation\nb. Output feature class: Save with an appropriate name. (e.g. elev_contours_15ft)\nc. Contour interval: Start with 15ft (the unit is based on the projection of the layer).\n3. Click Run.\n4. If you want, try a few other values for your contours, remembering to save names appropriately.\nMIT Libraries, GIS Services, Updated 1/6/2022\n\n_____________________________________________________________________________________\n_____________________________________________________________________________________\n_____________________________________________________________________________________\nWhile you can build in any location, flatter areas may be easier to access for people who are walking.\nAlso keep in mind that areas of low elevation that are close to water may be more prone to flooding.\nLooking at the original elevation data and contour lines, what areas may you want to build in?\nSelect an area in which to build and add a point\nUsing all the information you gathered with the processing tools, select an area (or areas) that could be\npotential building sites. You will add a point (or points) to represent these areas.\n1. Open the ArcCatalog pane (View > Catalog Pane).\n2. Navigate to your working folder in the Folders menu of ArcCatalog. If you don't see the folder,\nright click on Folders and select Add Folder Connection. Navigate to the main folder containing\nyour output data.\n3. Right click on your work folder > New > Shapefile.\na. Feature Class Name: Choose a name for your new shapefile.\nb. Geometry type: point.\nc. Coordinate System: From the dropdown choose the projected unemployment layer so\nthat the coordinate system will be the same as the other layers in our map\nd. Click Run.\nThere are currently no features in the layer. Accordingly, the attribute table of your point layer is blank,\nwith the exception of a few fields that ArcGIS adds by default and generates automatically for features.\nWe're going to create features for this layer.\n1. Click on the new building layer in the Contents pane so it is selected.\n2. In the Edit tab at the top of the screen, select the Create tool in the Features group.\n3. Click the building layer and select the Point tool.\nEach time you click on a location on the map, it will add a point.\n4. Add your point(s).\nMIT Libraries, GIS Services, Updated 1/6/2022\n\n5. When you are finished, click the Finish button at the bottom of the map.\n6. Close the Create Features pane.\nAn actual building was built at 65 Bay Street. Add the data layer, \"Bay_street_building\" from the Final\nExercise folder. Is there where you chose to build?\nThere are a lot of factors we did not consider, such as available lots, cost of building, etc., which went\ninto choosing the Bay street building site. However, it was also deemed an area of high unemployment\nby selectively showing data from nearby census tracts. You can read more here.\nResources for learning more\nSpatial Statistics: https://pro.arcgis.com/en/pro-app/tool-reference/spatial-statistics/an-overview-of\nthe-spatial-statistics-toolbox.htm\nNetwork Analyst: https://pro.arcgis.com/en/pro-app/tool-reference/network-analyst/an-overview-of\nthe-network-analyst-toolbox.htm\nSpatial Analyst: https://pro.arcgis.com/en/pro-app/tool-reference/spatial-analyst/an-overview-of-the\nspatial-analyst-toolbox.htm\nMIT Libraries, GIS Services, Updated 1/6/2022\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\nRES.STR-001 Geographic Information System (GIS) Tutorial\nIAP 2022\nFor information about citing these materials or our Terms of Use, visit:\nhttps://ocw.mit.edu/terms\nMIT Libraries, GIS Services, Updated 1/6/2022"
        },
        {
          "category": "Resource",
          "title": "GIS Level 2 ArcGIS Pro Workshop Exercises (PDF)",
          "type": "PDF",
          "source_url": "https://ocw.mit.edu/courses/res-str-001-geographic-information-system-gis-tutorial-january-iap-2022/mitres_str001iap22_level2_arcgispro.pdf",
          "content": "GIS Level 2: ArcGIS Pro Workshop Exercises\nExercise 1: Map projections\nMap projections, also called Coordinate Reference Systems (CRS) can be viewed or changed using GIS\nsoftware.\n1. Examine the data in GIS_Level2_Data\\workshop_exercise. Is there a projection file for each\ndataset?\nNote that cambridge_dem is a raster dataset and uses a .tfw file (known as a \"world\" file), which\ncontains the information needed to transform image coordinates to real-world coordinates.\nShapefiles use a .prj file, which includes the coordinate system information.\n2. Open ArcPro. Click the Map option under Blank Templates and save it to your working folder.\n3. Add the following two data layers from GIS_Level2_Data\\workshop_exercise\na. MBTAbusroutes\nb. CambridgePlaygrounds\n4. Right click on CambridgePlaygrounds and select Zoom to Layer.\nDo the playgrounds and bus routes seem to be in the correct locations?\nThey should be since both layers had a defined projection (.prj) file.\n5. Right click on CambridgePlaygrounds and select Properties.\n6. Select the Source tab and expand Spatial Reference.\nWhat is the coordinate reference system?\nThere are two, a projected coordinate system of NAD83 / Massachusetts Mainland (ftUS) and a\ngeographic coordinate system of NAD 1983.\n7. Do the same for the MBTAbusroutes data layer. What is the coordinate reference system?\n8. Close the Properties box and select the Analysis tab and Tools.\n9. Search for Project and open Project (Data Management Tools).\nWe will use the Project tool to change the projection of the playgrounds so that it is the same as\nthat of the bus routes. There is also a tool called Define Projection that is used to assign a\nprojection to a data layer that does not already have one or has one that is incorrect. Our map\nprojections appear to be correct so we do not need to use this tool.\nAlthough not always required, your analysis results may be more accurate if your data layers are\nin the same projection. If you want to calculate the proximity of playgrounds to bus routes, you\nwould first want to make sure the projections of both data layers are the same.\n10. Choose playgrounds as the Input Dataset.\na. Save your output dataset in your working folder.\n\nb. Click the Output Coordinate System dropdown menu and select MBTAbusroutes. ArcGIS\nPro will automatically fill in the coordinate system of\nNAD_1983_StatePlane_Massachusetts_Mainland_FIPS_2001.\nc. Click Run.\n11. Add the data layer to your map if it was not added automatically.\nExercise 2: Access basic analysis tools\nTools can be accessed in a variety of ways in ArcGIS Pro:\n-\nA subset of tools are located on the Analysis tab.\n-\nSome tools are available by right clicking a layer.\n-\nClick (Analysis > Toolbox) or (View > Geoprocessing) to see all available tools. You can search for\na tool by name or click the Toolboxes tab and open a specific toolbox. This is a good way to see\nthe different types of tools available to you.\n1. Add MBTA_NODE to the map from GIS_Level2_Data\\workshop_exercise.\n2. Click View > Geoprocessing and search for the buffer tool.\n3. Open Buffer (Analysis Tools).\nHow do you know what each input and parameter should be or if you need it? Try clicking the question\nmark to learn more about this tool and its parameters.\n4. Select the MBTA_NODE as your Input Features from the dropdown menu. Choose a location to\nsave your buffers in the Output Feature Class box.\n5. Enter a Distance of 1000 meters and Run the tool.\n6. Turn off your buffers after you have looked at the layer.\nThe interface for all tools looks similar in ArcGIS Pro, with most requiring input data, an output location,\nrequired parameters, and optional parameters.\nExercise 3: Use raster tools\nDifferent tools can be used with raster data versus vector data, although the output could be a vector,\nraster, or table, depending on the tools. There are also tools that allow you to convert from one data\ntype to another.\n1. Add the cambridge_dem.tif to your map. It may take a minute to load.\n2. We will start by changing the symbology so it is easier to see, which you may remember from\nGIS Level 1.\na. Right click on the cambridge_dem and select Symbology.\nb. Change the Primary Symbology dropdown to Stretch.\n\nc. Close the Symbology window when you are finished.\n3. Open the Geoprocessing window if it is not already. Search for contour. Open Contour (Spatial\nAnalyst Tools).\n4. Select the dem as your Input raster and choose an output location.\n5. Type 5 for the Contour interval. What are the units of this interval? How might you figure it out?\n6. Click Run.\nYou will notice that the output is a vector line layer, which could then be exported to other\nprograms or used as input for vector analysis tools.\nExercise 4: Use the spatial statistics toolbox\nAs mentioned above, toolboxes can be a good way to learn about the variety of tools available to you\nand to also find tools that are similar to others.\n1. Add the file median_income_suffolk_ma to the map.\n2. Click View > Geoprocessing to open the Geoprocessing window.\n3. Click the Toolboxes tab and expand Spatial Statistics Tools > Mapping Clusters. Open Cluster and\nOutlier Analysis (Anselin Local Moran's I).\n4. Choose median_income as the Input Feature Class. Use VALUE0 as the Input Field, which is the\nmedian income value. See the text file in the workshop_exercise folder for the attribute field\ninformation.\n5. Choose an output name and location.\n6. Leave the default values for now. In the future you have the option of changing the parameters\nto define neighborhoods in different ways. Run the tool.\n7. At the bottom of the tool window, a box indicates that the tool ran with warning. Click the View\nDetails link to read more about this. The warning indicates that the tool used a value of 2266\nmeters to define the neighborhood, which is determined to be optimal for our data based on\nthe inverse distance relationship. Close the Detail window.\n8. Where are there clusters of high and low income? The tool has also output a histogram and\nscatterplot that you can examine by double clicking on them. Turn off the income data layers\nwhen you are finished examining them.\nThe Moran scatter plot provides a classification of spatial association into four categories, corresponding\nto the location of the points in the four quadrants of the plot. These categories are referred to as High-\nHigh, Low-Low, Low-High and High-Low, relative to the mean, which is the center of the graph.\nYou can learn more about the statistics used in the Moran's I calculation here:\nhttps://pro.arcgis.com/en/pro-app/tool-reference/spatial-statistics/h-how-cluster-and-outlier-analysis\nanselin-local-m.htm\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\nRES.STR-001 Geographic Information System (GIS) Tutorial\nIAP 2022\nFor information about citing these materials or our Terms of Use, visit:\nhttps://ocw.mit.edu/terms"
        },
        {
          "category": "Resource",
          "title": "GIS Level 2 Instructions (PDF)",
          "type": "PDF",
          "source_url": "https://ocw.mit.edu/courses/res-str-001-geographic-information-system-gis-tutorial-january-iap-2022/mitres_str001iap22_level2_instructions.pdf",
          "content": "GIS Level 2 Setup Instructions\nThank you for registering for GIS Level 2. Before the workshop, please do the following:\n1. Download and install either ArcGIS Pro or QGIS & Geoda\n2. Install 7-zip if necessary.\n3. Download all workshop materials.\n4. Update and setup Zoom. (Your version of Zoom MUST be up-to-date in order to use the\nbreakout rooms effectively.)\nDownload and install ArcGIS Pro or QGIS & Geoda\nQGIS is a free, open source software program that will work on any operating system and doesn't take\nup much space on your computer. While it has many of the same capabilities as ArcGIS Pro, there are\nsome analyses you can't do in QGIS and it tends to have more bugs. QGIS has limited tools for spatial\nstatistical analysis, so you can use another free, open source program, Geoda, along with it.\nArcGIS Pro is a commercial software from ESRI that we have a subscription for at MIT. It only runs on\nWindows and requires an account or a connection to the MIT license server to run. It includes a full\nsuite of GIS tools, but may not run well if you have a slower computer.\nIf you are not sure which software to use, this website has a lot of additional information:\nhttps://gisgeography.com/qgis-arcgis-differences/\nNote: This workshop will NOT use ArcGIS Desktop/ArcMap, only ArcGIS Pro, the newest GIS software\nfrom ESRI.\nArcGIS Pro installation\n1. Create an ArcGIS Online (AGOL) account: https://libguides.mit.edu/gis/webmap#s-lg-box-wrapper\n2. If you have not already downloaded Pro, log into your AGOL account. From your account page, click\nyour name in the upper right and select My settings > Licenses and click download next to ArcGIS Pro.\n3. After installing Pro, choose the Named User License type and select ArcGIS Online. You'll then see the\nsame login screen that you used to create your account.\nQGIS Installation\nFull instructions and links for installing QGIS for a number of different operating systems can be found\nhere: http://qgis.org/en/site/forusers/download.html\nDownload the most recent version of the software. Windows users should download the Standalone\noption. If you already have QGIS installed, we have tested the workshop exercises with versions 3.16\nand higher so we recommend upgrading if you are using an older version.\nGeoda Installation (install if using QGIS for the workshop)\n\nDownload links for a variety of operating systems are listed here:\nhttps://geodacenter.github.io/download.html\n7-zip installation\nWorkshop files (and most GIS data) are in zipped folders. Most Windows computers have the option to\nextract data by right clicking and most Macs will automatically extract data. Occasionally your computer\nmay not have a built-in data extraction tool. In this case we recommend installing 7-zip: https://www.7\nzip.org/\nWorkshop materials\nDownload all workshop materials.\nMaterials include the presentation, workshop exercises, take-home exercise, and all required data.\nZoom setup\n1. Make sure your Zoom app is up-to-date using these instructions:\nhttps://support.zoom.us/hc/en-us/articles/201362233-Upgrade-update-to-the-latest-version\n2. If you have access to a second monitor (or a second \"smart\" device that can connect to a Zoom\nsession) it may greatly improve your workshop experience and make it easier to follow the\ninstructor and complete the exercises simultaneously. If not, it is still doable, for example, by\norganizing your screen in this way:\nhttps://raw.githubusercontent.com/hbctraining/bioinformatics_online/master/guidelines/img/S\ncreenshot%202020-03-23%2015.21.10.png\n3. We encourage participation during the session and kindly ask you to use your video, if possible.\n4. Mute audio except when talking (Tip: you can temporarily unmute yourself by pressing and\nholding a space bar. When it is released, Zoom goes back to the mute mode).\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\nRES.STR-001 Geographic Information System (GIS) Tutorial\nIAP 2022\nFor information about citing these materials or our Terms of Use, visit:\nhttps://ocw.mit.edu/terms"
        },
        {
          "category": "Resource",
          "title": "GIS Level 2 QGIS Take-Home Exercises (PDF)",
          "type": "PDF",
          "source_url": "https://ocw.mit.edu/courses/res-str-001-geographic-information-system-gis-tutorial-january-iap-2022/mitres_str001iap22_level2_qgis_takehome.pdf",
          "content": "GIS Level 2\nIn the Introduction to GIS workshop we filtered data and visually examined it to determine where to\npotentially build a new mixed use facility. In order to get a low interest loan, the building needs to be\nlocated in an area with high unemployment. You also want to consider access to public transportation\n(for people who may be living at the building and commuting to the city or commuting to the building\nfor work) and the terrain of the area.\nIn this exercise we will learn how to use the analysis tools in QGIS & Geoda with vector and raster data\nto further examine potential building sites.\nUse Spatial Autocorrelation to Determine Areas of High Unemployment\nChange a projection\nBecause spatial autocorrelation uses distance among features as part of the calculation, we will first\nconvert the census data from a geographic coordinate system to one that is projected.\n1. Open QGIS.\n2. Click the Data Source Manager button.\n3. Select the Vector tab.\n4. Click the ... next to the Vector Dataset(s) box and select Hudson_tracts_unemp_2017.shp (the\nunemployment rate by census tract) from the folder Data\\Final Exercise.\n5. Click Add. Press OK when the Select Transformation box appears. This will change the map\nprojection of our project so that data look less distorted, but will not change the projection of\nour data.\n6. Right click on the name of the data layer and select Properties > Information. We can see that\nthe coordinate reference system is NAD83 which uses Lat/Long as units so we'll want to change\nthis to a projected coordinate system that uses a linear unit like meters. Close the Properties\nbox.\n7. Right click on the name of the data layer and select Export > Save Features As.\na. Select ESRI Shapefile as the Format.\nb. Click the coordinate reference system button next to the CRS dropdown menu.\nc. Search for 3424 in the Filter box, which is the code given to the coordinate system we\nwant to use. Results will appear in the Projected Coordinate Reference Systems box.\nSelect NAD83/New Jersey (ftUS) EPSG:3424. Click Ok.\nd. Click ... next to the File name box and select a location in which to save the data and\nname the file. Click Ok.\nMIT Libraries, GIS Services, Updated 1/6/2022\n\ne. Depending on your version of QGIS, a box may appear in which you can choose from\nvarious mathematical methods for transforming the data. Keep the first method\nselected and click OK. Ignore this step if you do not see this box.\n8. The transformed data will now be added to your map. It will look identical to the old layer but\nhave a different internal projection. QGIS automatically aligns data with different projections.\n9. Remove the original data layer and save your QGIS project (Project > Save).\nMIT Libraries, GIS Services, Updated 1/6/2022\n\nSpatial Autocorrelation\nSpatial Autocorrelation is a statistical technique that identifies clusters of low or high values by\ncomparing the value of each feature to that of its neighbors. QGIS does not extensive spatial statistics\ntools so we will use the free program, Geoda. You can learn more about Geoda here:\nhttps://geodacenter.github.io/documentation.html\n1. Open Geoda.\n2. In the Input file box, click the folder icon and select ESRI shapefile. Select the projected\nunemployment file that you just saved in QGIS. Your file will open in the map viewer.\n3. You first need to specify how you will define neighbors. Click the W icon in the toolbar (Weights\nManager) and Create.\n4. Specify the following:\na. Weights File ID Variable: GEOID (this is any ID that uniquely identifies each polygon)\nb. Rook contiguity (rook shares borders, queen shares borders and vertices/corners)\nc. Keep the defaults for the other options.\nd. Click Create and save your weights file in your project folder. Close the Weights File\nCreation box and the Weights Manager. The file you just created is automatically\nloaded.\n5. Select Space > Univariate Local Moran's I.\n6. Choose Unemp_rate as the variable. The weights file you just created should be chosen in the\nWeighs dropdown box. Click OK.\n7. Check off the significance map and cluster map and click Ok. The maps show the different types\nof clusters and their significance.\nMIT Libraries, GIS Services, Updated 1/6/2022\n\n8. Right click on the cluster map image and select Save Results. Click OK. This will save the cluster\ninformation to the attribute table.\n9. At the top of the screen, click File > Save As. Click the folder icon and select ESRI Shapefile. Save\nthe file to your project folder so we can load it in QGIS. Click OK.\n10. Close Geoda.\nVisualize the Clusters in QGIS\n1. In QGIS add the cluster shapefile to your map.\n2. Right click on this file and select Open Attribute Table.\n3. Scroll to the right and see the new columns that were added by Geoda. LISA_CL can be used to\nvisualize clusters. See the Geoda website for information about what each code means:\nhttps://geodacenter.github.io/workbook/6a_local_auto/lab6a.html#saving-the-local-moran\nstatistics\n4. Close the Attribute Table. Right click on the layer and select Properties > Symbology.\n5. Select Categorized from the dropdown menu at the top of the window.\n6. Choose LISA_CL from the Value dropdown menu.\n7. Click the Classify button and all the values from the table will appear.\n8. Double click on each number in the Legend column to name it based on the codes from the\nGeoda website (0 for non-significant, 1 for high-high, 2 for low-low, 3 for low-high, and 4 for\nhigh-low).\n9. Double click on the color in the symbol column to choose colors for each category that make\nsense to you. Click OK when you are finished.\nMIT Libraries, GIS Services, Updated 1/6/2022\n\n_____________________________________________________________________________________\n_____________________________________________________________________________________\n_____________________________________________________________________________________\n10. Look at the legend in the Contents pane. Where is there statistically significant clustering of high\nunemployment? Low unemployment?\nBased on this information, where might you build?\nExamine proximity to transportation\nMake a Multiple Ring Buffer\nIn this part of the exercise, you will be looking at proximity to the PATH station on the line that runs to\nthe World Trade Center in Manhattan.\n1. Turn off all the data layers.\n2. Add the following data layers from Data\\Final Exercise:\na. PathStation\nb. Streets\n3. Notice the point that shows where the PATH station is. Feel free to change the color or make it\nlarger so it is easier to see. The street network is also on the map.\n4. Add the multi ring buffer tool by clicking Plugins > Manage and Install Plugins and searching for\nMulti Ring Buffer. Select it and click Install Plugin. Close the window. Because QGIS is an open\nsource program, various people create tools, which can be added from this plugin menu.\n5. Click Vector > Multi Ring Buffer to open the tool.\nMIT Libraries, GIS Services, Updated 1/6/2022\n\n6. Enter the information specified below. Notice the 5280 is equal to 1 mile in feet as the path\nstation is projected in a New Jersey State Plane projection in feet. Click OK.\n7. Note that the resulting layer is temporary until you right click and select Make Permanent. If you\nare continuing with this exercise you can leave it as temporary, but will want to save it if you\nplan to close QGIS and continue later.\n8. If your buffer looks a bit distorted you can change the coordinate reference system of the QGIS\nproject to that of the data layers.\na. Click Project > Properties and select the CRS tab.\nb. Select NAD83/New Jersey (ftUS) from the Recently Used Coordinate Reference Systems\nbox and click Ok.\nc. Close the Project Properties.\nThe project CRS changes how data look on the screen but does not change the coordinate\nsystem of the data itself.\n9. Right click on the new buffer layer and select Properties > Symbology. Expand Layer Renderings\nat the bottom of the box and move the Opacity slider to about 50%. Click OK.\n10. Add a basemap by clicking Web > QuickMapServices > OSM > OSM Standard. If you do not see\nthe Web menu, add the QuickMapServices plugin.\nApproximately how much of Jersey City are within 1 miles of the station? 3 miles? Is this an accurate\nrepresentation of distance from the Path Station?\n11. Turn off the street data to better see what is within each of the distance rings.\nMIT Libraries, GIS Services, Updated 1/6/2022\n\n_____________________________________________________________________________________\n_____________________________________________________________________________________\nQGIS includes some basic network analysis tools. For more extensive options, we recommend using\nArcGIS Pro. You can create buffers (called service areas) based on a road or other network to increase\nthe accuracy of your estimates. That is, the service areas take into account the roads that you need to\ntravel on to get from one location to another. To save time we won't do that as part of this exercise, but\nyou can learn more here:\nhttps://docs.qgis.org/3.16/en/docs/training_manual/vector_analysis/network_analysis.html\nhttps://pro.arcgis.com/en/pro-app/tool-reference/ready-to-use/itemdesc-generate-service-areas.htm\nhttps://pro.arcgis.com/en/pro-app/help/analysis/networks/service-area-tutorial.htm\n12. We previously created a service are for you using ArcGIS Pro. Add the network_buffer data layer\nto your map from the Final Exercise folder.\n13. To show the different service area distances, we'll change the symbology. Right click on the\nnetwork_buffer layer name and select Properties > Symbology.\n14. Choose Categorized from the dropdown menu at the top of the box.\n15. In the Value drop down menu, select ToBreak, which indicates the furthest distance covered by\nthe service area.\n16. Click the Classify button at the bottom of the box to show the values.\n17. Click the Color ramp drop down menu and select a color scheme. Click Ok.\nHow do the buffer and service area differ? If you wanted this new building to be close to the train\nstation, where might you chose to build?\nExamine Terrain\nAdd Raster Data\nYou have explored some of the tools available for analysis of vector data. Now let's explore what can be\ndone with different types of the raster data.\nThis section will use elevation data which is developed from satellite imagery. If you are interested in\nlearning more about satellite imagery and image processing see the Introduction to Satellite Remote\nSensing Workshop.\nProject Raster\nBefore performing analyses it's always a good idea to make sure the data is in a projected coordinate\nsystems if it may be necessary to use the tools.\n1. Add Elevation.tif from the Final Exercise folder. Make sure to choose the Raster option in the\nData Source Manager. It may take a minute to load. Elevation represents elevation from the\nASTER sensor aboard the Terra satellite. Turn off any data layers that you do not need.\n2. Right click on the name of the data layer and select Export > Save As.\na. The CRS dropdown menu shows coordinate systems that we are currently using in our\nproject. Select one of the options for EPSG: 3424.\nMIT Libraries, GIS Services, Updated 1/6/2022\n\nb. Click ... next to the File name box and select a location in which to save the data and a\nfile name.\nc. Keep the Format as GeoTIFF.\n3. Click OK.\n4. Remove the old elevation data from the map.\nClip Raster by Mask\nBackground Information:\nThe term Mask draws upon image processing terminology and also hints at an interesting underlying\nprocess taking place. As you learned in Introduction to GIS, vectors and rasters have some key\ndifferences. Vectors have defined coordinate boundaries, while rasters use cell values in a grid of rows\nand columns. When you clip a vector you are in a way moving the coordinates to new locations.\nHowever, when you try to clip a raster it must remain as a rectangular grid. To have it appear as though\nyou have \"clipped\" out certain sections, \"clip raster by mask\" replaces pixels/cells that fall outside the\nboundary used (aka \"mask\") with NoData values, visualized using NoColor and therefore making the\nraster appear clipped. To check that this is the case after running the tool, click on a pixel and see its\nvalues.\n1. Right click the projected elevation raster and select Zoom to Layer to see its full extent. As you\ncan see, satellite imagery is often provided at large scales, which can be reduced to be easier to\nwork with.\n2. Select Raster > Extraction > Clip Raster by Mask Layer.\n3. We will use the tracts as the mask, so input the following:\na. Input layer: projected elevation raster\nb. Mask layer: projected Hudson unemployment tracts\nc. Advanced parameters > Clipped (mask): Click the ... > Save to file and save your output\nraster to your folder using an intuitive name. (If you don't see these, scroll down.)\nd. Leave the defaults for all other options.\n4. Click Run. The resulting layer has been masked so that all pixels outside the tracts have no value\nand those inside are symbolized with a black and white color ramp stretched from the min to\nmax values (you will need to turn off the original layer to see this). Close the tool window.\nCreate Contour Lines\nContour abstracts a digital elevation surface into lines representing different elevations. Lines can be\neasier to overlay on top of other datasets without covering them up as a raster surface would. They can\nalso help clarify visual trends in a way that a surface can be difficult to observe.\n1. Select Raster > Extraction > Contour.\n2. Use the following inputs:\na. Input layer: the clipped/masked elevation\nb. Interval between contour lines: Start with 15ft (as mentioned previously, the unit is\nbased on the measurement setting for the project).\nc. Advanced parameters > Contours: Click ... > Save to file and save your output vector to\nyour folder. Choose SHP files as the type.\nMIT Libraries, GIS Services, Updated 1/6/2022\n\n_____________________________________________________________________________________\n_____________________________________________________________________________________\n_____________________________________________________________________________________\nd. Leave the defaults for everything else. Click Run. Close the tool window.\n3. If you want, try a few other values for your contours, remembering to save names appropriately.\nWhile you can build in any location, flatter areas may be easier to access for people who are walking.\nAlso keep in mind that areas of low elevation that are close to water may be more prone to flooding.\nLooking at the original elevation data and contour lines, in what areas may you want to build?\nSelect an area in which to build and add a point\nUsing all the information you gathered with the processing tools, select an area (or areas) that could be\npotential building sites. You will add a point (or points) to represent these areas.\n1. Click the New Shapefile Layer button.\na. Click the ... next to File Name and navigate to your working folder and choose a file\nname. Click Save.\nb. Geometry type: point.\nc. Additional dimensions: From the dropdown make sure a coordinate system with EPSG:\n3424 is selected.\nd. You have the options of adding fields/columns to your attribute table, but we won't do\nthis now. Click OK.\nThere are currently no features in the layer. Accordingly, the attribute table of your point layer is blank.\nWe're going to create features for this layer.\n1. Click on the empty building layer so it is selected in the Layers pane.\n2. Click the Toggle Editing icon (pencil).\n3. Click the Add Point Feature button.\n4. Click a location or locations on the map to add points. You will be asked to assign an ID number\nto each point as you add it. This can be any unique number.\n5. When you are finished, click the Save Layer Edits button.\n6. Turn off editing by clicking the Toggle Editing icon (pencil) again.\nAn actual building was built at 65 Bay Street. Add the data layer, \"Bay_street_building\" from the Final\nExercise folder. Is there where you chose to build?\nMIT Libraries, GIS Services, Updated 1/6/2022\n\nThere are a lot of factors we did not consider, such as available lots, cost of building, etc., which went\ninto choosing the Bay street building site. However, it was also deemed an area of high unemployment\nby selectively showing data from nearby census tracts. You can read more here.\nResources for learning more\nSpatial statistics:\nhttps://geodacenter.github.io/documentation.html\nNetwork analysis:\nhttps://docs.qgis.org/3.16/en/docs/training_manual/vector_analysis/network_analysis.html\nhttps://pro.arcgis.com/en/pro-app/tool-reference/network-analyst/an-overview-of-the-network\nanalyst-toolbox.htm\nWorking with raster data:\nhttps://docs.qgis.org/3.16/en/docs/user_manual/working_with_raster/index.html\nMIT Libraries, GIS Services, Updated 1/6/2022\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\nRES.STR-001 Geographic Information System (GIS) Tutorial\nIAP 2022\nFor information about citing these materials or our Terms of Use, visit:\nhttps://ocw.mit.edu/terms\nMIT Libraries, GIS Services, Updated 1/6/2022"
        },
        {
          "category": "Resource",
          "title": "GIS Level 2 QGIS Workshop Exercises (PDF)",
          "type": "PDF",
          "source_url": "https://ocw.mit.edu/courses/res-str-001-geographic-information-system-gis-tutorial-january-iap-2022/mitres_str001iap22_level2_qgis.pdf",
          "content": "GIS Level 2: QGIS Workshop Exercises\nExercise 1: Map projections\nMap projections, also called Coordinate Reference Systems (CRS) can be viewed or changed using GIS\nsoftware.\n1. Examine the data in GIS_Level2_Data\\workshop_exercise. Is there a projection file for each\ndataset?\nNote that cambridge_dem is a raster dataset and uses a .tfw file (known as a \"world\" file), which\ncontains the information needed to transform image coordinates to real-world coordinates.\nShapefiles use a .prj file, which includes the coordinate system information.\n2. Open QGIS. Click Project > Save As and save the new project to your working folder.\n3. Add the following two data layers from GIS_Level2_Data\\workshop_exercise\na. MBTAbusroutes\nb. CambridgePlaygrounds\n4. Click Ok when you are asked to select a transformation. Close the Data Source Manager\nwindow.\nThe transformation box changes the coordinate reference system of your map project (not the\ndata layers). This changes how the data look on the screen and can help minimize distortion.\n5. To add a basemap click Web > QuickMapServices > OSM > OSM Standard.\n6. Right click on CambridgePlaygrounds and select Zoom to Layer.\nDo the playgrounds and bus routes seem to be in the correct locations?\nThey should be since both layers had a defined projection (.prj) file.\n7. Right click on CambridgePlaygrounds and select Properties.\n8. Select the Information tab.\nWhat is the coordinate reference system?\nDepending on your version of QGIS, you will either see the name NAD83 / Massachusetts\nMainland (ftUS) or a generic name, such as SOURCECRS. QGIS sometimes has trouble identifying\nthe names of projections even though the .prj file is being read correctly by the software.\nRegardless of the name we can tell it is projected because the Units are in feet.\n9. Do the same for the MBTAbusroutes data layer. What is the coordinate reference system? Is it\nthe same or different from the playgrounds?\n10. Close the Properties box and select Vector > Data Management Tools > Reproject Layer.\nWe will use this tool to change the projection of the playgrounds so that it is the same as that of\nthe bus routes. Note that when right clicking on a layer there is the option to Set Layer CRS. This\nshould only be used to assign a projection to a data layer that does not already have one or to\n\nchange one that is incorrect. Our map projections appear to be correct so we do not need to use\nthis tool.\nAlthough not always required, your analysis results may be quicker and more accurate if your\ndata layers are in the same projection. If you want to calculate the proximity of playgrounds to\nbus routes, you would first want to make sure the projections of both data layers are the same.\n11. Choose playgrounds as the Input layer.\na. In Target CRS, from the dropdown menu select EPSG 26986 -NAD83 / Massachusetts\nMainland_FIPS, the coordinate system of the MBTA bus routes. EPSG numbers are\nunique ID numbers assigned to every CRS.\nb. Click the ... icon next to the [create temporary layer] box and select Save to File. Save\nyour output dataset in your working folder.\nc. Click Run.\nExercise 2: Access basic analysis tools\nTools can be accessed via the menus at the top of the screen in QGIS.\n-\nA number of \"core\" tools come with QGIS and most can be found under the Vector or Raster\nmenus. You will also find tools by opening the Processing Toolbox (Processing > Toolbox).\n-\nSince QGIS is an open source GIS software, additional tools have been developed by individuals.\nThese can be added by clicking Plugins > Manage and Install Plugins and searching for the tool\nyou want.\n-\nGoogling is a good way to find tools that have been created for QGIS. Note that when there is a\nmajor upgrade, some tools may not work immediately.\n1. Add MBTA_NODE to the map from GIS_Level2_Data\\workshop_exercise.\n2. Click Ok if you see a coordinate system message.\n3. Click Vector > Geoprocessing Tools > Buffer.\nHow do you know what inputs and parameters to use? A short description of the tool appears on the\nright side of the tool window. Click the help button to learn more about this tool and its parameters.\n4. Select the MBTA_NODE as your Input layer from the dropdown menu.\n5. Enter a distance of 1000 meters.\n6. Most QGIS tools will create a temporary layer unless you specify otherwise. Do this by clicking\nthe ... button next to the box at the bottom of the window that says [Create temporary layer].\nSelect the Save to File option and choose an output location. Choose .shp as the file type.\n7. Run the tool. Turn off your buffers after you have looked at the layer.\nThe interface for all tools looks similar in QGIS, with most requiring input data, required parameters, and\noptional parameters.\n\nExercise 3: Use raster tools\nDifferent tools can be used with raster data versus vector data, although the output could be a vector,\nraster, or table, depending on the tools. There are also tools that allow you to convert from one data\ntype to another.\n1. Add the cambridge_dem.tif to your map. Click Ok if you see a coordinate system window. Close\nthe Data Source Manager window.\n2. Click Raster > Extraction > Contour.\n3. Select the dem as your Input layer and scroll down to choose an output location in the Contours\nbox. It's useful to choose an output name that indicates the contour interval so you can use this\nfor future reference.\n4. In the Interval between contour lines box, type 5. What are the units of this interval? While\nsome tools default to the unit of the coordinate reference system, QGIS also uses the\nmeasurement unit specified in the project properties. You can find this under Project >\nProperties > General. It's a good idea to set the unit the same as the CRS of your data layers.\n5. Click Run. Close the Contour window when the tools is finished running.\nYou will notice that the output is a vector line layer, which could then be exported to other\nprograms or used as input for vector analysis tools.\nExercise 4: Use Geoda to access spatial statistics tools\nWhile QGIS includes a wide variety of tools, there are some tools that are not currently included in QGIS,\nincluding those for spatial statistics. We will use another open-source software called Geoda, which was\nspecifically developed for exploratory analysis and spatial statistics.\n1. Open Geoda.\n2. Next to the Input file box, click the folder icon and select ESRI shapefile. Select\nmedian_income_suffolk_ma from the workshop data folder.\n3. Click the W icon in the toolbar (Weights Manager) and Create. Specify the following:\na) Weights File ID Variable: spatial_id (this is any ID that uniquely identifies each polygon)\nb) Rook contiguity (rook shares borders, queen shares borders and vertices/corners)\nThese parameters tell Geoda how to define a neighborhood for analysis. Feel free to experiment\nwith other parameters in the future.\n4. Click Create and save your weights file.\n5. Close the Weighs File Creation window and Weights Manager window.\n6. Select Space > Univariate Local Moran's I.\n7. Choose VALUE0 as the variable, which is the median household income in each tract, and verify\nthat your weights file is listed in the Weights box. See the text file in the workshop exercise data\nfolder for the attribute field information. Click OK.\n\n8. Check off the cluster map and Moran Scatter Plot and click OK.\n9. Where are there clusters of high and low income? The tool has also output a scatterplot that\nyou can examine. Close Geoda when you are finished.\nThe Moran scatter plot provides a classification of spatial association into four categories,\ncorresponding to the location of the points in the four quadrants of the plot. These categories are\nreferred to as High-High, Low-Low, Low-High and High-Low, relative to the mean, which is the center\nof the graph. It is important to keep in mind that there is a difference between a location being in a\ngiven quadrant of the plot, and that location being a significant local cluster or spatial outlier.\nIn the take-home exercise you will learn how to output these results so they can be added to QGIS.\nYou can learn more about the statistics used in Geoda here:\nhttps://geodacenter.github.io/documentation.html\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\nRES.STR-001 Geographic Information System (GIS) Tutorial\nIAP 2022\nFor information about citing these materials or our Terms of Use, visit:\nhttps://ocw.mit.edu/terms"
        },
        {
          "category": "Resource",
          "title": "GIS Level 1 ArcGIS Pro Take-Home Exercises (DOCX)",
          "type": "DOCX",
          "source_url": "https://ocw.mit.edu/courses/res-str-001-geographic-information-system-gis-tutorial-january-iap-2022/mitres_str001iap22_level1_arcgis_takehome.docx",
          "content": "Introduction to GIS & Mapping: ArcGIS Desktop\nYour task in this exercise is to determine the best place to build a mixed use facility in Hudson County, NJ. In order to revitalize the community and take advantage of special loans, you want to build your facility in an area with at least 1.5 times the national unemployment rate (It was 4.4% as of August 2017, which is the year of our data). You will also explore what sort of railroad transit is available in this area.\nOpen ArcGIS Pro\nBefore you begin, decide where you will be storing the GIS files that you will be downloading and creating in this exercise. You can create a working folder on the desktop or in the Documents folder. The exercise data is in the folder you downloaded before the workshop in the folder Data\\Final Exercise.\nOpen ArcGIS Pro (Start (Windows icon)) > All Programs > ArcGIS > ArcGIS Pro). You will see an open screen where you can create a new map from a blank template. Click on \"Map\" to do so.\n\nYou will see a new form where you will name your project and where it will be located:\n\nUncheck the \"Create a new folder for this project\" checkbox and select the folder where you downloaded the data to (and not the folder that actually contains the data).\nArcgis Pro is designed like most Windows programs. All of the menus are context sensitive. In the top area (the toolbar), you see a number of tools. Those tools change with the selection of tabs and depending on what data layers you have highlighted.\nAdd a basemap from ArcGIS Online\n\nNotice that the map you created is not blank, but includes a default basemap. You can change the basemap if you choose:\n\nClick the Map tab and Basemap.\nClick on Imagery.\n\nNote that the layer is served over the web so it may take some time to draw (and you have to be connected to the internet for it to continue drawing). What you see depends on the scale you are working in on your map - as you zoom in closer you will typically find more detailed information. Your scale is displayed below the map and automatically adjusts as you zoom in and out.\n\nTo navigate your data, you will primarily use these buttons in the Map tab:\n\nFrom left to right, top row first, they are used to Zoom to the extent of all layers in the map, zoom to selected data, fixed zoom in, and fixed zoom. You can use the scroll button on your mouse to zoom in and out and you can left click and hold the click to pan around the map.\nFind and add data\nAs you learned, there are many sources for GIS data. We will first find transportation data for New Jersey.\nGo to: http://njogis-newjersey.opendata.arcgis.com/datasets?t=Transportation. This shows all the open transportation data for New Jersey. We found this site by doing an internet search for \"new jersey gis data.\"\nSearch for \"railroad\" in the top search box. Options should drop down from the search box. View the Passenger Rail Stations data layer by clicking on its name.\nA page opens that previews the data on a map. Click the download icon to the left of the map.\n\nA download pane opens on the left side of the screen. Click Download under Shapefile.\nWhile the file downloads, click the information icon.\n\nBrief metadata is provided in the sidebar. Click the View Full Details button to see more.\nReturn to the search box and repeat this process to locate and download the Railroads Network. If you want to explore any other data from this area, feel free to download it.\nMove the data to your working folder and unzip each file by right clicking and selecting 7-zip > Extract here (or use whatever data extraction tool you have installed on your computer).\nClick the Add Data button on the Map tab and navigate to your working folder where you unzipped the data and add it to the map. One is called Railroads_Network and one has a long code name.\nRight click on each layer name and select Properties. In the General tab rename Railroads_Network to Railroad_Stations and the long code name to Railroad_Lines.\nIn addition to the transportation data you just downloaded, add census unemployment data from the workshop materials. It can be found in GIS_Level1_Data\\takehome_exercise.\nRight click on Hudson_tracts and select Zoom to Layer.\nThe US Census divides the country into continuous polygons and aggregates census data for these polygons before releasing the data to the public so that individual responses cannot be identified. Our data is for census tracts, which contain between 1200 and 8000 people total.\nIn the Table of Contents of ArcGIS (where all layer names are listed) turn the layers on or off using the checkboxes located to the left of each layer name. Leave the basemap layer unchecked for now so that the next few steps will go more quickly.\n\nAdjust which layer draws on top by dragging layers above or below one another. You will want your rail stations and rail lines on top so they won't be covered by the census tracts polygons. If your layers will not drag, click the List by Drawing Order button at the top of the table of contents.\n\nExplore the attribute table\nRight click on each layer and select Attribute Table.\nEvery point, line, or polygon file has an attribute table. Any data in the attribute table can be used for displaying and labeling on the map and making queries. You can also create new columns in the table and add data or calculations. Metadata can be key to understanding attribute tables that use codes and abbreviations.\nLeave the attribute table for the tract unemployment data open.\nCan you tell what any of the column headings mean? It's unlikely, so you will need to look at the metadata.\nOpen the text file (outside of ArcGIS Pro) that is in your Data\\Final_Exercise folder. You now see the definition for each column. This data was downloaded from a database called Social Explorer, and joined to a polygon file from the US Census.\nVariable A17005_003 is the number of unemployed people in the civilian population. Is this what we want to map? Why or why not?\nMapping raw numbers is usually not useful because the total population in one census tract may be more or less than another. One way to \"normalize\" the data is to take into account the total population and calculate a rate.\nAt the top of the Attribute Table, click the Add field button.\n\nName the variable Unemp_rate and choose the type as double (you may need to double click on the Data Type box in order to select it with the cursor). Close the Fields window with the \"X\" and save your changes.\n\nRight click on the new column that was added and select Calculate Field.\nWe want to divide the number of people unemployed by the total number of people in each tract. Based on the metadata, which columns will you use?\nAdd fields to the equation by double clicking on them in the list. Make sure your equation matches this one: A17005_003! / !A17005_001! and click Run. Be patient, it will take a few seconds.\n\nWe want to find tracts that are 1.5 times the national unemployment rate. This is equal to .066 or greater.\nClick the Table tab at the top of the window, then Select By Attributes. Keep all of the defaults and then click Add (+) New Expression then Create a new expression.\nIn the Where clause of the expression, you will notice three fields:\nIn the left field, change the column that you want to work with from FID to Unemp_rate in the dropdown list.\nIn the middle field, change \"is equal to\" to \"is greater than or equal to\".\nIn the last field, enter 0.066. Click Run to select the tracts that have an unemployment rate greater than 0.066.\n\nAll rows that correspond to a tract with a higher than average unemployment rate are highlighted and the corresponding tracts are highlighted on the map.\nClose the Attribute Table.\nExport to a new file\nWe will export the selected tracts to a new data layer so that we can more easily visualize which tracts have high unemployment. Exporting a smaller area of data is the easiest way to subset a dataset to only the desired records or keep your file sizes smaller and more manageable.\nMake sure the Hudson_tracts is highlighted in the table of contents.\nClick the Data tab and Layer from Selection. Note that this layer is temporary until we export it.\nRight click on the new layer created from the selection and select Data > Export Features.\nClick on the folder icon to view and edit the save location. Select the folder where you want to save the file (you'll name the layer in the next step).\nIn the Output Feature Class box name the layer unemp_high.\n\nNote that file names and locations can be very important when working on projects. GIS software tends to generate many files, so you want to make sure to use file names that are descriptive and easy to remember in the future.\n\nClick Run.\nClear the selected features by selecting the Clear button in the Map tab.\n\nSave your map document.\n\nSymbolize data\nChange a single symbol\nRather than completely covering the unemployment polygon layer with the one for high unemployment, we can change the symbology of the high unemployment layer so that we can still see the tracts for the entire county underneath.\nIn the table of contents, double click the colored rectangle below the high unemployment layer (unemp_high) and change the fill to a pattern, such as 10% simple hatch (you will have to scroll down to find it). That way we can still see the unemployment tract data layer underneath.\nClose the Symbology box.\n\nExplore data distribution\nBefore we make a choropleth map of the unemployment rate, we need to examine our data in order to create the most appropriate map. A quick way to explore the distribution of our data in ArcMap is to make a graph. For future projects, you will likely want to explore your data outside of ArcGIS in statistical or data visualization software in order to better understand it.\nClick on the Hudson_tracts_unemp_2017 layer in the Table of Contents.\nAt the top of the window under Feature Layer, select the Data tab.\nClick Create Chart, choose Histogram.\nChoose Unemp_rate as the Number. Feel free to change the number of bins and see how the histogram changes.\n\nThis histogram is showing the number of tracts (y axis) that fall into each unemployment range (x axis). Not all ranges are shown because of size constraints on the axis, but this still gives you an idea of the general shape of your data. We see that unemployment rate is relatively low, but that there are some outlying tracts with a high employment rate.\nClose the Chart Properties box and the chart itself.\n\nMake a choropleth map\nMake sure the Hudson_tracts_unemp_2017 layer is highlighted in the table of contents. At the top of window, click the Appearance tab. Click on the dropdown triangle below Symbology and select Graduated Colors. This will open the Layer Properties window.\n\nSelect \"Unemp_rate\" as the Field.\nSymbolize the data in whatever way you think is best. Map symbology can be used to alter the way people view and understand information, just like statistics. It is important to understand what you want to express in your map and how to best symbolize your data.\nChose a classification method and number of classes. In order to help you choose a classification method. Here is more information about each method: https://pro.arcgis.com/en/pro-app/help/mapping/layer-properties/data-classification-methods.htm\nPick a color scheme from the drop down menu.\nYou can adjust the number of decimals shown by clicking the Advanced symbol options button and adjusting the Rounding options.\n\nClose the window when you are finished.\nSave your map document.\nDo you have an idea about where you might build based on the unemployment rate? Obviously many factors go into selecting a building site. We will examine one more: train access.\nFind tracts that have railroad stations\nYou will use the Select by Location tool to select all tracts that contain a railroad station.\nClick on the Map tab. In the Selection menu at the top, click \"Select By Location\".\nFor the Input Features, choose Hudson_tracts_unemp_2017.\nChange Relationship to Contains.\nFor the Selecting Features, choose Railroad_Stations_in_NJ.\n\nClick Run. Now all tracts that contain a railroad station are highlighted in blue. This is temporary until you clear the selection.\nMake these into a temporary layer again in the Data tab using the Layer from Selection button. We don't have to export them to a permanent layer this time.\nChoose a tract for building\nWith the Hudson_tracts_unemp_2017 layer selected in the Table of Contents click the Map tab and the Clear button.\nNow choose the Select button in the tab. Click on the tract that you want to build in, based on the visualization you have made. You can select more than one tract by holding the Shift key as you make your selection.\nAgain, create a layer from the selected data. Export the data using the method in the Export to\nA New File section of the exercise.\nClear the selection once you have exported the layer and change the symbology of the layer to show it is the one you selected for building.\n\nWondering what area was actually chosen for this building? Add Bay_street_building from Data\\Final_Exercise. You may need to double click on the point symbol and adjust the size to see it. Read the article here.\nMake final changes to the color of any of the data layers and zoom and center your map to prepare for creating a layout.\nCreate a layout of your map\nAt the top of the window, in the Insert tab select New Layout.\nSelect 8.5\" x 11\" Letter under ANSI Landscape.\nYou should have an empty page. Click the Insert tab and Map Frame. Select the image of your map. Draw a box where you would like the map placed. Drag the corner of the map to fill most of the page but leave room for a title, scale bar etc. If you need to adjust the scale once the map frame has been inserted, select or type in a value in the scale bar at the bottom of the screen (the smaller the number, the more zoomed in the map).\nClick on the Insert tab and Legend. You need to drag the box big enough to see all of the entries. Only the visible layers in your map will be included in the legend.\nUsing the same procedure, insert a North arrow.\nFrom the Text dropdown (it will say rectangle now), choose Text and place it on your map. Write a title.\nExport your map\nClick on the Share tab.\nClick Export Layout from the Output section.\nChoose PDF in File Type and select the location to save to.\nClick on the Export button.\nNote that if you save as an AI (Adobe Illustrator), the layers will remain as separate, editable layers in Illustrator. If you save as JPEG or TIFF, you can adjust the resolution of the exported file.\nOpen your map in Adobe Acrobat to see what it looks like.\nSave your ArcMap document\nClick Save button.\nNote that when you save an ArcGIS Pro document, you are only saving a link to the layers in your project. If you move your project to a new location, you will need to move all the files linked to your project with it. Each shapefile has multiple files associated together, and they need to stay together to work properly! It is best to save all files in the project folder so they are more transportable with the project.\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\nRES.STR-001 Geographic Information System (GIS) Tutorial\nIAP 2022\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms"
        },
        {
          "category": "Resource",
          "title": "GIS Level 1 ArcGIS Pro Workshop Exercises (DOCX)",
          "type": "DOCX",
          "source_url": "https://ocw.mit.edu/courses/res-str-001-geographic-information-system-gis-tutorial-january-iap-2022/mitres_str001iap22_level1_arcgispro.docx",
          "content": "GIS Level 1: ArcGIS Pro Workshop Exercises\n\nExercise 1\nOpen software\nOpen ArcGIS Pro on your computer. Select Map from the Blank Templates area.\nName your Project GIS_Level1 and select a location for saving it. A blank map will now open.\nAdd data\nClick the Map tab and the Add Data button.\n\nNavigate to the workshop folder and select GIS_Level1_Data\\workshop_exercises.\nAdd all the data layers:\nMBTA_NODE\nMBTA_ARC\ncambridge_demographics\ncambridge_DEM\ncambridge_restaurants\nIt may take a minute for the data to load.\nReview interface & organize data\nThe center of the screen contains a basemap that has been automatically loaded. It is there to provide context for the data that we added.\nYou can move around the map using the pan and zoom buttons in the Map tab of the top menu bar.\n\nData layer names are shown in the Contents pane on the left. You can right click on any layer and select Zoom to Layer to center it on the screen.\n\nDrag the layers up or down so that they do not cover each other.\nYou can turn layers on and off by checking/unchecking the box next to each name. Uncheck the cambridge_DEM for now so it is easier to see the other data layers (we will change its appearance later in the exercise).\nClicking the menus at the top of the screen will show various tools you can use to edit, visualize and analyze your data. The toolbox in the Analysis tab will open the full list of analysis tools, which we will explore more in GIS Level 2.\n\nIdentify types of data & explore attributes\nLook at the data layers in the Contents pane. Are they vector or raster data? If they are vector, are they point, line or polygon?\nTo see the underlying data of each layer, right click on it and select Attribute Table.\nWhat columns are included with the MBTA_ARC data?\nWhat about the cambridge_DEM? Why are they different?\nThe cambridge_restaurants data layer is currently not in a shapefile format so it is not displaying on the map, however we can convert it to point data by plotting the coordinates included in the table.\nRight click on the cambridge_restaurants table in the Contents pane and select Display XY Data.\nClick the folder next to Output Feature Class to select a location to save the data and choose a file name.\nThe X Field should already be filled in with Longitude and the Y field with Latitude. Keep the Coordinate System as GCS_WGS_1984.\nClick OK.\nSave your map project and keep your map open.\n\nExercise 2\nData can be symbolized in a variety of ways, depending on the data format and available attributes.\nChange a single symbol\nDouble click on the point symbol below the Cambridge_restaurants layer in the Contents pane.\nChoose a symbol to represent the restaurants. You can make additional modifications to the symbol in the Properties tab.\nClose the Symbol window when you are finished.\nSymbolize categories\nYou want to change the color of the mbta lines (MBTA_ARC) so they correspond to the correct color.\nRight click on MBTA_ARC and select Symbology.\nChoose Unique Values under Primary symbology, which means that each value will be assigned a unique color, pattern, etc.\nLook at the metadata (https://www.mass.gov/info-details/massgis-data-mbta-rapid-transit) to determine which column contains information about the name of the rapid transit line. Choose the appropriate column from the dropdown menu in Field 1.\nClick the Add all Values button to add all unique values found in the LINE column.\n\nClick on the line symbol in the Symbol column to select an appropriate color. Click Apply and the back arrow after selecting each color.\nClose the Symbology window when you are finished.\nMake a choropleth map\nSelect the Cambridge_demographics layer in the Contents pane by clicking on it so it is highlighted.\nClick the Appearances menu and Symbology.\nSelect Graduated Colors from the Primary symbology dropdown menu to create a choropleth map.\nOpen the metadata for this layer outside of ArcGIS Pro. It is in the workshop_exercise data folder and called Cambridge_demographics_variable_names.txt. Choose which data you would like to symbolize and choose the corresponding column from the Field dropdown menu.\nExperiment with different break methods, classes, and color schemes from the dropdown menus until you are happy with your map.\nClick the Advanced symbology options tab and expand Format labels.\n\nClick the Category dropdown to select the appropriate numeric display for your data and alter the number of decimal places if needed.\nClose the symbology window when you are finished.\nSymbolize a raster\nRight click on Cambridge_DEM and select Symbology.\nThere are different options for symbolizing raster data versus vector data. The DEM is currently symbolized as Unique values which are most appropriate for values that each represent a different data category, such as land use so you should choose a different symbology. Feel free to experiment with other options from the dropdown menu:\nStretch: assigns a continuous color scheme from the minimum to the maximum value of each raster cell\nDiscrete: you choose a specific number of colors to use when symbolizing data\nClassify: data value are grouped into classes, similar to when creating a choropleth map.\nWhen you are happy with your raster symbolization, close the Symbology window.\nSee the take home exercise for information on how to create a layout for printing or exporting your map.\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\nRES.STR-001 Geographic Information System (GIS) Tutorial\nIAP 2022\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms"
        },
        {
          "category": "Resource",
          "title": "GIS Level 1 Instructions (DOCX)",
          "type": "DOCX",
          "source_url": "https://ocw.mit.edu/courses/res-str-001-geographic-information-system-gis-tutorial-january-iap-2022/mitres_str001iap22_level1_instructions.docx",
          "content": "GIS Level 1 Setup Instructions\n\nNote: This activity uses online resources that may not be freely available to OCW users.\nThank you for registering for GIS Level 1. Before the workshop, please do the following:\nDownload and install either ArcGIS Pro or QGIS\nInstall 7-zip if necessary\nDownload all workshop materials\nUpdate and setup Zoom\nDownload and install ArcGIS Pro or QGIS\nQGIS is a free, open source software program that will work on any operating system and doesn't take up much space on your computer. While it has many of the same capabilities as ArcGIS Pro, there are some analyses you can't do in QGIS and it tends to have more bugs.\nArcGIS Pro is a commercial software from ESRI that we have a subscription for at MIT. It only runs on Windows and requires an account or a connection to the MIT license server to run. It includes a full suite of GIS tools, but may not run well if you have a slower computer.\nIf you are not sure which software to use, this website has a lot of additional information: https://gisgeography.com/qgis-arcgis-differences/\nNote: This workshop will NOT use ArcGIS Desktop/ArcMap, only ArcGIS Pro, the newest GIS software from ESRI.\nArcGIS Pro installation\n1. Create an ArcGIS Online (AGOL) account: https://libguides.mit.edu/gis/webmap#s-lg-box-wrapper-5115587\n2. If you have not already downloaded Pro, log into your AGOL account. From your account page, click your name in the upper right and select My settings > Licenses and click download next to ArcGIS Pro.\n3. After installing Pro, choose the Named User License type and select ArcGIS Online. You'll then see the same login screen that you used to create your account.\nQGIS Installation\nFull instructions and links for installing QGIS for a number of different operating systems can be found here: http://qgis.org/en/site/forusers/download.html\nWindows users should download QGIS Standalone Installer. (Mac users only have one option.)\nDownload QGIS 3.16 or higher. If you already have QGIS installed, we have tested the workshop exercises with versions 3.16 and higher so we recommend upgrading if you are using an older version.\n7-zip installation\nWorkshop files (and most GIS data) are in zipped folders. Most Windows computers have the option to extract data by right clicking and most Macs will automatically extract data. Occasionally your computer may not have a built-in data extraction tool. In this case we recommend installing 7-zip:\nhttps://www.7-zip.org/\nWorkshop materials\nDownload all workshop.\nMaterials include the presentation, workshop exercises, take-home exercise, and all required data.\nZoom setup\nMake sure your Zoom app is up-to-date using these instructions. You may have difficulty completing exercises in breakout rooms if your Zoom is not updated: https://support.zoom.us/hc/en-us/articles/201362233-Upgrade-update-to-the-latest-version\nIf you have access to a second monitor (or a second \"smart\" device that can connect to a Zoom session) it may greatly improve your workshop experience and make it easier to follow the instructor and complete the exercises simultaneously. If not, it is still doable, for example, by organizing your screen in this way: https://raw.githubusercontent.com/hbctraining/bioinformatics_online/master/guidelines/img/Screenshot%202020-03-23%2015.21.10.png\nWe encourage participation during the session and kindly ask you to use your video, if possible.\nMute audio except when talking (Tip: you can temporarily unmute yourself by pressing and holding a space bar. When it is released, Zoom goes back to the mute mode).\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\nRES.STR-001 Geographic Information System (GIS) Tutorial\nIAP 2022\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms"
        },
        {
          "category": "Resource",
          "title": "GIS Level 1 QGIS Take-Home Exercises (DOCX)",
          "type": "DOCX",
          "source_url": "https://ocw.mit.edu/courses/res-str-001-geographic-information-system-gis-tutorial-january-iap-2022/mitres_str001iap22_level1_qgis_takehome.docx",
          "content": "Introduction to GIS & Mapping: QGIS Desktop\nYour task in this exercise is to determine the best place to build a mixed use facility in Hudson County, NJ. In order to revitalize the community and take advantage of special loans, you want to build your facility in an area with at least 1.5 times the national unemployment rate (4.4% as of August 2017, the year of our data). You will also explore what sort of railroad transit is available in this area.\nOpen QGIS Desktop\nThis exercise has been tested with QGIS versions 3.16 and higher, though previous releases will likely work as well.\nDecide what folder you will use to store your map and data. We recommend using the folder where you downloaded the workshop materials.\nOpen QGIS (Start (Windows icon)) > All Programs > QGIS > QGIS Desktop 3.X). Note: if this is the computer's first time opening the new version it may present window with a welcome message; click \"Let's get started!\" Now, open a new map by clicking on the Project tab in the top menu and then the 'New' project icon in the upper left corner of the QGIS Desktop window.\nIf you do not see this icon it may be due to what toolbars are turned on. Go to the View tab in the top menu > Toolbars (at bottom) > and make sure the following toolbars are checked: Attributes, Map Navigation, and Project. You can also access the panel and toolbar menu by right clicking anywhere in the grey of the top menu.\n\nNote: the QGIS Project file is a record of the layers that have been added to a map display, along with the map display itself. This allows users to recover a map display including the layers in the map, symbolization, visibility, units of measurement, and other display settings (similar to other software).\n\nClick Project > 'Save As...' to save your project in the folder you set up. We recommend saving frequently with any GIS software as there can be crashes when running tools.\nAdd a basemap\nAdding a basemap is a quick and easy way to provide context to spatial data you are displaying or analyzing.\n\nLook for the Web menu at the top of the screen and QuickMapServices. If you do not see it, follow the instructions below. If it is there, continue to step 2.\nIf you cannot see the QuickMapServices plugin, click 'Plugins' in the top menu > 'Manage and Install Plugins...'\nSelect 'QuickMapServices' from the list of plugins.\nClick 'Install Plugin' > and 'Close' the window.\nClick the Web tab in the top menu, and hover over the QuickMapServices Plugin until the dropdown menu shows. Click on OSM Standard.\n\nNote that the layer is served over the web so it may take some time to \"draw\" (you must be connected to the internet to use this plugin). What you see depends on the scale you are working in on your map - as you zoom in closer (see methods below) you will typically find more detailed information. Your scale is displayed in the Standard toolbar and automatically adjusts as you zoom in and out.\nTo navigate your data you will primarily use these buttons:\n\nFrom left to right, they are used to pan, pan to selection, zoom in, zoom out, and zoom to the full extent of all visible data. Take a moment to explore these options as you will use them often. Note that the icons may vary slightly depending on the version of QGIS that you have. You can hover over an icon to see its name.\nThe coordinate of your mouse pointer and zoom scale are shown along the bottom right of the map:\n\nFind and add data\nAs you learned, there are many sources for GIS data. We will first find transportation data for New Jersey.\nGo to: http://njogis-newjersey.opendata.arcgis.com/datasets?t=Transportation. This shows all the open transportation data for New Jersey. We found this site by doing an internet search for \"new jersey gis data.\"\nSearch for \"railroad\" in the top search box. Options should drop down from the search box. View the Passenger Rail Stations data layer by clicking on its name.\n\nA page opens that previews the data on a map. Click the download icon on the left side of the map.\n\nA download pane opens on the left side of the screen. Click Download under Shapefile.\nWhile the file downloads, click the information icon. Brief metadata is provided in the sidebar. Click the View Full Details button to see more.\n\nReturn to the search box and repeat this process to locate and download Railroads Network. If you want to explore any other data from this area, feel free to download it.\nMove the files to your folder and unzip the files by right clicking on file and selecting 7-Zip > Extract Here (or use the data extraction software installed on your computer).\nGo back to QGIS. In the top menu select Layer > Add Layer > Add Vector Layer...\nNavigate to your working folder by clicking on ... to the right of the Source box.\nSelect the two shapefiles by selecting the file with the .shp extension. Hold ctrl to select multiple files. One is called Railroads_Network and one has a long code name.\nClick Open > Add (if a projection warning comes up, hit OK for now) > close window when done.\nNote that even though you selected the .shp files, QGIS is using all the files that make up the shapefile in order to place the data in the proper position on the map.\nIf the box appears for converting coordinate reference systems, click Ok and Ok again if prompted. We will work with coordinate reference systems in GIS Level 2.\nRight click on the layer name and select, \"Zoom to layer.\" Note depending on the random color assigned to the railroad lines they may be hard to see.\nRight click on each layer name and select Rename Layer. Rename Railroads_Network to Railroad_Stations and the long code name to Railroad_Lines.\n\nIn addition to the transportation data you just downloaded, add census unemployment data to the map. This data can be found in the folder Data\\Final_Exercise. Repeat the process of adding a vector layer: \"Hudson_tracts_unemp_2017.shp\". Close the Add Vector data box and Zoom to this layer to hone in on the project site.\nThe US Census divides the country into continuous polygons and aggregates census data for these polygons before releasing the data to the public so that individual responses cannot be identified. Our data is for census tracts, which contain between 1200 and 8000 people.\nIn the Table of Contents of QGIS (where all layer names are listed) turn the layers on or off using the checkboxes located to the left of each layer name. Leave the basemap layer unchecked for now so that the next few steps will go more quickly (basemaps can slow down the drawing of other layers).\nAdjust which layer draws on top by dragging layers above or below one another. Note: You will want to end up with your rail stations and rail lines on top so they won't be covered by census tract polygons.\nExplore the attribute table\nRight click on each layer's name > select Open Attribute Table... This is the data associated with each layer, and what that layer's symbolization will be based upon.\nEvery point, line, or polygon file has an attribute table. Any data in the attribute table can be used for displaying and labeling that layer as well as make queries from. You can also create new columns in the table and add data or calculations. Note: metadata can be key to understanding attribute tables that use codes and abbreviations.\nLeave the attribute table for the tract unemployment data open.\nCan you tell what any of the column headings mean? It's unlikely, so you will need to look at the metadata. Open the text file (outside of QGIS) in Data\\Final Exercise. You now see the definition for each column. Note: this data was downloaded from a web based GIS, Social Explorer, and joined to a polygon file from the US Census.\nQ: Variable A17005_003 is the number of unemployed people in the civilian population. Is this what we want to map? Why or why not?\nA: Mapping raw numbers is not often useful because the total population in one census tract may be more or less than another, and so the counts are not meaningful to compare between geometries. One way to \"normalize\" data is to divide the counts by the total population to calculate a rate.\nClick the Open Field Calculator icon\n\nNote, in some versions of QGIS this may be greyed out until you click the Toggle edit icon\n\nMake the Output field name Unemp_rate and make the Output field type Decimal number.\nIn some versions of QGIS, you may need to specify the field length (if these options are greyed out, ignore this step). In this case, make Output field length 11 (number of characters) and precision (number of decimal places) 11.\nQ: Since we want to divide the number of people unemployed by the total number of people in each tract. What columns would you use to do this, (remember you can look at metadata to know what each column is)?\nA: To create the expression that will calculate the unemployment rate:\nClick in the Expression box\nOpen the Fields and Values menu in the box to the right (under the search line)\nDouble click on the fields to add them to the expression box (you can also type them in directly)\nUse the divide by function button between fields to create the expression shown.\n\nClick OK.\nIf you turned on editing, click the Save edits icon in the table's menu\n\nAnd click the Toggle edit ( ) to stop editing.\n\nIf you did not turn on editing, proceed to the next step.\nNext, based on the original problem statement we know that we want to find tracts that are 1.5 times the national unemployment rate. This is equal to .066 or greater. Click the Select features using an expression button at the top of the table's menu window.\n\nOpen the Fields and Values menu. Double click on Unemp_rate in the list. This will add it to the expression box on the left. Finish the expression by setting it greater than or equal to .066 (\"Unemp_rate\" >= .066). You will find >= in the Operators menu (below the Fields and Values menu). Click Select Features and close the Select by expression window, to see the rows that were selected.\n\nAll rows that correspond to a tract with a higher than average unemployment rate are highlighted and the corresponding tracts are highlighted on the map.\nWithout clicking anywhere within the table or map (will alter the selection), close the Attribute Table.\nExport to a new file\nWe will now export the selected tracts to a new data layer so that we can more easily visualize which tracts have high unemployment. Exporting a smaller area of data is the easiest way to subset a dataset to only the desired records or keep your file sizes smaller and more manageable.\nRight click the unemployment layer in the table of contents > Export > Save Selected Features As...\n\nMake the Format ESRI Shapefile. Click the ... next to the File name box and navigate to your folder. Name the file \"Unemp_ratehigh\" in your folder. Keep the CRS (EPSG,4269, NAD83). Click OK.\n\nNote: file names and locations can be very important when working on projects. GIS software tends to generate many files, so you want to make sure to use file names that are descriptive and easy to remember.\n\nClear the selected features by clicking the \"Deselect features from all layers\" icon in the top menu.\n\nNow try turning on/off this new layer and the original unemployment data. What do you notice?\nSave your map document to your working folder on your local drive using the Save icon.\nSo far you have learned how to open and navigate the software, use plugins to add a basemap, find, download, and add data, explore and select from the attribute table based on information in the metadata, perform a selection, and export your new dataset. You have completed many parts of getting started in a GIS and are half way through the exercise. Feel free to take a short break before continuing on to symbolization, decision making, and creating and exporting your final map.\nSymbolize data\nChange a single symbol\nRather than completely covering the unemployment polygon layer with the one for high unemployment, we can change the symbology of the high unemployment layer so that we can still see the tracts for the entire county underneath.\nIn the table of contents, double click the high unemployment layer (Unemp_ratehigh) name.\nClick on the Symbology tab\nClick on the words, \"Simple fill\" to bring up the options.\nIn Fill Style, change the Simple fill style to a pattern, such as Diagonal X. That way we can still see the unemployment tract data layer underneath.\nAdjust the color (using the drop down menu in the 'Fill' box) and click OK when done.\n\nNote: Your help screen may look slightly different depending your version of QGIS.\nExplore data distribution\nBefore we make a choropleth map of the unemployment rate, we need to examine our data in order to create the most appropriate map. A quick way to explore the distribution of our data in QGIS is to make a graph.\nDouble Click hudson_tracts_unemp_2017 in the Layers Panel.\nChoose Symbology from the left column.\nSelect Graduated from the top dropdown menu.\nChoose Unemp_rate as your Value/Column.\nSelect a color ramp of your choosing.\nClick Classify to load that field's values.\n\nNow select the Histogram tab (next to Classes). Click on Load values and see how the frequency of different values are being symbolized based on the method, number of classes, & color ramp.\nWe see that unemployment rate is relatively low, but that there are some outliers with a high employment rate.\nMake a choropleth map\nSymbolize the data in whatever way you think is best. Map symbology can be used to alter the way people view and understand information, just like statistics. It is important to understand what you want to express in your map and think carefully about how best to symbolize your data. Note: you can click apply when finished instead of OK to test options, without leaving the Layer Properties window.\nPick a color ramp from the drop down menu.\nChoose the mode and number of classes (options below the classes box)\nHere is brief information about some of the available classification methods. For a more in depth analysis check out our mini-tutorial on choropleth mapping.\nEqual Interval: classes are all the same size.\nQuantile - number of values in each class is the same. If there are 100 values and we want 4 classes, quantile method will make it such that each class will have 25 values.\nNatural Breaks (Jenks) - algorithm finds natural groupings of data to create classes. It maximizes the variance between individual classes and min. variance within each class.\nStandard Deviation - creates classes based on standard deviations from the mean.\nPretty Breaks - This is based on the statistical package R's pretty algorithm. It is a bit complex, but the pretty in the name means it creates classes with round numbers.\nTo reduce the number of decimals shown in the legend, use the Precision options in the upper right part of the Symbology window.\nClick Ok when you are finished.\nSave your map document.\nDo you have an idea about where you might build based on the unemployment rate? Obviously many factors go into selecting a building site. We will examine one more: train access.\nFind tracts that have railroad stations\nYou will use the Spatial Query tool to select all tracts that contain a railroad station.\nFrom the top menu, click Vector > Research Tools > Select by Location.\nSelect features from the hudson_tracts_unemp_2017 data layer, where the features \"contain\" features from the Railroad_Stations_in_NJ.\nClick Run > then Close.\n\nNow all tracts that contain a railroad station are highlighted. Based where there is high unemployment (1.5 times the national unemployment rate, use 'Unemp_ratehigh' layer) and access to transportation, where might you want to build?\n\nRemember you can repeat the process of exporting your selection to its own layer, which you can symbolize in such a way (e.g. hollow with dots) that it can be seen alongside other layers. You may also want to turn off railroad lines and stations once you have performed the prior steps.\n\nOnce you have finished this step, clear the selection.\n\nChoose a tract for building\nClick the selection button at the top of the screen and click on the tract that you want to build in, based on the visualization you have made. You can select more than one tract by holding down the Ctrl button.\n\nSave the selected feature(s) using the same method you used above so that you know which location(s) you selected to build on.\nClear the selection once you have exported the layer.\n\nWondering what area was actually chosen for this building? Add Bay_street_building from Data\\Final_Exercise. You may need to double click on the point symbol and adjust the size to see it. Read the article here.\nMake final changes to the color of any of the data layers.\nLayout and export your map\nIn QGIS, you can create a map to export and print in the Map Layout.\nOn the main toolbar menu at the top of QGIS click Project > Layout Manager.\nIn the Layout manager window, click Create... and name your new layout something like \"New Jersey Building Tract\".\nClick OK.\n\nA new window will open where you can work on the layout your map. If you close the new layout, you can re-open it by clicking Project > Layouts, and choosing your layout from the list.\n\nThe menus on the left of the layout window are tools that help you move around and add things to your map. The menus across the top are tools that allow you to save and export, zoom in and out and more. Hover over the symbols to read what they do.\nOn the left-hand menu, click on the Add Map icon.\n\nClick and drag a box on the blank page. Your map will appear in the box you've drawn. You can click and drag the map around and resize it to make the margins work the way you want.\nUse the select/move item icon to select and move your map around on the page.\n\nUse the move item content icon to adjust the placement of your map.\n\nRight click the map itself > Page Properties to test switching between portrait or landscape orientation.\n\nUse the Add Label button and click on the page to add a title box.\n\nOn the right side of the Layout window, click on the Item properties tab and type your title in the Main Properties box. Change font (click right dropdown arrow), margins, position, size and background the way you think it should be.\nInsert a legend using the Insert legend button, then click and drag a box for the legend placement. Use the Item properties tab to modify your legend.\n\nInsert a scale bar and/or North arrow (click once to start line, again to end it, & right click to finish). Note these are the least important features you need to add so do not pick distracting formats.\n\nUse again the Add New Label icon to create a text box for your name, date, and sources for your data. If you do not like the default settings for any item, use the item properties to edit its display.\nSave your layout.\nExport your map\nIn the top menu go to Layout > and look at the different export options: Export as Image, Export as SVG..., Export as PDF... You can also use the icons to save your map in any of these ways. Note: if you save as a JPEG or TIFF, you can adjust the resolution of the file.\nIf you receive a \"Project Contains WMS Layers\" warning, this means that the owner of the basemap won't allow large areas to be exported. Our area is small enough to ignore this warning so feel free to have your basemap on when exporting (you can move layout view to the side to edit what layers are on in original data view window).\n\nSave your exported map.\nClick close (if needed after export).\nOpen your map to see what it looks like.\nClose the Layout window & then the Layout Manager window\nSave your QGIS document\nClick the Save icon.\nNote that when you save a QGIS document, you are only saving the links to the layers in your project and how you have symbolized them, not the actual datasets. If you move your project to a new location, you will need to move all the files linked to your project. Note: also keep in mind that each shapefile has multiple files associated with it, and they need to stay together to work properly.\nBy default, QGIS stores the full path name to each layer in the QGIS document. This means that if you move your files around, your path name will change and you will need to redirect QGIS to the new file location for each folder of data. If you will be moving files around, it is recommended that you save a relative path to the data files in your project. QGIS does this by default.\nTo be sure the default is set that way, go to Project > Properties.\nClick on the General tab.\nCheck that the dropdown menu next to Save paths is set to relative, not absolute. Click OK to close the window.\n\nCongratulations!\nYou should now be familiar with the following:\nOpening a QGIS Desktop Project\nAdding basemaps & data\nExploring attribute tables\nSelecting & exporting data\nSymbolizing data\nPerforming selections & analyses\nExporting & Saving a map\nFor more information, check out the QGIS Documentation.\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\nRES.STR-001 Geographic Information System (GIS) Tutorial\nIAP 2022\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms"
        },
        {
          "category": "Resource",
          "title": "GIS Level 1 QGIS Workshop Exercises (DOCX)",
          "type": "DOCX",
          "source_url": "https://ocw.mit.edu/courses/res-str-001-geographic-information-system-gis-tutorial-january-iap-2022/mitres_str001iap22_level1_qgis.docx",
          "content": "GIS Level 1: QGIS Workshop Exercises\n\nExercise 1\nOpen software\nOpen QGIS on your computer. Select the new Project icon.\n\nA blank map will now open. Click the Save icon to name and save your project.\nAdd data\nClick the top Layer Tab > Data Source Manager button.\n\nClick the Vector icon on the left.\n\nTo the right of the 'Vector Dataset(s)' box, click the ... icon. Navigate to the workshop folder and GIS_Level1_Data/workshop_exercises.\nHold Ctrl and select the .shp files for each of the following layers:\ncambridge_demographics.shp\nMBTA_ARC.shp\nMBTA_NODE.shp\nWhen done selecting > click Open > and then click Add > and follow the instructions below.\nA coordinate reference system window may appear because our project has a different coordinate system than our data layers. This tool will change the project coordinate reference system to that of the data layers so they appear less distorted on screen. We will discuss map projections more in GIS Level 2. You can select OK to close this window for now.\nNow we will add raster data. Click the raster icon on the far left-hand side of the Data Source Manager window.\n\nClick the ... icon to the right of the Raster dataset(s) box and select cambridge_dem.tif from the data folder.\nClick Add and then close the window.\nNote: if you accidentally added duplicate layers you can right click them and select to remove.\nMake sure the Quick map plugin is installed by clicking Plugins > Manage and Install Plugins > and searching for QuickMapServices. Click the Install Plugin button. (This button will only be visible if the plugin is not installed.) Close the plugin window.\nAdd a basemap by clicking Web > QuickMapServices > OSM > OSM Standard.\nReview the interface & organize data\nThe center of the screen displays any data that we added.\nThe names of data layers are shown in the Layers pane on the left.\nMove around the map using the pan and zoom buttons in the top menu bar.\nRight click on any layer and select Zoom to Layer to center it on the screen\nTurn layers on and off by checking/unchecking the box next to each name.\n\nDrag the layers up or down in the Layers box so that they do not cover each other.\nThe menus at the top of the screen show various tools you can use to analyze vector or raster data. New menus may appear when you load additional plugins using the Plugins menu.\nIdentify types of data & explore attributes\nLook at the data layers in the Layers pane. Are they vector or raster data? If they are vector, are they point, line or polygon?\nTo see the underlying data table for a layer, right click and select Open Attribute Table.\nWhat columns are included with the MBTA_ARC data?\nIs there an attribute table for cambridge_dem? Why might that be?\nCreating geographic data from tabular data\nThe cambridge_restaurants data layer is currently not in a shapefile format so it was not added to the map, however we can convert it from a .csv to point data by plotting the coordinates included in the table.\nOpen the Layer > Data Source Manager again and select the Delimited Text tab.\n\nNext to File Name > click the ... menu and navigate to the .csv in the data folder.\nIn the Geometry Definition section (click the arrow to extend the dropdown) select Point coordinates with the X Field as Longitude and the Y field as Latitude.\nIn the same section, for Geometry CRS, select EPSG:4326 - WGS 84 from the dropdown menu. If you don't see it listed, click the Select CRS button next to the dropdown menu to search for it.\nClick Add and Close. Now see where the cambridge_restaurants show up as points.\nSave your project and keep it open.\n\nExercise 2\nData can be symbolized in a variety of ways, depending on the data format and available attributes.\nChange a single symbol\nDouble click on the cambridge_restaurants layer in the Layers pane.\nClick the Symbology tab.\nClick on the text, Simple marker. Down below, choose a symbol to represent the restaurants. You can make additional modifications to the symbol using the various dropdown menus.\nClick Ok and close the Properties window when you are finished.\nSymbolize categories\nNow change the color of the mbta lines (MBTA_ARC) so they correspond to the correct color.\nRight click on MBTA_ARC and select Properties. Select the Symbology tab.\nFrom the dropdown menu at the top, choose the styling to be Categorized, which means that each value will be assigned a unique color, pattern, etc.\nLook at the metadata (https://www.mass.gov/info-details/massgis-data-mbta-rapid-transit) to determine which column contains information about the name of the rapid transit line. Choose the appropriate column from the dropdown menu in the Value box.\nClick the Classify button, at the bottom, to add all unique values found in the LINE column.\nDouble click on the line symbol in the Symbol column to select an appropriate color.\nClick OK when you are finished.\nMake a choropleth map\nDouble click the cambridge_demographics layer and select the Symbology menu.\nSelect Graduated from the dropdown menu at the top to create a choropleth map.\nOpen the metadata for this layer outside of QGIS. It is in workshop_exercise data folder and called cambridge_demographics_variable_names.txt.\nChoose which data you would like to symbolize and choose the corresponding column from the Value dropdown menu.\nClick the Classify button at the bottom of the window. Experiment with different break methods, classes, and color schemes from the dropdown menus until you are happy with your map.\nUse the precision dropdown menu to alter the number of decimal places if needed. Click Ok when you are finished.\n\nSymbolize a raster\nDouble click on cambridge_dem and select the Symbology tab.\nNotice that there are different options for symbolizing raster data versus vector data.\nThe data are currently symbolized as Singleband gray, which assigns a continuous color scheme from the minimum to the maximum value of each raster cell.\nAnother option that could be appropriate for this data is Singleband pseudocolor, in which data value are grouped into classes, similar to when creating a choropleth map. Choose a color ramp to see the options for this rendering. Note: Paletted/Unique values would be the most appropriate for values that each represent a different data category, such as land use.\nExperiment with the symbolization. When you are happy with your raster click OK.\nSee the take home exercise to learn how to create a layout for printing or how to export your map.\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\nRES.STR-001 Geographic Information System (GIS) Tutorial\nIAP 2022\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms"
        },
        {
          "category": "Resource",
          "title": "GIS Level 2 ArcGIS Pro Take-Home Exercises (DOCX)",
          "type": "DOCX",
          "source_url": "https://ocw.mit.edu/courses/res-str-001-geographic-information-system-gis-tutorial-january-iap-2022/mitres_str001iap22_level2_arcgispro_takehome.docx",
          "content": "GIS Level 2\nIn the Introduction to GIS workshop we filtered data and visually examined it to determine where to potentially build a new mixed-use facility. In order to get a low interest loan, the building needs to be located in an area with high unemployment. You also want to consider access to public transportation (for people who may be living at the building and commuting to the city or commuting to the building for work) and the terrain of the area.\nIn this exercise we will learn how to use the analysis tools in ArcGIS Pro with vector and raster data to further examine potential building sites.\nUse Spatial Autocorrelation to Determine Areas of High Unemployment\nChange a projection\nBecause spatial autocorrelation uses distance among features as part of the calculation, we will first convert the census data from a geographic coordinate system to one that is projected.\nOpen ArcGIS Pro and select the Map option and create a new project.\nClick the Map tab and use the Add Data button to add Hudson_tracts_unemp_2017 (the unemployment rate by census tract) from the folder Data\\Final Exercise.\n\nRight click on the name of the data layer and select Properties > Source > Spatial Reference. We can see that the coordinate system is NAD 1983 and the unit is a Degree so we'll want to change this to a projected coordinate system that uses a linear unit like meters.\nOpen the Geoprocessing pane if it is not already open (View > Geoprocessing).\nSearch for the project tool. Click the Project tool that is part of the Data Management Tools.\nComplete the information specified below.\nInput: Hudson_tracts_unemp_2017\nOutput: Save the output dataset to your working folder.\nOutput Coordinate System: Click the button to the right of the text box and search for 'new jersey' as shown.\n\nWe could choose from any number of map projections. Expand the folders: Projected Coordinate Systems > State Plane > NAD 1983 (US Feet). Select the NAD 1983 StatePlane New Jersey FIPS 2900 (US Feet) projection. Since it is specific for New Jersey, distance will be fairly accurate in this area.\nClick OK to close the Coordinate System box and then Run. The new data layer should be automatically added to your map. It will look identical to the old layer but have a different internal projection. ArcMap automatically aligns data with different projections.\nRemove the original data layer.\nSpatial Autocorrelation\nSpatial Autocorrelation is a statistical technique that identifies clusters of low or high values by comparing the value of each feature to that of its neighbors.\nClick the back arrow to return to the Geoprocessing search box. Search for the Cluster and Outlier Analysis tool. Open it.\nFill in the information as below:\nInput: projected unemployment data layer\nInput Field: Unemp_rate\nOutput: working folder\nConceptualization: Inverse Distance (assumes that closer features are more influential than ones further away)\nDistance method: Euclidean\nStandardization: Row\nClick Run.\nAfter you run the tool you should see results similar to these. You may also see a warning that tells you the distance used to define neighborhoods. To make the map look less distorted, right click on Map in the Contents pane and select Properties > Coordinate Systems. Scroll up and expand Layers and select the NJ state plane coordinate system. Click Ok.\n\nLook at the legend in the Contents pane.\nWhere is there statistically significant clustering of high unemployment? Low unemployment?\nIs this what you expect based on the original data? You can change the symbology in the Properties menu of this layer to visualize the unemployment rate.\nSave your project using the save icon in the upper left.\nBased on this information, where might you build?\n_______________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________\nExamine proximity to transportation\n\nMake a Multiple Ring Buffer\nIn this part of the exercise, you will be looking at proximity to the PATH station on the line that runs to the World Trade Center in Manhattan.\nTurn off all the data layers.\nAdd the following data layers from Data\\Final Exercise:\nPathStation\nStreets\nNotice the point that shows where the PATH station is. Feel free to change the color or make it larger so it is easier to see. The street network is also on the map.\nSearch for and open the Multiple Ring Buffer tool in the Geoprocessing pane.\nEnter the information specified below. Notice the 5280, 10560, 15840, and 21120 values are 1, 2, 3, and 4 miles as the path station is projected in a New Jersey State Plane projection in feet. Click Run.\n\nClick on the new layer to highlight it in the Contents pane once it is added to the map. Click the Appearance tab at the top of the screen and move the transparency slider in the Effects group to about 50%.\nApproximately how much of Jersey City are within 1 miles of the station? 3 miles? Is this an accurate representation of distance from the Path Station?\nTurn off the street data to better see what is within each of the distance rings.\nYou can use the Network Analyst tools in ArcGIS Pro to create buffers (called service areas) based on a road or other networks to increase the accuracy of your estimates. This tools will take into account the roads you will need to travel on to get from one place to another. To save time we won't do that as part of this exercise, but you can learn more here:\nhttps://pro.arcgis.com/en/pro-app/tool-reference/ready-to-use/itemdesc-generate-service-areas.htm\nhttps://pro.arcgis.com/en/pro-app/help/analysis/networks/service-area-tutorial.htm\nWe previously created a service are for you. Add the network_buffer data layer to your map.\nTo show the different service area distances, we'll change the symbology. Right click on the network_buffer layer name and select Symbology.\nChoose Unique Values from the dropdown menu.\nIn the Field 1 drop down menu, select ToBreak, which indicates the furthest distance covered by the service area.\nClick the Color scheme drop down menu and select a color scheme.\nHow do the buffer and service area differ? If you wanted this new building to be close to the train station, where might you choose to build?\n__________________________________________________________________________________________________________________________________________________________________________\nExamine Terrain\nAdd Raster Data\nYou have now explored some of the tools available for analysis of vector data. Now let's explore what can be done with different types of the raster data.\n\nThis section will use elevation data which is developed from satellite imagery. If you are interested in learning more about satellite imagery and image processing see the Introduction to Satellite Remote Sensing Workshop.\n\nProject Raster\nBefore performing analyses it's always a good idea to make sure the data is in a projected coordinate system if it may be necessary to use the tools.\nAdd Elevation from the Final Exercise folder. It may take a minute to load. Elevation represents elevation from the ASTER sensor aboard the Terra satellite. Turn off any data layers that you do not need.\nGo back to the Geoprocessing search pane and find the tool \"Project Raster\".\nUse the Elevation layer as your Input Raster.\nSave the output raster to your working folder using an intuitive name. In many cases rasters need names that are 13 characters or less when working in Pro.\nFrom the Output Coordinate System dropdown menu, select the projected unemployment data to convert the raster to the same projection. Click Run.\nRemove the old elevation data from the map.\n\nExtract by Mask (aka clip raster)\nBackground Information:\nWhoever named this tool, decided against \"clip for raster\" which arguably would have been more intuitive to the majority of people. Alas, the name \"extract by mask\" while less intuitive, draws upon image processing terminology and also hints at an interesting underlying process taking place. As you would have learned in Introduction to GIS, vectors and rasters have some key differences. Vectors have defined coordinate boundaries, while rasters use cell values in a grid of rows and columns. When you clip a vector, you are in a way moving the coordinates to new locations. However, when you try to clip a raster it must remain as a rectangular grid. To have it appear as though you have \"clipped\" out certain sections, \"extract by mask\" replaces pixels/cells that fall outside the boundary used (aka \"mask\") with NoData values, visualized using NoColor and therefore making the raster appear clipped. To check that this is the case after running the tool, click on a pixel and see its values.\nRight click the projected elevation raster and select Zoom to Layer to see its full extent. As you can see, satellite imagery is often provided at large scales, which can be reduced to be easier to work with.\nSearch for and open the \"Extract by Mask\" tool.\nWe will use the tracts as the mask, so input the following:\nInput raster: projected elevation raster\nInput raster or feature mask data: projected Hudson unemployment tracts\nOutput raster: Save your output raster to your folder using an intuitive name.\nClick Run. The resulting layer has been masked so that all pixels outside the tracts have no value and those inside are symbolized with a black and white color ramp stretched from the min to max values.\nCreate Contour Lines\nContour abstracts a digital elevation surface into lines representing different elevations. Lines can be easier to overlay on top of other datasets without covering them up as a raster surface would. They can also help clarify visual trends in a way that a surface can be difficult to observe.\nSearch for and open the Contour (Spatial Analyst) tool.\nUse the following inputs:\nInput raster: the clipped/masked elevation\nOutput feature class: Save with an appropriate name. (e.g. elev_contours_15ft)\nContour interval: Start with 15ft (the unit is based on the projection of the layer).\nClick Run.\nIf you want, try a few other values for your contours, remembering to save names appropriately.\n\nWhile you can build in any location, flatter areas may be easier to access for people who are walking. Also keep in mind that areas of low elevation that are close to water may be more prone to flooding. Looking at the original elevation data and contour lines, what areas may you want to build in?\n_______________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________\nSelect an area in which to build and add a point\n\nUsing all the information you gathered with the processing tools, select an area (or areas) that could be potential building sites. You will add a point (or points) to represent these areas.\nOpen the ArcCatalog pane (View > Catalog Pane).\nNavigate to your working folder in the Folders menu of ArcCatalog. If you don't see the folder, right click on Folders and select Add Folder Connection. Navigate to the main folder containing your output data.\nRight click on your work folder > New > Shapefile.\n\nFeature Class Name: Choose a name for your new shapefile.\nGeometry type: point.\nCoordinate System: From the dropdown choose the projected unemployment layer so that the coordinate system will be the same as the other layers in our map\nClick Run.\n\nThere are currently no features in the layer. Accordingly, the attribute table of your point layer is blank, with the exception of a few fields that ArcGIS adds by default and generates automatically for features. We're going to create features for this layer.\nClick on the new building layer in the Contents pane so it is selected.\nIn the Edit tab at the top of the screen, select the Create tool in the Features group.\nClick the building layer and select the Point tool.\n\nEach time you click on a location on the map, it will add a point.\nAdd your point(s).\n\nWhen you are finished, click the Finish button at the bottom of the map.\n\nClose the Create Features pane.\n\nAn actual building was built at 65 Bay Street. Add the data layer, \"Bay_street_building\" from the Final Exercise folder. Is there where you chose to build?\nThere are a lot of factors we did not consider, such as available lots, cost of building, etc., which went into choosing the Bay street building site. However, it was also deemed an area of high unemployment by selectively showing data from nearby census tracts. You can read more here.\nResources for learning more\nSpatial Statistics: https://pro.arcgis.com/en/pro-app/tool-reference/spatial-statistics/an-overview-of-the-spatial-statistics-toolbox.htm\nNetwork Analyst: https://pro.arcgis.com/en/pro-app/tool-reference/network-analyst/an-overview-of-the-network-analyst-toolbox.htm\nSpatial Analyst: https://pro.arcgis.com/en/pro-app/tool-reference/spatial-analyst/an-overview-of-the-spatial-analyst-toolbox.htm\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\n\nRES.STR-001 Geographic Information System (GIS) Tutorial\nIAP 2022\n\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms"
        },
        {
          "category": "Resource",
          "title": "GIS Level 2 ArcGIS Pro Workshop Exercises (DOCX)",
          "type": "DOCX",
          "source_url": "https://ocw.mit.edu/courses/res-str-001-geographic-information-system-gis-tutorial-january-iap-2022/mitres_str001iap22_level2_arcgispro.docx",
          "content": "GIS Level 2: ArcGIS Pro Workshop Exercises\nExercise 1: Map projections\nMap projections, also called Coordinate Reference Systems (CRS) can be viewed or changed using GIS software.\nExamine the data in GIS_Level2_Data\\workshop_exercise. Is there a projection file for each dataset?\nNote that cambridge_dem is a raster dataset and uses a .tfw file (known as a \"world\" file), which contains the information needed to transform image coordinates to real-world coordinates. Shapefiles use a .prj file, which includes the coordinate system information.\nOpen ArcPro. Click the Map option under Blank Templates and save it to your working folder.\nAdd the following two data layers from GIS_Level2_Data\\workshop_exercise\nMBTAbusroutes\nCambridgePlaygrounds\nRight click on CambridgePlaygrounds and select Zoom to Layer.\nDo the playgrounds and bus routes seem to be in the correct locations?\nThey should be since both layers had a defined projection (.prj) file.\n\nRight click on CambridgePlaygrounds and select Properties.\nSelect the Source tab and expand Spatial Reference.\nWhat is the coordinate reference system?\nThere are two, a projected coordinate system of NAD83 / Massachusetts Mainland (ftUS) and a geographic coordinate system of NAD 1983.\n\nDo the same for the MBTAbusroutes data layer. What is the coordinate reference system?\nClose the Properties box and select the Analysis tab and Tools.\nSearch for Project and open Project (Data Management Tools).\nWe will use the Project tool to change the projection of the playgrounds so that it is the same as that of the bus routes. There is also a tool called Define Projection that is used to assign a projection to a data layer that does not already have one or has one that is incorrect. Our map projections appear to be correct so we do not need to use this tool.\n\nAlthough not always required, your analysis results may be more accurate if your data layers are in the same projection. If you want to calculate the proximity of playgrounds to bus routes, you would first want to make sure the projections of both data layers are the same.\n\nChoose playgrounds as the Input Dataset.\nSave your output dataset in your working folder.\nClick the Output Coordinate System dropdown menu and select MBTAbusroutes. ArcGIS Pro will automatically fill in the coordinate system of NAD_1983_StatePlane_Massachusetts_Mainland_FIPS_2001.\nClick Run.\n\nAdd the data layer to your map if it was not added automatically.\nExercise 2: Access basic analysis tools\nTools can be accessed in a variety of ways in ArcGIS Pro:\nA subset of tools are located on the Analysis tab.\nSome tools are available by right clicking a layer.\nClick (Analysis > Toolbox) or (View > Geoprocessing) to see all available tools. You can search for a tool by name or click the Toolboxes tab and open a specific toolbox. This is a good way to see the different types of tools available to you.\nAdd MBTA_NODE to the map from GIS_Level2_Data\\workshop_exercise.\n\nClick View > Geoprocessing and search for the buffer tool.\nOpen Buffer (Analysis Tools).\nHow do you know what each input and parameter should be or if you need it? Try clicking the question mark to learn more about this tool and its parameters.\nSelect the MBTA_NODE as your Input Features from the dropdown menu. Choose a location to save your buffers in the Output Feature Class box.\nEnter a Distance of 1000 meters and Run the tool.\nTurn off your buffers after you have looked at the layer.\nThe interface for all tools looks similar in ArcGIS Pro, with most requiring input data, an output location, required parameters, and optional parameters.\nExercise 3: Use raster tools\nDifferent tools can be used with raster data versus vector data, although the output could be a vector, raster, or table, depending on the tools. There are also tools that allow you to convert from one data type to another.\nAdd the cambridge_dem.tif to your map. It may take a minute to load.\nWe will start by changing the symbology so it is easier to see, which you may remember from GIS Level 1.\nRight click on the cambridge_dem and select Symbology.\nChange the Primary Symbology dropdown to Stretch.\nClose the Symbology window when you are finished.\nOpen the Geoprocessing window if it is not already. Search for contour. Open Contour (Spatial Analyst Tools).\nSelect the dem as your Input raster and choose an output location.\nType 5 for the Contour interval. What are the units of this interval? How might you figure it out?\nClick Run.\n\nYou will notice that the output is a vector line layer, which could then be exported to other programs or used as input for vector analysis tools.\nExercise 4: Use the spatial statistics toolbox\nAs mentioned above, toolboxes can be a good way to learn about the variety of tools available to you and to also find tools that are similar to others.\nAdd the file median_income_suffolk_ma to the map.\nClick View > Geoprocessing to open the Geoprocessing window.\nClick the Toolboxes tab and expand Spatial Statistics Tools > Mapping Clusters. Open Cluster and Outlier Analysis (Anselin Local Moran's I).\nChoose median_income as the Input Feature Class. Use VALUE0 as the Input Field, which is the median income value. See the text file in the workshop_exercise folder for the attribute field information.\nChoose an output name and location.\nLeave the default values for now. In the future you have the option of changing the parameters to define neighborhoods in different ways. Run the tool.\nAt the bottom of the tool window, a box indicates that the tool ran with warning. Click the View Details link to read more about this. The warning indicates that the tool used a value of 2266 meters to define the neighborhood, which is determined to be optimal for our data based on the inverse distance relationship. Close the Detail window.\nWhere are there clusters of high and low income? The tool has also output a histogram and scatterplot that you can examine by double clicking on them. Turn off the income data layers when you are finished examining them.\nThe Moran scatter plot provides a classification of spatial association into four categories, corresponding to the location of the points in the four quadrants of the plot. These categories are referred to as High-High, Low-Low, Low-High and High-Low, relative to the mean, which is the center of the graph.\nYou can learn more about the statistics used in the Moran's I calculation here:\nhttps://pro.arcgis.com/en/pro-app/tool-reference/spatial-statistics/h-how-cluster-and-outlier-analysis-anselin-local-m.htm\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\n\nRES.STR-001 Geographic Information System (GIS) Tutorial\nIAP 2022\n\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms"
        },
        {
          "category": "Resource",
          "title": "GIS Level 2 Instructions (DOCX)",
          "type": "DOCX",
          "source_url": "https://ocw.mit.edu/courses/res-str-001-geographic-information-system-gis-tutorial-january-iap-2022/mitres_str001iap22_level2_instructions.docx",
          "content": "GIS Level 2 Setup Instructions\n\nThank you for registering for GIS Level 2. Before the workshop, please do the following:\nDownload and install either ArcGIS Pro or QGIS & Geoda\nInstall 7-zip if necessary.\nDownload all workshop materials.\nUpdate and setup Zoom. (Your version of Zoom MUST be up-to-date in order to use the breakout rooms effectively.)\nDownload and install ArcGIS Pro or QGIS & Geoda\nQGIS is a free, open source software program that will work on any operating system and doesn't take up much space on your computer. While it has many of the same capabilities as ArcGIS Pro, there are some analyses you can't do in QGIS and it tends to have more bugs. QGIS has limited tools for spatial statistical analysis, so you can use another free, open source program, Geoda, along with it.\nArcGIS Pro is a commercial software from ESRI that we have a subscription for at MIT. It only runs on Windows and requires an account or a connection to the MIT license server to run. It includes a full suite of GIS tools, but may not run well if you have a slower computer.\nIf you are not sure which software to use, this website has a lot of additional information: https://gisgeography.com/qgis-arcgis-differences/\nNote: This workshop will NOT use ArcGIS Desktop/ArcMap, only ArcGIS Pro, the newest GIS software from ESRI.\nArcGIS Pro installation\n1. Create an ArcGIS Online (AGOL) account: https://libguides.mit.edu/gis/webmap#s-lg-box-wrapper-5115587\n2. If you have not already downloaded Pro, log into your AGOL account. From your account page, click your name in the upper right and select My settings > Licenses and click download next to ArcGIS Pro.\n3. After installing Pro, choose the Named User License type and select ArcGIS Online. You'll then see the same login screen that you used to create your account.\nQGIS Installation\nFull instructions and links for installing QGIS for a number of different operating systems can be found here: http://qgis.org/en/site/forusers/download.html\nDownload the most recent version of the software. Windows users should download the Standalone option. If you already have QGIS installed, we have tested the workshop exercises with versions 3.16 and higher so we recommend upgrading if you are using an older version.\nGeoda Installation (install if using QGIS for the workshop)\nDownload links for a variety of operating systems are listed here:\nhttps://geodacenter.github.io/download.html\n7-zip installation\nWorkshop files (and most GIS data) are in zipped folders. Most Windows computers have the option to extract data by right clicking and most Macs will automatically extract data. Occasionally your computer may not have a built-in data extraction tool. In this case we recommend installing 7-zip: https://www.7-zip.org/\nWorkshop materials\nDownload all workshop materials.\nMaterials include the presentation, workshop exercises, take-home exercise, and all required data.\nZoom setup\nMake sure your Zoom app is up-to-date using these instructions: https://support.zoom.us/hc/en-us/articles/201362233-Upgrade-update-to-the-latest-version\nIf you have access to a second monitor (or a second \"smart\" device that can connect to a Zoom session) it may greatly improve your workshop experience and make it easier to follow the instructor and complete the exercises simultaneously. If not, it is still doable, for example, by organizing your screen in this way: https://raw.githubusercontent.com/hbctraining/bioinformatics_online/master/guidelines/img/Screenshot%202020-03-23%2015.21.10.png\nWe encourage participation during the session and kindly ask you to use your video, if possible.\nMute audio except when talking (Tip: you can temporarily unmute yourself by pressing and holding a space bar. When it is released, Zoom goes back to the mute mode).\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\n\nRES.STR-001 Geographic Information System (GIS) Tutorial\nIAP 2022\n\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms"
        },
        {
          "category": "Resource",
          "title": "GIS Level 1 Presentation Slides (PDF)",
          "type": "PDF",
          "source_url": "https://ocw.mit.edu/courses/res-str-001-geographic-information-system-gis-tutorial-january-iap-2022/mitres_str001iap22_level1_pres.pdf",
          "content": "GIS Level 1: Introduction\nto GIS & Mapping\nCourtesy of US Air Force. Image is in the public domain.\n\nOutline\n- Introduction - What is GIS?\n- Software options\n- Applications\n- Understanding Maps & Data\n- Data Layers\n- Spatial Data Types\n- Characteristics of Spatial Data\n- Metadata\n- Making Great Maps - Data Visualization Principles\n\nINTRODUCTION\n\nGeographic Information System\n\"A system for\ncapturing, storing, checking, integrating,\nmanipulating, analyzing and displaying\nspatial data\"\n\nGeographic Information System\n\"A system for\ncapturing, storing, checking, integrating,\nmanipulating, analyzing and displaying\nspatial data\"\n\nInput: spatial data\nGIS/Mapping Software:\nanalysis and data\nvisualization\nDoes not\ncome with its\nown data\nOutput: new data and maps\n\nas digitized themed data \"layers\"\n(e.g. boundaries, socioeconomic, hydrology,\ninfrastructure, transportation, land use/cover)\nassembled in any combination\nand overlaid for analysis\nTheoretical Overview\nGIS recreates real world spatial data\nImage (c) source unknown. All rights reserved. This content is\nexcluded from our Creative Commons license. For more\ninformation, see https://ocw.mit.edu/help/faq-fair-use/\n\nassembled in any combination\nand overlaid for analysis\nTheoretical Overview\nGIS recreates real world spatial data\nas digitized themed data \"layers\"\n(e.g. locations, boundaries, infrastructure,\nsocioeconomic hydrology, land use/cover)\nImage (c) source unknown. All rights reserved. This content is\nexcluded from our Creative Commons license. For more\ninformation, see https://ocw.mit.edu/help/faq-fair-use/\n\nand overlaid for analysis\nTheoretical Overview\nGIS recreates real world spatial data\nas digitized themed data \"layers\"\n(e.g. locations, boundaries, infrastructure,\nsocioeconomic hydrology, land use/cover)\nassembled in any combination\nImage (c) source unknown. All rights reserved. This content is\nexcluded from our Creative Commons license. For more\ninformation, see https://ocw.mit.edu/help/faq-fair-use/\n\nTheoretical Overview\nGIS recreates real world spatial data\nas digitized themed data \"layers\"\n(e.g. locations, boundaries, infrastructure,\nsocioeconomic hydrology, land use/cover)\nassembled in any combination\nand overlaid for analysis\nImage (c) source unknown. All rights reserved. This content is\nexcluded from our Creative Commons license. For more\ninformation, see https://ocw.mit.edu/help/faq-fair-use/\n\nSOFTWARE\n\nTypes of GIS & Mapping Software\nType\nAnalysis Power\nExample(s)\nGeobrowser\nWeak\n(mainly only to display data)\nGoogle Maps, Google Earth,\nApple Maps, Waze, etc.\nWeb-based\nDesktop\nMedium\n(able to upload additional\ndata, customize display, and\nperform basic analyses)\nStrong\n(installed locally, provides full\ncontrol of map creation, and\nperform advanced analyses)\nCarto, ArcGIS Online, Mapbox,\nGoogle MyMaps, etc.\nArcGIS Pro\nQGIS\n\nWhich desktop software should you use today?\nArcGIS Pro (by ESRI)\n-\nCommercial software (expensive\nto purchase)\n-\nOnly runs on Windows\n-\nLarger program - can run slowly\non some computers\n-\nFull set of GIS functions and tools\n-\nIntegration with ArcGIS Online\n-\nFully developed training program\n(online modules, written\ntutorials, MOOCs)\n-\nComprehensive support (direct\nsupport from ESRI,\ndocumentation for every tool)\nQGIS\n-\nFree, open-source tool\n-\nRuns on any operating system\n-\nSmaller program that will not\naffect performance of your\ncomputer\n-\nMany available tools, but lacking\nsome for specific functions, such\nas network analysis (i.e. routing)\nand spatial statistics\n-\nBasic tutorials by QGIS developers\nand users\n-\nTools can be developed by anyone\nso performance and\ndocumentation is inconsistent.\n-\nSupport via forums\n\nGIS APPLICATIONS\n\nView Imagery\nCity of Cambridge Aerial Photograph, April 2010\nCheck out our workshops\non Remote Sensing &\nImagery\nImage (c) source unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see https://ocw.mit.edu/help/faq-fair-use/\n\nCreate 3D models\nWe have additional\n3D software: AutoCAD,\nRhino, PhotoScan, etc.\n\nCreate Maps\nCourtesy of US Census. Image is in the public domain.\nMaps\ncombine\nart & science\n\nConduct Analyses\nAnalyze values\n(Spatial Statistics)\nCreate data\n(Buffer tool)\nEdit geometry\n(Clip tool)\nLearn these tools and more\nin our GIS Level 2 workshop\nCrime hotspots (c) Scott & Warmerdam. All rights reserved. This content is excluded from our\nCreative Commons license. For more information, see https://ocw.mit.edu/help/faq-fair-use/\n\nUNDERSTANDING MAPS & DATA\nYou may have been looking at geospatial data for a long time\n\nUnderstanding data 'layers'\nWhat individual data layers were used to create this map?\n(c) Google. All rights reserved. This content is excluded from our Creative Commons license. For more information, see\nhttps://ocw.mit.edu/help/faq-fair-use/\n\nUnderstanding data 'layers'\nWhat individual data layers were used to create this map?\nStreet network\nParks and other open space\nT stops with label\nBodies of water\nPoints of\ninterest\nGoogle maps is\na 'Geobrowser'\n(c) Google. All rights reserved. This content is excluded from our Creative Commons license. For more\ninformation, see https://ocw.mit.edu/help/faq-fair-use/\n\nMAPS & DATA:\nSPATIAL DATA TYPES\n\nGeospatial Data Types\nGeospatial or coordinate data can\nbe represented in two different\ndata formats:\nVector:\ne.g. points, lines, and polygons\nRaster:\ne.g. row and column matrix\nImages (c) University of Washington. All rights reserved.\nThis content is excluded from our Creative Commons\nlicense. For more information, see\nhttps://ocw.mit.edu/help/faq-fair-use/\n\nData Types: Vector versus Raster\nVectors are composed of\ncoordinates\nRaster's are composed of pixels\nThese are often used for variables with:\ndefined borders, e.g. manmade continuous surface, e.g. environmental\nImage courtesy of Zina Yonten. Used under CC BY-NC.\n\nData Types: Vector examples\nPoints\nLines\nPolygons\n(Combined)\n\nData Types: Vector mapping\nVectors have a frontend geometry\n- In this example the geometry\nrepresents state polygons\n\n- Here each row (stat\nsymbolized by 'NA\n(categorical variabl\nVectors have a backend database,\nnormally called an 'attribute table'\n- rows represent\nunique geometries\n(e.g. state polygons)\n- columns represent\na number of variables\n(theoretically infinite)\ne) is\nME'\ne)\nData Types: Vector mapping\n\nData Types: Vector mapping\n- Here each state is\nbeing symbolized by\n'NAME'\n(qualitative variable)\nVectors have a backend database,\nnormally called an 'attribute table'\n\nVectors have a backend database,\nnormally called an 'attribute table'\nData Types: Vector mapping\n- Here each state is\nbeing symbolized by\n'POP_PER_SQMI'\n(quantitative variable)\n\nData Types: Vector file formats\n- The shapefile is the most common vector file\nformat.\n- \"A\" shapefile is actually a collection of several\ndifferent files with different extensions.\nMake sure to keep all\nfiles together when\nmoving.\nShapefile =\n.shp .shx\n.sbx\n.dbf\n.prj\nWhen adding files to\nArcGIS Pro, you will\nonly see one file, not\nevery extension.\n\nData Types: Raster\nRaster data includes aerial photographs, digital\nelevation models, and scanned maps.\n(Remember these are constructed from pixels)\n\nRaster data have a frontend cell matrix\n- Where each cell has its own value\n- A raster can only symbolize one\nvariable at a time\nData Types: Raster mapping\n\nData Types: Raster mapping\nRaster data have a frontend cell matrix\n- Here each cell/pixel is being\nsymbolized by elevation value\n\nData Types: Raster mapping\nRaster data have a backend database,\nnormally called an 'attribute table'\n- rows represent unique values\n(1m, 2m, 3m, etc.)\n- columns have\nspecific variables\n1) unique 'ROW ID'\n2) unique 'VALUE'\n3) 'COUNT' of pixels\nwith that 'VALUE'\n\nData Types: Raster file formats\nThere are many different raster file extensions,\nincluding common image formats.\n.tiff\n.asc\n.img\n.jpg\nLearn more about raster\nSome formats may include a\nformats in this ArcGIS Pro\ncollection of files with different\ndocumentation. QGIS supports\nextensions, similar to a\nsimilar formats.\nshapefile.\n\nData Types: Tabular\nTabular data can be transformed\ninto spatial data in two ways:\n1. Joining\n- Use a shared unique identifier (GEOID, name, etc.) to\nmatch up tabular data to the spatial data's attribute table.\n2. Geocoding\n- Use lat/lon coordinates in table to plot as points on map\n- Use addresses to plot locations based on a street network\n\nData Types: Tabular file formats\nGIS software can read commonly used tabular formats in\norder to transform them into spatial data.\n.csv\n.xlsx\n.dbf\nShapefiles include a\n.dbf, which is a\ntabular format that\ncan be opened in\nQGIS cannot read Excel file\nother software, like\nformats.\nExcel.\n\nGeodatabases\n- ESRI/ArcGIS storage system\n- a collection of geographic datasets of\nvarious types held in a common file\nsystem folder\n- Advantages: larger files size limits,\nfaster processing time when using\nanalysis tools\n- Disadvantages: can only be opened\nin ESRI software\n- Learn more about using\ngeodatabases in Pro.\n\nOther data formats\nGIS can import and convert data produced in other formats:\n- KML / KMZ files (Google Earth)\n- DXF / DWG (CAD)\n- NetCDF (scientific data)\n- LAS (Lidar)\n- GPX (GPS units)\n- Geojson\nGIS software can export many formats:\n- Adobe Illustrator\n- KML\n- CAD\n- TIF\nmany types of data\nvisualization software.\n- JPG\nThe GIS & Data Lab has\n\nCommon Associated Workflows\nSatellite\nRemote Sensing\n3D Modeling &\nPhotogrammetry\nGIS\n- Processed imagery as rasters or vectors\n(e.g. enhancements, classifications)\n- Raw Imagery for basemaps\n- Processed imagery as rasters or models\n(e.g. orthophotos, DEMS, 3D models)\nStatistical\nAnalysis\n- Attribute tables for running analyses,\n(e.g. regressions, predictions)\nVisual Design\n(e.g. Illustrator)\n- Maps for improved design aesthetics\n\nExercise 1\n- Goals:\n- Become familiar with the GIS interface\n- Learn how to add data\n- Explore data types & attributes\n- Complete either the QGIS or ArcGIS Pro\nexercise from your workshop folder.\n\nMAPS & DATA:\nCHARACTERISTICS OF SPATIAL DATA\n\nGeneralization\n- The most detailed data available - e.g. resolution of coastline data\nis not suitable for all purposes\nfor this map is scale dependent\n(or often a manageable file size)\n- Red: county map\n- Blue: town map\n\nAbstraction\nThe process of reducing data from its complete state to\nwhat is necessary for use and presentation\n\nQuiz: Which data symbology (pictured above)\nwould you select for each of the following maps?\n- Land use study of adjacent property\n- Development map of the airport\n- National map of airports\n\nSpatial Resolution/Scale\nSuitable data geometry is dependent on scale:\ne.g. roads are polygons at local scale but lines at national scale\n(c) Google. All rights reserved. This content is excluded from our Creative Commons license. For more information, see\nhttps://ocw.mit.edu/help/faq-fair-use/\n\nTemporal Resolution\n1977 to 2006\nKeep in mind temporal resolution when obtaining data\n(c) Google. All rights reserved. This content is excluded from our Creative Commons license. For more information, see\nhttps://ocw.mit.edu/help/faq-fair-use/\n\nback to when starting\na project\nSearching for Spatial Data\n- Look in general GIS data repositories\n- Search the internet\n- Include \"gis\", or \"data\" in the search terms\n- Search by location and/or topic\n- Search for country statistical agencies or open data\nsites (large cities often have their own open data\nportals as well)\n- Contact GIS departments, universities, or researchers\nin your area of interest.\n- Search for articles on your topic and look for the\nsources of the data.\nGreat slide to refer\n\non our website.\nFind many more\nRepositories and Websites\nLibguides.mit.edu/gis\n- Can also find by googling 'MIT GIS', first result\n- Click on Find Data Tab for a list of resources, including\nan assembled links of common data sources per topic.\nGeodata.mit.edu (Geoweb)\n- Includes data licensed freely or restricted to MIT and\nother institutions, plus CDs and DVDs in the GIS lab.\n- MIT instance is mainly historical-local or purchased data.\nOpenStreetMap.org\n- Crowd-sourced maps; content will vary by location\n- Download as a shapefile via http://www.geofabrik.de/\n- Best source to start for rural international data.\n\nMAPS & DATA:\nMETADATA\n\nWhat is Metadata?\nUse metadata to learn\nhow and why the data\nwere created, access\nrestrictions, columns in\nthe attribute table, and\nmuch more!\n\nMetadata Examples\n1. MassGIS:\nhttps://www.mass.gov/info-details/massgis-data\nmarine-beaches\n2. GeoWeb: geodata.mit.edu/catalog/mit\nw37ehgh6nvl4w\n3. City of Boston:\nhttps://data.boston.gov/dataset/traffic\nsignals\n\nMAKING GREAT MAPS:\nDATA VISUALIZATION PRINCIPLES\n\nMaking Great Maps\n- Cartography is the art and science of making maps\n- Maps are always simplifications of reality, which makes\nthem helpful when making decisions or explaining patterns\n- Maps are designed by people (who have intentions),\nso we have to create them responsibly\n\nMaking Great Maps\nFrom: Making Maps: A Visual Guide to Map Design for GIS by John Krygier and Denis Wood\nExample of how a map can be used to prove many different points.\nHowever in the past only those in power had the software and data to do so.\nImages (c) John Krygier and Denis Wood. All rights reserved. This content is excluded from our Creative Commons license. For more\ninformation, see https://ocw.mit.edu/help/faq-fair-use/\n\nThree Key Questions\n1. Who wants the map?\n- e.g. experts (detailed), students (contextual), the community (interactive)\n2. Where will it be seen?\n- e.g. 8x11 paper (static small, room for main points)\n- e.g. 30x40 poster board (static large, room for detail)\n- e.g. web map (interactive, users control navigation of map)\n3. What is it's purpose?\n- e.g. to show a variable through time (time series)\n- e.g. to show change over time (change detection)\n- e.g. to combine multiple variable into an index to pick best/worst\n(sustainability/risk/vulnerability mapping, site selection)\nEach question deserves a well-thought answer before mapping\n\nFigure 5.3\nMap Design Process\nStart with assembling the\ndata from multiple sources\nNext choose the data,\nanalyses, & symbolization\nLastly insert the title, legend,\nnorth arrow, scale bar, & labels\n\nVector Symbolization\nFrom: Making Maps: A Visual Guide to Map Design for GIS by John Krygier and Denis Wood - makingmaps.owu.edu\nSee our tutorial for additional\nColorbrewer provides\naccessible color options.\n\"Cartography Tips\".\nImages (c) John Krygier and Denis Wood. All rights reserved. This content is excluded from our Creative Commons license. For more\ninformation, see https://ocw.mit.edu/help/faq-fair-use/\n\nRaster Symbolization\n\nChoosing Color Tips\nMatch the type of data to the type of color scheme:\n- Qualitative (categories)\n- Quantitative (numbers)\nImages (c) Morphocode. All rights reserved. This content is excluded from our Creative Commons license. For more information, see\nhttps://ocw.mit.edu/help/faq-fair-use/\n\nQualitative Color Example\nDoes this\nmake sense\nfor the data?\n(c) Pennsylvania State University. All rights reserved. This content is excluded from our Creative Commons license. For more information,\nsee https://ocw.mit.edu/help/faq-fair-use/\n\nSequential Color Example\nDoes this\nmake sense\nfor the data?\n(c) Pennsylvania State University. All rights reserved. This content is excluded from our Creative Commons license. For more information,\nsee https://ocw.mit.edu/help/faq-fair-use/\n\nDiverging Color Example\nDoes this\nmake sense\nfor the data?\n(c) Pennsylvania State University. All rights reserved. This content is excluded from our Creative Commons license. For more information,\nsee https://ocw.mit.edu/help/faq-fair-use/\n\nCommonly used map type: Choropleth\nThese use different shading and coloring to display\nthe quantity or value in defined areas.\n(c) Alyson Hurt and Katie Park/NPR.\nAll rights reserved. This content is\nexcluded from our Creative\nCommons license. For more\ninformation, see\nhttps://ocw.mit.edu/help/faq-fair-\nuse/\n\nChoropleth map choices\n1. Number of Classes\n- Aggregates data for display\n- More classes = more variation\n(best to have no more than 7)\n2. Classification Method\n- Data classification is how\ndata is arranged into\nseparate classes.\n- Major types\n- Equal Intervals\n- Quantile (Equal Count)\n- Natural Breaks\n- Defined Intervals\n\nClassification Methods\n- Equal Interval = classes have equal ranges\n- Quantile = classes have equal counts\n- Natural Breaks = optimizes class variation\n- Manual = you define classes\nNote: each has pros/cons to their usage,\nfor \"Choropleth Classification Methods\" use this link:\nhttps://libguides.mit.edu/gis/tutorials#s-lg-box\nwrapper-4119325\n\n2020 % population over 65\nNatural\nbreaks\nQuantile\nEqual\ninterval\n\nExercise 2\n- Goal:\n- Learn how to symbolize different types of data\n- Complete Exercise 2 for either QGIS or ArcGIS\nPro.\n\nMap Layout Design Example\nOverview:\n- Map layout design is about\ndeveloping a balanced arrangement\n- Maps, title, legend, scale bar, labels,\netc. all need relative positioning & sizing\n- Goal is to design the map layout to\nsupport your design questions\n- Who wants the map\n- Where will it be seen\n- What is its purpose\nFrom: Designing Better Maps: A Guide for GIS Users by Cynthia A. Brewer\nImage (c) Cynthia A. Brewer. All rights reserved. This content is excluded from our Creative Commons license. For more information,\nsee https://ocw.mit.edu/help/faq-fair-use/\n\nMap Layout Design Example\nTips:\n- Inset/locator maps are often placed in the\ntop/bottom corners (e.g. continent view\ntop left and zoomed view in bottom\nright).\n- Main map often placed in center (usually\nlargest & most detailed).\n- Legend is tucked into the main map for easy\ncomparison with the data.\n- Scale bars and north arrows shouldn't be a\ndistraction from the main map.\n- Sources should run along the bottom.\nFrom: Designing Better Maps: A Guide for GIS Users by Cynthia A. Brewer\nComplete the take-home\nImage (c) Cynthia A. Brewer. All rights reserved. This content is excluded\nexercise to learn more.\nfrom our Creative Commons license. For more information, see\nhttps://ocw.mit.edu/help/faq-fair-use/\n\nTAKE-HOME EXERCISE\n\nExercise Overview\nQuery and use unemployment and transportation\ndata to create a map that helps you decide where\nto build a mixed use facility.\n1. Navigate the software interface\n2. Find and add data, including basemaps\n3. Access and explore attribute information\n4. Symbolize data layers, for vector and raster\n5. Select data by attributes and spatial location\n6. Design a simple map for export\n\nBoburg, S. (2017, May 31). How Jared Kushner built a luxury skyscraper using loans meant for job-starved areas. Washington Post. Retrieved from\n(c) The Washington Post. All rights reserved. This content is excluded from our Creative Commons license. For more information, see\nhttps://ocw.mit.edu/help/faq-fair-use/\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\nRES.STR-001 Geographic Information System (GIS) Tutorial\nIAP 2022\nFor information about citing these materials or our Terms of Use, visit:\nhttps://ocw.mit.edu/terms"
        },
        {
          "category": "Resource",
          "title": "GIS Level 1 Presentation Slides with Notes (PDF)",
          "type": "PDF",
          "source_url": "https://ocw.mit.edu/courses/res-str-001-geographic-information-system-gis-tutorial-january-iap-2022/mitres_str001iap22_level1_presentation_notes.pdf",
          "content": "GIS stands for geographic information system but what does that really mean?\nA GIS system can do a lot of things.\n\nThe most important thing to know is that a GIS is a system works with spatial data.\n\nGIS software works upon the data you provide it.\nJust like other software, such as Excel or Word, you need to input data and can then\nuse the software to display and analyze that data.\n\nGIS software recreates or reproduces the real world as spatial data.\n\nMore specifically, the spatial data is broken down into themed data \"layers\" such as\nlocations, boundaries of various kinds, socioeconomic variables, hydrology, and land\nuse/cover.\n\nThese data layers can be assembled in any combination you want, depending on what\nyou want to highlight.\n\nPower of GIS is in the ability to detect trends and make quantified decisions that would\nhave otherwise been difficult just by hand or eye.\nOnce they have been overlaid in a particular combination, you can then conduct\nanalyses.\n\nThe software you choose depends on what you will be doing with the data (displaying it vs.\ncreating a new map vs. conducting analysis), the size of the data (large datasets require\nstorage), and your audience (is it best to present the map on paper? Online? Do people need to\ninteract with it?).\nThere are three types of software with very different capabilities.\n1. Geobrowsers like Google Maps and Apple Maps are generally only useful for displaying data.\n2. Web based tools like Carto, ArcGIS Online, and Mapbox, allow you to upload data, customize\ndisplays and perform basic analyses. Carto is licensed for MIT use and is free to use while you\nare at MIT but charges a fee otherwise. ArcGIS Online has both a free, public version and a paid\nversion with additional features that MIT affiliates can access.\n-Web-based software is the best way to add interactive elements. If you have programming\nskills you can use tools like Leaflet or OpenLayers to create online maps. Otherwise ArcGIS\nOnline is easy to use and customize. Find out more about getting and account:\nhttps://libguides.mit.edu/gis/webmap\nLearn more about using ArcGIS Online: https://doc.arcgis.com/en/arcgis-online/create-maps/\ncreate-maps-and-apps.htm\n3. Desktop software, which are installed locally, provide the fullest suite of GIS tools for basic\nand advanced analyses and map creation. You will get hands on experience for each type of GIS\nin this presentation series.\n\n- Arcgis Pro is a more complete set of GIS tools but is license software and you may\nnot have access to it beyond MIT. QGIS is free and open source but is a more limited\nset of GIS tools.\n- Along with the comprehensive support from Esri for Arcgis Pro, there is complete\ndocumentation for all ArcGIS Pro tools. In QGIS tools are made by many people with\nvarying resources. Because of this there performance and documentation across\ntools is inconsistent.\n- Arcgis Pro only runs on Windows while Qgis runs on Windows, Apple, and Linux\nmachines.\n- Both interfaces are similar so after you learn one software, it is fairly easy to use the\nother\n- For most uses, either software will work well so you may want to base your decision\non your computer's resources, how frequently you will need to use it, what you want\nto do, and the industry you plan to work in (or are currently working in). ESRI\nproducts are frequently used in educational settings, municipal governments, and\nlarge businesses and organizations. Because of cost considerations, QGIS may be\nused in small businesses and non-profits.\n\nNow let's discuss some applications you can do with a GIS.\n\nMany people use a GIS to look at satellite imagery or have it as a background to their\nmaps.\n-materials from our remote sensing workshops are on our guide: libguides.mit.edu\n\nYou can also make custom visualizations.\nIn this example, buildings in New York City have been color coded by land use and\nextruded vertically to represent height.\nIt is also possible to create animations over time and record videos flying through your\nmap in a GIS.\n\nMaps also are used to share information, where design plays an important (even\npersuasive) role.\nSee how the creator chose green for Irish ancestry, and a darker shade of green for\nhigher percentage\n\nGIS has many tools for acting upon datasets:\nSome tools act on the geometry (clip), create new data (buffer), or analyze the data\nvalues (spatial statistics).\n\nWe will explore maps and data is this section of the presentation.\n\nGoogle Maps is a type of GIS, really a web mapping tool or geobrowser, and its maps\nare created from multiple layers of spatial data. As shown previously, a layer is data\nabout a specific set of similar features, such as the location of schools or bicycle paths.\nQuestion: Take a moment to determine what distinct layers are in this map.\nPresenter should move on after a few responses come in.\n\nAnswers: street networks, parks/open spaces, water, T stops, points of interest, etc.\nNotes: data are organized by theme: infrastructure, hydrology, administrative\nboundaries, etc.\n-When you create your own maps you can choose which data layers to include and how\nto visualize them to create a custom map.\n\nThere are two main approaches to representing real world data, vector and raster.\nVector represents the world in points, lines, and polygons, while raster uses rows and\ncolumns.\n\nIn some cases data can be represented as either a vector or raster, but usually certain\ntypes of data are better suited for a certain method of representation.\nVectors are composed of coordinates and are best suited to manmade features with\ndefined locations and boundaries.\nRasters are composed of pixels and are best suited to variables, usually environmental,\nthat change over surfaces such as temperature, precipitation, or elevation.\nYou are able to switch between vector and raster format to use different tools, which\nyou can see in our GIS Level 2 workshop materials.\n\nHere you see an example of points, lines, polygons, and all three combined\nQuestion: Can anyone guess based on how these vector layers are color coded, also\nknown as symbolized, what these datasets may represent?\nAnswer: MBTA Stops, Lines, and Towns, where the lines have been symbolized by color\n\nGeographic data include both a frontend geometry, meaning what you see on the\nscreen in GIS software and a backend database.\nVector data's frontend geometry is composed of coordinates and displayed as points,\nlines and polygons. Here is a layer with polygon geometry.\n\nThe backend database is called an attribute table. Each row is equivalent to one feature\non the map. In this example each row represents a different state polygon.\nEach column is a different piece of information about that feature. In this example\nthere is information about the state name and the population per square mile.\nVector data can have a large number of columns associated with their geometries, each\nof which can then be symbolized to produce different maps.\n\nThe map can be symbolized based on any column in the attribute table, meaning the\ncolor, size, shape, pattern, etc. of a feature can be changed to correspond to the data in\na particular column.\nHere the map was color coded based on a qualitative (aka categorical) variable, state\nname, where each unique state name was symbolized by a different color.\n\nHere the map was color coded based on a quantitative (aka numerical) variable,\npopulation per square mile, where each class of values was symbolized by a different\ncolor. We will talk about classes in depth later in the presentation.\n\nA shapefile is a open source format for vector data that can be opened in any GIS\nsoftware.\nShapefiles are often in a zipped (.zip) folder because they include several different files.\nThis folder needs to be unzipped to use in ArcGIS Pro, but files can be imported directly\nfrom the .zip folder in QGIS.\nThe .shp includes the actual geometry of the data, the .dbf includes the attribute table,\nand the .prj contains the map projection, which is covered more in GIS Level 2. Other\nfiles include indexes that speed up the loading and display of the data. Keep these files\ntogether when you move or share data in order for them to load properly.\n\nHere you see examples of rasters, such as aeriel photographs, digital elevation models,\nand scanned maps. All of which are constructed from pixels.\nAdditional Notes:\nEarly maps were created from surveys and early digital geospatial data were \"digitized\"\nfrom these maps. Data are now created using GPS. Some data are created from aerial\nphotographs. Data are constantly being updated\n\nRaster data is a continuous cell matrix. Each cell or pixel is the same size and has its\nown value.\nRasters can only symbolize one variable at a time due to how its attribute table\nfunctions.\n\nHere the map is color coded based on a quantitative (aka numerical) variable,\nelevation, where each unique pixel value is symbolized by a shade of grey stretching\nfrom black to white.\n\nRaster data have attribute tables with specific properties: a unique id for each\ncell/pixel, the value of that cell, and the count of other cells with that same value.\nNote: the map is the same elevation data symbolized with a different color ramp.\n\nRaster file formats include common image formats and there are many more raster file\nformats that are not listed here.\nThere are often associated files that tell the GIS software where to place the raster on\nthe map, similar to how a .prj file works in a shapefile.\nIf you import an individual image, such as a .jpg of a scanned map, you will need to do\nwhat is called \"georeferencing\" and tell the software how to align it with the rest of\nyour data.\n\nYou can convert tabular data such as those in spreadsheets so long at the data contains\ncertain geospatial information (i.e. shared unique identifiers, lat/lon, and/or addresses).\nSee our GIS Level 2 workshop materials for hands on experience.\n\nGIS software can read common tabular data formats. If there is geographic information\nincluded in the data table, GIS tools can be used to transform the table into a shapefile.\n\nGeodatabases are a file storage format used in ArcMap and ArcGIS Pro.\nGeodatabases are similar to zipped files in that they can store and compress a variety\nof different data types, including vectors, rasters, and data tables.\nThey are useful for organizing data and speeding up processing time when working with\nlarge files. A disadvantage is that they can only be opened in ESRI software.\n\nGIS software can import and export data in a variety of formats. Some common import\nformats include KML/KMZ from Google Earth and CAD files. Maps can be exported in\nimage formats for reports or presentations, such as CAD or Illustrator for further\ndevelopment.\n\nMany people do not just need GIS software to conduct their research.\nThe ability to import and export data and maps allows you to work in a variety of\nsoftware before or after using GIS.\nCommon workflows include using GIS in conjunction with remote sensing software,\nwhich is used to analyze satellite imagery, with 3D modeling software such as CAD or\nRhino, using attribute tables in statistical analysis software, and creating elaborate\nmaps designs with visual design software.\n\nThere are characteristics of spatial data that make it unique from other types of data.\nYou need to know about these special features in order to find and use spatial data.\nSpatial data is generalized, meaning it is simplified from what you would find in real life.\nThe more detailed your data are, the larger the files sizes, which means more data to\nstore and longer processing times when analyzing it in GIS software.\nDepending on your project, you may need data with more or less detail. In this\nexample, the coastline outlined in red would be suitable for display on a county or state\nmap. It would be difficult to see a lot of the small inlets and islands at that scale so you\nwant something more generalized, with less detail.\nThe coastline outlined in blue would be suitable for a map of the town or something\nsmaller, such as a specific bay or beach. More detail is often useful when mapping or\nanalyzing a small area.\n\nSpatial data are also abstracted, meaning they include only what is necessary for your\nmap and analysis. It would be impossible to include every feature that you see in real\nlife on a map. Not only would it create large files, but the map would be difficult to\nread.\nThis example includes data that have been abstracted in different ways, for different\npurposes.\nExample A is satellite imagery of an airport without any additional symbology.\nExample B uses a symbol of an airplane to represent the airport.\nExample C uses a polygon to represent the border of the airport property.\nExample D uses polygons and lines to represent the airport border and the runways.\nWhich data symbology would you select if you wanted to do a land use study of\nproperties adjacent to the airport?\nC - Because it shows the border, you can easily see what is adjacent. Example D also\nshows the airport border, but includes runway information, which you do not need.\nWhich data symbology would you select if you wanted to create a map of potential new\ndevelop within the airport? (pause)\nD - Because it shows the airport layout. It would be important to know where the\nrunways are when planning future development.\nWhich data symbology would you select if you wanted to create a map of all airports in\na country? (pause)\nB - Because it just shows the airport as one symbol. If you used the symbols pictured in\nC or D, you map would be messy and difficult to read.\n\nThe spatial data you make visible on a map depends on its scale, meaning how small or\nlarge of an area you are showing. You should show enough detail at a particular scale so\nthat your viewer can clearly see all the features you have added.\nQuestion: Can you spot any other features dependent on scale?\nIn the city map on the left, you can see points of interest, street widths, directions and\nnames, and public transportation stops. These are not visible in the regional map on\nthe right because they are not needed at that scale and would make the map\nimpossible to read. The regional map includes points that represent major cities,\nhighways, and larger state and national parks.\n\nSpatial data changes over time. The data pictured on the previous slides are only\naccurate for that particular point in time. Coastlines may erode or be created in a\nstorm. An airport could expand or close. The names of stores or number of streets may\nchange.\nIn this example, you can see from the imagery that Spring Valley had a lot of\ndevelopment from 1977 to 2006. Data for roads or houses will look different at\ndifferent points in time.\nNote: These aerial images are from the Google Earth Historical Imagery Time Slider.\n\nNow that you know what type of spatial data to look for, where can you find it?\nA lot of data is available freely online, especially for the US.\nThese are tips you can use in the future for data searches.\n\nHere we've listed 3 of the data repositories we frequently use when assisting\nresearchers.\nAt the top is the MIT Libraries GIS research guide which you can find by simply Googling\nMIT GIS. If you hover over the Find Data tab, you'll see a breakdown of GIS data sources\nby geography and subject.\nMIT also has a resource called Geoweb which includes freely available data as well as\nlicensed data restricted to MIT and other universities. The data restricted to use by MIT\ncommunity members consists largely of data purchased by the GIS team on specific\ntopics or areas of the world.\nOpenStreet Map is an open repository of crowd sourced maps. The amount of GIS data\nwill vary by location.\n\nNow we will talk about metadata, aka information about our data.\n\nMetadata is a way of describing an information resource so you can better understand\nthe data. It often describes how and why a dataset was created as well as provides\ninformation about any codes used within the dataset.\n\nShown here are some common metadata sources for geospatial repositories around\nBoston. Let's go through each link and see how their metadata are represented\ndifferently.\n\nLet's talk about some data visualization principles for making great maps.\n\nArt & science = design & analysis\nSimplifications of reality = you can't show everything\nDesigned by people = there's a motive behind their creation\n\nIn this example, we see successive maps all using similar symbology but different\nvariables to argue the location a highway connector should be placed. Things to keep in\nmind are:\n-only relevant features (for a particular group) were selected to be in each map.\n-each map is by a different creator and trying to convey a different message\n-each map is good for a different group\nQuestion: which is best, and what they think the solution should be?\nAnswer: (all correct, but all biased)\n\nYou also want to keep in mind some key questions, such as who wants the map and\nwhere it will be seen, both of which will affect the level of detail and whether or not\nthe map should be interactive.\nDepending on the purpose for the map will affect what type you will create, such as\nchange through time vs. space, and/or combining multiple variables for decision\nmaking.\n\nStage 1: collecting your data (we talked about this at the beginning of the workshop)\nStage 2: symbolize your data (we will talk about the next 2 items now)\nStage 3: create a layout (add title, scale bar, legend, north arrow, etc.)\n\nThere are many ways to symbolize vector data as points, lines, and polygons. While\ncolor is one of the more common ways to symbolize data, this chart shows additional\nways to show differences among features on your map by varying size, pattern, shape\nand orientation.\nWhen choosing any type of symbology, it is important to think about accessibility,\nespecially in relation to color blindness. The Colorbrewer website allows you to filter\ncolors based on those that can be viewed by people with color-blindness. ArcGIS Pro\nalso has this option in its symbology menu.\n\nRaster data are symbolized differently from vector data, as you saw in the earlier\nmodules about types of spatial data, because they are continuous surfaces. Raster data\ncan be displayed by showing all data values, grouping values into categories, varying\ncolors across the surface based on the value, or creating a vector field using symbols,\nwhich you might see in a map of wind direction and speed.\n\nWhen it comes to choosing color, you want to be mindful of they type of data you are\nworking with. Qualitative data often uses different colors for each category, while\nquantitative data often uses one color or two if there is a diverging phenomena.\nExamples of each would be:\nExample of qualitative/categorical: land use\nExample of sequential numbers: population\nExample of diverging numbers: weather/political (e.g. red, blue, neutral)\n\nLet's test our knowledge. In this example we have the variable \"Internet Users (per 100\npeople)\".\nQuestion: Can you tell where the highest internet users are?\nAnswer: No, doesn't make sense with quantitative (numerical) data.\n\nQuestion: Can you tell where the highest internet users are?\nAnswer: Yes, this has an ascending trend which is reflected in the darker color\nindicating greater intensity.\n\nQuestion: Can you tell where the highest internet users are?\nAnswer: It depends. Potentially, this would make sense if there was a certain\nphenomena that occurred and you wanted to show above/below this value (white\ncolored area).\n\nOne of the most commonly used types of maps is a choropleth map. Choropleth maps\nuse different shading and colors to display the quantity or value in defined areas.\nChoropleth maps are best used with polygon data so that it's easier to see color\nvariations.\nThis example of a choropleth map uses shades of 2 different colors, orange and teal, to\nshow spending per student by school districts. School district is the defined area and\nspending per student the quantity.\n\nWhen designing a choropleth map, you have to make 2 basic choices:\n-the number of classes you want your quantity value divided into\n-the classification method for arranging the data into those classes\nWhen choosing the number of classes, keep these points in mind:\n-the more classes, the more variation you have . The human eye can't distinguish\nbetween large numbers of variations of the same color. It is best to have no more than\n7 variations.\n-the major types of classification method are Equal Intervals, Quantile, Natural Breaks\nand Defined Intervals.\n\nequal interval classification classes have equal ranges : ranges such as 1-5, 5-10, 10-15\nquantile classification, classes have equal counts.: 5 items in each class\nNatural breaks optimizes class variation: the algorithm figures out where the breaks\nshould be\nmanual classification, the user sets the breaks based on prior knowledge of the data\n\nIt's ok that you can't see the exact numbers where the breaks are. The important thing\nis that these maps all use the same data (see histograms), but look different depending\non the classification method used (see the amount of each color based on breaks in\nhistograms).\nData source: SimplyAnalytics\n\nOnce you have collected and symbolized your data, you are ready to create a layout for\nyour map.\nIn this example, the eye tends to be drawn more to the legend and highlighted area\nthan to the main map.\n\nIn this rearranged map we have a much nicer visual flow, where the main map takes up\nthe majority of the frame, and inset maps are tucked into the top and bottom corners\nfor context.\nNotice how the legend is not far from the main map for easy interpretation and there is\nroom below the map for discussion and source credits.\n\nComplete the take home exercise for either QGIS or ArcGIS Pro.\n\nYour exercise is based on data presented in a Washington Post article. The article was\nabout Jared Kushner's use of maps to get federal funds meant for job starved areas, but\nmany other developers have used maps for persuasion as well. This is a map from the\narticle and it shows where the development was built. Data was left out to justify\nbuilding in this location. Will you choose the same location? Where should the\ndevelopment really be built? If we have time, we'll look at some maps that you have\ncreated at the end of the workshop."
        },
        {
          "category": "Resource",
          "title": "GIS Level 2 Presentation Slides (PDF)",
          "type": "PDF",
          "source_url": "https://ocw.mit.edu/courses/res-str-001-geographic-information-system-gis-tutorial-january-iap-2022/mitres_str001iap22_level2_pres.pdf",
          "content": "GIS Level 2:\nIntroduction to Spatial Analysis\nCourtesy of US Air Force. Image is in the public domain.\n\nOUTLINE\n- Introduction to spatial analyses\n- Use map projections & metadata to\nunderstand and transform spatial data\n- Use different types of processing tools in\nsoftware(s) to perform a multi-step analysis\n- Exercise new knowledge with GIS software(s)\nIntroduction » Map Projections » Metadata » Processing Tools » Exercise\n\nINTRODUCTION TO SPATIAL\nANALYSIS\nIntroduction » Map Projections » Metadata » Processing Tools » Exercise\n\nEdit geometry\n(Clip tool)\nWhat analyses can you do?\nAnalyze values\n(Vectors)\n(Rasters)\nCreate data\n(Buffer tool)\nImages (c) sources unknown. All rights reserved. This content is excluded from our Creative Commons license. For more\ninformation, see https://ocw.mit.edu/help/faq-fair-use/\nIntroduction » Map Projections » Metadata » Processing Tools » Exercise\n\nSpecialized tools are used to quantify\npatterns & relationships in your data.\nNetwork Analysis\nSpatial Statistics\nSuitability Analysis\nInterpolation\n\nIntroduction > Projections > Metadata > Processing Tools > Exercise\nImages (c) sources unknown. All rights reserved. This content is excluded from our Creative Commons license. For more\ninformation, see https://ocw.mit.edu/help/faq-fair-use/\nIntroduction » Map Projections » Metadata » Processing Tools » Exercise\n\nIntroduction > Projections > Metadata > Processing Tools > Exercise\nMultiple tools are often used together.\nMultiple\ndata inputs\nSingle outputs\n(raster or vector)\n(c) Esri. All rights reserved. This content is excluded\nfrom our Creative Commons license. For more\ninformation, see https://ocw.mit.edu/help/faq-fair\nuse/\nIntroduction » Map Projections » Metadata » Processing Tools » Exercise\n\nMAP PROJECTIONS:\nWHY DO WE CARE ABOUT THEM?\nIntroduction » Map Projections » Metadata » Processing Tools » Exercise\n\nIf a coordinate system is wrong or missing,\ndata will not display in the correct location.\nhttps://ihatecoordinatesystems.com/\n(c) Dan Mahr. All rights reserved. This content is excluded from our Creative Commons license. For more information, see\nhttps://ocw.mit.edu/help/faq-fair-use/\nIntroduction » Map Projections » Metadata » Processing Tools » Exercise\n\nAnalysis >> Projections >> Metadata >> Processing Tools >> Exercise\nIntroduction > Projections > Metadata > Processing Tools > Exercise\nUsing the same projection for all the datasets in\nyour project will lead to faster processing time.\nIntroduction » Map Projections » Metadata » Processing Tools » Exercise\n\nAnalysis >> Projections >> Metadata >> Processing Tools >> Exercise\nIntroduction > Projections > Metadata > Processing Tools > Exercise\nIntroduction » Map Projections » Metadata » Processing Tools » Exercise\nAnalysis tools that involve shape, area, direction,\nform, or distance calculations require data to be\nin a suitable projected coordinate system.\n(c) source unknown. All rights reserved. This content is excluded from our\nCreative Commons license. For more information, see\nhttps://ocw.mit.edu/help/faq-fair-use/\n\nAnalysis >> Projections >> Metadata >> Processing Tools >> Exercise\nIntroduction > Projections > Metadata > Processing Tools > Exercise\nIntroduction » Map Projections » Metadata » Processing Tools » Exercise\nMAP PROJECTIONS:\nWHAT ARE THEY?\nIntroduction » Map Projections » Metadata » Processing Tools » Exercise\n\nIntroduction > Projections > Metadata > Processing Tools > Exercise\nIntroduction » Map Projections » Metadata » Processing Tools » Exercise\nEllipsoid\nRepresentation\nDatum\nSphere\nRepresentation\nDatum\nCourtesy of NOAA. Image is in the public domain.\nA Geographic Coordinate\nSystem (GCS) consists of\n- Datum\n- Prime Meridian\n- Angular Unit\nA Datum is an idealized\nmathematical representation\nof the Earth.\nhttp://desktop.arcgis.com/en/arcmap/latest/map/projections/\nwhat-are-map-projections.htm\nIntroduction » Map Projections » Metadata » Processing Tools » Exercise\n\nA projection algorithm is applied to\nthe GCS to create a Projected\nCoordinate System (PCS).\nImagine an orange as the\nEarth, and you want to be\nable to peel it in such a\nway as to lay the peel flat.\nSimilarly,\nprojection is a method\nby which cartographers\ntranslate a 3D globe\n(spheroid or ellipsoid)\nto a 2D map surface.\nOriginal image (c) GIS Geography. All rights reserved. This content\nis excluded from our Creative Commons license. For more\ninformation, see https://ocw.mit.edu/help/faq-fair-use/\nDatum\n\nIntroduction > Projections > Metadata > Processing Tools > Exercise\nIntroduction » Map Projections » Metadata » Processing Tools » Exercise\nIntroduction » Map Projections » Metadata » Processing Tools » Exercise\n\nAnalysis >> Projections >> Metadata >> Processing Tools >> Exercise\nIntroduction > Projections > Metadata > Processing Tools > Exercise\nA Projected Coordinate System consists of\n- Geographic Coordinate\nSystem\n- Projection Algorithm\n- Linear Unit\n- Parameters that center\nthe system on a certain\nlocation\n(c) Jochen Albrecht. All rights reserved. This content is\nexcluded from our Creative Commons license. For more\ninformation, see https://ocw.mit.edu/help/faq-fair-use/\nIntroduction » Map Projections » Metadata » Processing Tools » Exercise\n\nAnalysis >> Projections >> Metadata >> Processing Tools >> Exercise\nIntroduction > Projections > Metadata > Processing Tools > Exercise\nThere are many different types of projections.\nEach have certain strengths and limitations\nin the following types of distortions:\nshape, area, distance, direction\n(c) source unknown. All rights reserved. This content is excluded from our Creative Commons\nlicense. For more information, see https://ocw.mit.edu/help/faq-fair-use/\nIntroduction » Map Projections » Metadata » Processing Tools » Exercise\n\nCoordinate Systems Characteristics\nGeographic\n- 3D spherical/spheroidal\nsurface defines locations\n- Units: degrees (angular)\n- Lengths, angles, and areas\nchange with distance away\nfrom equator\nProjected\n- 2D flat/planar\nsurface defines locations\n- Units: ft, m, miles, etc. (linear)\n- Lengths, angles, and areas\nconstant across the two\ndimensions\nIntroduction » Map Projections » Metadata » Processing Tools » Exercise\n\nCoordinate Systems Summary\n1. Data often start in a geographic coordinate system.\n2. They are projected into a projected coordinate system.\n3. The projection depends on the data location and analyses\nImage (c) Michael Minn. All rights reserved. This content is excluded from our Creative Commons license. For\nmore information, see https://ocw.mit.edu/help/faq-fair-use/\nIntroduction » Map Projections » Metadata » Processing Tools » Exercise\n\nCommonly Encountered Systems\nGeographic Coordinate System\n- NAD83 (North American Datum) - best fitting ellipsoid for North America\n- WGS1984 (World Geodetic System) - best fitting ellipsoid for the globe/world\nIntroduction » Map Projections » Metadata » Processing Tools » Exercise\nCourtesy of NOAA. Image is in the public domain.\n\nCommonly Encountered Systems\nProjected Coordinate System\n- UTM (Universal Transverse Mercator) - often best for large regions\nCourtesy of the National Geospatial-Intelligence Agency.\n(c) Jochen Albrecht. All rights reserved. This content is\nImage is in the public domain.\nexcluded from our Creative Commons license. For more\ninformation, see https://ocw.mit.edu/help/faq-fair-use/\nIntroduction » Map Projections » Metadata » Processing Tools » Exercise\n\nCommonly Encountered Systems\nProjected Coordinate System\n- USA State Plane Systems - have been optimized per state, see updates here.\nIntroduction » Map Projections » Metadata » Processing Tools » Exercise\n\nTips on selecting a\nProjected Coordinate System\n- Based on your project's analyses:\n- Preserve area with equal-area projections\n- Preserve shape with conformal projections\n- Preserve direction with azimuthal projections\n- Preserve distance with equidistant projections\n- Other projections compromise on the distortions\n- (Usually you stick with one, but can re-project)\nIntroduction » Map Projections » Metadata » Processing Tools » Exercise\n\nTips on selecting a\nProjected Coordinate System\n- Based on your project's location:\nSize\n- Locally, the US has 'state plane systems'\n- Regionally, UTM is often a good option\n- World, World Mercator (EPSG: 3857)\nRegion\n- To map tropical regions, use a cylindrical projection\n- To map middle latitudes, use a conic projection\n- To map a polar region, use an azimuthal projection\nIntroduction » Map Projections » Metadata » Processing Tools » Exercise\n\nAnalysis >> Projections >> Metadata >> Processing Tools >> Exercise\nIntroduction > Projections > Metadata > Processing Tools > Exercise\nMAP PROJECTIONS:\nHOW DO YOU KNOW THE COORDINATE\nSYSTEM OF YOUR DATA?\nIntroduction » Map Projections » Metadata » Processing Tools » Exercise\n\nAnalysis >> Projections >> Metadata >> Processing Tools >> Exercise\nIntroduction > Projections > Metadata > Processing Tools > Exercise\nOption 1: Look for a .prj (projection) file within the\nfiles that make up the \"shapefile\" and then...\nIntroduction » Map Projections » Metadata » Processing Tools » Exercise\n\nAnalysis >> Projections >> Metadata >> Processing Tools >> Exercise\nIntroduction > Projections > Metadata > Processing Tools > Exercise\nOption 1 continued: Open the file in QGIS or\nArcGIS and examine the data layer information.\nNote: ESRI products (ArcGIS Desktop and ArcGIS Pro) refer to geographic &\nprojected coordinate systems with names while QGIS uses EPSG codes:\nNAD 1983 StatePlane New Jersey FIPS 2900 (US Feet) versus EPSG: 3424\nIntroduction » Map Projections » Metadata » Processing Tools » Exercise\n\nAnalysis >> Projections >> Metadata >> Processing Tools >> Exercise\nIntroduction > Projections > Metadata > Processing Tools > Exercise\nOption 2: Consult the metadata\nIntroduction » Map Projections » Metadata » Processing Tools » Exercise\n\nExercise 1: Coordinate Systems\nGoals\n- Learn how to transform a coordinate system in\nGIS software\nSteps\n- Open either the QGIS or ArcGIS Pro.\n- You will now choose a breakout rooms and be\nguided through the first exercise.\nIntroduction » Map Projections » Metadata » Processing Tools » Exercise\n\nAnalysis >> Projections >> Metadata >> Processing Tools >> Exercise\nIntroduction > Projections > Metadata > Processing Tools > Exercise\nPROCESSING TOOLS: OVERVIEW\nIntroduction » Map Projections » Metadata » Processing Tools » Exercise\n\nIntroduction » Maps & Data » Making Maps » Software » Exercise\nIntroduction > Projections > Metadata > Processing Tools > Exercise\nUse processing tools to:\n\"capture, store, check, integrate,\nmanipulate, analyze and display\ngeospatial data\"\nIntroduction » Map Projections » Metadata » Processing Tools » Exercise\n\nAnalysis >> Projections >> Metadata >> Processing Tools >> Exercise\nIntroduction > Projections > Metadata > Processing Tools > Exercise\nTool considerations\n- Read the tool help resource to\nunderstand how it works and\ndetermine if it is appropriate\nfor your data.\n- The accuracy of the input data\ndetermines the accuracy of\nthe results.\nIntroduction » Map Projections » Metadata » Processing Tools » Exercise\n\nAnalysis >> Projections >> Metadata >> Processing Tools >> Exercise\nIntroduction > Projections > Metadata > Processing Tools > Exercise\nBatch tools\nRecord tools, inputs, and parameters used.\nExport this information as python code, if\npossible, so results can be replicated.\nThis is the focus of the\nGIS Level 3 workshop\nQGIS: Graphical Modeler & Python\nArcGIS Pro: Model Builder & Python\nIntroduction » Map Projections » Metadata » Processing Tools » Exercise\n\nAnalysis >> Projections >> Metadata >> Processing Tools >> Exercise\nIntroduction > Projections > Metadata > Processing Tools > Exercise\nPROCESSING TOOLS:\nARCGIS PRO VS QGIS\nIntroduction » Map Projections » Metadata » Processing Tools » Exercise\n\nIntroduction > Projections > Metadata > Processing Tools > Exercise\nAnalysis Tools\nArcGIS Pro (by ESRI)\n- Can easily import all data types\n(raster, vector, tabular)\n- Full set of GIS functions & tools\n(depends on licensing level)\n- Comprehensive support\n(direct support from ESRI,\naccess to online modules and\ntutorials, and documentation\nfor every tool)\nQGIS\n- Can easily import all data types\n(raster, vector, tabular, & more)\n-\nMany available tools, but lacking\nsome advanced analyses:\nnetwork analysis, spatial statistics\n-\nTools can be developed by anyone\nso performance & documentation\ncan be inconsistent.\n- Support via forums, eg StackExchange\nBoth have similar interfaces\nand many of the same analysis tools.\nIntroduction » Map Projections » Metadata » Processing Tools » Exercise\n\nAnalysis >> Projections >> Metadata >> Processing Tools >> Exercise\nIntroduction > Projections > Metadata > Processing Tools > Exercise\nPROCESSING TOOLS: ARCGIS PRO\nIntroduction » Map Projections » Metadata » Processing Tools » Exercise\n\nAnalysis >> Projections >> Metadata >> Processing Tools >> Exercise\nIntroduction > Projections > Metadata > Processing Tools > Exercise\nArcGIS Pro Analysis Tools\nArcGIS Pro offers a variety of toolboxes that contain tools that\nwork on certain types of data or perform specific types of\nanalysis.\nIntroduction » Map Projections » Metadata » Processing Tools » Exercise\n\nAnalysis >> Projections >> Metadata >> Processing Tools >> Exercise\nIntroduction > Projections > Metadata > Processing Tools > Exercise\nArcGIS Pro Extensions\nAdvanced Analysis\n-\n3D Analyst\n-\nBusiness Analyst\n-\nGeostatistical Analyst\n-\nImage Analyst\n-\nNetwork Analyst\n-\nSpatial Analyst\nUsed most\noften\nIndustry Focused\n-\nAviation Airports & Charting\n-\nDefense Mapping\n-\nMaritime\n-\nPipeline Referencing\n-\nProduction Mapping\n-\nRoads and Highways\nData and Workflows\n-\nData Interoperability\n-\nData Reviewer\n-\nIndoors\n-\nLocateXT\n-\nPublisher\n-\nStreetMap Premium\n-\nTerritory Design\n-\nWorkflow Manager\n-\nWorkflow Manager (Classic)\nIntroduction » Map Projections » Metadata » Processing Tools » Exercise\n\nAnalysis >> Projections >> Metadata >> Processing Tools >> Exercise\nIntroduction > Projections > Metadata > Processing Tools > Exercise\nPROCESSING TOOLS: QGIS\nIntroduction » Map Projections » Metadata » Processing Tools » Exercise\n\nAnalysis >> Projections >> Metadata >> Processing Tools >> Exercise\nIntroduction > Projections > Metadata > Processing Tools > Exercise\nQGIS Analysis Tools\nQGIS offers vector analysis, raster analysis, sampling,\ngeoprocessing, geometry, & database management tools.\nAdditional tools include:\n- Integrated GRASS tools with more than 400 modules.\n- Processing plugin, a powerful geospatial analysis framework to call native\nand third-party algorithms from QGIS, such as GDAL, SAGA, GRASS, R, etc.\n- Extensible plugin architecture, can extend QGIS functionality where\nlibraries can be used to create your own plugins.\nIntroduction » Map Projections » Metadata » Processing Tools » Exercise\n\nAnalysis >> Projections >> Metadata >> Processing Tools >> Exercise\nIntroduction > Projections > Metadata > Processing Tools > Exercise\nQGIS Vector Analysis Tools\nIntroduction » Map Projections » Metadata » Processing Tools » Exercise\n\nAnalysis >> Projections >> Metadata >> Processing Tools >> Exercise\nIntroduction > Projections > Metadata > Processing Tools > Exercise\nQGIS Raster Analysis Tools\nIntroduction » Map Projections » Metadata » Processing Tools » Exercise\n\nAnalysis >> Projections >> Metadata >> Processing Tools >> Exercise\nIntroduction > Projections > Metadata > Processing Tools > Exercise\nQGIS Processing Plugin\nProcessing plugin:\na powerful geospatial analysis\nframework to call native and\nthird-party algorithms from\nQGIS, such as GDAL, GRASS,\nSAGA, GRASS, R, etc.\nIntroduction » Map Projections » Metadata » Processing Tools » Exercise\n\nAnalysis >> Projections >> Metadata >> Processing Tools >> Exercise\nIntroduction > Projections > Metadata > Processing Tools > Exercise\nQGIS Plugin Repositories\n- add useful features\nto the software\n- are written by QGIS\ndevelopers & other\nindependent users\n- available through\nthe Plugins menu\nIntroduction » Map Projections » Metadata » Processing Tools » Exercise\n\nAnalysis >> Projections >> Metadata >> Processing Tools >> Exercise\nIntroduction > Projections > Metadata > Processing Tools > Exercise\nVECTOR ANALYSIS\nIntroduction » Map Projections » Metadata » Processing Tools » Exercise\n\nAnalysis >> Projections >> Metadata >> Processing Tools >> Exercise\nIntroduction > Projections > Metadata > Processing Tools > Exercise\nBuffer\n- Creates a polygon around a\nfeature at given distance(s)\n- Where, the input feature can\nbe a point, line, or polygon\n- Options to dissolve or\ncreate separate features\n- Examples:\n- 50 miles around mines\n- 5 miles around rivers\nIntroduction » Map Projections » Metadata » Processing Tools » Exercise\n\nAnalysis >> Projections >> Metadata >> Processing Tools >> Exercise\nIntroduction > Projections > Metadata > Processing Tools > Exercise\nCreate and Edit Features\n- New shapefiles can be\ncreated from scratch\n- Features can be edited or\ncreated using the editor\ntoolbar in Arc or QGIS\n- Example: creating a major\nroad layer (green) for\nHavana, Cuba based\non satellite imagery\nIntroduction » Map Projections » Metadata » Processing Tools » Exercise\n\nAnalysis >> Projections >> Metadata >> Processing Tools >> Automation >> Exercise\nIntroduction > Projections > Metadata > Processing Tools > Exercise\nClip (Vectors)\n- Use one layer's extent to\nclip down the features of\nanother layer\n- Input layer can be points,\nlines, or polygons, but the\nclip layer must be a polygon\n- Example:\nEuropean railroad layer\nclipped to France layer\nIntroduction » Map Projections » Metadata » Processing Tools » Exercise\n\nIntroduction > Projections > Metadata > Processing Tools > Exercise\nExercise 2: Vector Analysis\nGoals\n- Learn how to access, interpret, and\ntroubleshoot analysis tools in GIS software\nSteps\n- You will go back into your breakout room and\nbe guided through the second exercise.\nIntroduction » Map Projections » Metadata » Processing Tools » Exercise\n\nAnalysis >> Projections >> Metadata >> Processing Tools >> Exercise\nSURFACE ANALYSIS\nIntroduction > Projections > Metadata > Processing Tools > Exercise\n\nInterpolation\nCreate a continuous surface from points.\n(c) Esri. All rights reserved. This content is excluded from our Creative Commons license. For\nmore information, see https://ocw.mit.edu/help/faq-fair-use/\n\nExtract by Mask (Pro)/Clip Raster (QGIS)\n- Only cells/pixels within a boundary are retained in output\n- Input must be a raster but the clip feature can be anything:\n- points, lines, polygons, or another raster (anything with area)\nImage (c) Esri. All rights reserved. This content is excluded from our Creative Commons license.\nFor more information, see https://ocw.mit.edu/help/faq-fair-use/\nIntroduction > Projections > Metadata > Processing Tools > Exercise\n\nContour\n- Creates contour line layer from raster surface.\n- Note: they will not extend past the spatial\nextent of the raster nor in areas with no data\nImage (c) Esri. All rights reserved. This content is excluded from our Creative Commons license.\nFor more information, see https://ocw.mit.edu/help/faq-fair-use/\nIntroduction > Projections > Metadata > Processing Tools > Exercise\n\nSlope\n- For each cell, the maximum rate of change in value\nfrom that cell to its neighbors is calculated.\n- The output slope raster can be calculated in two\ntypes of units, degrees or percent (percent rise).\nImage (c) Esri. All rights reserved. This content is excluded from our Creative Commons license.\nFor more information, see https://ocw.mit.edu/help/faq-fair-use/\nIntroduction > Projections > Metadata > Processing Tools > Exercise\n\nZonal Statistics (...as Table)\n- Zonal Statistics - calculates one statistic\n(e.g. mean, max, min, stdev, range)\nfrom an input raster over a zone/area\nand produces a new layer.\n- Zonal Statistics as Table (Pro)/Zonal\nHistogram (QGIS) - calculates multiple\nstatistics but produces a table (which\ncan be joined back to geometry, or\nexported to statistical software)\nImage (c) Esri. All rights reserved. This content is excluded from our Creative Commons license.\nFor more information, see https://ocw.mit.edu/help/faq-fair-use/\nIntroduction > Projections > Metadata > Processing Tools > Exercise\n\nSurface analysis tools: also are used to...\n- Analyze Patterns\n- Analyze Terrain\n- Generalize\n- Conduct hydrological analysis\n- Manage Data\n- Summarize Data\n- Use Proximity\nIntroduction > Projections > Metadata > Processing Tools > Exercise\n\nExercise 3: Raster tools\nGoals\n- Learn how to access raster tools\nSteps\n- You will go back into your breakout room and\nbe guided through the third exercise.\n\nAnalysis >> Projections >> Metadata >> Processing Tools >> Exercise\nIntroduction > Projections > Metadata > Processing Tools > Exercise\nSPATIAL STATISTICS\nIntroduction » Map Projections » Metadata » Processing Tools » Exercise\n\nAnalysis >> Projections >> Metadata >> Processing Tools >> Exercise\nWhat are spatial statistics?\n- methods for analyzing spatial distributions,\npatterns, processes, and relationships\n- they incorporate space (proximity, area,\nconnectivity, and/or other spatial\nrelationships) directly into their mathematics\nIntroduction > Projections > Metadata > Processing Tools > Exercise\n\nAnalysis >> Projections >> Metadata >> Processing Tools >> Exercise\nSpatial autocorrelation (Moran's I)\n- Measures the patterns of attribute values associated with\nfeatures (ex. median home value, percent female, etc.).\n- Compares the value of the feature to that of its neighbors\nand the entire study area.\n- Indicates clusters of high or low values (positive I value) or\noutliers (negative I value).\nUse Moran's I to\ntest visual\npatterns for\nstatistical\nsignificance.\n(c) sources unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see https://ocw.mit.edu/help/faq-fair-use/\nIntroduction > Projections > Metadata > Processing Tools > Exercise\n\nAnalysis >> Projections >> Metadata >> Processing Tools >> Exercise\nNeighbors: Distance Models\n- Inverse distance: all features\ninfluence all other features,\nbut the closer something is,\nthe more influence it has\n- Distance band: features\noutside a specified distance\ndo not influence the features\nwithin the area\n- Zone of indifference:\ncombines inverse distance\nand distance band\nIntroduction > Projections > Metadata > Processing Tools > Exercise\n\nAnalysis >> Projections >> Metadata >> Processing Tools >> Exercise\nNeighbors: Adjacency Models\n- K Nearest Neighbors: a\nspecified number of\nneighboring features are\nincluded in calculations\n- Polygon Contiguity:\npolygons that share an edge\nor node influence each\nother\n- Spatial weights: specified\nby user (ex. Travel times or\ndistances)\nIntroduction > Projections > Metadata > Processing Tools > Exercise\n\nAnalysis >> Projections >> Metadata >> Processing Tools >> Exercise\nIntroduction > Projections > Metadata > Processing Tools > Exercise\nSpatial autocorrelation (Moran's I)\n(c) sources unknown. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see https://ocw.mit.edu/help/faq-fair-use/\n\nAnalysis >> Projections >> Metadata >> Processing Tools >> Exercise\nOther spatial statistics tools\n- Analyzing patterns\n- Nearest neighbor, Ripley's K\n- Geographic distributions\n- mean, median, directional mean\n- Regression\n- Geographic, Ordinary Least Squares (OLS)\nIntroduction > Projections > Metadata > Processing Tools > Exercise\n\nExercise 4: Spatial Statistics\nGoals\n- Learn how to access specialized analysis tools\n- Understand the results of a basic spatial\nautocorrelation.\nSteps\n- You will go back into your breakout room and\nbe guided through the fourth exercise.\n\nAnalysis >> Projections >> Metadata >> Processing Tools >> Exercise\nDISTANCE & NETWORK ANALYSIS\nIntroduction > Projections > Metadata > Processing Tools > Exercise\n\nAnalysis >> Projections >> Metadata >> Processing Tools >> Exercise\nDistance in a GIS\n(c) Google. All rights reserved.\nThis content is excluded from\nour Creative Commons license.\nFor more information, see\nhttps://ocw.mit.edu/help/faq\nfair-use/\nIntroduction > Projections > Metadata > Processing Tools > Exercise\n\nAnalysis >> Projections >> Metadata >> Processing Tools >> Exercise\nDistance functions in GIS\nWithout\nregard to any\nnetwork, over\nthe surface of\nthe earth vs\non a road\nnetwork\n(c) Google. All rights reserved.\nThis content is excluded from\nour Creative Commons license.\nFor more information, see\nhttps://ocw.mit.edu/help/faq\nfair-use/\nIntroduction > Projections > Metadata > Processing Tools > Exercise\n\nAnalysis >> Projections >> Metadata >> Processing Tools >> Exercise\nNetwork Analysis Tools\n- Routing\n- Service Areas\n- Closest facility\n- OD Cost Matrix\n- Vehicle Routing Problem\n- Location-Allocation\n- (Only for ArcGIS Products)\nIntroduction > Projections > Metadata > Processing Tools > Exercise\n\nAnalysis >> Projections >> Metadata >> Processing Tools >> Exercise\nTAKE-HOME EXERCISE\nIntroduction > Projections > Metadata > Processing Tools > Exercise\n\nAnalysis >> Projections >> Metadata >> Processing Tools >> Exercise\nTake-home Exercise overview\n- Continuing with the data from GIS Level 1,\nexplore where you may build a mixed use\nfacility in Jersey City.\n- This exercise will take into account the\nfollowing factors:\n- Clustering of unemployment\n- Distance to transportation\n- Terrain\nIntroduction > Projections > Metadata > Processing Tools > Exercise\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\nRES.STR-001 Geographic Information System (GIS) Tutorial\nIAP 2022\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms"
        },
        {
          "category": "Resource",
          "title": "GIS Level 2 Presentation Slides with Notes (PDF)",
          "type": "PDF",
          "source_url": "https://ocw.mit.edu/courses/res-str-001-geographic-information-system-gis-tutorial-january-iap-2022/mitres_str001iap22_level2_pres_notes.pdf",
          "content": "This workshop is a sampler of the some tools available in ArcGIS Pro or\nQGIS.\n\nIn this workshop, we will focus on the analysis tools you can use with your data.\nAnalysis tools can be used to edit or subset data (left), analyze data values (top right),\nand create data (bottom right). A tool may do all of these things at once and you may\nuse several tools in conjunction with one another. Our level 2 workshop goes into these\nfurther in this presentation.\n\nGeographic information systems have spatial analysis tools that allow you\nto quantify patterns and relationships in the data and display the results as\nmaps, tables, and charts. Using tools within a GIS you can examine the\nattributes and location of spatial data and reveal relationships that you\nmight not be able to see otherwise.\nThese pictures are examples of some analysis results:\n-\nHot spot analysis of diseases by zip code (spatial stats)\n-\nCreating a continuous surface from points (interpolation)\n-\nThe time it takes to travel from a particular energy source (network\nanalysis)\n-\nWildfire hazard potential (suitability analysis)\n\nYou will often use multiple tools to answer spatial questions about your\ndata. This is an example of a suitability analysis, a common process done\nusing GIS. It is not a particular set of tools, but rather a way to work with\nseveral tools to quantify patters and relationships to determine the best\nplace or site for something.\nSuitability example: This shows a suitability analysis for selecting a new\nschool location using: land use, slope, recommended sites, and other\nschool locations.\nSource: https://desktop.arcgis.com/en/arcmap/latest/extensions/spatial-\nanalyst/solving-problems/using-the-conceptual-model-to-create-\nsuitability.htm\n\nMap projections are especially important when conducting spatial analysis.\n\nWhen data are in different projections, tools will convert them into a similar projection\nduring each step of the analysis, which adds time, especially when using multiple data\nlayers or complex tools.\n\nSome analysis tools requires that your data be in a projection that uses linear units\n(meters, feet, etc.) in order to run the tool.\n\nAs you know, geographic data for any particular area are stored in separate layers. For\nexample, roads are stored in one layer, parks in another, and buildings in a third. To\nenable the data in each layer to integrate when displayed and queried, each layer must\nreference locations on the earth's surface in a common way. Coordinate systems\nprovide a framework for this to happen.\nOne type of coordinate system is the geographic coordinate systems. It consists of\nseveral parts:\n-\nA datum is part of the coordinate system. The earth is not a perfect sphere,\nalthough the analysis tools often assume it is, so datums are used to \"smooth out\"\nthe earth's surface so it can be more easily analyzed. There are different datums\nthat are designed to be more accurate for different parts of the world. The pictures\nabove show how the imperfect shape of the earth is transformed into a perfect\nellipse and then a perfect sphere.\n-\nA coordinate system also includes a prime meridian (which specifies the location of\n0° longitude) and an angular unit (often degrees).\nTo use the analysis tools, you often have to make sure the coordinate system is\nappropriate for your data and the tool you are using.\nSources:\nhttps://www.esri.com/arcgis-blog/products/arcgis-pro/mapping/coordinate-systems-\ndifference/\n\nA projection is the mathematical algorithm that defines how to present the round earth\non a flat map. For example, if we were all to peel an orange and flatten out the peel, we\nwould all do it in different ways. The peel would be different shapes and sizes in\ndifferent areas and these pieces would be spaced in different ways.\nThis algorithm is applied to the geographic coordinate system, which includes the\ndatum, and is part of a Projected Coordinate System, which we will discuss next.\nSource: https://gisgeography.com/map-projections/\n\nA projection is part of a Projected Coordinate System. A projected\ncoordinate system also includes a geographic coordinate system, a linear\nunit, and parameters that can be used to center the coordinate system on\ndifferent parts of the world. A projected coordinate system is more\naccurate when it is centered over a location and thousands of systems\nhave been developed for different parts of the world. For example, each\nstate has several projected coordinate systems that are idealized for that\nstate.\n\nRepresenting the earth's surface in two dimensions causes distortion in\nthe shape, area, distance, or direction of the data. (as shown in the\nprevious orange example)\nWhen creating a map, you will want to think about which of the distortions\nyou want to minimize and choose an appropriate projection.\n\nTo summarize, a datum is a representation of the earth's surface and is part of a\ngeographic coordinate system. A projection algorithm can be applied to that system to\ncreate a projected coordinate system for a specific location.\n\nIn the picture above the larger turquoise ellipse fits well for the entire earth/geoid, but\nnot for a smaller region. The red ellipse is a better fit in this case.\nTwo commonly used geographic coordinate systems are NAD83, which is the best fit\n(has the least distortion) for North American, and WGS84, which is the best fit for the\nentire world.\nSource: https://slideplayer.com/slide/220638/\nAlternative (very informative source):\nhttps://www.ngs.noaa.gov/web/science_edu/presentations_library/files/spcs2022_njs\npls_2019.pdf\n\nAs mentioned previously, geographic coordinate systems can be \"projected\" (aka\n\"flattened\") so that they appear less distorted on the screen and use a linear unit of\nmeasurement (meters, feet vs. decimal degrees). UTM is a common projected\ncoordinate system for the world. It divides the earth into vertical zones. You would\nchoose the zone that is appropriate for the location of your data in order to minimize\ndistortions.\n\nThere are specific projected coordinate systems for each state (and sometimes parts of\na state) that minimize distortion in that area. The state plane system is used in the\nUnited States.\n\nIf you are transforming data from a geographic coordinate system into a projected\none, you will need to choose the appropriate projected coordinate system. First, think\nabout the analyses you will be doing. Which types of distortion would you want to\nminimize? For example, if you will be calculating the area of building you would want to\nchoose a projected coordinate system that preserves area.\nAdditional Sources:\nhttps://eipd.dcs.wisc.edu/for-credit/GIS-cert/summer2017/geog370_m1/lesson_4.html\nhttps://ihatecoordinatesystems.com/\n\nNext consider the region in which you are working and the size of your area of analysis.\nSome projected coordinate systems are designed for very small areas and some for\nlarge ones. There are systems for every part of the world.\n\nWhen you download data from the web or are given it from a colleague, how do you\nknow if it has a coordinate system? For shapefiles, look for a .prj file.\n\nOnce you have confirmed there is a .prj file, how do you know what the projection is?\nYou can view coordinate system information for each data layer in GIS software.\nWhen using QGIS, you will always see an EPSG code for each coordinate reference\nsystem. This is a unique number that is assigned to each system.\nIt's useful to use the EPSG code when searching for a projection to make sure you are\nselecting the one you want. Often projections have similar names and it's easy to select\none the incorrect one if you are just looking by name.\n\nIf you downloaded data from a website, you can often find metadata that lists the map\nprojection.\nYou can find metadata:\n-Downloaded with your data layers\n-On the website where you got your data\n-Sometimes you may need to contact the data provider to get metadata\nMost commonly used metadata formats are html/xml, text files, or in a table format,\nsuch as excel or csv.\n\nGIS software includes hundreds of tools you can use to perform different processes on\nyour data.\n\nBoth QGIS and ArcGIS Pro tools include links to help documentation. Read this to\ndetermine how the tool works, the required input fields, and any other considerations.\nCertain tools may required data in certain formats or projections. There may also be\nother assumptions about the input data.\n\nYou will often use several tools in a row to process your data. Make sure to keep a\nrecord of the tools you use, their inputs, parameters, and the names of the output files.\nYou can do this manually or use the Graphical Modeler in QGIS or the Model Builder in\nArcGIS Pro. Drag and drop tools and inputs into these programs to visually see your\nworkflow. You can also run all the tools multiple times using these programs and export\nyour process a python code to share with others. If you are familiar with python you\ncan use it to write code for your GIS analysis. Our GIS Level 3 workshop, which will\nlikely be offered in January, covers using python with ArcGIS Pro.\n\nNow we will discuss the general way tools are set-up and run in both QGIS and ArcGIS\nPro.\n\nFor most uses, either software will work well so you may want to base your decision on\nyour computer's resources, how frequently you will need to use it, what you want to\ndo, and the industry you plan to work in (or are currently working in).\nBoth softwares have many of the same tools, but you may find a tool in QGIS that is not\nin ArcGIS Pro and vice versa.\n\nArcGIS Pro organizes tools into toolboxes.\n\nSome of the more specialized tools require an extra license or an additional installation.\nAll are available while you are at MIT and the most commonly used one are built into\nArcGIS Pro.\nIf you run into a licensing error when trying to use these tools, email us and we can\nmake sure the license is activated on your account.\n\nQGIS has a similar set of tools, but they are organized in a different way. Additionally\nthere are tools created by users.\nQGIS tools are often built on other languages, such as GRASS or GDAL. While we aren't\nfamiliar enough with these languages to provide help, it's possible to run analysis\ndirectly through the, outside of QGIS, or use them to build your own QGIS tools.\n\nQGIS comes with a variety of tools that are grouped into those that work on Vector\ndata and those that work on Raster data. Similar to ArcGIS Pro, you can see here that\nthe vector tools are grouped into several categories.\n\nThe Raster tools are organized in a similar way.\n\nIn addition to what you find at the top menu, QGIS includes additional tools in the\nProcessing Toolbox (again, similar to the toolbox in ArcGIS Pro).\n\nAdditionally there is a QGIS plugin repository where you can find additional tools\ncreated by users. Adding these to your QGIS may add additional toolbar menus or\nadditional options under the existing menus.\nTo summarize:\nArcGIS Pro tools can be found in the toolbox, with some requiring an additional license.\nSome of the more popular tools display at the top menu ribbon. These tools are\ncreated by developers at ESRI, which created the software.\nQGIS tools can be found in the toolbar menu, the processing toolbox, or as an\nadditional plugin. These tools are created by a variety of QGIS users.\nGoogling is a great way to find out if a tool exists and where it is located in the\nsoftware.\n\nThe buffer tool creates a polygon surrounding a feature at a distance you\nchoose.\n\nEditing tools are used to create new data, often times from satellite\nimagery or a scanned map. For example you can extract features or trace\ndata from an image.\n\nThe clip tool is like a cookie cutter and can be used to subset data. You\noften don't need all the data in a file you have downloaded and extracting\nonly what you need will speed up processing and loading time.\n\nThere separate tools to be used with vectors vs. rasters because the file formats are\ndifferent.\n\nInterpolation tools create a continuous raster surface from individual points on a map.\nIn these examples, the elevation surface is interpolated from individual elevation point\nvalues and the ozone level for California is interpolated from values at individual\nmonitoring stations.\nThere are a variety of algorithms to choose from in order to create this surface.\n\nExtract by Mask is what you would use to clip a raster. Again, extracting only what you\nneed decreases file sizes.\n\nContour lines can be produced from elevation rasters called DEMs (digital elevation\nmodel).\n\nSlope can also be calculated from elevation rasters, and used as inputs in other tools.\n\nZonal statistics can be used to summarize a raster by different zones/cookie cutter\nareas. For example, if you have a raster where each pixel is a different land use, you\ncould overlay town boundaries to find the predominant land use in each town.\n\nThere are a lot of additional tools that fall under the following categories.\n\nIf you see what appear to be clusters of similar data or outliers in your choropleth map,\nyou can use spatial statistics tools to analyze the values of the data to see if there is a\nstatistically significant pattern.\nSpatial autocorrelation analyzes the values in your attribute table, comparing the value\nof each feature (i.e. each row) to that of neighboring features and the entire study area\nto find clusters of low or high values.\n\nThe results of spatial autocorrelation are dependent on how the neighborhood is\ndefined. In GIS software you create what is called a \"weights\" file to define your\nneighborhoods. This is used as input when running a spatial statistics tool.\nHere are some examples of how you may define a neighborhood based on distance.\n\nYou can also define neighbors based on adjacency or by creating your own weights file.\n\nOne method use to determine clusters of similar values is called Moran's I.\nIt can be used with points (you would want to choose distance neighborhood model) or\npolygons, although it tends to be more widely used with polygon data.\nIn both examples the output of this tools are additional data layers indicating where\nthere are clusters of high values or low values and where there are places with outliers\n(a low value surrounded by high values or a high value surrounded by low values).\n\nThere are other tools that look at the patterns created by the location of features\n(rather than the value of the attributes) and the location of points. You can also do\nregression.\nQGIS has a more limited set of spatial statistics tools. There is another free, open-\nsource program called Geoda, which can be used to supplement the tools found in\nQGIS. This will be used in the final exercise.\n\nHere we can see that Google maps a route from Back Bay in Boston to the GIS and Data\nLab at 77 Massachusetts Avenue in Cambridge.\nGoogle appropriately picks roads that likely have sidewalks and routes you along those\nroads. It doesn't assume that you have a boat to cross the river on.\n\nThere are two main types of distance functions that exist in GIS: tools that use a line\nnetwork (roads, trains, etc.) and those that use a straight-line distance.\nIn the former, your paths have to remain on part of the network. You can see in the\nexample above the point in Back Bay. Using the road network, the distance from the\npoint to any areas 1 mile away is shown in brown. Red shows 1 mile from the point not\nusing the road network. It's clear that the distance traveled over road networks limits\nyour actual distance from the point, especially when there are significant barriers to\ntravel, like the Charles River.\nThe distance without regard to networks was calculated using the Buffer tool. The\nbuffer tool requires only a point to calculate distance.\nThe distance with regard to networks was calculated with the Network Analysis\nextension tool called Service Area. The Service Area tool requires a road network to\nfind distances. There are some basic network analysis tools in QGIS, but more extensive\nones in ArcGIS Pro.\n\nNetwork analyst tools are often used to vehicle routing or anytime you want to\ncalculate something using a road (or other transportation) network.\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\nRES.STR-001 Geographic Information System (GIS) Tutorial\nIAP 2022\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms"
        }
      ],
      "source_url": "https://ocw.mit.edu/courses/res-str-001-geographic-information-system-gis-tutorial-january-iap-2022/",
      "course_info": "RES.STR-001 | Non-Credit",
      "subject": "General"
    },
    {
      "course_name": "EarthDNA's Climate 101",
      "course_description": "The Climate 101 presentation was developed by Brandon Leshchinskiy in collaboration with Professor Dava Newman, MIT Portugal, and EarthDNA in an effort to mobilize young people as educators on the issue of climate change. The presentation addresses not only the science but also the economics and civics of climate change, incorporating a negotiation activity that brings key concepts to life.\nThis resource includes the slides and instructions for the presentation, along with an introductory video from Prof. Newman, a video of Leshchinskiy actually delivering the presentation to a classroom full of students, and extensive supporting materials that will help users to become climate ambassadors and deliver the Climate 101 presentation themselves.",
      "topics": [
        "Science",
        "Earth Science",
        "Climate Studies",
        "Environmental Science",
        "Science",
        "Earth Science",
        "Climate Studies",
        "Environmental Science"
      ],
      "syllabus_content": "",
      "files": [],
      "source_url": "https://ocw.mit.edu/courses/res-env-003-earthdnas-climate-101-fall-2019/",
      "course_info": "RES.ENV-003 | Non-Credit",
      "subject": "General"
    }
  ]
}