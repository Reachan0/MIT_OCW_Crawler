{
  "course_name": "Social and Ethical Responsibilities of Computing (SERC)",
  "course_description": "Social and Ethical Responsibilities of Computing (SERC), a cross-cutting initiative of the MIT Schwarzman College of Computing, works to train students and facilitate research to assess the broad challenges and opportunities associated with computing, and improve design, policy, implementation, and impacts.\nThis site is a resource for SERC pedagogical materials developed for use in MIT courses. SERC brings together cross-disciplinary teams of faculty, researchers, and students to develop original pedagogical materials that meet our goal of training students to practice responsible technology development through incorporation of insights and methods from the humanities and social sciences, including an emphasis on social responsibility.\nMaterials include the MIT Case Studies Series in Social and Ethical Responsibilities of Computing, original Active Learning Projects, and lecture materials that provide students hands-on practice and training in SERC, together with other resources and tools found useful in education at MIT. Original homework assignments and in-class demonstrations are specially created by multidisciplinary teams, to enable instructors to embed SERC-related material into a wide variety of existing courses.\nThe aim of SERC is to facilitate the development of responsible “habits of mind and action” for those who create and deploy computing technologies, and fostering the creation of technologies in the public interest.",
  "topics": [
    "Engineering",
    "Computer Science",
    "Artificial Intelligence",
    "Teaching and Education",
    "Curriculum and Teaching",
    "Higher Education",
    "Engineering",
    "Computer Science",
    "Artificial Intelligence",
    "Teaching and Education",
    "Curriculum and Teaching",
    "Higher Education"
  ],
  "syllabus_content": "",
  "files": [
    {
      "category": "Assignment",
      "title": "RES.TLL-008 Social and Ethical Responsibilities of Computing (SERC), 6.864 Assignment 2 Task A",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/res-tll-008-social-and-ethical-responsibilities-of-computing-serc/0ae39a79ffc5fe4b546f9fd4d37f7e36_MITRES-TLL008F21-6864taska.pdf",
      "content": "6.804/6.864 HW2 TASK A: Comment Moderation\nSocial media platforms and other online forums are an increasingly common venue for\ndiscourse. But unfortunately, they have also created avenues for online harassment. A recent\nPew Research Center survey found \"41% of Americans have been personally subjected to\nharassing behavior online, and an even larger share (66%) has witnessed these behaviors\ndirected at others.\"1\nThe effects of online harassment on the victim can be severe: from compromising their privacy\nto threatening their physical safety. And there are also significant negative consequences on\nthe quality of these online platforms: both experiencing and simply witnessing harassment\nsilences users and can ultimately drive them off online spaces. In its \"milder\" forms, toxic\ndiscourse can still foster a negative and hostile environment.\nWhile employing moderators to read through and mark toxic comments is one potential\nmitigation, it's difficult to scale. Recent efforts have tried to utilize technology to help with\ncomment moderation efforts -- for example, by building machine learning models to identify\nabusive comments. These might be used in a variety of ways, from helping human moderators\nprioritize what to look at, to allowing readers to filter what comments they see.\nThese models are most likely trained on data consisting of past comments annotated by\nwhether or not they contained toxic speech (or how much). In this part of the assignment,\npretend you're on a research team at a new social media company that's collecting this data.\nYou have a set of comments scraped from Wikipedia, and now you want to label them. You\nhave a budget to hire annotators, but you need a labeling scheme and instructions to give\nthem.\nHere are some examples of what the comments look like:\n●\nYour comments on my discussion page are rude, arrogant, bullying and\ntotally inappropriate. Napoleon complex is a stub and you might learn\nsomething about yourself by improving it, little boy.\n●\nhello old and crazy man.....\n●\nPrick. Gimme some time to flesh things out. Stop being such a prick.\n●\nSo when is someone going to warn YOU about your toxic attitude then?\nTell me that. Tell me when someone's going to give you a block warning\nfor the bullshit you've pulled on Wikipedia, like getting into\narguments with people and issuing blocks to them when you don't like\nhearing the truth.\n●\nSurely concerns re: fossil fuels/alternative energy sources, pollution\nand other environmental concerns should be included with the mention of\nanimal rights.\n●\nI have restored material that was removed and added a substantial\nreference within the text and also tried to add some perspective and\nalso some copyediting. I would appreciate those of you who feel the\n1 https://www.pewresearch.org/internet/2017/07/11/online-harassment-2017/\n\ninformation restored is unfounded taking a look at the references at\nthe bottom of the page. With the opening of the KGB archives a flood of\nmaterial has become available.\n●\nStop being such a goddamn prick. The article will be sorted out in\ntime. Meanwhile spend some time away from wikipedia. And do normal\nthings. for instance leave your parent's basement.\n●\nYou are full of shit sir. You are clearly one of those racists who\nlurk all over the internet looking to shut down viewpoints that differ\nfrom yours and expose truths covered in fantasy. There is NO reason\nthat you should have blocked me or even said anything. What you should\nhave done is to reply to what was written with intelligence. Since you\ndid not, it is clear that you lack it. You are the prime reason why\nthe internet community is finally realizing that this site is a joke\nand is covered by clowns with agendas. That is, people who want to put\nforth propaganda.\n●\nUSA is #1 and we made the facebook, deal with it. Oh wait, all you\nkids on facebook do instead is cry about things on the facebook. Make\na stupid facebook group about it, why don't you.\n●\nNo! This is a GROUP EFFORT! Wikipedia is a collaborative COMMUNITY\nand there are no school essays here. The article needs to be more\nprofessional and adopt a better title besides the references. This is\nall that needs to be done, so get off your high horse and accomplish\nwhat you want to see done. If you have these goals, then put yourself\nto the test of solving this problem. That's what I do whenever\nsomething perturbs me. You're just looking for a fight about something\nyou admittedly care nothing about. How about I come by your house and\ncriticise your gardens? ``Why?`` You say. ``Because they are too ugly\nand I don't like the way they don't blend in with the neighbours'\nyards. So tacky, but I'm only passing by and I've never been down this\nroad before.``\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\nRES.TLL-008 Social and Ethical Responsibilities of Computing (SERC)\nFall 2021\nFor information about citing these materials or our Terms of Use, visit:\nhttps://ocw.mit.edu/terms"
    },
    {
      "category": "Resource",
      "title": "Active Learning Project Exploring the Functionalities, Data and Interfaces of a Modern Online Advertising System",
      "type": "DOCX",
      "source_url": "https://ocw.mit.edu/courses/res-tll-008-social-and-ethical-responsibilities-of-computing-serc/1ac96d823bf0485acf3d0aafabb52d43_RES-TLL008F21-ALP-ELO_Practice_Lab.docx",
      "content": "Active Learning Project Exploring the Functionalities, Data and Interfaces of a Modern Online Advertising System\nAuthored by: Grace Chuan, Emily Jiang, and Bhavik Nagda\n\nAssociated MIT SERC Case Study:\n\nIdentity, Advertising, and Algorithmic Targeting: Or How (Not) to Target Your \"Ideal User\"\n\nKant, T. (2021). Identity, Advertising, and Algorithmic Targeting: Or How (Not) to Target Your \"Ideal User.\" MIT Case Studies in Social and Ethical Responsibilities of Computing, (Summer 2021). https://doi.org/10.21428/2c646de5.929a7db6\n\nOverview:\n\nThe last two decades of digital transformation have revealed our broad societal dependence upon data-rich, \"Big Tech\" firms. From seemingly humble beginnings to present-day backlash and congressional scrutiny, these companies have weathered good and bad times alike. Facebook is, perhaps, the epitome of this Big Tech archetype. The company capitalizes on its users' time, selling advertising space for its Facebook, WhatsApp, and Instagram platforms. As you'll notice in the following lab, Facebook is relevant in digital advertising for many types of organizations, including small and medium-sized businesses, Fortune 500s, restaurants, and political campaigns.\n\nAs we explore the ethical implications of digital advertising, it's particularly helpful to concretely identify the functionalities, data, and interfaces driving ad systems in the modern era. The following lab focuses on Facebook's Ads Manager with this in mind.\n\nImagine, for the next hour, that you're the owner of Beurre Bakery, a bakery and cafe chain with multiple locations throughout Boston and Cambridge. As owner, you've been reticent to transform the local, grassroots marketing that has been so effective over the past decade; however, competition has been intensifying, so you've decided to explore Facebook's Ads offering. Explore the following lab, revamping Beurre's digital marketing with an eye toward the societal and ethical implications of the data platform.\n\nStep 1: Enter Facebook Business's Ads Manager with the following login information.\nWe can use one account for several different pages/businesses.\nUsername: XYZ\nPassword: ABC\n\nStep 2: Click on the \"Ads\" tab in the left-hand bar to reach the Ad Center.\n\nStep 3: Click \"Ads Manager.\"\n\nStep 4: Within Ads Manager, click the green \"Create\" button.\n\nStep 5: You will need to choose a campaign objective from one of three broad categories: Awareness, Consideration, and Conversion.\n\nQ1: What differentiates these three categories?\nQ2: In what situations would you select each category over the others?\nQ3: Under \"Awareness\", there are two objectives: \"Brand awareness\" and \"Reach.\" How might these two objectives target audiences differently?\n\nStep 6: Select \"Brand awareness\" as your campaign objective.\n\nStep 7: Name your campaign!\n\nStep 8: Scroll through the special ad categories. You will see four different options.\n\nQ4: What is the purpose of selecting a special ad category, and why might Facebook ask advertisers to do so if they have an ad that falls under one of these four categories?\nQ5: Choose two of the four categories, and provide real-world examples of how running an ad within each of them might lead to unintended social impacts.\nQ6: For ads that fall under the first three categories listed, some targeting features are disabled, such as \"Look-Alike audiences,\" which allows the user to target audiences by age, gender, ZIP code, or other demographic identifiers. Why do you think Facebook made this a choice for these three categories specifically?\nQ7: In addition to Look-Alike audiences, there also exists a \"Special Ad Audience\" feature that determines an audience based on similarities in online behavior and activity. Do you think this is a better alternative to a Look-Alike audience from an advertising and/or ethical standpoint? Why or why not?\nQ8: Refer to section \"Database Ethics: Targeting from the Developer's Perspective\" in the case study. Based on Kant's discussion of session-based recommendation vs. traditional identity profiling, what are the tradeoffs of an advertiser deciding to implement one over the other?\n\nStep 9: Click \"Next\" to reach the next page, \"New Ad Set.\"\nAn ad set is a specific ad you are designing for an ad campaign; therefore, one campaign can run multiple ad sets. Ad sets can target different audiences and be scheduled to appear on feeds at different times.\n\nStep 10: Name your ad set!\nStep 11: Click \"Learn More\" in the \"Dynamic Creative\" section, and read the article provided.\n\nQ9: The dynamic creative feature is still a form of targeting, but is less explicitly focused on identifying features such as race or gender. What are some possible drawbacks or limitations to this approach?\n\nStep 12: Within the \"Audience\" section, select \"Create New → Lookalike Audience.\"\n\nStep 13: Click on \"Create New Source → Custom Audience with LTV.\" A custom audience allows Facebook to construct an audience for your ad based on the customer dataset you provide and your choices about which features to optimize for. This audience will be composed of individuals outside your own customer list.\n\nStep 14: Upload the provided .csv as your customer list.\n\nQ10: What are the ethical implications of businesses being able to target audiences who resemble individuals described in this customer list by the features included?\n\nThe key feature in this dataset is the \"Customer Value\" column. The customer value is a numeric representation of the net profit you predict will be attributable to a given customer over the duration of your relationship with them. The Lookalike Audience feature will target more people who are similar to the individuals with the highest customer values.\n\nQ11: What are three different ways of potentially measuring customer value, and the ethical implications of each?\n\nStep 15: Select the \"Customer Value\" column and name the customer list to move on to the next page.\n\nStep 16: After clicking \"Next,\" be sure to assign the correct identifiers to each column of the dataset.\n\nStep 17: Upload the list. Facebook is now hashing the data.\n\nWhen you upload your customer list in Ads Manager to create a Custom Audience, the information in your list is hashed before it's sent to Facebook. Hashing is the application of cryptographic primitives to map data to representative numerical values. Facebook's hash functions are one-way functions: you cannot recover the original data from the hashed data.\n\nFacebook uses this hashed information and compares it to the company's own hashed information. Then, Facebook builds your audience by finding the Facebook profiles that match the specified criteria, and creates a Custom Audience from those matches. After your Custom Audience is created, the matched and unmatched hashed information is deleted.\n\nQ12: How does hashing individuals' data and then deleting it potentially preserve (or not preserve) people's privacy? Do you think hashing makes a difference in ameliorating the negative implications of targeting? Why or why not?\n\nStep 18: Complete the process of selecting your lookalike source.\n\nStep 19: Select an audience location based on where you think your ad would be most impactful given your business description.\n\nStep 20: Select an audience size -- the larger the percentage, the broader the audience.\nQ13: What are the equity implications of selecting a broader or narrower audience?\n\nStep 21: Finish creating your audience and exit the window.\n\nStep 22: Adjust age and gender group.\n\nStep 23: Open \"Detailed Targeting.\"\n\nThis feature includes and/or excludes certain audiences into tiers. For example, you could add vegetarians to \"Include/Exclude,\" and people who are interested in gardening to \"Narrow Audience.\" Doing so would result in the following setup:\nInclude/Exclude: Frequent travelers or vegetarians\nNarrow Audience: People interested in cooking or gardening\nNarrow Further: College grads\nOne criterion from each tier must be met for inclusion/exclusion; for example, a vegetarian college graduate who is interested in gardening would be in the audience, but a frequent traveler interested in cooking who isn't a college graduate would not be.\nQ14: How do you think the ethics of Detailed Targeting compare to the other targeting methods we've seen so far?\n\nStep 24: Save your ads, but do not hit publish!\n\nDone!\n\nDiscussion questions:\nWhat was your most surprising finding while performing the lab? How did the ad-targeting system compare to what you expected?\nDo you feel differently about the ethics of targeted advertising depending upon the type of ad being run (e.g., fashion, politics, housing)? If so, how and why?\nWhat benefits or drawbacks do you observe to Facebook's advertising model, for Facebook and/or society?\nIs there a need for the government to intervene? If so, what role should the government play? And if not, why not?\nWhat are the responsibilities of employees within an organization that commits ethical violations?\n\nFacebook screenshots (c) Facebook. All rights reserved. This content is excluded from our Creative Commons license. For more information, see https://ocw.mit.edu/help/faq-fair-use/\n\nWall Street Journal article excerpt (c) Wall Street Journal/Dow Jones & Company Inc. All rights reserved. This content is excluded from our Creative Commons license. For more information, see https://ocw.mit.edu/help/faq-fair-use/\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\n\nRES.TLL-008 Social and Ethical Responsibilities of Computing (SERC)\nFall 2021\n\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms"
    },
    {
      "category": "Resource",
      "title": "Active Learning Project on Developing Codes on Conduct",
      "type": "DOCX",
      "source_url": "https://ocw.mit.edu/courses/res-tll-008-social-and-ethical-responsibilities-of-computing-serc/0ddc2160f045ce3f896d53ad99980c2a_RES-TLL008F21-ALP_Open_Technologies_Open_Communities.docx",
      "content": "Active Learning Project on Developing Codes on Conduct\nAuthored by: Sohini Kar, Sarah Vu, and Jenny Cai\n\nAssociated MIT SERC Case Study:\nHacking Technology, Hacking Communities: Codes of Conduct and Community Standards in Open Source\nDunbar-Hester, C. (2021). Hacking Technology, Hacking Communities: Codes of Conduct and Community Standards in Open Source. MIT Case Studies in Social and Ethical Responsibilities of Computing, (Summer 2021). https://doi.org/10.21428/2c646de5.07bc6308\n\nTable of Contents\nIntroduction\nCreating a Github Code of Conduct\nOption 1: Using the Built-in Code of Conduct\nOption 2: Course Staff Design a Code of Conduct Template\nCode of Conduct Guidelines\nTeam Purpose and Pledge\nList of Standards\nUnacceptable Behavior\nEnforcement\nAdditional Sections\nProject Ethics\nConclusion\n\nIntroduction\n\nThis project guides students in the creation and design of codes of conduct (CoCs) for users of the technology they develop. Many MIT classes, including WebLab, 6.08, 6.031, 6.170, and BattleCode, all have \"final project\" team assignments where groups of students build applications and share a code base; students of these classes could benefit from this ALP.\n\nIn this document, we focus on creating CoCs for team-based projects in Github-hosted project repositories. README files are considered an essential and default aspect of repositories, and we believe a code of conduct should be equally essential for both developers and users. After creating the CoC, the team may choose to enforce the document passively, by only applying restorative justice when guidelines have been violated, or actively, by asking team members to periodically reflect on the document throughout the term.\n\nWhile writing the file, it might be helpful to bear in mind the following questions:\nWhy might creating a code of conduct be helpful? Do you feel it's necessary to do so? (Note: this may be circumstantial.)\nWhat is the goal of this team? Which values will be most salient to advancing this mission?\nWhat types of behavior will not be tolerated? If harassment is a prohibited behavior, how can you create specific guidelines that will identify what would be classified as harassment (even if unintentional)?\nHow can the team rigorously enforce this code of conduct? Who will benefit from adhering to the rules outlined in this document? Who is responsible for its passive and/or active enforcement?\n\nOur active learning project will guide users through the creation of codes of conduct for any Github-hosted team projects; however, the guiding questions and thought process can be applied to any team project.\n\nThis project directly connects to real-world applications and promotes best practices for computer science students at MIT. While the codes do not have to replace any team contracts already being used in classes, merging them with existing practices may encourage further use of codes of conduct in other projects, generally resulting in more open and inclusive communities. Below, we detail a guideline to creating a code of conduct, including a guide on how to create and add one to a Github repository.\n\nCreating a Github Code of Conduct\nThis active learning project uses Github as an example because it is a common classroom tool; however, note that codes of conduct can be adapted and applied to other code-sharing bases and team projects.\nOption 1: Using the built-in Code of Conduct feature\nGitHub already has code of conduct templates available; the video below demonstrates how one can be created. This option requires the least amount of work from course staff, but they should read through the template to ensure it aligns with their class goals before choosing this option.\n\nOption 2: Course Staff Design a Code of Conduct Template\nCodes of conduct may vary depending upon the context of the projects given to students. (For example, some projects may or may not be intended for the general public, so creating \"community\" guidelines can differ). However, at the very least, any code of conduct template given to students must contain the content within the guideline described in the \"Code of Conduct Guidelines\" section of this paper. Below are two demos from GitHub Classroom; course staff can create a template repo with an existing code of conduct for students to clone and create assignments from.\n\nCode of Conduct Guidelines\nIn this section, we guide users through important sections of a standard code of conduct applied to a classroom team project. We describe flexible guidelines and alternatives, so these sections may be adjusted as necessary.\nTeam Purpose and Pledge\nPresent a brief overview of team goals and the project description. Provide a purpose and motivation for the project, as well as an overview of the code of conduct.\nGenerally describe the goals for the code of conduct and which values the team considers important\nConsider including aspects from standard team contracts, such as timelines, deliverables, and general project goals.\nConsider including project rubric, work breakdown by member, and other project-related information.\n\nList of Standards\nList and describe best practices for maintaining a strong sense of community and inclusivity within the project.\nDetail behaviors that lead to an inclusive and positive project and team environment.\nOutline what respectful, positive, and considerate conversations look like, as well as general standards for detailing and signaling an open and accepting environment.\nMay include general team contract points, including which forms of communication to use or when/how often meetings occur, but the main goal should be to define respectful conduct.\nMay include examples of positive situations or successful conversations.\n\nUnacceptable Behavior\nDefine what actions or conversations are disallowed in order to maintain a positive working environment.\nProvide examples of behavior by team members that would be considered inappropriate for the project's setting.\nMay include threatening or bullying speech, spam, insulting comments, or actions that invade privacy.\nMay include any behavior specifically disallowed by the team through discussions and team meetings.\n\nEnforcement\nProvide a brief outline of what to do if the code of conduct is violated.\nWhat instances of negative or harmful behavior should be resolved by the group members, and how? Which situations should be resolved by the team, and which should be addressed by outside parties such as course staff?\nDescribe courses of action that could be taken in cases where a team member is not as active as required, or if a team member feels uncomfortable with any conversations or work related to the project.\n\nAdditional Sections\nHere, we provide examples of additional sections that may be included in a code of conduct. These may not be relevant for all projects, but incorporating these sections may serve to create productive conversations for the team and class.\nProject Ethics\nDiscussions addressing potential ethical problems related to the specific project. For example, describe the ethical pitfalls of models or datasets used for a machine learning project, or the problems related to data privacy or misuse for a security project.\nThis section allows course staff to integrate more discussions and conversations about the social and ethical responsibilities of computing into class projects. It may be used as an assignment in and of itself for classes focused on generating more conversations about ethics (e.g., 6.806, 6.036, or 6.170).\nReal-World Examples\nAs part of the assignment, groups can read a short article or case study about a real-world code of conduct before writing their own; this would both ground the assignment in reality and encourage students to think more critically about the reasons codes of conduct have been encouraged, such as the following.\nHacking Technology, Hacking Communities: Codes of Conduct and Community Standards in Open Source by Christina Dunbar-Hester\nAfter Working at Google, I'll Never Let Myself Love a Job Again, https://www.nytimes.com/2021/04/07/opinion/google-job-harassment.html\nScope\nDefine the scope of the code of conduct.\nDoes it apply both within project spaces and public spaces when an individual is representing the project or its community? Does it only apply within online settings, or does it apply to in-person conversations?\n\nRecommendations for CoC Discussions\nConversations about creating a code of conduct may reveal conflicting values between team members, so it is important for teaching staff to maintain discussion guidelines. One resource from the University of Michigan outlines the following set of guidelines for planned, high-stakes conversations:\n\nIdentify a clear purpose\nEstablish ground rules\nProvide a common basis for understanding\nCreate a framework for the discussion that maintains focus and flow\nInclude everyone\nBe an active facilitator\nSummarize discussion and gather student feedback\n\nOne difficulty we perceive in following this template is the ability of course staff to be present for every team's CoC discussion, especially in classes with few TAs and 100 or more students. Without an active, trained facilitator, the risk of CoC conversations ending poorly increases, so course staff should plan accordingly. One solution is to remove a lecture or recitation during one week of the semester to set aside time for team meetings with a course instructor/TA.\n\nAnother template for facilitating CoC discussions is \"SPECS\", developed by the University of Washington's Center of Neurotechnology (CNT) Neuroethics Trust. It involves an individual survey of ethics topics and a facilitated group discussion, and can be adapted to CoC discussions by providing students with a guiding survey to answer before taking part in a facilitated conversation. During this discussion, students would discuss their survey answers and motivations under the supervision of a course staff member. Benefits of this method include that it saves time (students take the survey and reflect on it before meeting), and that discussion is more controlled because it centers on specific cases and questions presented by the survey (which, we assume, has been created by course staff).\n\nCourse Staff Considerations\nHow will defining and resolving disputes play out among students?\nRetributive justice approaches to conflict -- will students feel about how this approach influences interpersonal dynamics? Will this resolution approach create too much reliance upon authority figures (course staff) when resolving issues? How will staff choose to handle instances where unacceptable behavior is reported?\nOnce behavior has been reported to course staff, the issue is out of students' hands and their code of conduct \"enforcement\" is no longer in play; this removes student autonomy and input.\nWill staff work with students as a group to decide what happens when behavior is reported? (This would be taking a more \"restorative justice\" type of approach.)\nRestorative justice approaches encourage students to figure out how to resolve conflicts amongst themselves.\nHave students talk to each other about issues, such as a member not putting in enough work. Why has this been an issue? How can the team accommodate members with extenuating circumstances?\nMake decisions based on shared values (which may differ from those of other groups or the course staff). For example, in a situation where someone is not meeting a deadline due to personal reasons, perhaps the value of care is more important than the value of achievement.\nNote that students should still be encouraged to work with course staff when they feel they are out of their depth. We do not want them to feel they have to handle everything.\nHow will the process of developing a code of conduct influence students' thinking of what is necessary to address DEI issues in open-source communities.\nIf students think that developing a code of conduct is all that needs to be done, then codes of conduct simply become \"security theater,\" in which actions taken give the feeling of improving the situation, while accomplishing little or nothing else.\n\nConclusion\nBy encouraging students and instructors to incorporate a code of conduct into team-based projects within an undergraduate curriculum, our active learning proposal is intended to promote a more inclusive environment for student teams working on Github-based projects, as well as to increase mindfulness with respect to the ethical implications of the technology the students create. To develop a CoC, instructors may either use the default CoC template provided or create a template repo with their own CoC (the latter is useful when the structure of the desired CoC deviates from GitHub's provided one).\n\nWhen writing the document, there are several sections students must fill out, including: a team purpose, list of standards, list of unacceptable behaviors, and mechanisms for enforcement. While these form the bare minimum for a code of conduct, we provide additional sections students may find useful: a discussion of project ethics, which allows students to dive into the ethical and social issues that may result from the use of their final product; a deep dive into real-world examples when a CoC was (or was not) effective; and a broader scoping that covers which spaces and conversations the CoC should apply to.\n\nOnce the CoC is finally drafted out, several more discussions should take place. The first deals with CoC enforcement: students should decide whether to let figures of higher authority handle CoC violations or resolve conflict amongst themselves. After that, it'd be useful for students to recognize and discuss the limitations of their CoC -- namely, that it won't address larger diversity, equity, or inclusion issues within open-source communities, as its scope is limited to the single community it's designed for.\n\nCreating a code of conduct is just the first step toward affecting change and making open-source communities more welcoming and transparent. By nudging students and instructors toward these essential conversations about behavior, community standards, and the implications their work may have on others, our project hopes to take the first step toward creating more self-aware and inclusive technology, as well as more just technology development communities.\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\n\nRES.TLL-008 Social and Ethical Responsibilities of Computing (SERC)\nFall 2021\n\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms"
    },
    {
      "category": "Resource",
      "title": "Cyber Crisis Scenario",
      "type": "DOCX",
      "source_url": "https://ocw.mit.edu/courses/res-tll-008-social-and-ethical-responsibilities-of-computing-serc/mitres_tll008_17_46_cybercrisis2.docx",
      "content": "Cyber Crisis Scenario\n\nInstructions for Implementation\n\nBackground\n\nThe cyber crisis scenario was originally designed as an end-of-semester exercise for an MIT undergraduate political science course, 17.46: U.S. National Security Policy. The scenario was intended to provide students with an opportunity to apply core class concepts, which included an understanding of the interagency process, the various actors involved in making and implementing national security policy, the law of armed conflict/international law, and the changing character of international crises.\n\nAlthough the scenario was designed to meet the teaching objectives of a specific class, instructors could also implement the scenario in courses on U.S. Foreign Policy, emerging technology and international security, the politics of cybersecurity, or U.S.-China relations. Instructors should feel free to modify elements of the scenario in order to tailor it to their teaching objectives.\n\nDevelopment of the crisis scenario was generously supported by MIT Schwarzman College of Computing's Social and Ethical Responsibilities of Computing (SERC) program.\n\nThe scenario was designed by Erik Lin-Greenberg (Assistant Professor, MIT Department of Political Science) and Lily Tsai (PhD Candidate, MIT Department of Electrical Engineering and Computer Science).\n\nImplementation\n\nThe crisis scenario was implemented over two class sessions (each 80 minutes long).\n\nPre-class Preparation\n\nTwo days prior to the first of these classes, the instructor randomly assigned students into five teams of approximately six members each: 1) Department of State; 2) Department of Defense; 3) Department of Homeland Security; 4) Department of Justice; 5) Office of the Director of National Intelligence. Groups larger than ~7 may be more difficult to manage and quieter students may feel less inclined to participate.\n\nStudents were not assigned to specific roles within these teams (i.e., there was no designated Secretary of Defense, etc.)\n\nThe instructor emailed the first page of the crisis scenario packet (\"The Road to Crisis\") to students two days prior to the first crisis scenario class.\n\nClass Session 1\n\nWhen students arrived in class, they sat at tables organized by their team assignment (e.g., one table for State Department, one for Defense Department etc.).\n\nThe instructor then handed all students a copy of the second page of the crisis scenario packet (\"Move 1\")\n\nStudents had 30 minutes to review the tasks for their team and to address responses. At the end of the 30 minutes, each team briefed the National Security Advisor on their recommendations (The National Security Advisor was played by a PhD student, but a course instructor could take on this role).\n\nThe teaching team member playing the National Security Advisor followed up with each team's briefer, asking questions 1) to ensure: the recommendations aligned with the president's objectives introduced in the Road to Crisis; 2) to assess whether students had given thought about how their recommended actions might be perceived by international actors (NB: this was intended to tie back to concepts of perceptions/misperceptions and inadvertent escalation covered in the assigned reading materials earlier in the semester); and 3) to assess whether students representing different departments and agencies were coordinating with other teams (NB: this was to help emphasize the role of the interagency process).\n\nStudents were given a short break and the instructor then distributed the third sheet of crisis scenario packet (\"Move 2\").\n\nThe National Security Advisor told the students that several days had transpired since the briefing and that president had implemented some of their recommendations (The instructor can select any/all of the recommendations put forward by students at the end of Move 1).\n\nStudents then had 35 minutes to work through Move 2. The teaching team then repeated the briefing procedure from Move 1. In Move 2, however, there is less direct guidance about the tasks for each team, allowing students to think about the role their organization would likely play in an actual contingency. This was an intentional design choice to help reinforce student learning about the rules and responsibilities of different government agencies.\n\nClass Session 2\n\nDuring the final class session of the semester, students worked through Move 3 and discussed what they had learned from the crisis scenario.\n\nFollowing the format used in Class session 1, the instructor provided students with page 4 of the crisis scenario packet (\"Move 3\"). This move was scheduled for 40 minutes as it 1) included several significant events and 2) did not provide students with defined tasks. The additional time was intended to allow students to process the events and to think about their department's role in providing a response.\n\nAt the end of the 40 minute period, each team then briefed the National Security Advisor, who asked students questions similar to those outlined above.\n\nAfter all teams had briefed, the class ended the exercise and held a facilitated discussion about lessons learned from the crisis scenario (and more broadly, on the use of scenarios as a learning tool). Potential discussion questions are on the next page.\n\nPotential Discussion Questions:\n\nHow has technology changed the character of international crises?\n\nWhat did the scenario teach you about the role of the strategic implications of technology on international security?\n\nWhat key challenges did your teams face when dealing with new technology in the crisis scenario? (e.g., trust in AI analysis, attributing blame for cyber actions, etc.)\n\nWhat key international relations theories did the crisis scenario help reinforce?\n\nWhat, if anything, did the scenario teach you about U.S.-China Relations?\n\nWhat, if anything, did the scenario teach you about crisis decision-making?\n\nWas it challenging to coordinate with other departments/agencies during the simulation? Why or why not?\n\nDid China always respond in the way you thought they would?\n\nWhat types of actors had an outsized influence in the scenario? Put differently, what actors had a bigger influence than you anticipated (e.g., protestors, hackers)? What actors had less of an impact/played less of a role?\n\nAre scenarios a useful tool for studying international relations? Why or why not?\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\n\nRES.TLL-008 Social and Ethical Responsibilities of Computing (SERC)\nFall 2022\n\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms"
    },
    {
      "category": "Resource",
      "title": "Design Decisions",
      "type": "DOCX",
      "source_url": "https://ocw.mit.edu/courses/res-tll-008-social-and-ethical-responsibilities-of-computing-serc/b89d2884415283f892633d8ab97dd456_MITRESTLL-008F21-6170designReflection.docx",
      "content": "Design Decisions\n\n1. Insert your short and compelling design decision title phrase\n\nBegin your design decision discussion with introducing the decision and the rationale behind why you chose it but be sure to discuss any limitations this choice still has.\n\nAlternatives Considered: Then go on to listing alternative design choices you may have considered and discuss why you didn't choose them, comparing them to the design you did choose.\n\n2. Insert your short and compelling design decision title phrase\n\nBegin your design decision discussion with introducing the decision and the rationale behind why you chose it but be sure to discuss any limitations this choice still has.\n\nAlternatives Considered: Then go on to listing alternative design choices you may have considered and discuss why you didn't choose them, comparing them to the design you did choose.\n\n3. Insert your short and compelling design decision title phrase\n\nBegin your design decision discussion with introducing the decision and the rationale behind why you chose it but be sure to discuss any limitations this choice still has.\n\nAlternatives Considered: Then go on to listing alternative design choices you may have considered and discuss why you didn't choose them, comparing them to the design you did choose.\n\n4. Insert your short and compelling design decision title phrase\n\nBegin your design decision discussion with introducing the decision and the rationale behind why you chose it but be sure to discuss any limitations this choice still has.\n\nAlternatives Considered: Then go on to listing alternative design choices you may have considered and discuss why you didn't choose them, comparing them to the design you did choose.\n\nEthical / Social Reflection\n\nDescribe how conducting the A4 reflection informed your design process in this assignment. In particular, has your interface design changed as a result - how, or why not? Also, are there other social/ethical implications that you encountered when translating your wireframes into a working implementation?\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\n\nRES.TLL-008 Social and Ethical Responsibilities of Computing (SERC)\nFall 2021\n\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms"
    },
    {
      "category": "Resource",
      "title": "Ethical Implications",
      "type": "DOCX",
      "source_url": "https://ocw.mit.edu/courses/res-tll-008-social-and-ethical-responsibilities-of-computing-serc/d9fd91777252a2cc082f4ff820c42b6b_MITRESTLL-008F21-6170ethical.docx",
      "content": "Ethical Implications\n\nAnswer the following questions. In your answers, please distinguish which implications follow from your conceptual design and which follow from your UI design.\n\nDid you make cultural or other assumptions about your users that affect how they interact with Fritter?\n\nWould an effective use of design heuristics to maximize engagement with Fritter be manipulative?\n\nHow would you adjust your design if your only goal were to: get children addicted to Fritter? or make it hard for older people to use Fritter? or stop fake news spreading? or prevent harassment? How, if at all, do your answers to these questions inform how you would actually design Fritter?\n\nYou have the option to allow users to see which other users have upvoted a Freet. What forms of engagement between users (positive or negative) would be encouraged by allowing this?\n\nIn A3, we asked about stakeholders who aren't your immediate users. Identify a design choice you faced that would benefit or harm such a stakeholder, and explain how.\n\nWhat are the accessibility implications of your design for people with different abilities?\n\nOne of the heuristics is to \"speak the user's language.\" In retrospect, assuming you followed this, can you identify what kind of user you had in mind?\nMIT OpenCourseWare\nhttps://ocw.mit.edu\n\nRES.TLL-008 Social and Ethical Responsibilities of Computing (SERC)\nFall 2021\n\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms"
    },
    {
      "category": "Resource",
      "title": "Fritter User Test",
      "type": "DOCX",
      "source_url": "https://ocw.mit.edu/courses/res-tll-008-social-and-ethical-responsibilities-of-computing-serc/16a11f2babb9f1c77c67da33a4a14054_MITRESTLL-008F21-6170user.docx",
      "content": "Fritter User Test\n\nSpecify Tasks for the User completed for your user test\nTask 1: User upvotes another user's freet, then removes their upvote\nTask 2: User follows another user, then checks their feed\n....\nTask n: User refreets another user's freet\n\nSummary of Observations\n\nDiscuss your observations you had as you observed your user go through the tasks you provided them.\n\nChanges in Responses to UI\n\nNote any changes you will make to your UI in response to what you observed from your user test.\nMIT OpenCourseWare\nhttps://ocw.mit.edu\n\nRES.TLL-008 Social and Ethical Responsibilities of Computing (SERC)\nFall 2021\n\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms"
    },
    {
      "category": "Resource",
      "title": "Heuristic Evaluation",
      "type": "DOCX",
      "source_url": "https://ocw.mit.edu/courses/res-tll-008-social-and-ethical-responsibilities-of-computing-serc/b91f260be72dba5c48c53d9bab5b5f61_MITRES-TLL-008F21-6170Heuristic.docx",
      "content": "Heuristic Evaluation\n\nFor each heuristic, you should cite one example in your wireframe either illustrating how the heuristic suggests an improvement, or pointing to a design decision you made that supports the heuristic.\n\nFitt's Law\n\nSpeak the User's Language\n\nConsistent Naming & Icons\n\nInformation Scent\n\nFollow Conventions\n\nShow Location & Structure\n\nAccelerators\n\nKeep Paths Short\n\nUndo & Cancel\n\nPerceptual Fusion\n\nGestalt Principle of Grouping\n\nRecognition vs. Recall\n\nAnticipation & Context\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\n\nRES.TLL-008 Social and Ethical Responsibilities of Computing (SERC)\nFall 2021\n\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms"
    },
    {
      "category": "Resource",
      "title": "Module: Big Data and Personal Privacy",
      "type": "DOCX",
      "source_url": "https://ocw.mit.edu/courses/res-tll-008-social-and-ethical-responsibilities-of-computing-serc/8283d95f3ec08827137334de3d3959ca_MITRES-TLL008F21-STS-012module.docx",
      "content": "Module: Big Data and Personal Privacy\n\nReadings:\n\nSarah Valentine, Impoverished Algorithms: Misguided Governments, Flawed Technologies, and Social Control. (2019). 46 Fordham Urb. L.J. 364.\n\nBoyd, Danah, and Kate Crawford. 2012. \"Critical Questions for Big Data.\" Information, Communication & Society 15(5): 662-679.\n\nAt home exercise:\n(Voluntary)\n\nLearn more about your data rights.\nhttps://www.dataprotection.ie/en/individuals/know-your-rights/right-access-information\nhttps://tapmydata.com/features/#superpower\nAccess your data from three websites/services you frequently use (Examples: Facebook, Twitter, Instagram, Google etc.)\nTip: Tapmydata is an application that makes it easy to send these requests. (Remember however that after a certain point in the process, they might ask you to use your data in a particular way.)\nWrite and post a short 200-word reflection on what you found and whether what you found surprised you. Think reflection should incorporate insights from the two readings for this week, particularly the sections on data triangulation and commercialization.\nRead your classmates posts.\n\nIn class:\n\nDiscussion of the key points of the articles and of the student responses.\n\nAims:\n\nTo find overlaps and differences in the experience of students learning about their right to privacy\nTo discuss whether they believe existing rights to be adequate\nTo examine whether current ethical standards (such as those instituted by the GDPR) sufficiently protect their rights (as they exist or as they believe should exist).\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\n\nRES.TLL-008 Social and Ethical Responsibilities of Computing (SERC)\nFall 2021\n\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms"
    },
    {
      "category": "Resource",
      "title": "RES.TLL-008 Social and Ethical Responsibilities of Computing (SERC), 6.036 Lab 1.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/res-tll-008-social-and-ethical-responsibilities-of-computing-serc/a1509590b6e7e45cac07a269b11b3d75_RES-TLL008F21-6036_lab1.pdf",
      "content": "6.036 Spring 2021\nLab -- Separators\nInstructions\nThis lab is focused on getting you started in 6.036 and introducing you to some of the kinds of problems we will be thinking\nabout in this class.\nFor this first week only, the lab includes introductions by an instructor at the start of the lab section.\nIn 6.036 a large part of the learning happens by discussing lab questions with partners. You will be assigned to a breakout\nroom after introductions. Once you are in your breakout rooms, please complete this group self-partnering question with\nother people in your breakout room.\nGroup information\nCreate Your Group\nOnce you and your partner(s) are in a breakout room, you need to create a group.\nInstructions:\n(1) One of you should click here to create a group.\n(2) Everyone else should then enter the given new group name (including trailing numbers) into the box below\n(and press enter when done).\nName of group to join:\nReload this page anytime to refresh your group status (and to get a delete button, if you want to remove\nyourself from a group you've joined).\nGroups are limited to 3 persons max each, so that checkoff discussions can be inclusive.\nYou are not currently in any group\nThis 'Group Information' box will be similar to what you will see at the top of future labs as well.\n1/10\n\n6.036 Spring 2021\nNote: Write all your answers down somewhere you can share them with a staff member. Be prepared to discuss your\nanswers!\nCheckoff 1:\nCheck-in with a staff member, to confirm your attendance and that the setup is working for you.\nAsk for Help\nAsk for Checkoff\nNow let's get started!\n1) Finding Good Models\nMachine Learning is about using data that represent examples of a phenomenon in the world (such as how individual\nhumans respond to a medical treatment), in order to make predictions about new examples (how different humans will\nrespond to the same treatment).\nIn order to make predictions, however we must make the assumption that there is an underlying structure in the data and\nthat this structure extends to new, unseen data as well. But how can we know whether a prediction rule we have identified\nthat agrees with previous data, will be accurate on future data?\nIn this lab, we will practice making predictions from data and explore conceptual and more technical strategies for\nevaluating the effectiveness of prediction rules.\n1.1) Power in Numbers\nAcme Apparel is a company that has data from previous catalogs indicating which past customers ordered something from\nthe catalog and they are trying to decide which customers to mail catalogs to (yes, that's still a thing!) this holiday season.\nEach customer is represented in terms of two features (they could represent anything, such as age, address, previous buying\nhistory, etc.), so we can plot a point in 2D coordinates representing each person and label it according to whether they\nbought something last time: positive (shown as a green plus sign) and negative (shown as a red minus sign). We want to\npredict whether a brand new customer, characterized in terms of these same two features, will make a purchase.\nOur historical data looks like this:\nNote: Here we use x1 and x2 as axes instead of the typical x, y axis because as you'll see later, we use 'y' to denote\nsomething else!\n2/10\n\n6.036 Spring 2021\n1.1.1)\nSuppose there are 4 people who have not recieved a catalog. We collect information from them and represent them in the\nimage below using the four points marked as purple numbers. Which people do you predict will buy something? Why or why\nnot?\n1.1.2)\nAcme's marketing department studied the data and came up with a hypothesis about which potential customers will make a\npurchase, which is illustrated by the blue line below: points on one side are positive whereas points on the other side are\nnegative.\nhttps://introml.odl.mit.edu/cat-soop/6.036/labs/lab01\n3/10\n\n5/19/2021\n6.036 Spring 2021\nHow do you think this hypothesis will perform on future customers?\n1.1.3)\nThe Acme sales department comes up with a different hypothesis, shown in black below.\nHow do you think the black hypothesis will perform? If you had to choose between the blue and the black hypotheses, which\nwould you choose to use for future predictions? Why?\n1.1.4)\nMeanwhile, at Acme Apparel, the marketing department won the argument and so they mail out catalogs based on the first,\nsimple (blue) linear hypotheses. After the holiday rush, they make a plot of their new data and see this:\n4/10\n\n6.036 Spring 2021\nMarketing department (linear) hypothesis with both old and new data\nSales department (non-linear) hypothesis with both old and new data\n5/10\n\n6.036 Spring 2021\nDid using the simple,linear hypothesis to mail out catalogs result in a good outcome? Why or why not?\n1.1.5)\nWhich hypothesis should Acme use next holiday season? What might they have done differently to avoid mailing so many\ncatalogs to uninterested customers?\n1.1.6)\nThe engineering department decides they want to try their hand at developing a new hypothesis. The department collects\nboth new and old data from sales and marketing and divides it at random into two separate data sets, called A and B. They\nuse data set A to develop a new hypothesis and don't use data set B to develop the hypothesis.\nData set A (training) has 10,000 data points. Data set B (test) has 5,000 data points.\nThe engineers' hypothesis, when applied to data set A (training), makes wrong predictions on 5% of the data. When that\nsame hypothesis is applied to data set B (test set), it makes wrong predictions 10% of the time. What would you estimate\nthe error rate of applying this hypothesis to brand new data (neither A nor B) to be?\n1.1.7)\nFor the same setup as described above, how well do you think your hypothesis will perform in the real world if your data set\nB had 5 data points, versus if it had 5,000 data points?\n1.1.8)\nFor the same setup as described above, how well do you think your hypothesis will perform in the real world if your data set\nA had 10 points, versus if it had 10,000 points? Why? Note that the same setup as described above applies here.\n1.2) Comparing Apples to Oranges\nAcme Apparel (AA) is looking to expand to a new demographic (engineering college students), so they decide to use one of\nthe hypotheses their departments have developed (using data from existing AA college student customers) to determine\n6/10\n\n6.036 Spring 2021\nwhich college students to send their catalog to. AA also hires some consultants to gather some college student purchasing\npatterns data from a rival company specializing in engineering-themed apparel, Zenith Zapatos (ZZ).\n1.2.1)\nThey use a hypothesis developed by the engineering department which has a 5% error rate on the data set A and had 10%\nerror rate on data set B of existing Acme college student customers. They apply it to the college student customer data\nfrom ZZ and find it has a 35% error rate. What could account for this problem?\n1.2.2)\nHere is some actual data from AA current college student customers (left) and ZZ college-student customers (right). The\nengineering department finds another hypothesis, shown as the blue line below, that has the same error rate on both the\nAA data and the ZZ data. What do you think about this hypothesis? Should we use it for both populations? If not, what\nhypothesis or hypotheses would be better and why?\nCheckoff 2:\nHave a check-off conversation with a staff member, to discuss your answers until this point! While you're\nwaiting, please continue working on the lab.\nAsk for Help\nAsk for Checkoff\n2) A More Rigorous Evaluation\nAA and ZZ have merged to form A2Z and hired you as their chief data scientist! Luckily they have found a source of a huge\namount of data. Now, your job is to come up with some procedures for predicting how well classifiers you come up with will\nperform.\nNote the following notation and definitions, used throughout this problem:\n7/10\n\n6.036 Spring 2021\nA generator G is a function that takes as input n, the number of samples desired, and returns a (X , y) pair where X is\na d by n array of randomly sampled data points and y is a 1 by n array of their corresponding labels {+1, -1}.\ni\nA training dataset Dtrain is a set of labeled samples X , y generated by a generator G, where x represents the\ni\ni\nfeatures of an object to be classified (vector of real and/or discrete values), and y represents the label of x . (You can\nthink of i as the index for point xi.)\n2.1) Evaluating a classifier\nImagine that you have a generator G that pulls from a finite dataset of millions of points.\nLet's assume that Dtrain is one such output of the generator G.\nConsider the situation in which you have run a machine learning algorithm on some training dataset Dtrain, and it has\nreturned to you a specific classifier h. Your job is to design (but not implement yet!) a procedure for evaluating h's\neffectiveness as a classifier. (Want more on classifiers? Check the the notes on Linear Classifiers.)\nAssume we have a eval_classifier function that takes a classifier h, dataset D - a tuple of data and labels: (X, y) - and\nreturns the percentage of correctly classified data points as a decimal between 0 and 1. We'll package it as follows:\ndef eval_classifier(h, D):\ntest_X, test_y = D\nreturn score(h, test_X, test_y)\n2.1.1)\nPercy Eptron suggests reusing the training data to assess h:\neval_classifier(h, D_train)\nExplain why Percy's strategy might not be so good.\n2.1.2)\nNow write down a better approach for evaluating h (which may use h, G) and create a score function for h. The syntax is not\nimportant, but do write something down. Hint: How can you incorporate G?\n2.1.3)\nExplain why your method might be more desirable than Percy's. What problem does it fix?\n2.1.4)\n′\nHow would your method from 2.1.2 score the classifier h on a different dataset\nthat was generated from a different\nDtest\nunderlying distribution than Dtrain (i.e generated from a different generator)? Would the score be better, worse, or about\nthe same? For example, if we're trying to predict whether or not a certain medication works, how well would a classifier\ntrained on an adult population score on a population of children?\n8/10\n\n6.036 Spring 2021\nCheck and submit this box once you've finished this section:\nI've finished this section.\nSave\nSubmit\nClear Answer\nAsk for Help\nAs staff, you are always allowed to submit. If you were a student, you would see the following:\nYou have infinitely many submissions remaining.\nSolution:\nI've finished this section.\nExplanation:\nGood job! Keep going!\n3) Good Hypotheses: Beyond Accuracies\nSo far in this lab we have discussed the difficulties of evaluating a model and defined a slightly more rigorous process for\nevaluation. In all of the above cases, however, we made a few critical assumptions.\nWe assumed that we would always know with complete certainty whether a model made a correct or incorrect prediction on\nunobserved data. We also used accuracy as the ultimate quantitative metric of \"goodness\" of a model (albeit, accuracies on\ndifferent datasets). In the real world, however, there are other metrics we should care about beyond just accuracy, such as\nfairness and whether the model's decisions have any ethical implications that need to be considered while evaluating the\nmodel's performance. Thus, we must be careful in how we define the \"goodness\" of a particular model. To illustrate this,\nlet's look at a fictional case study.\nTo Loan or Not to Loan, that is the question\nFeirna Sinemel was recently hired to be director at a mortgage lender company, Loan Investing Team (LIT) Corporation. LIT\nwants to be competitive with other industry leaders in the mortgage lending space, but has had difficulty scaling due to the\nlimited speed at which humans can manually review loan applications.\nThe company is therefore interested in developing a machine learning model that can be used to determine whether or not\nto give someone a mortgage. They hope to use the model as an initial screening for the applications and reserve manual\nreviewing only for promising applicants.\nFeirna knows you are learning about machine learning and reaches out to seek your advice on how to start designing a\nmodel. She suggests, however, that you approach this role with caution and reminds you that the mortgage business has a\nlengthy history of systemic racism and sexism , including a form of discrimination known as \"redlining\", which continues to\nthis day.\nThe loan application assessment process is about assessing the likelihood that a person will be able to repay the loan in the\ngiven period of time.\n3.1)\n9/10\n\n6.036 Spring 2021\nOne of the first things to choose when developing a machine learning model is what inputs will be provided to the model\nand what the implications may be of including a particular input. For example, you may wish to include a person's current\nsalary. Presumably, the company is more willing to give loans to those who have well-paying jobs. An implication of including\na feature like \"salary\", however, is that historically certain demographic groups (ex. women, minorities, immigrants) have\nlower salaries, which may skew results of the model.\nOther example inputs may include work history and loan repayment/approval history. What are the implications for\nincluding work history and loan history as inputs to the model? What are other inputs you may want to use for the model\nand what are the implications of using those inputs?\n3.2)\nIn developing your model, would you opt to include sensitive inputs, like race or gender identity? What are the reasons you\nmight do so, and what are the reasons you might not?\n3.3)\nWhat are the differences (if any) between using a computation model and having a human make these decisions? What are\nthe benefits and drawbacks to each approach?\nFor next week's lab, we will delve deeper into this scenario and think about how to handle fairness in such situations.\nCheckoff 3:\nHave a check-off conversation with a staff member, to discuss your answers, and make sure you're setup for the\nrest of the week.\nAsk for Help\nAsk for Checkoff\n10/10\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\nRES.TLL-008 Social and Ethical Responsibilities of Computing (SERC)\nFall 2021\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms"
    },
    {
      "category": "Resource",
      "title": "RES.TLL-008 Social and Ethical Responsibilities of Computing (SERC), 6.036 Lab 2.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/res-tll-008-social-and-ethical-responsibilities-of-computing-serc/e9a2abd7df63d1896e4c692c5b250f07_RES-TLL008F21-6036_lab2.pdf",
      "content": "6.036 Spring 2021\nLab -- Features; Train / Test\nInstructions\n1. If you haven't already, please create a group using the box below.\n2. Work through the lab assignment with your group, write your answers on paper, and ask questions while you're\nworking! Put yourself in the help queue to do so.\n3. When you're finished, put yourself in the queue for a checkoff. Only 1 person in the group needs to request the\ncheckoff (creating the group adds you all to the system together!)\n4. You should try to finish and get your checkoff done before the lab ends. If you don't finish, you can get the checkoff\nduring office hours. The lab checkoff is due as specified on the top of the page.\n5. After your checkoff, you're welcome to leave or stay to work on the homework.\nGroup information\nCreate Your Group\nOnce you and your partner(s) are in a breakout room, you need to create a group.\nInstructions:\n(1) One of you should click here to create a group.\n(2) Everyone else should then enter the given new group name (including trailing numbers) into the box below\n(and press enter when done).\nName of group to join:\nReload this page anytime to refresh your group status (and to get a delete button, if you want to remove\nyourself from a group you've joined).\nGroups are limited to 3 persons max each, so that checkoff discussions can be inclusive.\nYou are not currently in any group\n1/9\n\n6.036 Spring 2021\nLab 2\nWelcome to Lab 2, where will will discuss the evaluation of learning algorithms, and explore how to represent input features\nfor the model. We intend for you to begin thinking about these concepts, but please do not stress if you don't understand\neverything perfectly by the end. Use the lab session to build your understanding and clear up confusion, and explore the\ndifferent ways in which we can represent the features we input to the model. Come to office hours if you want to discuss lab\ntopics further. The staff are here to help you learn!\n1) Evaluating a learning algorithm\nNote the following notation and definitions, used in the problem:\nA generator G is a function that draws a random subset from a very large data set.\n(i)\nA training dataset Dtrain is a set of labeled samples X , y generated by a generator G, where x\nrepresents the\n(i)\n(i)\nfeatures of an object to be classified (vector of real and/or discrete values), and y\nrepresents the label of x . (You\n(i)\ncan think of i as the index for point x .)\nA binary classifier h is a function that takes a data point x (a d × 1 vector) as input and returns +1 or -1 as output.\nIn last week's lab, we explored the question of what makes a good hypothesis and the challenges involved with evaluating a\nhypothesis. This week, we explore how to evaluate the learning algorithms, which are used to generate hypotheses.\nA learning algorithm is a function L that takes as input the data set Dtrain as training data and returns a hypothesis (in this\nparticular question, our hypothesis is a classifier) h.\n1.1)\nWhat is the difference between a classifier and a learning algorithm? (Stuck? Check the notes on Linear Classifiers).\n1.2)\nLet Dtrain1 , Dtrain2 be different training datasets generated by G1, G2, respectively. Would running the learning algorithm L\non Dtrain1 and Dtrain2 produce the same classifier? In other words, would h1 = L(Dtrain1) be the same classifier as h2 =\nL(Dtrain2 )?\nWhat if Dtrain1 , Dtrain2 were generated by the same generator?\n1.3)\nNow, consider a situation in which someone is trying to sell you a new learning algorithm, and you want to know how good it\nis. There is an interesting theorem called the No Free Lunch Theorem, that says that without any assumptions about your\ndata there is no learning algorithm that, for all data sources, is better than every other learning algorithm. So, you'll need to\nassess the learning algorithm's performance in the context of a particular data source.\nAssume that you have a generator of labeled data, G, which will be suitable for your application. The learning algorithm's\nperformance on G-generated data will be a good predictor of the learning algorithm's performance on data from your\napplication. (You can review how to evaluate learning algorithms in the notes on Linear Classifiers.\nLinnea Separatoria wants to evaluate a learning algorithm, and suggests the following procedure:\n2/9\n\n6.036 Spring 2021\ndef eval_learning_alg(L, G, n):\n# draw a set of n training data points (points and labels)\ntrain_X, train_y = G(n)\n# run L\nh = L(train_X, train_y)\n# evaluate using your classifier scoring procedure, on some new labeled data\ntest_data = G(n) # draw new set of test data\nreturn eval_classifier(h, test_data)\nHow well or not well does Linnea's strategy evaluate the learning algorithm?\n1.4)\nNext, Linnea decides to generate one classifier h but evaluate that classifier with multiple (10) test sets in her\neval_learning_alg . More specifically, Linnea changed her code above into:\ndef eval_learning_alg(L, G, n):\n# draw a set of n training data points (points and labels)\ntrain_X, train_y = G(n)\n# run L\nh = L(train_X, train_y)\n# evaluate using your classifier scoring procedure, on some new labeled data\nscore = 0\nfor i in range(10):\ntest_data = G(n) # draw new set of test data\nscore += eval_classifier(h, test_data)\nreturn score/10\nIs Linnea's strategy better now? Explain why or why not.\nShow Hint\n1.5)\nNow design a better procedure, better_eval_learning_alg for evaluating L, that takes L, G and n and returns a score.\nWhat would the output score measure? What are the best and worst score values? Why is your method more desirable than\nLinnea's?\n1.6)\nIn reality, it's almost never possible to have a generator of all the data you want. In fact, in some domains, data is very\nexpensive to collect, and so, you are given a fixed, small set of samples. Now assume that you only have 100 labeled data\npoints to use for training and testing/evaluation.\nHow would you implement better_eval_learning_alg without G but instead with your 100 labeled data?\n3/9\n\n6.036 Spring 2021\nCheck and submit this box once you've finished this section:\nI've finished this section.\nSave\nSubmit\nView Answer\nAsk for Help\nAs staff, you are always allowed to submit. If you were a student, you would see the following:\nYou have infinitely many submissions remaining.\n2) Features Engineering\nThe performance of our hypotheses on the real world depends heavily on how we represent our data. In the next few\nquestions we will introduce you to several ways of representing data (from standard numerical data to text data and image\ndata!).\nPlease make sure you read the notes on Feature Representation for this lab.\n2.1) Feature engineering for car data\nOpen and view auto-mpg.tsv . You can also download a local version through the google sheets link or here. This file is in a\ncommon format, called \"tab separated values\". In the first line you will find the names of the columns. Each row is a data\npoint; the first column is the label for that point (1 or -1).\nThe original data came from the StatLib library from CMU. It was modified by Ross Quinlan to remove entries with unknown\nmpg (miles per gallon). We have modified it further by removing six entries with unknown horsepower. We have also\nbinarized the mpg column to turn this into a classification problem (later in the term, we will look at predicting continuous\nvalues, i.e. regression problems). Here are the nine columns in the dataset:\n1. mpg:\ncontinuous (modified by us to be -1 for mpg < 23, 1 for others)\n2. cylinders:\nmulti-valued discrete\n3. displacement:\ncontinuous\n4. horsepower:\ncontinuous\n5. weight:\ncontinuous\n6. acceleration:\ncontinuous\n7. model year:\nmulti-valued discrete\n8. origin:\nmulti-valued discrete\n9. car name:\nstring (many values)\nThere are 392 entries in the dataset, evenly split between positive and negative labels. The field names should be self-\nexplanatory except possibly displacement and origin . You can read about displacement here; in this data set\ndisplacement is in cubic inches. origin is 1=USA, 2=Europe, 3=Asia. We'll ignore car name in this assignment.\nA new student, Hiper Playne, suggests that we should just use all the numeric features in their raw form to predict whether\nthe car will get good or bad gas mileage. He will use the Perceptron algorithm to learn the classifier. Once he trains the\nmodel on this dataset, he wants to predict whether cars in 2021 will get good gas mileage.\n2.1.1)\nWhich of the following is a problem or may lead to problems when using the raw features directly?\n4/9\n\n6.036 Spring 2021\nBecause weight values and cylinders values are on different scales, perceptron might take many\niterations\ncylinders is a multi-valued discrete number feature\norigin is a multi-valued discrete number feature\nThere are too many features and the classifier will overfit\nmodel year is in the 70s, so a classifier based on this data might not perform well in 2021\nSave\nSubmit\nView Answer\nAsk for Help\nAs staff, you are always allowed to submit. If you were a student, you would see the following:\nYou have infinitely many submissions remaining.\n2.1.2)\nFor each feature from the following:\n[cylinders, displacement, horsepower, weight, acceleration, model_year, origin]\nindicate how you can represent it so as to make classification easier and get good generalization on unseen data, by\nchoosing one of:\n'drop' - leave the feature out,\n'raw' - use values as they are,\n'standard' - standardize values by subtracting out average value and dividing by standard deviation. Check the notes\non Feature Representation (Section: Hand-constructing features for real domains) for more details\n'one-hot' - use a one-hot encoding.\nThere could be multiple answers that make sense for each feature; please mention the tradeoffs between each answer. Be\nprepared to justify your choices (ex. why standardize instead of using raw features? why use one-hot encoding?)\nCheckoff 1:\nHave a check-off conversation with a staff member, to explain your answers.\nAsk for Help\nAsk for Checkoff\n2.2) Feature engineering for food reviews (text data)\nIn this part of the assignment, we are going to explore ways of defining features for textual data.\nOpen and view reviews.tsv . This file is in \"tab separated values\" (tsv) format, and it consists of 10,000 fine food reviews\nfrom Amazon. You can find additional information here. We will be focusing on the text field and use it to predict the\nsentiment field (-1 or 1).\nWe will convert review texts into fixed-length feature vectors using a bag-of-words (BOW) approach. We start by compiling\nall the words that appear in a training set of reviews into a list of d unique words.\n2.2.1)\n5/9\n\n6.036 Spring 2021\nFor instance, consider two simple documents \"Mary is selling apples.\" and \"Tom is buying apples to eat\". If we had only these\ntwo sentences in our training set of reviews, which option corresponds to the list of unique words that we build when using\nthe bag-of-words approach discussed above?\nSave\nSubmit\nView Answer\nAsk for Help\nAs staff, you are always allowed to submit. If you were a student, you would see the following:\nYou have infinitely many submissions remaining.\n(Mary, is, selling, apples, T om, is, buying, apples, to, eat)\n(Mary, is, selling, apples, T om, buying, to, eat)\n(Mary, is, selling, red, apples, T om, buying, blue, to, eat)\n2.2.2)\nith\nWe can now transform each of the reviews into a feature vector of length d by setting the\ncoordinate of the feature\nith\nvector to 1 if the\nword in the list of unique words appears in the review or 0 if it does not. Hence, how would we\nrepresent the sentence \"Tom is buying apples to eat\" as a feature vector using the bag-of-words approach and the list of\nunique words we found above?\nSave\nSubmit\nView Answer\nAsk for Help\nAs staff, you are always allowed to submit. If you were a student, you would see the following:\nYou have infinitely many submissions remaining.\n(1, 1, 0, 0, 1, 1, 1, 1)\n(0, 1, 0, 1, 1, 0, 1, 1)\n(0, 1, 0, 1, 1, 1, 1, 1)\n2.2.3)\nTalk with your group about the weaknesses of the bag-of-words approach seen above. For instance, how would you\ninterpret the feature vector (1, 1, 1, 1, 1, 0, 1, 0)?\n2.2.4)\nWords like \"the\", \"to\", \"a\", \"and\" and so on occur with very high frequency in English sentences. Do they help in detecting the\nsentiment in a review? Talk to your group about how to deal with these words, when building your list of unique words,\nusing the bag-of-words approach.\n2.3) Image features\nWe will be exploring in the homework how the perceptron algorithm might be applied to classify images of handwritten\ndigits, like those from a well-known (\"MNIST\") dataset, with items like these:\n6/9\n\n6.036 Spring 2021\nFor today, assume we only have images of digits '1' and '3' and we would like to find a linear classifier which can classify\nthese images correctly, giving label +1 for the digit '1' and label -1 for the digit '3'.\nFor simplicity, assume each image provided is a 5-pixel wide and 5-pixel tall (5x5) black and white image.\n2.3.1)\nAssume images from the MNIST dataset are provided to you as 5x5 matrices. An image is represented as a matrix, say A,\nith\njth\nith\njth\nwith the entry of the\nrow and\ncolumn (Ai,j ) representing the image pixel found at the\nrow and\ncolumn of\npixels. Black pixels have value 0 while white pixels have value 1 in the matrix.\nWith the help of your group, write down the matrix corresponding to the image shown here:\n2.3.2)\nImagine we want to use the perceptron algorithm to perform the task of distinguishing between images of digits '1' and '3'.\nEach image is a data point, which we need in vector form, to feed to the perceptron algorithm. One approach is to take the\ntwo-dimensional matrix representation of an image and concatenate the rows one after the other, into a one-dimensional\nvector of the form [A1,1 , A1,2 , A1,3 , A1,4 , A1,5 , A2,1 , A2,2 , ..., A5,5 ]\nFor the image shown above, what will be the last\nentries of the one-dimensional vector representing that\nimage? Reminder that 0 represents black and 1 represents white. Enter a python list of length\nfor your\nanswer:\nSave\nSubmit\nView Answer\nAsk for Help\nAs staff, you are always allowed to submit. If you were a student, you would see the following:\nYou have infinitely many submissions remaining.\n2.3.3)\nHow well would you expect the perceptron algorithm to work on classifying images if you simply represented them as 1D\nvectors (if you do not reliably know the width and length of the image)?\n2.3.4)\n7/9\n\n6.036 Spring 2021\nWhat approaches might you suggest to extract more meaningful features from the images, such that the perceptron\nalgorithm might do a good job of classification? (Hint: What makes the image of the digit '1' different compared to the\nimage of the digit '3'?)\nDiscuss these questions with your group, and write down your answers. Be prepared to discuss these with the staff for your\nlab checkoff.\nIn the homework for this week we will investigate these datasets in more detail. And later in the semester, we'll explore\nother algorithms, including neural networks and convolutional neural networks, which can essentially do feature extraction\non their own.\n3) Fairness in ML\nLast week, Feirna Sinamel introduced the problem of using machine learning to predict whether or not to give someone a\nloan. We saw how even the seemingly simple decision of choosing input features has several ethical and societal\nimplications (and having done this lab, you can probably imagine that the way we represent features also has ethical\nimplications).\nAfter we have thoroughly thought through the implications of certain technical decisions (like, choosing features and their\nrepresentation), we will need some way of evaluating the impact of our choices (presumably based on the performance of\nthe model).\nSo this raises the question -- how do we evaluate the fairness of a model?\nTo get started thinking about this, let's take a look at some past data that Feirna gave you, and for the sake of concreteness,\nlet's focus specifically on \"fairness\" across genders.\nYou notice that only 30% of the applicants for loan applications come from women, and of the applications that get\napproved, 10% are from women. So, you ask Feirna how gender has been used in the application assessment process in the\npast. She finds that though applications do contain information on gender, the application readers cannot view these fields.\nThis brings up the interesting question: What would a \"fair\" outcome by an application screening model look like when it\ncomes to the gender distribution? More generally, what does it mean for a model to be \"fair\"?\nLIT Company's Definition of Fairness (Group Unaware): The company believes that a fair process and, therefore, a fair\nmodel, would not account for gender or race at all.\nAdvocacy Group's Definition (Demographic parity): An advocacy group believes that a model is fair if the distribution of\noutcomes for each demographic, gender, or other subgroup is the same among those that applied and those that were\naccepted. For example, in the example above, 30% of the applicants for loan applications come from women. In the\ndemographic parity definition of fairness, this means 30% of the approved loan applications should come from women.\nNote: The list of definitions of fairness mentioned above is not exhaustive (scroll down for some more examples).\nNote also that questions about a model's \"fairness\" are not strictly questions about statistical distribution of the\nmodel's outputs. Questions of fairness may also concern assumptions about the model's data. This also brings up the\nquestion of whether the application of machine learning itself is discriminatory or socially unjust ( See here for some\ninteresting reading on this).\n3.1)\nWhat are the merits and drawbacks of these particular definitions. What situations do those definitions account for? What\ndo they not account for?\n8/9\n\n6.036 Spring 2021\n3.2)\nHow might we implement and evaluate these two fairness standards?\n3.3)\nNow of course, gender discrimination is not the only form of discrimination, and one could argue that race-based\ndiscrimination is far more prevalent in loan approval processes. In general, as machine learning engineers, how can we make\nsure fairness (across all different demographic groups) is considered when we formulate and test hypotheses?\nWhile you're waiting for the checkoff, some further food for thought...\nIf you want to learn more about ML fairness in loan applications, check out this paper (Black Loans Matter) that discusses\nthis exact problem! If you're interested in more definitions of fairness in ML, here is an article from Google about 5 common\ndefinitions (including the two discussed above).\nFinally many researchers have identified major ethical limitations in attempts to formalize fairness in ML, arguing that those\nattempts overlook deeper patterns of inequality and injustice. See this article in The Lancet for limitations of algorithmic\nfairness in healthcare. For longer technical articles offering different positions on this debate, see here and here.\nCheckoff 2:\nHave a check-off conversation with a staff member, to explain your answers.\nAsk for Help\nAsk for Checkoff\n9/9\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\nRES.TLL-008 Social and Ethical Responsibilities of Computing (SERC)\nFall 2021\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms"
    },
    {
      "category": "Resource",
      "title": "RES.TLL-008 Social and Ethical Responsibilities of Computing (SERC), 6.036 Lab 5.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/res-tll-008-social-and-ethical-responsibilities-of-computing-serc/5ae324ceb0dffba0c6637b0c378c3e0e_RES-TLL008F21-6036_lab5.pdf",
      "content": "6.036 Spring 2021\nLab -- Neural Networks\nGroup information\nCreate Your Group\nOnce you and your partner(s) are in a breakout room, you need to create a group.\nInstructions:\n(1) One of you should click here to create a group.\n(2) Everyone else should then enter the given new group name (including trailing numbers) into the box below\n(and press enter when done).\nName of group to join:\nReload this page anytime to refresh your group status (and to get a delete button, if you want to remove\nyourself from a group you've joined).\nGroups are limited to 3 persons max each, so that checkoff discussions can be inclusive.\nYou are not currently in any group\nNeural Networks\nFor this lab, you will need to understand the material in the notes on Neural Networks up through and including section 6 on\nloss functions.\n1) Exploring neural networks\nNotes on the functions in the code boxes below:\nThe initialization of weights in a neural network is random, so subsequent runs might produce different results.\niters indicates how many single steps of SGD to run, each using one training point.\nPay attention to the decision boundaries, shown in the answers after you run the code. Also note that the accuracy of\nthe network on the training data is printed above the graph.\n1/8\n\n6.036 Spring 2021\n1.1) Simple separable data set\nHere's a very simple data set.\nX = np.array([[2, 3, 9, 12],\n[5, 2, 6, 5]])\nY = np.array([[1, 0, 1, 0]])\nThe code below runs a very simple neural network composed of a single sigmoid unit with two inputs, using negative log\nlikelihood (NLL) loss:\nThe function sigmoid_nn in the code box below plots the classifier found after training for the specified number of\niterations with the specified \"learning rate\" (step size). The classifier predicts label +1 if the output of the sigmoid, a, is\ngreater than 0.5 and label 0 otherwise -- remember that the range of the sigmoid function is (0, 1).\n1.1.A) What is the shape of the separator produced by this network? Explain.\n1.1.B) Are you able to get relatively consistent 100% accuracy with some combination of iters and learning rate lr ?\nRun Code\nSave\nSubmit\nView Answer\nAsk for Help\nAs staff, you are always allowed to submit. If you were a student, you would see the following:\nYou have infinitely many submissions remaining.\ndef run():\nreturn sigmoid_nn(iters=100, lr=0.05)\n1.2) Not-XOR\nThe XOR dataset is a classic example showing the need for more than one layer of non-linear units. Here, we will consider a\nfunction outputting the negation of XOR, Not-XOR:\nX = np.array([[0, 1, 0, 1],\n[0, 1, 1, 0]])\nY = np.array([[1, 1, 0, 0]])\n1.2.A) Draw a plot showing the locations of these data points in x1, x2 coordinate space, with the corresponding labels.\nNow consider a network with no hidden layers as in part 1.1 above, which just has input units connected (via weights) to an\noutput sigmoid unit. Can this network learn a separator for the given dataset? Explain.\n2/8\n\n6.036 Spring 2021\n1.2.B) Consider the following truth table representing the logical AND and OR operators. We would like to represent the\nAND function as a neural network, using the same structure as from Problem 1.1. Find weights w1 , w2 , and w0 that\nrepresent the (i) AND operation and (ii) OR operation.\n1.2.C) We can express Not-XOR using only AND, OR, and NOT operations. Which expression corresponds to x1 Not-XOR x2?\n(\nAND\n) AND (NOT\nAND NOT\n)\n(\nOR\n) AND (NOT\nOR NOT\n)\n(\nAND\n) OR (NOT\nAND NOT\n)\n(\nOR\n) OR (NOT\nOR NOT\n)\nSave\nSubmit\nView Answer\nAsk for Help\nAs staff, you are always allowed to submit. If you were a student, you would see the following:\nYou have infinitely many submissions remaining.\nx1\nx2\nx1\nx2\nx1\nx2\nx1\nx2\nx1\nx2\nx1\nx2\nx1\nx2\nx1\nx2\n1.2.D) Consider the following network with the hidden layer of Sigmoid (σ) units, where f is a sigmoid unit and\nw0,1 ... w0,n , w0,Σ are the offsets.\nWe can use this network to represent the Not-XOR function. What is the minimal number of units we need in the hidden\nlayer?\n3/8\n\n6.036 Spring 2021\nEnter the minimal number of units we need in the hidden layer:\nSave\nSubmit\nClear Answer\nAsk for Help\nAs staff, you are always allowed to submit. If you were a student, you would see the following:\nYou have infinitely many submissions remaining.\nSolution: 2\nExplanation:\nDiscuss in checkoff\n1.2.E) Now that we have our architecture, find the weights and offsets corresponding to the units.\nExplain how the network works with reference to your earlier drawing of the Not-XOR data in x1 and x2 space. (Try to spend\njust 10 minutes on this, then ask for tips!)\n1.2.F) In the run box below, first try to see if you can get a network of the size you found above to separate the data reliably\n(several times in a row, keeping randomInit = True ). If not, try larger networks. Try each value of hidden units a few\ndifferent times. Experiment with different learning rates and iterations as well. Explain what's going on. Keep in mind that\nthe network is being trained using batch gradient descent.\nNow, change randomInit = False . Try different values of hidden units. Try these values a few different times. Comment on\nhow the behavior is different.\nThe single_layer_nn function in the code below runs on the dataset using a network with a single hidden layer of ReLU\nunits, a sigmoid output layer, and NLL loss. You can specify the number of hidden units, the number of iterations, and the\nlearning rate.\nRun Code\nSave\nSubmit\nView Answer\nAsk for Help\nAs staff, you are always allowed to submit. If you were a student, you would see the following:\nYou have infinitely many submissions remaining.\ndef run():\nreturn single_layer_nn(hidden_units=1, iters=1000, lr=0.05, randomInit=True)\n1.3) Hard data set\nIn this next example we use a much harder data set that is barely separable (although not linearly). We'll try a two-layer\nnetwork architecture.\n1.3.A) Running the code below, can you get this architecture to separate the data set with at least 95% accuracy? How about\n100% accuracy (Don't spend too long looking for 100%)? If you can't, explain why not. If you can, explain why. Make sure\nyour accuracy is reliable by running the code several times.\n1.3.B) Do you think it's a good idea to try to find a \"perfect\" separator for this data? Explain.\n4/8\n\n6.036 Spring 2021\nThe network here has two hidden layers of ReLU units and a sigmoid output unit with NLL loss. In the two_layer_nn\nfunction call below, you can play around with the number of hidden units in each hidden layer, the number of iterations, and\nthe learning rate.\nRun Code\nSave\nSubmit\nView Answer\nAsk for Help\nAs staff, you are always allowed to submit. If you were a student, you would see the following:\nYou have infinitely many submissions remaining.\ndef run():\nreturn two_layer_nn(hidden_units=2, iters=100, lr=0.05)\n2) Checkoff\nCheckoff 1:\nHave a check-off conversation with a staff member, to explain your answers.\nAsk for Help\nAsk for Checkoff\n3) Activation and Loss Function Applications\nOne important part of designing a neural network application is understanding the problem domain and choosing\nA representation for the input\nThe number of output units and what range of values they can take on\nThe loss function to try to minimize, based on actual and desired outputs\nWe have studied input representation (featurization) in a previous lab, so in this problem we will concentrate on the number\nof output units, activation function on the output units, and loss function. These should generally be chosen jointly.\nJust as a reminder, among different loss functions and activation functions (see Sections 3 and 6 of the Chapter 8 notes), we\nhave studied:\nActivation functions: linear, ReLU, sigmoid, softmax\nLoss functions: negative log likelihood (NLL a.k.a. cross-entropy), quadratic (mean squared)\nFor each of the following application domains, specify good choices for the number of units in the output layer, the\nactivation function(s) on the output layer, and the loss function. When you choose to use multiple output units, be very clear\non the details of how you are applying the activation and the loss. Please write your answers down!\n3.A) Map the words on the front page of the New York Times to the predicted (numerical) change in the stock market\naverage.\n3.B) Map a satellite image centered on a particular location to a value that can be interpreted as the probability it will rain at\nthat location sometime in the next 4 hours.\n3.C) Map the words in an email message to which one of a user's fixed set of email folders it should be filed in.\n3.D) Map the words of a document into a vector of outputs, where each index represents a topic, and has value 1 if the\ndocument addresses that topic and 0 otherwise. Each document may contain multiple topics, so in the training data, the\n5/8\n\n6.036 Spring 2021\noutput vectors may have multiple 1 values.\n4) Social Utility\nOver the last several labs, we've explored different forms of biases with problematic outcomes: historical bias,\nrepresentation bias, aggregation bias. This week, we'll start discussing potential benefits and drawbacks of intentionally\nbiasing your model, and how this can affect the model's utility.\nDr. Niyu Ralnette's research group is investigating the use of machine learning to support radiologists.\n2% of the population have a rare, deadly disease which can be detected with x-rays. The research group built a model that\nachieves 98% accuracy on the test set of 100,000 people and a 99% accuracy on the training set of 1 million individuals.\nThe Ralnette group starts to test the model in the wild, but when Dr. Ralnette takes a look at the results, she finds that the\nmodel never produces a positive diagnosis of the disease. Dr. Ralnette is confused by this since the model seemed to\nperform well on both the training data and test data.\n4.A) Can you think of a possible explanation for why the model had high accuracies on the training data and test data, but\nseems to be unable to correctly diagnose the disease in the wild?\nWe now introduce another evaluation tool, used in addition to accuracy measurements, called confusion matrices. A\nconfusion matrix is a table used to provide more detailed information on the performance of a classification model.\nOur model that achieved a 98% accuracy on the test set, had the following confusion matrix.\n6/8\n\n6.036 Spring 2021\nIt seems the model learned to always predict \"False\" for the diagnosis! Dr. Ralnette's group trains a few more models to see\nif we get different performance\n4.B) The confusion matrices of the developed models are below. Calculate the accuracy of each model.\n4.C) Which of the following models would you prefer to deploy, and why? In the case of diagnosing this rare, deadly disease,\ndo you prefer false negatives, false positives, or do you not have a preference for the type of failures? Why?\nNote: In case you are curious, one way achieve models with different combinations of false positive and false negative rates\nis to use an asymmetric loss (as seen in the Chapter 1 notes).\n4.D) This disease can be treated if detected, but the treatment has extremely harsh, non-lethal side effects. Does this\nknowledge change the model you would choose? Would you choose a different model if the model were going to diagnose\nthe patient without a radiologist making the final recommendation?\n7/8\n\n6.036 Spring 2021\n5) Checkoff\nCheckoff 2:\nHave a check-off conversation with a staff member, to explain your answers.\nAsk for Help\nAsk for Checkoff\n8/8\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\nRES.TLL-008 Social and Ethical Responsibilities of Computing (SERC)\nFall 2021\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms"
    },
    {
      "category": "Resource",
      "title": "RES.TLL-008 Social and Ethical Responsibilities of Computing (SERC), 6.036 Lab 9.pdf",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/res-tll-008-social-and-ethical-responsibilities-of-computing-serc/7a3c3be8168d0e427cc41f74a9e1e72a_RES-TLL008F21-6036_lab9.pdf",
      "content": "6.036 Spring 2021\nLab -- Recurrent Neural\nNetworks\nGroup information\nCreate Your Group\nOnce you and your partner(s) are in a breakout room, you need to create a group.\nInstructions:\n(1) One of you should click here to create a group.\n(2) Everyone else should then enter the given new group name (including trailing numbers) into the box below (and press\nenter when done).\nName of group to join:\nReload this page anytime to refresh your group status (and to get a delete button, if you want to remove yourself from a\ngroup you've joined).\nGroups are limited to 3 persons max each, so that checkoff discussions can be inclusive.\nYou are not currently in any group\nFor this lab:\nYou will need to understand the material in the notes on recurrent neural networks.\nWe have prepared a Colab notebook that is essential for doing this lab that can be found here. We recommend using the colab but\ncode files can be found here. You can download this to your computer if you prefer.\nRNNs\n1) Applications of RNNs\n1.1) Examples\nIn this section, we'll consider examples of RNN applications with respect to the forms of inputs and outputs.\n1/9\n\n6.036 Spring 2021\n1.2) Choose a structure\nChoose an RNN structure from one-to-many, many-to-one, and many-to-many, to address each of the problems below. For each, describe\nhow you would structure the input to the RNN (which has to be a fixed-length vector at each time step), and what kind of output unit(s) you\nwould use.\nNote that yellow nodes stand for inputs, blue nodes stand for hidden units, and red nodes stand for outputs.\n1.2.1)\nGiven a review for a new product on a shopping website, detect whether the text's sentiment is positive or negative, that is, whether the\nwriter writes positively or negatively about the new product.\n1.2.2)\nAssign a part-of-speech tag to each word in an English sentence: \"The old man will man the boat.\" -> [\"determiner\", \"adjective\", \"noun\",\n\"modal\", \"verb\", \"determiner\", \"noun\", \"punctuation\"]\n1.2.3)\nGiven a picture (encoded as a vector of features computed by a CNN), generate a caption, for example: \"A cat is sitting on a rock\" or \"Dogs\nplaying at the park\".\n1.2.4)\nTranslate a sentence from Spanish to English: \"Quiero aprender mas algebra lineal.\" -> \"I want to learn more linear algebra.\" As you can see,\nhere we have different sequence lengths and words might be in different order (algebra lineal vs. linear algebra). What architecture (or\ncombination of architectures), from the above described, would you use to address this problem? Be ready to discuss some challenges of\nthese architectures.\nCheck this box and submit when you have finished all parts of this question.\nSave\nSubmit\nView Answer\nAsk for Help\nAs staff, you are always allowed to submit. If you were a student, you would see the following:\nYou have infinitely many submissions remaining.\n2) Generating sequences\nIn this question, we will look into using an RNN model to predict the next element in a sequence. We will focus on sequences of text\ncharacters (this is sometimes referred to as a \"language\" model). We will want to train on one or more sequences and then, given an initial\ncharacter or sequence of characters, we want the RNN to predict what characters should come next. An example sequence might be the\nfollowing:\nc = ['m', 'i', 't']\n2/9\n\n6.036 Spring 2021\nThis sequence will be used both as input to an RNN and as desired output (offset by one time step), since we are training the RNN to\nproduce the next character in the sequence.\n2.1) RNN structure\nSince the input to an RNN at each time step is encoded as a fixed-length vector, we will first encode each character of the sequence using a\none-hot encoding. Let φ(ct) represent the one-hot encoding of character ct. Recall that if we have V possible characters, then φ(ct) will be\na vector of size V where each element corresponds to one of the possible characters.\nThe inputs to the RNN, x, will consist of the encoded characters with a special start character. The output sequence of the RNN, y, will also\nconsist of the encoded characters but have a special end character. In this lab, we will use '.' and '\\n' as the start and end character\nrespectively. This format will allow us to train an RNN to do character prediction (at time t, the RNN will have seen c1, ... , ct-1 and will try\nto predict ct).\nx = [<start>, φ(c1), φ(c2), ... , φ(cn )]\ny = [φ(c1), φ(c2), ... , φ(cn ), <end>]\nNote that x and y are shifted by one time step.\nThe following diagram unravels the RNN and shows what x and y would be for the sequence c=['m','i','t'] :\nThe particular form of the RNN that we will look at is:\nNote that this in the same form as the Continuous State Machines in Lab 8.\n2.1.1)\nBe prepared to discuss these points during checkoff:\nWhen the symbols are all the lowercase letters in the English alphabet, what is the size of V ?\nWhich time step of x should the output yt match?\nWhat is the role of st?\nHow is pt related to st?\nTraining: We will first describe how to train this RNN given a dataset of sequences. For each sequence in the dataset:\nFormat the input and output for the RNN as described above (add start/end characters to the sequence for the input/output\nrespectively).\nFeed each character of the input into the RNN (at time t, this will be ct-1 from the original sequence).\n3/9\n\n6.036 Spring 2021\nUse the NLL between the predictions pt and the true character encodings yt and perform backpropagation to update the weights in\nthe matrices.\nGeneration: Once the RNN is trained, we can use it to generate new text based on its own predictions.\nStarting with the start symbol ('.'), it predicts a next character by sampling it from the softmax distribution on the output pt in the\ntrained model, then it feeds that character as the next input into the model and repeats until an end symbol ('\\n') is generated.\nAn alternative generation approach picks the most likely character at pt instead of sampling from the softmax distribution.\nWe visualize this process below where we use y^ t to represent the encoding of the character the network predicted at time t. Notice how the\nnetwork uses its own predictions as inputs. This differs from training where we always used the characters from the sequence in our dataset\nas inputs (see the training diagram above).\n2.1.2)\nBe prepared to discuss these points during checkoff:\nHow are the training sequences used in the training phase?\nHow are multiple sequences produces in the generation phase?\n2.2) Memorizing a Sequence\nWe will first see how well these models can learn to produce a single sequence. Let's consider generating a sequence of 10 a characters. We\nwill train the RNN and then call the generation method 11 times. The first time we give it '.' as input and then the following 10 times we\ngive it the output of the RNN at the previous time step. We want the outputs to be:\n['a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', '\\n']\n2.2.1)\nWhat does the RNN need to learn in order to perform this task? Mark all that are true.\nA linear classifier that predicts 'a' versus `\\n' depending on the hidden state\nA state machine that encodes a count of the number of characters seen so far in the hidden state\nSave\nSubmit\nView Answer\nAsk for Help\nAs staff, you are always allowed to submit. If you were a student, you would see the following:\nYou have infinitely many submissions remaining.\n4/9\n\n6.036 Spring 2021\nNext, assume that the one-hot encoding of 'a' is [[1], [0]] and the encoding of '\\n' is [[0], [1]] . For now, assume that the encoding of '.'\nis also [[0], [1]] .\nPicking the dimension of the hidden state, m, to be 1 and training an RNN with this sequence for 10000 iterations of SGD, we obtain the\nfollowing RNN matrices:\nWss = [[2.66555941]] Wsx = [[-0.75865931,\n2.91783285]] Wss0 = [[-0.37149935]]\nWo = [[ 9.63304408], [-9.63296282]]\nWo0 = [[ 2.64391274], [-2.64382701]]\nIf we now call the RNN generation function repeatedly, we get the following output (approximately). Note that state is st-1 , x is xt,\nnew_state is st and p is pt.\nt= 1 state [[0.]]\nx [[0] [1]] new_state [[0.98779174]] p [[1.0], [0.0]]\nt= 2 state [[0.98779174]] x [[1] [0]] new_state [[0.90566354]] p [[1.0], [0.0]]\nt= 3 state [[0.90566354]] x [[1] [0]] new_state [[0.85753147]] p [[1.0], [0.0]]\nt= 4 state [[0.85753147]] x [[1] [0]] new_state [[0.81961469]] p [[1.0], [0.0]]\nt= 5 state [[0.81961469]] x [[1] [0]] new_state [[0.78357789]] p [[1.0], [0.0]]\nt= 6 state [[0.78357789]] x [[1] [0]] new_state [[0.74361363]] p [[1.0], [0.0]]\nt= 7 state [[0.74361363]] x [[1] [0]] new_state [[0.69210644]] p [[1.0], [0.0]]\nt= 8 state [[0.69210644]] x [[1] [0]] new_state [[0.61361073]] p [[1.0], [0.0]]\nt= 9 state [[0.61361073]] x [[1] [0]] new_state [[0.46639812]] p [[1.0], [0.0]]\nt=10 state [[0.46639812]] x [[1] [0]] new_state [[0.11257404]] p [[1.0], [0.0]]\nt=11 state [[0.11257404]] x [[1] [0]] new_state [[-0.68052211]]\np [[0.0], [1.0]]\n2.2.2)\nFor what values of\nis the output character '\\n'?\npositive values\nnegative values\nSave\nSubmit\nView Answer\nAsk for Help\nAs staff, you are always allowed to submit. If you were a student, you would see the following:\nYou have infinitely many submissions remaining.\nst\n2.2.3)\nBe prepared to discuss these points during checkoff:\nNote that the state starts with value 0, how does it get be close to 1 at the first step?\nAt what time step does the new_state (st) go below 0?\nHow does the change in sign of st affect the output? (Think about how softmax works)\n2.2.4)\nThe sequence above had a fixed length, but what if we didn't include a termination character and wanted to generate repeating strings?\nWhat if we wanted to train a language model to generate the sequence ['m', 'i', 't', 'm', 'i', 't', ....] forever? What\nwould the state need to encode?\nWhat about ['m', 'm', 'i', 'i', 't', 't', 'm', 'm', 'i', 'i', ...] What would the state need to encode?\nWhat about ['m', 'm', 'm', 'm', ....] What would the state need to encode?\n2.3) Hard Sequences\nSome sequences are harder to memorize than others. As a measure of difficulty of learning, let's consider two factors:\n5/9\n\n6.036 Spring 2021\nnum_hidden : The dimension of the hidden state (referred to as m above),\nnum_steps : The number of steps to run the optimizer for.\nWe will focus on the first of these - the dimension of the hidden state.\nThe RNN will first be trained on a dataset of a single sequence. We will then use the trained RNN to generate a new sequence as described\nabove (see the generation section). Our goal is to have the RNN reproduce the training sequence reliably during generation (including\nstopping at the right place).\nWe'll consider these sequences (note we visualize them as strings instead of list of characters):\n(1)\n\"aaaaaaaaaa\"\n\"aabaaabbaaaababaabaa\"\n\"abcdefghijklmnopqrstuvwxyz\"\n\"abcabcabcabcabc\"\nWhich sequence do you think will be most difficult for the RNN to learn? Recall that the vocabulary includes all the letters in\nthe input, but we're not using size of V as indicating difficulty. Here, \"difficult\" just consists of needing larger hidden\ndimension.\n--\nSave\nSubmit\nView Answer\nAsk for Help\nAs staff, you are always allowed to submit. If you were a student, you would see the following:\nYou have infinitely many submissions remaining.\nc\n=\nc\n=\n(2)\nc\n=\n(3)\nc\n=\n(4)\nBe prepared to explain your reasoning during the checkoff.\n2.4) Running the code\nWe will now try training an RNN on these single-sequence datasets. We have provided code to do this for you. In the Colab you will find\ndefinitions of a procedure for training and using models of sequential data (you can also use code_for_lab9.py from the downloadable\nfiles).\ntest_word(word, interactive=False, num_hidden=1, num_steps=10000, step_size=0.005)\nword is a string representing the sequence of characters. These will be converted into a training set of sequence pairs for a language\nmodel as described above.\nnum_hidden indicates the number of units in the hidden layer (the dimension of the states),\nnum_steps indicates steps of (stochastic) gradient descent,\nstep_size the magnitude of the gradient descent steps,\ninteractive indicates, when False, to generate 100 random sequences from learned model, when True, it asks for a partial sequence\nand then completes it in the most likely way given the learned model. Note: input sequences can only include characters present in the\nword (or the start character . )\nNote that test_word(word=\"aaaaaaaaaa\") uses as both training and test set only the input word (i.e. the model is literally only trying to\nlearn how to represent that sequence).\nTry using different values of each of the following parameters:.\nnum_hidden : The dimension of the hidden state,\nnum_steps : The number of steps. Try num_steps in [1000, 5000, 10000, 15000, 20000].\nNote that the initial weights are chosen randomly, so results will vary for each run. You can set the random seed if you can't get consistent\nresults.\n2.4.1)\n6/9\n\n6.036 Spring 2021\nTry learning each of the above sequences, using the test_word function for different values of num_hidden and num_steps ; pay attention to\nthe training error value printed by the code. The output of test_word is 100 sequences generated from a trained model, that is, sampling\nfrom the softmax distribution on the output pt. Find the difficulty of each string (the minimum size of hidden layer and number of steps\nrequired to consistently reproduce the string, where we prioritize minimizing hidden layer size (i.e. num_hidden ). Comment on your results.\nCheckoff 1:\nHave a check-off conversation with a staff member, to explain your results.\nAsk for Help\nAsk for Checkoff\n3) Language Modeling\n3.1) Larger datasets\nWe will now try training the RNN using larger datasets with more realistic sequences. We will specifically look at different strategies to\ngenerate sequences with a trained model.\ninteractive=True : You will be prompted to enter the start of a sequence. We will use the RNN to complete the sequence (taking the\nmost likely character at each prediction).\ninteractive_top5=True : Similar to interactive=True but instead of choosing the most likely character at each time step, you will be\nshown the top 5 most likely characters and asked to choose one.\nThe test_food function uses the file food.txt of recipe names.\nRun test_food with interactive=True .\nRun test_food with interactive_top5=True .\n3.1.1)\nWhat is the mechanism by which these RNNs generate the top 5 characters? More specifically, what characters do the trained RNN seem to\npropose for you to choose at each location?\n3.1.2)\nWithout having you manually choose the next character, what would be a mechanism by which these RNNs should generate their output?\nWould that produce diverse sequences (i.e., if you run the generation multiple times with the same start-of-sequence string, would you get\ndifferent outputs)?\nNote: If your installation of Python has trouble finding the data files, try setting the dirname in the code_for_lab9.py file to the pathname\nfor the folder where the data can be found.\n4) Word Embeddings\nRNNs are often used to process language, for example to map from one sequence of words to another sequence of words.\nRNNs, like other NNs, take vectors as input, so to get them to process words we need some way of turning words into vectors. One way to\ndo this is with a one-hot encoding (as in the previous lab problems). But there are lots of lower dimensional but more informative\nrepresentations of words called \"word embeddings\".\nOne popular technique for producing word embeddings is called word2vec. It assigns each word a vector embedding such that words that\nappear in similar sentence contexts have embeddings that are close in vector space. Typically, we create these embedding vectors through\nmachine learning techniques (i.e. an embedding weight matrix of size [number of words x embedding size] is learned).\n4.1) Exploring embeddings\n7/9\n\n6.036 Spring 2021\nHere, we investigate a phenomenon that will affect any RNN that uses these embeddings. We've trained embeddings for all the words that\nappeared in a large dataset of news articles. Instead of loading embeddings for every word in this set (together they take up about 3 GB!),\nwe have pre-selected several words whose embeddings have interesting properties.\nwords = [\"woman\", \"man\", \"boy\", \"girl\", \"doctor\", \"nurse\", \"programmer\", \"homemaker\", \"queen\", \"king\", \"receptionist\",\n\"librarian\", \"socialite\", \"hairdresser\", \"nanny\", \"bookkeeper\", \"stylist\", \"maestro\", \"protege\", \"philosopher\",\n\"captain\", \"architect\", \"surgeon\", \"brilliant\", \"mother\", \"father\"]\nThe function below takes two lists and computes the cosine distance between corresponding elements of the lists:\nw1 ⋅ w2\nd(w1, w2) = 1 - ∣∣w1∣∣∣∣w2∣∣\n[We can see that with cosine distance, the magnitude of the involved vectors is irrelevant; distance is dependent on the angle between the\ntwo vectors. Smaller angles correspond to closer vectors. Using cosine distance, we also know that distances will range between 0 and 1.]\nUse the function below to find the distances between various pairs of words from the above list. Compare the distances to each other. What\ndo the relative distances seem to reflect? What unexpected distances do you notice?\nRun Code\nSave\nSubmit\nView Answer\nAsk for Help\nAs staff, you are always allowed to submit. If you were a student, you would see the following:\nYou have infinitely many submissions remaining.\ndef run():\nreturn t1(w1list=[\"woman\", \"man\"], w2list=[\"mother\", \"father\"])\n4.2)\nNow let's take a look at some of the problems that arise when we use these embeddings in the wild. Please go to Google Translate and\ntranslate the following into Hungarian: \"She is an engineer. He is beautiful\". What do you get?\nNow take the Hungarian translation above and translate it back into English using Google Translate. Please note that Hungarian is a gender\nneutral language (so there are no gendered pronouns). What do you get? Why might this be happening? How does this relate to the\nunexpected distances we saw in the previous problem? And where do these unexpected distances come from?\n4.3)\nWhat are some applications where using biased word embeddings may have a negative impact?\nCheckoff 2:\nHave a check-off conversation with a staff member, to explain your results.\nAsk for Help\nAsk for Checkoff\nWhile you wait for a checkoff...\nDe-biasing these translations is ongoing process. Here's an example from 2019. And here is their fix as of today, but as illustrated in the\nabove examples, it is still far from perfect. If you are curious to read more on the Hungarian translation example, see this blog post. There is\nalso a lot of research in this space. Here's a paper that works on debiasing such embeddings\nAs of November 20, 2019\nvs. November 1, 2020\n8/9\n\n6.036 Spring 2021\n(c) Google. All rights reserved. This content is excluded from\nour Creative Commons license. For more information, see\nhttps://ocw.mit.edu/help/faq-fair-use/\n5) More Food for Thought\nIn the past few years, another model architecture, the transformer, has replaced the RNNs as the model of choice for language processing\ntasks. Generative Pre-trained transformer (GPT-3) is one such language model developed by Open-AI. Many developers have come up with\nmany different applications that are often indistinugishable from human generated texts.\nThis is an application where GPT-3 is used to generate tweets given any word as the theme. For example, here's a tweet generated with mit\nas the theme word: \"MIT slaps you across the face with reality and drags you to Mars. That's why it's the best.\" We'll look at the transformer\nmodel in next week's lab.\n9/9\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\nRES.TLL-008 Social and Ethical Responsibilities of Computing (SERC)\nFall 2021\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms"
    },
    {
      "category": "Resource",
      "title": "RES.TLL-008 Social and Ethical Responsibilities of Computing (SERC), 6.390: Introduction to Machine Learning, Markov Lab",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/res-tll-008-social-and-ethical-responsibilities-of-computing-serc/mitres-tll008s23_6039_markov.pdf",
      "content": "Introduction to Machine Learning\n(Fall 2022)\nLab attendance check\nType in your section passcode to get attendance credit (within the first fifteen minutes of your scheduled section).\nPasscode:\nEnter\nGroup information\nCreate/join a group\n1. One person (and only one) should create a group.\n2. Everyone else should enter the group name below (in the form groupname_0000 ).\nJoin group:\nSubmit\nTo join another group or leave your current group, reload the page.\nYou are not in a group.\nFor this lab:\nYou will need to understand the material in the course notes on Markov decision processes.\nDon't spend too long on any one question - use the help queue if you are stuck!\n1) Deterministic Wash & Paint MDP\nWe will model aspects of a very simple wash and paint machine as a Markov decision process (MDP). An agent controls the actions taken, while the\nenvironment responds with the transition to the next state.\nOur simple machine has three possible operations: \"wash\", \"paint\", and \"eject\" (each with a corresponding button). Objects are put into the machine.\nEach time you push a button, something is done to the object. The machine has a camera inside that can clearly detect what is going on with the\nobject and will output the state of the object: dirty, clean, painted, or ejected.\nIn this question, you will devise a policy that will take the state of an object as input and select a button to press until finally you press the eject\nbutton. You get reward +10 for the \"eject\" action on a painted object, reward 0 for \"eject\" action on an object that is dirty or clean, reward 0 for any\naction on an ejected object, and reward -3 otherwise.\nWe start out with a brand-new machine that operates reliably and deterministically, as illustrated in the state diagram below. Here state transition arcs\nare labeled with the action responsible for the transition. Specifically, when we \"wash\" a dirty or painted object, it becomes clean; and when we\n\"paint\" a clean object it becomes painted. If we \"eject\" a dirty, clean, or painted object, it becomes ejected. An ejected object stays ejected, for any\naction.\n\n1.1)\nYou will formulate the brand-new machine as an MDP, but with a deterministic transition function. It will be useful to write out and save\ntables/diagrams of your answers and show them to staff during the checkoff.\nWrite out a specification of the state space and action space.\nThe transition model is specified by the diagram above, where an arc from state to state\nunder action indicates a transition probability\n, and lack of an arc from to\nindicates a transition probability\n.\nThe reward function,\n, needs your definition. Given\nstates and actions, the reward matrix should be\nby , and will look something\nlike:\nwash paint eject\ndirty\n--\n--\n--\nclean\n--\n--\n--\npainted --\n--\n--\nejected --\n--\n--\nFor the matrix in the response below, order the states as \"dirty\", \"clean\", \"painted\", and \"ejected\": and the actions as \"wash\", \"paint\", \"eject\".\nEnter the reward matrix as a list of lists:\nCheck Formatting\nSubmit\nView Answer\nAsk for Help\nAs staff, you are always allowed to submit. If you were a student, you would see the following:\nYou have infinitely many submissions remaining.\n1.2)\nSuppose we have an infinite horizon and discount factor 1. That means you can take as many steps as you want to, and all rewards are weighted\nequally whether they happen at the beginning or end of the action sequence. What would be the optimal action to take in each state? What would\nyour total sum of rewards be (under the optimal policy) if you started in state dirty?\n1.3)\nSuppose we have a horizon of 2 and discount factor 1. That means you could only take two steps in total. Would the policy from the previous\nquestion change? Why, or why not? What would your total sum of rewards be (under the optimal policy) if you started in state dirty?\n1.4)\nSuppose we have an infinite horizon and discount factor 0.5. Let's also assume that under our action policy, we always \"paint\" an object if it is clean,\nand always \"eject\" an object if it is painted. What would be the sum of discounted future rewards if you start with a dirty object in each of the policies\nlisted next:\nYour policy is to \"eject\" an object whenever it is dirty?\ns\ns′\na\nT(s, a, s ) =\n′\ns\ns′\nT(s, a, s ) =\n′\nR(s, a)\nm\nn\nm\nn\n\nYour policy is to \"wash\" an object whenever it is dirty, followed by optimal actions after that?\nWhich is the better policy?\n2) Stochastic Wash & Paint MDP\nOur wash and paint machine has gotten old, and is no longer so reliable. Now, many of its state transitions are stochastic in response to specific\nactions:\nWash:\nIf you perform the \"wash\" operation on any object, whether it's dirty, clean, or painted, it will end up clean with probability 0.9 and dirty\notherwise.\nPaint:\nIf you perform the \"paint\" operation on a clean object, it will become nicely painted with probability 0.8. With probability 0.1, the paint misses\nbut the object stays clean, and also with probability 0.1, the machine dumps rusty dust all over the object and it becomes dirty.\nIf you perform the \"paint\" operation on a painted object, it stays painted with probability 1.0.\nIf you perform the \"paint\" operation on a dirty object, it stays dirty with probability 1.0.\nEject:\nIf you perform an \"eject\" operation on any object, the object comes out of the machine and this fun game is over. The object remains ejected\nregardless of any further action.\nHere is an example state diagram for the \"wash\" operation, now with arcs labeling the probability\n, for action being \"wash\".\n2.1)\nIn order to visualize the stochastic machine MDP, draw the state diagrams for the \"paint\" and \"eject\" operations.\n2.2)\nThe state space, action space, and reward function remain the same as for our deterministic machine, but now our transition model has changed.\nWrite out the transition matrices for the \"wash\", \"paint\", and \"eject\" actions. Specifically, provide three transition matrices (rows should sum to one,\nwith the conventions used in this class), one transition matrix for each of the \"wash\", \"paint\", and \"eject\" actions.\nGiven\nstates, each transition matrix should be\nby\n, corresponding to\nwith row indicating and column\n. Thus, a transition matrix\nfor a given action will look something like:\nT(s, a, s )\n′\na\nm\nm\nm\nT(s, a, s )\n′\ns\ns′\na\n\ndirty clean painted ejected\ndirty\n--\n--\n--\n--\nclean\n--\n--\n--\n--\npainted --\n--\n--\n--\nejected --\n--\n--\n--\nFor the prompt just below, order the rows and columns as dirty, clean, painted, ejected.\nEnter the transition matrix as a list of lists for \"wash\" action:\nCheck Formatting\nSubmit\nView Answer\nAsk for Help\nAs staff, you are always allowed to submit. If you were a student, you would see the following:\nYou have infinitely many submissions remaining.\n2.3)\nWe next consider some finite horizon scenarios (and with discount factor\n), but now with our stochastic wash & paint MDP.\n2.3.1)\nFirst, assume horizon\nWhat is our optimal action\nif you are in a painted state? What is the optimal action-value function\nfor this case,\n?\n2.3.2)\nIf we instead have a finite horizon of\n, what is our optimal action\nif we are in a painted state with two steps to go? Why is this different than\n(or the same as)\n? What is\n; how does this compare to\nand why?\n2.3.3)\nStill with a finite horizon of\n, now we start in state clean. In the deterministic (brand new) wash & paint machine, we saw that the optimal action\nwas to paint, then eject, for a total reward of 7.\nNow, with horizon\nin our stochastic wash & paint machine, we still hope to paint then eject. Will this\nhave a\nreward of 7, more than 7, or less than 7? Why?\n2.4)\nWe switch to an infinite-horizon scenario. For our stochastic machine, here is the infinite-horizon\nfunction (computed via value iteration) for near\n1.\nwash paint eject\ndirty [[ 2.32274541 -0.70048204 0.\n]\nclean [ 2.32274541 5.71581775 0.\n]\npainted [ 2.32274541 6.9 10.\n]\nejected [ 0. 0. 0.\n]]\nWhat is the optimal thing to do with a clean object?\nWhat will you do if it becomes dirty?\nDoes this optimal policy make intuitive sense?\n2.5)\nγ = 1\nh = 1.\na1\nQh\nQ (s =\npainted, a )\nh = 2\na2\na1\nQ (s =\npainted, a )\nQ (s =\npainted, a )\nh = 2\nh = 2\nQ (s =\nclean, a =\npaint)\nQ\nγ\n\nIf the machine became much less reliable (i.e., washing and painting only achieve the desired transition, say, 20% of the time), how do you think the\noptimal policy would change?\nCheckoff 1:\nHave a check-off conversation with a staff member, to explain your answers.\nAsk for Help\nAsk for Checkoff\n3) Grid-World -- Finite Horizon Q Values\nIn the previous problem, we only had four states: dirty, clean, painted, and ejected. In this problem, we use a two-dimensional \"grid-world\" with a\nrobot in it; we have a state for every square on the grid, representing the robot's location.\nOur four possible actions are moving North, South, East or West (note that the robot cannot move off the board, so some states have fewer possible\nactions). The transitions are also substantially noisy; when commanding a move to a target state, there is a 50% probability of moving to the target\nstate, and a\nprobability of landing instead at one of the vertical or horizontal neighbor states of the target state. In most cases, will\nbe four, but at the boundaries of our grid-world, and the available transitions will include only the neighboring squares that are within grid-world.\nWe want to identify the best action that the robot can take in each state (i.e., the best policy), if it had a specific horizon of remaining moves. We do\nnot have any discount for future moves: the discount factor\nConsider a grid world with its \"floor plan\" represented as a list of strings of characters:\n['..........',\n'........*.',\n'..........',\n'..........',\n'..........',\n'..........',\n'..........',\n'..........',\n'.$........',\n'..........']\nEach character corresponds to a square in the grid. The meanings of the characters are:\n'.' : a normally habitable square, from which the robot can move.\n'$' : a terminal state. Reward is 100 for any action from this state, and then the game immediately ends.\n'*' : a teleporter state. Reward is 50 for any action from this state, and the next state is chosen uniformly at random from all occupiable\nstates, including $ and *. This reward can be claimed multiple times.\nBelow are plots of the\nvalues of the states as we consider horizons from 0 to 99. The color for each square represents\n, where\nis the optimal finite-horizon action to take at horizon , i.e.,\nThe arrows represent the optimal move,\n, pointing N, S,\nE, or W.\n(50/g)%\ng\ng\ng\nh\nγ = 1.\nQh\nh\ns\nQ (s, a\n)\nh\nopt\naopt\nh\na\n=\nopt\narg max\nQ (s, a).\na\nh\naopt\nNote: Before proceeding, confirm that you understand what these diagrams mean, and how they relate to Qh in the finite-horizon set up in the\ncourse notes on MDPs. What equations in the notes apply to this scenario? Ask for help if you're not sure!\n\n99 (note scale change!)\n3.1)\nIn the first picture all the values are zero, and with a default \"best\" action, N. Why?\nThe second picture considers an horizon\nscenario. In this case, we have two states with non-zero Q values. What states are they? What values\ndo they reflect?\n3.2)\nWhat is new in the horizon 2 scenario?\nHow is it possible that there are non-zero\nfor states that do not neighbor $ and *?\n3.3)\nWhat happens for horizons roughly in the range of 3 to 7? What do you observe about the upper right and lower left portions of the grid?\n3.4)\nLook at the horizon 11 scenario. Why does the upper right teleporter state * now have higher\nvalue than the lower left terminal state, $?\n3.5)\nh = 1\nQ2\nQ11\n\nWhat's happening to the arrows in the pictures corresponding to horizon values near\n?\n3.6)\nWhat's happening around horizon 19?\nThe value of being near the \"teleporter\" is about 150. Why? Give an informal description of how an optimal policy plays out for states near the\nteleporter, with the estimated\nvalues at this point.\n3.7)\nThe last picture is for\n(note the change in scale for the color bar!). If we were to consider scenarios well beyond horizon 99, what would the\nvalue function look like for large ?\nFor very long horizons, do we expect the game to eventually terminate?\n3.8)\nIn thinking through each successive horizon above, we built our\nvalue based on knowing our\nvalue. If we were to run the infinite horizon\n, and were to plot the estimate of\nand\nafter each\nis the change in distance traveled in meters along the shortest path from start to goal, regularly calculated using the car's current position;\nis the change in speed in km/h;\nis the change in collision damage, expressed in range [0, 1], where 0 is no damage and 1 is damage when the car crashes.\nWhat information do you need to encode your state? Does this reward function align with your preferences, and why?\nHint: think about how you might compare a successful trajectory, a motionless trajectory where the car does not move, and/or an unsuccessful\ntrajectory where the car crashes\n.\n4.3)\nh = 16\nQh\nh = 99\nQh\nh\nQh\nQh-1\nvalue iteration algorithm (in pseudocode at the end of the chapter on MDPs) with γ = 1\niteration, what would those plots look like?\n4) Reward Hacking\nQ\na′\nReward functions and discount factors define a task and the optimal solutions to this task. We introduce the \"Value Alignment Problem\", which\nconcerns the challenge of aligning the preferences encoded by reward functions (and discount factors) with human preferences.\n4.1)\nCoastRunners is a boat racing game. This video shows how the game should be played.\nOpenAI added this game to their internal testing suite for reinforcement learning algorithms, and they used the game's score as the reward function.\nThey found their learned agents achieved scores ~20% higher than human players; a success. This video shows an example gameplay for their agent.\nHow is it possible that an agent which scores better than humans repeatedly crashes into targets, and does not make progress toward the goal?\n4.2)\nCarla is an open source urban driving simulator that aims to support the development, training, and validation of autonomous driving systems. This\nsimulator formulates driving as an MDP, and has the following (simplified) reward function and discount factor:\nr = (1)Δd + (0.05)Δv + (-0.00002)Δc\nγ = 0.99\nΔd\nΔv\nΔc\n(∆c = 1)\n\nLet's suppose we wanted an autonomous vehicle to observe speed limits. Is this a good idea? How might we add something like this into our RL\nsystem?\n4.4)\nRecall that our reward functions in their general form depend only on state s and action a. This means that the reward function does not depend on\nthe history of states. Do you think alignment (say, to a specific individual's preferences) is always possible with a reward that depends only on the\ncurrent state? Does this limitation affect what aspects of the situation you'd want to include in the problem state?\nCheckoff 2:\nHave a check-off conversation with a staff member, to explain your answers.\nAsk for Help\nAsk for Checkoff\nFurther Reading\nYou can read more about the (common!) problem of reward mis-design in autonomous driving in this recent paper. (You might also ask: should we\neven be trying to formulate the autonomous driving task this way in the first place?)\nWe will continue to explore this topic of value alignment next week. In the meantime, if you're interested in learning more about misspecification of\nreward functions, these academic papers are a good place to start!\nConcrete Problems in AI Safety\nThe Effects of Reward Misspecification: Mapping and Mitigating Misaligned Models\nHere is a long un-curated list of \"objective-hacking\" in a variety of learning contexts.\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\nRES.TLL-008 Social and Ethical Responsibilities of Computing\nSpring 2023\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\nRES.TLL-008 Social and Ethical Responsibilities of Computing\nSpring 2023\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms"
    },
    {
      "category": "Resource",
      "title": "RES.TLL-008 Social and Ethical Responsibilities of Computing (SERC), 6.390: Introduction to Machine Learning, Regression Lab",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/res-tll-008-social-and-ethical-responsibilities-of-computing-serc/mitres-tll008s23_6039_regression.pdf",
      "content": "Introduction to Machine Learning\n(Fall 2022)\nLab attendance check\nType in your section passcode to get attendance credit (within the first fifteen minutes of your scheduled section).\nPasscode:\nEnter\nInstructions\nIn 6.390 a large part of the learning happens by discussing lab questions with partners. Please complete this group self-partnering question then begin the\nlab.\nGroup information\nCreate/join a group\n1. One person (and only one) should create a group.\n2. Everyone else should enter the group name below (in the form groupname_0000 ).\nJoin group:\nSubmit\nTo join another group or leave your current group, reload the page.\nYou are not in a group.\nPlease refer to the course notes on Regression for definitions and explanations of basic concepts.\nLab 2\n1) Warm up\nAs a warm-up, discuss the following questions with your lab partner(s) and be ready to share your reasoning with your instructor:\n1.1)\nWhat is the difference between a learning algorithm and a hypothesis? Write down one possible hypothesis for a linear regression problem in which the\ninput dimension is d = 3. Name two learning algorithms that you know for linear regression.\n1.2)\nWe often use squared error as a loss function in regression. Can you think of a situation in which that might not be a good idea or other loss functions\nwould be better? (What would be a good loss function if you were trying to throw a ball of radius r into a circular hole of radius R?)\n\n2) Least-squares regression on a real data set\nIn this problem we will use linear regression to study the relationship between variables in a real public health dataset. Each data-point represents a U.S.\ncity, and it is characterized by a number of features characterizing aspects of the health of its population, each of which constitutes a dimension of the input\nassociated with that city. In this exercise, we will try to predict the attribute Percent_Person_Obesity based on the following other attributes:\nCount_Person\nMedian_Income_Person (k$)\nPercent_NoHealthInsurance(%)\nPercent_Person_PhysicalInactivity (%)\nPercent_Person_SleepLessThan7Hours (%)\nCommute_Time (min)\nPercent_Person_WithHighBloodPressure (%)\nPercent_Person_WithMentalHealthNotGood (%)\nPercent_Person_WithHighCholesterol (%)\nThe data we will be using contain the above information from 500 U.S. cities and is acquired from Data Commons, a free API combining publicly available\ndata from open sources.\nAs a simple illustration of the dataset, see below a plot of Percent_Person_Obesity vs Percent_Person_PhysicalInactivity using data from 50 random\ncities. (Does it look linear? What do you think linear regression will do on the data in this plot?)\nWe first separate the original 500 cities dataset into three training datasets\nTrain_small contains data from 10 large cities (SF, NYC, Atlanta, etc.)\nTrain_big contains data from 200 cities\nTrain_tiny contains data from 5 cities\nand one test dataset Test_data of 50 cities (different from those in the training sets).\nBecause these attributes are described in very different units (percentages, thousands of dollars, minutes, etc.) learning will work best if we pre-process\nthem so they are all roughly in the same range. (We'll study this process more in a few weeks.) Below, we will be using a black-box function that does linear\nregression on the processed data, then \"unprocesses\" the data and computes the error as well as plots the learned regression fits alongside the original\ndata. The processed datasets, together with the normalization coefficients used for scaling, are viewable at this online spreadsheet.\nOur goal is to learn a linear regression model using the training data such that it can make good predictions on the cities in Test_data .\nx\n\nIn ordinary least squares regression problems, we assume that our objective function\ncomes without a regularization term and only has a mean\nsquare error loss. In other words,\nwhere\nis the prediction made by the hypothesis, and\nis the actual sample output value. For our ordinary least squares case,\nis the squared loss\n, where we have made explicit that the hypothesis depends on both input data\n, and model parameters and\n. Recall that it is possible to solve an\nordinary least-squares regression problem directly via the matrix algebra expression for the optimal parameter vector in terms of the input data\nand\ndesired output vector\n:\nNote that above we have already added a row of all ones into\nand concatenated and\ntogether, making the hypothesis\n(so that the\nanalytic formula gives us both and\n!). We have written the expression for above in terms of our\nand\nmatrices where data-points correspond to\ncolumns; to make it match the notes and many other descriptions of regression (in which data points correspond to rows), you can use the\nversion of\nthe solution, which just works with the transposes of\nand\n. In the rest of the lab, we will implicitly use this \"augmented\" version of\nand ,\nunless otherwise specified.\nIn this section, we will explore the solutions that this analytic strategy produces. In the homework, we will actually implement this analytic strategy.\n1-D Regression\nWe start with a 1-dimensional regression first, so we can visualize the data by a 2D plot.\n2.1)\nWith the Train_small dataset and exactly one of the features above, what are the sizes of\n, , and\n?\nReminder: For labs, all members of a group should enter their answers in the answer checkers in order to get credit for those questions.\nEnter the size of\nas a list of [number_of_rows, number_of_columns]:\nCheck Formatting\nSubmit\nView Answer\nAsk for Help\nAs staff, you are always allowed to submit. If you were a student, you would see the following:\nYou have infinitely many submissions remaining.\nEnter the size of as a list of [number_of_rows, number_of_columns]:\nCheck Formatting\nSubmit\nView Answer\nAsk for Help\nAs staff, you are always allowed to submit. If you were a student, you would see the following:\nYou have infinitely many submissions remaining.\nEnter the size of\nas a list of [number_of_rows, number_of_columns]:\nCheck Formatting\nSubmit\nView Answer\nAsk for Help\nAs staff, you are always allowed to submit. If you were a student, you would see the following:\nYou have infinitely many submissions remaining.\nThe function test_analytic_regress below takes in the training dataset name (e.g., Train_small) and a list of feature names (from those listed above),\nfinds the parameters using the analytic regression formula, then evaluates the mean squared loss on Test_data and returns the test set loss as well as a\nplot of data alongside the learned predictor.\nTo answer the questions below, you should modify the arguments to test_analytic_regress as needed and then run the codebox by hitting\nSubmit.\nJ(θ, θ\n)\nJ(θ, θ\n) =\nL(g\n, a\n) =\nn\ni=1\n∑\nn\n(i)\n(i)\nL\n(h(x\n; θ, θ\n), y\n) ,\nn\ni=1\n∑\nn\ns\n(i)\n(i)\ng(i)\na(i)\nL\nL\ns\nx(i)\nθ\nθ\nθ\nX\nY\nθ = (XX )\nY .\nT -1\n(d+1)×n\nX\nT\nX\nθ\nθ\nY = θ X\nT\nθ\nθ\nθ\nX\nY\n,\nX~ Y~\nX\nY\nX\nθ\nθ\nX θ\nY\nX\nθ\nY\nθ\n\nRun Code\nSubmit\nView Answer\nAsk for Help\nAs staff, you are always allowed to submit. If you were a student, you would see the following:\nYou have infinitely many submissions remaining.\n2.2)\nRun the codebox above, using the Train_small dataset and the Count_Person feature. Do you think the fit or linear hypothesis is reasonable or helpful for\nthis case?\nUsing the Train_small dataset and exactly one of the features listed below, find the feature that gives you the lowest test set error.\nCount_Person\nPercent_Person_WithHighBloodPressure\nPercent_NoHealthInsurance\nMedian_Income_Person\nCommute_Time\nDoes this result make sense to you?\n2.3)\nNow use the feature you found in the previous problem (the one with the lowest test error) and train on Train_big. What do you observe and why? You\nshould use the codebox in the previous problem.\n2-D Regression\nNow let's make it more interesting with a 2-dimensional regression (so that the data is visualized by a 3D plot)!\n2.4)\nWith the Train_big dataset and exactly two features, what are the sizes of\n, , and\n?\nEnter the size of\nas a list of [number_of_rows, number_of_columns]:\nCheck Formatting\nSubmit\nView Answer\nAsk for Help\nAs staff, you are always allowed to submit. If you were a student, you would see the following:\nYou have infinitely many submissions remaining.\nEnter the size of as a list of [number_of_rows, number_of_columns]:\nCheck Formatting\nSubmit\nView Answer\nAsk for Help\nAs staff, you are always allowed to submit. If you were a student, you would see the following:\nYou have infinitely many submissions remaining.\nX θ\nY\nX\nθ\n# train_data can be 'Train_small', 'Train_big', 'Train_tiny'\n# features should be a list of strings. E.g ['Count_Person','Commute_Time']\ndef run():\nreturn test_analytic_regress(\ntrain_data = \"Train_small\",\nfeatures = [\"Count_Person\"]\n)\n\n3 ▾\n4 ▾\n\nEnter the size of\nas a list of [number_of_rows, number_of_columns]:\nCheck Formatting\nSubmit\nView Answer\nAsk for Help\nAs staff, you are always allowed to submit. If you were a student, you would see the following:\nYou have infinitely many submissions remaining.\n2.5)\nUsing the Train_big dataset and one of the feature pairs below, find the pair that gives you the lowest test set error. We've provided another codebox\nbelow for convenience; modify arguments as needed and hit the Submit button to run.\nCount_Person and Percent_Person_SleepLessThan7Hours\nPercent_NoHealthInsurance and Percent_Person_PhysicalInactivity\nPercent_Person_SleepLessThan7Hours and Median_Income_Person\nCommute_Time and Percent_Person_WithHighBloodPressure\nDoes the result agree with your intuition?\nRun Code\nSubmit\nView Answer\nAsk for Help\nAs staff, you are always allowed to submit. If you were a student, you would see the following:\nYou have infinitely many submissions remaining.\n2.6)\nCompare the lowest test set errors you got when using two features versus when using one feature.\n9-D Regression\nLet's now use all of the nine features. Unfortunately we can't easily visualize a 10D space, so we'll only see mean square error as output when running the\ncodebox below.\n2.7)\nRun the codebox below, where test_analytic_regress queries all nine features, and compare the test set losses when using Train_small vs. Train_big.\nY\n# train_data can be 'Train_small', 'Train_big', 'Train_tiny'\n# features should be a list of strings. E.g ['Count_Person','Commute_Time']\ndef run():\nreturn test_analytic_regress(\ntrain_data = \"Train_big\",\nfeatures = [\"Count_Person\",\n\"Percent_Person_SleepLessThan7Hours\"]\n)\n\n3 ▾\n4 ▾\n6 ▾\n\nRun Code\nSubmit\nView Answer\nAsk for Help\nAs staff, you are always allowed to submit. If you were a student, you would see the following:\nYou have infinitely many submissions remaining.\n2.8)\nIn our example, the size of the training set is at most 200 samples. Do you see any problems with our analytic regression if you were to attempt regression\nwith a very large training set size, e.g., as big as the population of the US (about 332 million)?\nWhat if we had a very large training set (again, perhaps 332 million samples), but now with many features per sample (e.g., 2 million features per each\nindividual)? Any problems with analytic regression in this case?\n2.9)\nIn the other extreme, let's try running analytic regression on the Train_tiny, which contains five cities, and use 'all_features'. You should use the\nprevious codebox. What do you see when you run the code? Can you explain why that is the case?\nCheckoff1:\nHave a check-off conversation with a staff member, to explain your answers.\nAsk for Help\nAsk for Checkoff\n3) A taste of regularization\nRecall the form of the regularized ridge regression objective:\n3.1)\nWhat happens to the learned regression line and what would you expect to happen to\n, with very large and very small (e.g., 0) values of ?\n3.2)\nIf our goal is to solely minimize\non the training dataset, what would be the best value of ?\n3.3)\nWhat purpose does adding the regularization term serve?\n3.4)\nJ\n(θ, θ\n) =\nridge\nL\n(h(x\n; θ, θ\n), y\n) +\nn\ni=1\n∑\nn\ns\n(i)\n(i)\nλ∥θ∥2\nJ\n(θ, θ\n)\nridge\nλ\n\nL\n(h(x\n; θ, θ\n), y\n)\nn\n1 ∑i=1\nn\ns\n(i)\n(i)\nλ\n#train_data can be 'Train_small', 'Train_big', 'Train_tiny'\n# features is a string: 'all_features'. (Do not change this)\ndef run():\nreturn test_analytic_regress(\ntrain_data = \"Train_small\",\nfeatures = 'all_features'\n)\n\n3 ▾\n4 ▾\n\nWhy don't we regularize the offset\nin ridge regression?\n3.5)\nCross validation\nCross-validation is a method that lets us estimate the performance of a learning algorithm on a data set. (Not a hypothesis! Make sure you are clear on\nthis point. Ask if not!)\nYou can think of changing a hyperparameter (like ) as changing the algorithm. So, we can use cross-validation to evaluate a choice of . For example,\nshown below is a validation curve obtained by doing leave-one-out cross-validation on a simple dataset, where we vary from 0.01 to 0.3.\nWhy is this the shape of the graph? What is the best value of , in terms of generalization performance, based on this data? Is it the same as the best value\nfor for performance on the training set, discussed in question 3.2 above?\nθ\nλ\nλ\nλ\nλ\nλ\nk\nIn this week's homework, you will actually implement -fold cross validation to select λ on the public health data!\n4) Bands of Bands\nIn many of our 6.390 labs, we will explore a variety of potential biases affecting machine learning. This week, we introduce aggregation bias.\nAggregation bias arises during model construction, when distinct populations are inappropriately combined. In many applications, the population of\ninterest is heterogeneous (i.e., consisting of dissimilar sub-populations) and a single model is unlikely to suit all subgroups.\nTo illustrate this, we look at a particular phenomenon called Simpson's paradox, which arises due to a form of aggregation bias.\n4.1)\nYou continue your foray into exploring Data Commons, and you make an interesting discovery about the relationship between age and blood pressure, as\nshown in the graph below! The blue line is produced from a linear regression on this data. What does this regression line indicate about the relationship\nbetween median age and high blood pressure?\n\n4.2)\nThis data is drawn from two different states: Mississippi (orange stars) and Vermont (green circles). If we plot separate regression lines for these different\ngroups as below, what does the graph tell us about the relationship between median age and high blood pressure? Why might aggregation of these two\ngroups reverse the relationship between age and high blood pressure?\n4.3)\nSimpson's paradox is a phenomenon in which a trend appears in multiple groups of data but disappears or is reversed when data is aggregated. Can you\nthink of a situation in which aggregating data could be harmful? Does this paradox mean we should not aggregate data, for risk of combining subgroups\ninappropriately? Can aggregating data ever be a good idea?\nCheckoff2:\nHave a check-off conversation with a staff member, to explain your answers.\nAsk for Help\nAsk for Checkoff\nFood for thought:\nRegression was first devised by Francis Galton, a Victorian scientist who is known as the \"father of eugenics.\" Galton's discovery of regression was motivated\nby his interest in applying heredity to \"improve the human race.\" He made the first regression line by plotting the diameter of sweet pea parental seeds\nagainst progeny seeds to examine whether exceptional physical traits were inheritable (see Figure). Galton subsequently introduced the idea of \"regression\ntowards mediocrity,\" in which he observed that extreme characteristics regress towards the mean of a distribution. Galton used these ideas to advocate for\n\"selective breeding.\"\nWhile Galton and other statisticians used their creations to advocate inhumane policies, this history does not invalidate the usefulness of regression. But,\nwhen you apply a statistical technique, consider: what are the limitations of this technique? How can your use of this technique create, perpetuate, or\namplify societal harms?\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\nRES.TLL-008 Social and Ethical Responsibilities of Computing\nSpring 2023\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms"
    },
    {
      "category": "Resource",
      "title": "RES.TLL-008 Social and Ethical Responsibilities of Computing (SERC), 6.390: Introduction to Machine Learning, Reinforcement Learning Lab",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/res-tll-008-social-and-ethical-responsibilities-of-computing-serc/mitres-tll008s23_6039_reinforcement.pdf",
      "content": "Introduction to Machine Learning\n(Fall 2022)\nLab attendance check\nType in your section passcode to get attendance credit (within the first fifteen minutes of your scheduled section).\nPasscode:\nEnter\nGroup information\nCreate/join a group\n1. One person (and only one) should create a group.\n2. Everyone else should enter the group name below (in the form groupname_0000 ).\nJoin group:\nSubmit\nTo join another group or leave your current group, reload the page.\nYou are not in a group.\nReinforcement Learning\nDue: Monday, December 05, 2022 at 11:00 PM\nFor this lab:\nYou may find it useful to refer to the notes on Reinforcement Learning.\nDon't spend too long on any one question - use the help queue if you are stuck!\n1) Q-Learning Warmup\nIn this week's lab, we explore the Q-learning algorithm with different methods of setting up rewards.\n1.1) Q-Learning vs. Value-Iteration\nBefore proceeding, it is important to note the differences between the value iteration (VI) algorithm in the MDP notes versus the Q-learning (QL)\nalgorithm in the Reinforcement Learning notes to be explored in this week's lab.\n1.1.1)\nWhat is the principal difference between VI and QL algorithms?\n\nPick one:\ni) VI computes and outputs a value function; QL learns and outputs a policy.\nii) VI computes and outputs a policy; QL learns and outputs a value function.\niii) While running, VI has access to the true state transition function T and reward function R of the MDP, while QL does not.\niv) While running, QL has access to the true state transition function T but not the reward function R of the MDP, while VI has\naccess to both.\nSubmit\nView Answer\n100.00%\nAs staff, you are always allowed to submit. If you were a student, you would see the following:\nYou have infinitely many submissions remaining.\n1.1.2)\nIn which of these settings would you use QL, because VI is not applicable? Assume that the sizes of the state space for all of these are small enough\nso that tabular VI and QL are in principle applicable.\nChoose the Q-learning applications:\ni) Finding shortest paths to a goal for a robot in a grid with perfect transitions (perfect in the sense the exact probability is\ncompletely known).\nii) Finding paths to a goal with shortest expected length for a robot in a grid with noisy transitions with known transition\nprobabilities, given the state at each time step.\niii) Finding paths to a goal with shortest expected length for a robot in a grid with unknown noisy transition probabilities, given\nthe state at each time step.\niv) Playing a single-person video game, where we know the transition probabilities of the game at each time step given the state\nof the game and a score\nv) Playing a single-person video game, whose transition probabilities we don't know, given at each time step the state of the\ngame and a score.\nSubmit\nView Answer\n100.00%\nAs staff, you are always allowed to submit. If you were a student, you would see the following:\nYou have infinitely many submissions remaining.\n1.2) Q-Learning algorithm with different reward functions\nWe explore the Q-learning algorithm using a deterministic MDP with two possible actions (b and c) and four states (s0, s1, s2, s3). The transition\nmodel is\nT (s0, b, s1) = 1\nT (s0, c, s2) = 1\nT (s1, ∗, s0) = 1\nT (s2, ∗, s3) = 1\nT (s3, ∗, s3) = 1\nwhere ∗ represents either b or c.\nSome notes:\n1. All other transitions have probability 0.\n2. The goal state is s2, and s3 is a terminal state (similar to $ in the grid-world question we have looked at).\n3. Assume that if there are ties in the Q function for actions b and c in a state, then we pick action b.\n4. Assume the Q function is initialized to 0 for every state-action pair and that, after every episode (sequence of actions) of length 10, the agent is\nrestarted in state s0.\n5. Assume a learning rate (α) of 0.5.\n\n6. Assume an ε-greedy strategy with ε = 0.\n7. Assume a discount factor of 1.\nNote that we restart the agent in state s0 after every 10 steps because otherwise it may reach s3 and stay there forever.\n1.2.1)\nDraw a state transition diagram, like you drew in the MDP lab.\nNext, we will see two typical schemes for setting up rewards in domains with a goal state: Goal-reward based, and Stochastic-shortest-path (SSP)\nbased, and we will study how each scheme affects the exploration of the state space.\nGoal-reward\nIn the goal-reward case, every action taken from the goal state s2 gives an immediate positive reward of 1, and leads to a zero-reward next state (in\nfact terminal state) s3 that can never be escaped. Taking any action from any state other than the goal state provides zero reward. In other words, we\nhave a reward function which outputs 0 for every state-action pair, except for R(s2, ∗) = 1.\n1.2.2)\nWhat action will be selected the first time the agent encounters\n? And why (explain why during the checkoff)?\nb\nc\nSubmit\nView Answer\n100.00%\nAs staff, you are always allowed to submit. If you were a student, you would see the following:\nYou have infinitely many submissions remaining.\ns0\n1.2.3)\nWhat action will be selected the second time the agent encounters\n? And why (explain why during the checkoff)?\nb\nc\nSubmit\nView Answer\n100.00%\nAs staff, you are always allowed to submit. If you were a student, you would see the following:\nYou have infinitely many submissions remaining.\ns0\n1.2.4)\nWhat action will be selected the hundredth time the agent encounters\n? And why (explain why during the checkoff)?\nb\nc\nSubmit\nView Answer\n100.00%\nAs staff, you are always allowed to submit. If you were a student, you would see the following:\nYou have infinitely many submissions remaining.\ns0\nStochastic shortest path\nIn the stochastic shortest path (SSP) case, we put zero reward on taking any action from the goal state. Every action taken from the goal state s2\nleads to a zero-reward terminal state s3 that can never be escaped. We put -1 in rewards everywhere else. In other words, we have a reward\n\nfunction which outputs -1 for every state-action pair except R(s2, ∗) = R(s3, ∗) = 0.\n1.2.5)\nWhat action will be selected the first time the agent encounters\n? And why (explain why during the checkoff)?\nb\nc\nSubmit\nView Answer\nAsk for Help\nAs staff, you are always allowed to submit. If you were a student, you would see the following:\nYou have infinitely many submissions remaining.\ns0\n1.2.6)\nWhat action will be selected the second time the agent encounters\n? And why (explain why during the checkoff)?\nb\nc\nSubmit\nView Answer\nAsk for Help\nAs staff, you are always allowed to submit. If you were a student, you would see the following:\nYou have infinitely many submissions remaining.\ns0\n1.2.7)\nWhat action will be selected the hundredth time the agent encounters\n? And why (explain why during the checkoff)?\nb\nc\nSubmit\nView Answer\nAsk for Help\nAs staff, you are always allowed to submit. If you were a student, you would see the following:\nYou have infinitely many submissions remaining.\ns0\n2) Q-Learning in a 2D grid\nNow, we'll take a look at Q-learning in a simple 2D grid setting but with a single goal location. We'll adopt the same state space and action space as\nin MDP lab.\nSpecifically, our state space is a 10-by-10 grid, with the bottom-left state indexed as state (0, 0), and our four possible actions are moving North,\nSouth, East or West (note that if the robot tries to move off the board, it cannot; it just stays in the same state). Our single goal is at state (3, 6).\nRemember that for Q-learning, the transition probabilities and reward values are not known in advance by the method--the agent just gets to\nobserve state, action, and reward values as it moves through the domain.\nSome notes (please read!):\nA new episode is started by sampling the first state uniformly at random.\nThe agent follows an epsilon-greedy policy with ε = 0.1.\nEvery action taken from the goal state leads to a zero-reward state that can never be escaped. Thus, to continue learning, we repeat the steps\nabove. Note that we start a new/reset episode only after the agent reaches the goal state.\nIn the case of a tie in the value max Q(s, a) across actions a, we choose the \"best\" action randomly.\na\nAll transitions are noisy; that is, there is some non-zero probability of the agent moving somewhere different from its desired destination. For\nexample, say the agent in in state (0,0) and takes a \"North\" action, there is a non-zero chance that it actually ends up in state (1,1).\nOur γ (discount factor) is set to 0.9 and our α (learning rate) is set to 0.5.\n\nNote that the scale of the colors changes across the different plots, per the bar on the right of each plot.\n2.1) Goal reward\n2.1.1)\nRecall that we are interested in learning the value of taking the best actions starting at a given state. In Q learning, we try to learn these values. But for\nthe moment in this sub-question, suppose we actually knew these \"true\" max Q(s, a) values exactly. Also suppose that taking an action in the goal\na\nstate yields a reward of 100. What is the highest value (a number) for the function maxa Q(s, a) among all state-action input pairs? Roughly what is\nthe max Q(s, a) value when s is a direct neighbor of the goal state (to answer this, ignore the error probabilities and imagine that the actions\na\nalways take the robot to the intended location)?\n2.1.2)\nNow let's go back to Q-learning (where we don't know the true values of states and want to learn them).\nBelow are plots of the maximum Q values max Q(s, a) at different points during an execution of Q learning, with the iteration number shown in\na\nthe title.\n\nWhat has been happening for the first 100 steps of Q-learning?\n2.1.3)\nAt iteration 500, why does the state at (3, 6) have value 50?\n2.1.4)\nAt iteration 1000, how many more times do you think the agent reached the goal state?\n2.1.5)\nAt iteration 10,000, how close are the values plotted (our estimates of the true value of taking the best actions starting at the given state) to the actual\nvalue of taking the best actions starting from the given state?\nIn particular, what should the value of the bottom-right corner be? (To make this easier to think about, you can assume that the transitions are\ndeterministic; that is, the robot always moves in the direction it is \"aiming\".)\n2.2) Stochastic shortest path\nThese are plots of the maximum Q values of the states max Q(s, a) using the SSP formulation as we run 10,000 iterations of Q-value learning,\na\nplotting at specific iterations. Note that the scale of the colors changes across the different plots, per the bar on the right of each plot.\n\n2.2.1)\nAt iteration 100, this is a pretty strange picture. At first we thought we had bugs! Remember that the squares are colored according to the maximum\nof Q(s, a) over all actions in that state, and that they are all initialized to 0. What can we say about the squares that are colored yellow? What about\nthe squares colored blue?\n2.2.2)\nAt iteration 100, how can it be possible for (6, 6) to be colored blue, when all its neighbors are yellow?\n2.2.3)\nAt iteration 100, is there a state where we have tried all the actions twice?\n2.2.4)\nAt iteration 1000, there is a yellow block in the upper left and lots of the policy arrows are pushing the agent to go up there. Why? Is that desirable\nbehavior in this problem? What if there is more than one goal state?\n2.2.5)\nAt iteration 10,000, how close are the values plotted (our estimates of the true value of taking the best actions starting at the given state) to the actual\nvalue of taking the best actions starting from the given state? Roughly what should the value in the bottom right corner be? (Assume that the\ntransitions are deterministic.)\nCheckoff 1:\nHave a check-off conversation with a staff member, to explain your answers.\nAsk for Help\nAsk for Checkoff\n3) No Exit\nRecall that the hyperparameter epsilon ( ) characterizes a trade-off between exploration and exploitation in reinforcement learning. When we use an \"\nε\nε-greedy\" strategy in Q learning, we take a completely random action with probability ε; and with probability 1 - ε, we take the action that'd lead to\nthe highest Q value, i.e. we take arg max Q(s, a).\na\nWe'll explore how choosing the value of epsilon affects the performance of Q learning in a very simple game.\n3.1) Intuition\n\nThe choice of epsilon can affect the overall behavior of Q-learning. Let's consider three possible values for epsilon: 0.0, 0.5, and 1.0.\n3.1.1)\nWhich of these epsilon values risks never finding the optimal policy? --\nSubmit\nView Answer\nAsk for Help\nAs staff, you are always allowed to submit. If you were a student, you would see the following:\nYou have infinitely many submissions remaining.\n3.1.2)\nWhich of these epsilon values has the highest risk of spending way too much time exploring parts of the space that are unlikely to be\nuseful? --\nSubmit\nView Answer\nAsk for Help\nAs staff, you are always allowed to submit. If you were a student, you would see the following:\nYou have infinitely many submissions remaining.\n3.1.3)\nWhich of these epsilon values is guaranteed to cause optimal behavior during learning? --\nSubmit\nView Answer\nAsk for Help\nAs staff, you are always allowed to submit. If you were a student, you would see the following:\nYou have infinitely many submissions remaining.\n3.2) Experience\nFor this part, you will use a Colab notebook we have prepared for you. You can find the Colab notebook here.\nOnce you run the code, wait patiently until you see a yellow and purple square on a teal background (you may need to scroll down from the \"score\"\nand \"reward\" text lines printed out). Ignore everything else for now. Click play in the button right below the square. This is a movie of a policy playing\nthe game No Exit. It's kind of like Pong: the purple square is the \"ball\" and the yellow square is your \"paddle\". The actions are to move the paddle up,\ndown, or keep it still.\nThe state is specified by the positions and velocities of the ball and paddle, with a special added \"game over\" state.\nThe transition model is a very approximate physics model of the ball reflecting off walls and the paddle, except if the ball gets past the paddle in the\npositive x direction, the game is over.\nThe agent gets a reward of +1 on every step it manages to survive.\nWhen watching the game play out, you'll sometimes see that the purple square gets near the right-hand border and then suddenly it changes to a\nstate with the purple square in the bottom left and the yellow one in the upper right -- this means that the game terminated and then reset to the\ninitial state.\nNow we can go back and look at the other output in the notebook:\nFirst, we print what happens during learning in the format (number of iterations, average score): after every 10 iterations of batch Q learning, we\ntake the current greedy policy and run it to see what its average score is. This score represents how long the episode ran before the ball ran off\nthe map, or 100 if it lasted for that long.\nNext is a plot of the score as a function of number of iterations.\nFinally, we run the greedy policy with respect to the last Q-value function for 10 games and report the rewards achieved on each game. We also\nshow a movie clip from a handful of these 10 games.\n\n3.2.1)\nWhat is the maximum possible score in the game? What is the minimum possible score?\n3.2.2)\nRun the code given on the notebook for values of ε in the set 0, 0.5, 1. Does your observation match your answers from 3.1?\nRemember that this is a small instance, so sometimes the random noise of the environment might prevent you from seeing any useful information.\nRun the notebook two or three times if something doesn't line up with your expectation, and then ask for help.\n4) Value Alignment\nLast week we first learned about the problem of \"value alignment\", which aims to ensure the values embedded in AI agents are aligned with human\nvalues.\n4.1)\nIf a reward function is value-aligned (to a specific individual's values), is an agent which used this reward function to learn necessarily also aligned?\nWhy or why not?\n4.2)\nPhilosophers argue over how AI agents should be aligned to human values. Assume, again, that we only want to create an agent which is aligned to a\nspecific person's values. Should this agent be aligned to:\nThe human's instructions?\nThe human's intentions?\nThe human's expressed behaviors?\nBehaviors which are in the 'best interest' for the human?\nAnd why?\nTo make this concrete, you might want to think about recommendations - like those of Netflix. Think about a person who aspires to watch more\n\"good\" films. This person might search for Oscar-winning films (their instructions). But perhaps they're really looking for Cannes-winning films (their\nintent), but they often spend their time watching reality TV instead (their expressed behaviors). Perhaps Netflix thinks it is actually in their best interest\nto watch more documentaries.\n(An article from Iason Gabriel at DeepMind has some nice discussions and formalization of this topic: Goal Misgeneralization)\n4.3)\nIn our consideration of the value alignment problem thus far, we have made a big assumption: that we only want to create agents which align with a\nspecific individual's values. In practice, agents will inevitably interact with many people with different value systems, and from different cultures and\nreligions with different values.\nHow might you try to design a reward function or agent in the face of conflict across different value systems? What are the pros and cons of your\nproposal?\nConsider, for example, writing a reward function for an autonomous vehicle. In a terrible scenario, an autonomous vehicle might have to choose\nbetween saving one of two people: one an elder and one a child. Research has shown that people from Western cultures often express a preference\nfor saving the child, while Eastern cultures express a preference for saving the elder. How might we think about reconciling these preferences? This is\nan open question, so we're not looking for 'correct' answers. Instead, we're looking for thoughtful, creative answers!\nCheckoff 2:\nHave a check-off conversation with a staff member, to explain your answers.\nAsk for Help\nAsk for Checkoff\n\nFurther discussions of these questions:\nThis study of moral preferences for autonomous vehicles is based off of research from MIT!\nMoral Machines\nHow East and West Differ on Who a Self Driving Car Should Save\nFurther reading:\nArtificial Intelligence, Values, and Alignment\nAI Alignment, Philosophical Pluralism, and the Relevance of Non-Western Philosophy - LessWrong (A talk transcript by MIT PhD student Tan Zhi\nXuan)\nFood for (lighter) thought\nThis blog post includes a little game that illustrates multi-armed bandits, which are non-sequential (environment resets after each action)\nreinforcement-learning problems. You can compare how well you do against some classic approaches to solving these problems. And, you can help\nsave the world from Bieber.\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\nRES.TLL-008 Social and Ethical Responsibilities of Computing\nSpring 2023\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms"
    },
    {
      "category": "Lecture Notes",
      "title": "RES.TLL-008  Social and Ethical Responsibilities of Computing (SERC), STS.047 Quantifying People: A History of Social Science Lecture",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/res-tll-008-social-and-ethical-responsibilities-of-computing-serc/9fd9e6dd436baf1b7d0be9ff0011d48c_RES-TLL-008F21-STS047.pdf",
      "content": "STS.047\nQuantify and Punish:\nData, Race, and Policing\nFrom the Burgess Method to Big Data\nModule 11\n(c) NYPD. All rights reserved. This content is excluded from our Creative Commons license. For more information, see https://ocw.mit.edu/help/faq-fair-use/\n\nLogistics\n▪\nFor next Thursday: come\nprepared to give a brief\n(3/5 minute) presentation\non an empowering work\nof recent social science\n▪\nIndividually or in pairs (if\nin pairs, both partners\nshould talk, presentation\nshould be proportionally\nlonger)\n▪\nSlides/visuals optional...\n▪\nPost links on Canvas\nboard\n(c) NYPD. All rights reserved. This content is excluded from our\nCreative Commons license. For more information, see\nhttps://ocw.mit.edu/help/faq-fair-use/\n\nToday's Plan\nI.\nStatistics, policing, and\nracial injustice: an overview\nII. Crime statistics and the\n\"condemnation of\nblackness,\" c. 1890-1940\nIII. Risk assessment and the\n\"actuarial\" approach to\npolicing and punishment,\nfrom the Burgess Method\n(1928) to AI\nIV. \"Data-driven\" policing from\nCompStat (1990s) to Big\nData\n(c) NYPD. All rights reserved. This content is excluded from our\nCreative Commons license. For more information, see\nhttps://ocw.mit.edu/help/faq-fair-use/\n\nQuantify and Punish: Overview\n▪\nModule 11 considers: what role have\nquantitative data, computational methods,\nand social science played in the\nconstruction of modern systems of\ncriminal justice?\n▪\nHow has quantification contributed to the\ninjustices of modern policing and\npunishment - to the creation and\nmaintenance of a system that\ndisproportionately and unjustly targets,\npunishes, incarcerates, and kills people\nof color, especially Black citizens?\n▪\nWhat can history tell us about the role that\ndata and computation should - or should\nnot - play in efforts to create a more just\nsystem of justice in the future?\n(c) Chicago Police Department. All\nrights reserved. This content is\nexcluded from our Creative Commons\nlicense. For more information, see\nhttps://ocw.mit.edu/help/faq-fair-use/\n\nQuantification-Race-Policing: Big Themes\n▪\nTurn to data and quantification\noften driven by desire to create\nfairer, more accountable, less\nbiased systems - often in\nresponse to crisis, calls for reform\n▪\nWhile quantitative turn has\nbrought some positive effects and\nreforms, it has also brought harms\n▪\nEfforts to quantify policing and\npunishment rely on historical\ndata, which reflect biases of\nprevious system - histories of data\nshape their futures\n▪\nData is always already mediated\nthrough previous criminal justice\napparatus - the crime data\" is in\nfact always \"policing data\"\n(c) NYPD. All rights reserved. This content is excluded\nfrom our Creative Commons license. For more\ninformation, see https://ocw.mit.edu/help/faq-fair-use/\n\nQuantification-Race-Policing: Big Themes\n▪\nIn fact, data has played a central\nrole in the historical construction\nof ideas about criminality that\nundergird structural racism of\nmodern criminal justice system\n▪\nComputational tools can obscure,\nlaunder, and exacerbate existing\npatterns of discrimination -\nbehind veil of \"objectivity\"\n▪\nThe establishment of quantitative\nsystems for guiding and\nevaluating policing can reshape\npolicing behaviors in detrimental\nways:\n▪\n\"Ratchet effects\"\n▪\n\"Juking the stats\"\n(c) NYPD. All rights reserved. This content is excluded\nfrom our Creative Commons license. For more\ninformation, see https://ocw.mit.edu/help/faq-fair-use/\n\nCrime, Numbers, and Social Science\n\"Cartes figurative: Crimes contre les proprietes / Crimes contre les personnes.\" Two\nlithograph maps within one border, 21.5 × 33 cm. From Quetelet's Sur l'homme et le\ndeveloppement de ses facultes; ou, Essai de physique sociale, 2 vols. in 1 (Brussels: Louis\nHauman, 1836) [Historic Maps Collection]. (Princeton Historical Maps Collection)\nImage is in the public domain.\n\nThree Episodes\n▪\nCrime statistics and the\n\"condemnation of\nblackness,\" c. 1890-1940\n▪\nRisk assessment and the\n\"actuarial\" approach to\npolicing and punishment,\nfrom the Burgess Method\n(1928) to AI\n▪\n\"Data-driven\" policing from\nCompStat (1990s) to Big\nData\n(c) Northpointe, NYPD. All rights reserved. This content is\nexcluded from our Creative Commons license. For more\ninformation, see https://ocw.mit.edu/help/faq-fair-use/\nImage is in the public domain.\n\nCrime statistics and the \"condemnation of\nblackness,\" c. 1890-1940\n\nThe Statistical Condemnation of Blackness\n▪\nIn 2011 book, Khalil Gibran\nMuhammad argues that\nstatistics played a crucial role\nin the establishing a link\nbetween Blackness and\ncriminality\n▪\nNotion that criminality was a\nfeature of Black Americans as a\ngroup, while crime by white\nAmericans was masked as\nindividual failure\n▪\n\"Black criminality [became] the\nmost significant and durable\nsignifier of black inferiority in\nwhite people's minds\" (p. 3)\n▪\nGibran argues this link was\nforged in the Jim Crow era\n(1890-1940)\n(c) Khalil Gibran Muhammad/Harvard University Press. All rights\nreserved. This content is excluded from our Creative Commons license.\nFor more information, see https://ocw.mit.edu/help/faq-fair-use/\n\nThe 1890 Census\n▪\n1890 Census was a watershed\nmoment\n▪\nContext: 25 years after\nemancipation; more than a\ndecade after end of\nReconstruction - question of\nstatus and future of African\nAmericans in American society\n▪\n1890 census publicized data\nabout prison populations by\nrace: Black Americans were\n12% of population and 30% of\nprisoners\n▪\nStatistical racists like Frederick\nT. Hoffman (Module 7) drew\nheavily on 1890\nImage is in the public domain.\n\nComparing Black and Foreign-Born\n▪\nCrucial to the creation of what\nMuhammad calls the \"statistical\nghetto\" was comparison\nbetween Black and foreign-born\nwhite Americans\n▪\nProgressive era social scientists\ninterpreted (or dismissed)\nstatistics on crime by European\nimmigrants as evidence that\nIrish, Italians, Poles, etc. could\nbe assimilated into US culture\n▪\nCharles R. Henderson, U.\nChicago sociologist, 1901: \"the\n[evil of immigrant crime] is not\nso great as statistics carelessly\ninterpreted might prove...\"\n(c) Khalil Gibran Muhammad/Harvard University Press. All rights\nreserved. This content is excluded from our Creative Commons license.\nFor more information, see https://ocw.mit.edu/help/faq-fair-use/\n\nComparing Black and Foreign-Born\n▪\nHenderson (1901), cont'd: But\nwhere the \"Negro factor\" is\nconcerned, \"racial inheritance,\nphysical and mental inferiority,\nbarbarian and slave ancestry\nand culture...\" were among the\n\"most serious factors in crime\nstatistics.\"\n(c) Khalil Gibran Muhammad/Harvard University Press. All rights\nreserved. This content is excluded from our Creative Commons license.\nFor more information, see https://ocw.mit.edu/help/faq-fair-use/\n\nRisk assessment and the \"actuarial\"\napproach to policing and punishment, from\nthe Burgess Method (1928) to AI\n\n\"Positive Criminology\" & \"Individualization\"\n▪\nKey finding of 19th c. quantitative\nsoc. sci. was regularity of \"laws\"\nof crime - Quetelet's \"budget of\nthe scaffold\"\n▪\nCrime was not random, but\npredictably steady\n▪\nAdvocates of \"positive\ncriminology\" like Cesare\nLombroso (1835-1909) and\nCharles Goring (1870-1919)\nheld criminals were not\nrandomly chosen from\npopulation\n▪\nCriminality seen to be correlated\nwith home conditions, physical\ntraits, genetic makeup,\nneighborhood, and race\nThis image is in the public domain.\n\n\"Positive Criminology\" & \"Individualization\"\n▪\nCirca 1900: international interest\nin the \"individualization of penal\ntreatment\"\n▪\nNational Conference on Criminal\nLaw and Criminology, 1909: U.\nChicago law profs. Ernst Freund\nand Roscoe Pound set agenda:\n▪\n\"Modern science recognizes that\npenal or remedial treatment\ncannot possibly be\nindiscriminate and machine-like,\nbut must be adapted to the\ncauses, and to the man as\naffected by those causes\"\nThis image is in the public domain.\n\nErnest Burgess and Parole Prediction\n▪\nGoal of \"Individualization\"\nencouraged move toward\nindeterminate sentencing for\ncrimes: local parole boards to\ndetermine length of sentence\n▪\n1920s: researchers like Hornell\nHart (Iowa Child Research\nStation) argue that statistics\nmight make it possible to\ncreate a \"prognostic score for\neach man coming up for\nparole\"\n▪\nRobert Burgess (1886-1966):\nPhD in Sociology from U.\nChicago in 1913; faculty 1916\n▪\nCo-wrote Introduction to the\nScience of Sociology w. Chicago\nmentor Robert Park (1921)\nErnest W. Burgess photographed by\nStephen Deutch, University of Chicago\nPhotographic Archive, apf1-02325, Special\nCollections Research Center, University of\nChicago Library.\n(c) University of Chicago. All rights reserved. This\ncontent is excluded from our Creative Commons\nlicense. For more information, see\nhttps://ocw.mit.edu/help/faq-fair-use/\n\nErnest Burgess and Parole Prediction\n▪\nBurgess emphasized quant.\nmethods over \"ecological\"\napproach dominant at Chicago\n▪\nBurgess: \"Prediction is the aim\nof the social sciences as it is of\nthe physical sciences.\" (1929)\n▪\n1927-28: Burgess and four\ncolleagues requested by\nchairman of Illinois parole\nboard to study Ill. procedures\n▪\nUnderstaffed, overworked\nparole officials in Ill. had been\nunable to give much attention\nor deliberation to parole cases\n▪\nBurgess conducts study of 3,000\nparole cases in Illinois ~1920-\nErnest W. Burgess photographed by\nStephen Deutch, University of Chicago\nPhotographic Archive, apf1-02325, Special\nCollections Research Center, University of\nChicago Library.\n(c) University of Chicago. All rights reserved. This\ncontent is excluded from our Creative Commons\nlicense. For more information, see\nhttps://ocw.mit.edu/help/faq-fair-use/\n\nErnest Burgess and Parole Prediction\n▪\nBurgess attempted to find a\nstatistical relationship between\nwho did/did not violate terms\nof parole and 22 other\nindependent factors\n▪\nFactors included: racial and\nethnic categorization, social &\npersonality type, mental age,\ncircumstances of crime, and\nprior criminal record\n▪\nBurgess develops 21-factor test:\nthose with high scores (16-21)\nhad low parole-offense rates\n(1.5%); those with low scores\n(2-4) had highest offending\nrates (76%)\n▪\nReading for this module...\nErnest W. Burgess photographed by\nStephen Deutch, University of Chicago\nPhotographic Archive, apf1-02325, Special\nCollections Research Center, University of\nChicago Library.\n(c) University of Chicago. All rights reserved. This\ncontent is excluded from our Creative Commons\nlicense. For more information, see\nhttps://ocw.mit.edu/help/faq-fair-use/\n\nThe Burgess Method Takes Hold\n▪\nBurgess Method implemented\nquickly at Joliet Penitentiary,\n1932-33\n▪\n1932 election: Democratic wave\nleads to Dem. Governor elected\nin IL; appoints John Landesco,\nBurgess's research assistant, to\nState Parole Board\n▪\nLandesco urges IL legislature to\npass bill to hire sociologists and\nactuaries to \"make analyses and\npredictions in the cases of all men\nbeing considered for parole\"\n▪\n1930s-40s: Adoption of Burgess\nMethod in IL triggers outpouring\nof academic research\nIllinois State Penitentiary, Joliet\n(Source)\n(c) Source unknown. All rights reserved. This content is\nexcluded from our Creative Commons license. For\nmore information, see https://ocw.mit.edu/help/faq-fair-\nuse/\n\nThe Burgess Method Takes Hold\n▪\nOthers seek to critique, improve\nBurgess Method through more\ndata and development of new\nrisk-assessment tools using\ndifferent variables and weighting\ndifferent variables more/less\n▪\nSome explored more\nsophisticated statistical\ntechniques (e.g. multiple\nregression) to develop\nassessment tools\n▪\nResearchers studying Burgess\nMethod found prominent\npositions at top institutions like U.\nChicago, Harvard Law School,\nUniversity of Southern California,\nand University of Minnesota\nIllinois State Penitentiary, Joliet\n(Source)\n(c) Source unknown. All rights reserved. This content is\nexcluded from our Creative Commons license. For\nmore information, see https://ocw.mit.edu/help/faq-fair-\nuse/\n\n▪\nFor the first few decades,\napplication actuarial parole\nmethods confined to Illinois\n▪\nOther states begin to adopt\nsimilar tools in 1960s\n▪\nPrior to 1970s, race and\nnationality were common\nfactors in these tools\n▪\nEarly 1970s: federal gov't\nadopts slim, 7-factor \"Salient\nFactor Score\"\n▪\nFederal adoption stimulates\nwidespread interest in\nparole prediction tools - first\nin California, then wave of\nother states in the 1980s-90s\nFrom Harcourt, Against Prediction: Policing,\nPunishing, and Profiling in an Actuarial Age\n(Chicago, 2007), p. 9.\nThe Actuarial Approach Takes Off\n(c) Bernard Harcourt. All rights reserved. This content\nis excluded from our Creative Commons license. For\nmore information, see https://ocw.mit.edu/help/faq-\nfair-use/\n\nFrom Harcourt, Against Prediction: Policing, Punishing, and Profiling in an Actuarial Age (Chicago, 2007), p. 9.\nThe Actuarial Approach Takes Off\n(c) Bernard Harcourt. All rights reserved. This content is excluded from our Creative Commons license. For more information, see\nhttps://ocw.mit.edu/help/faq-fair-use/\n\nExample of a criminal sentencing\nworksheet from the Virginia\nCriminal Sentencing Commission\n(Source)\n(c) Commonwealth of Virginia. Virginia Criminal\nSentencing Commission.. All rights reserved. This\ncontent is excluded from our Creative Commons\nlicense. For more information, see\nhttps://ocw.mit.edu/help/faq-fair-use/\n\nFrom Parole Prediction to Profiling\n▪\nBy 1951, Burgess argued\nactuarial risk assessment\ncould be applied much more\nwidely than parole selection\n▪\nLater part of the 20th century\nsaw adoption of risk-\nassessment methods to\npolicing potential crimes as\nwell (\"profiling\")\n▪\n1968: Federal Aviation\nAdministration implements\n\"airline-highjacker\" profile -\n25 characteristics\n▪\n1970s+: increasing use of\nprofiles for specific crimes\n\"drug-courier\"\nImage from hijacking of TWA flight 847, 1985\n(CNN)\n(c) JOEL ROBINE/AFP/Getty Images. All rights reserved.\nThis content is excluded from our Creative Commons\nlicense. For more information, see\nhttps://ocw.mit.edu/help/faq-fair-use/\n\n▪\nStarting in 1969, IRS began\nto use computerized\nassessment of past income\ntax returns to develop\npredictive tools (secret\n\"Discriminant Index\nFunction\") to flag income tax\nreturn for audit\nFrom Parole Prediction to Profiling\nImage from hijacking of TWA flight 847, 1985\n(CNN)\n(c) JOEL ROBINE/AFP/Getty Images. All rights reserved.\nThis content is excluded from our Creative Commons\nlicense. For more information, see\nhttps://ocw.mit.edu/help/faq-fair-use/\n\nSocial Costs of Prediction: the \"Ratchet\"\n▪\nLegal scholar Bernard Harcourt\nand others have identified\ncrucial social costs to the\nactuarial, predictive approach\nto criminal justice\n▪\nUsing statistical techniques to\ntarget policing/ punishment\nwill increase success rate of\nsearches, audits, parole\ndecisions, etc.\n▪\nMore searches (of specific\ngroup) will find more\ncontraband...\n▪\nMore parole denials (of\nspecific group) will prevent\nre-offenses...\n(c) Bernard Harcourt, University of Chicago Press. All rights reserved. This content is excluded from our Creative Commons license. For more information, see\nhttps://ocw.mit.edu/help/faq-fair-use/\n\nSocial Costs of Prediction: the \"Ratchet\"\n▪\nIf the actuarial methods\ndisproportionately target a\nspecific group - e.g. drywall\ncontractors for tax audits,\nyoung Black men for street\nfrisks - then over time the extra\npolicing attention will produce\nmore infractions from that\ngroup\n▪\nThis may be taken as\nconfirmatory evidence that the\nspecific group offends at a\nhigher rate (not that the group\nis under heightened attention)\n▪\nThis creates a \"ratchet\":\nincreased police attention more evidence of infractions increased police attention ...\n(c) Bernard Harcourt, University of Chicago Press. All rights reserved.\nThis content is excluded from our Creative Commons license. For more\ninformation, see https://ocw.mit.edu/help/faq-fair-use/\n\nSocial Costs of Prediction: the \"Ratchet\"\n▪\nsubject to police contacts, even with\nsmall/no punishment or for minor\ninfractions, can have significant social\ncosts\n▪\nHarcourt: \"Disproportionate criminal\nsupervision and incarceration reduces\nwork opportunities, breaks down families\nand communities, and disrupts\neducation.\" (161)\np.\n(c) Bernard Harcourt, University of Chicago Press. All rights reserved. This content is excluded from our Creative Commons license. For more information, see\nhttps://ocw.mit.edu/help/faq-fair-use/\n\nAlgorithmic Predictions and Their Biases\n▪\nToday, \"risk assessment\" for\ncriminal sentencing and parole are\nincreasingly conducted by\nalgorithms\n▪\nE.g. the COMPAS -- Correctional\nOffender Management Profiling for\nAlternative Sanctions - algorithm\nfrom for-profit company\nNorthpointe\n▪\nAlgorithmic risk scores widely\nused in assigning bail, criminal\nsentencing, and parole decisions\n▪\nAs of 2016, risk scores given\ndirectly to judges during\nsentencing in at least 11 states\n▪\nCOMPAS algorithm based on 137\nquestions/data points; not race\n(c) Northpointe. All rights reserved. This content is\nexcluded from our Creative Commons license. For more\ninformation, see https://ocw.mit.edu/help/faq-fair-use/\n\nAlgorithmic Predictions and Their Biases\n'The survey asks defendants such\nthings as: \"Was one of your parents\never sent to jail or prison?\" \"How\nmany of your friends/acquaintances\nare taking drugs illegally?\" and\n\"How often did you get in fights\nwhile at school?\" The questionnaire\nalso asks people to agree or\ndisagree with statements such as \"A\nhungry person has a right to steal\"\nand \"If people make me angry or\nlose my temper, I can be\ndangerous.\"'\nJulia Angwin, Jeff Larson, Surya Mattu\nand Lauren Kirchner, \"Machine\nBias,\" ProPublica (May 23, 2016).\n(c) Northpointe. All rights reserved. This content\nis excluded from our Creative Commons\nlicense. For more information, see\nhttps://ocw.mit.edu/help/faq-fair-use/\n\nAlgorithmic Predictions and Their Biases\n▪\n2016 study by ProPublica found\nthat COMPAS algorithm was...\n▪\n...very bad at predicting violent\ncrime: 20% of those predicted to\ncommit future violent crime did\n▪\n...only moderately good at\npredicting all crime (including\nmisdemeanor): 61% of those\ndeemed likely recidivists\ncommitted future crimes\n▪\n...racially biased: Black\ndefendants much more likely to\nbe flagged incorrectly as likely\nre-offenders (false positive), and\nwhite defendants more likely to\nbe mislabeled as low risk (false\nnegative)\n(c) Northpointe. All rights reserved. This content is\nexcluded from our Creative Commons license. For more\ninformation, see https://ocw.mit.edu/help/faq-fair-use/\n(c) Julia Angwin, Jeff Larson, Surya Mattu and Lauren\nKirchner, ProPublica. All rights reserved. This content is\nexcluded from our Creative Commons license. For more\ninformation, see https://ocw.mit.edu/help/faq-fair-use/\n\nAlgorithmic Predictions and Their Biases\n(c) Julia Angwin, Jeff Larson, Surya Mattu and Lauren Kirchner, ProPublica. All rights reserved. This content is excluded from our\nCreative Commons license. For more information, see https://ocw.mit.edu/help/faq-fair-use/\n\n\"Data-driven\" policing from CompStat\n(1990s) to Big Data\n\nBill Bratton and Data-Driven Policing\n▪\nNo single individual more\nresponsible for expansion of\n\"data-driven policing\" than\nBill Bratton\n▪\nAcross two stints as police\nchief in NYC and one in LA,\nBratton led three major\nexpansions of use of data\nand computation\n▪\nCritically: in all three cases,\nBratton was brought in to\nreform police depts. in crisis\n▪\nIn each case, Bratton turned\nto data and computation as a\nremedy for corruption, mal-\npractice, and bias\n(c) TIME. All rights reserved. This content is excluded from\nour Creative Commons license. For more information, see\nhttps://ocw.mit.edu/help/faq-fair-use/\n\nCompstat: Quantitative Policing in the '90s\n▪\nEarly 1990s, NYC experiencing\nhigh crime and raft of police\ncorruption\n▪\nMollen Commission (created\n1992) revealed widespread,\nunchecked corruption in NYPD:\n\"characterized by brutality,\ntheft, abuse of authority, and\nactive police criminality.\"\n▪\n1994: Mayor Rudolph Giuliani\nappoints Bratton new Police\nCommissioner; previously\nBoston police chief and head of\nNYC Transit Police\n▪\nAs head of Transit Police,\nBratton had overseen work of\nJack Maple\nhttps://www.innovations.harvard.edu/compst\nat-crime-reduction-management-tool\n(c) Harvard. All rights reserved. This content is excluded\nfrom our Creative Commons license. For more information,\nsee https://ocw.mit.edu/help/faq-fair-use/\n\nJack Maple's \"Charts of the Future\"\n▪\nJack Maple started in NYPD in 1970;\nbecame a transit police officer, inc.\nundercover Times Square / 42nd\nStreet Station\n▪\nIn 1970s-80s, subways major sites\nof crime, esp. violent robberies\n▪\nAs detective, Maple took to\nmapping patterns of subway crime\nwith pushpins on wall maps -\n\"Chart of the Future\"\n▪\nCharts allowed Maple to observe\nrepeated patterns in subways\ncrimes - large %age of crimes from\nserial offenders tracing set routes\n▪\nTargeting policing to key locations\ndisrupted these patterns; led to\n27% reduction in subway crime\nJack Maple (Source)\n(c) unknown. All rights reserved. This content is excluded from our\nCreative Commons license. For more information, see\nhttps://ocw.mit.edu/help/faq-fair-use/\n\nCompStat in Practice\n▪\nWhen appointed Commissioner\nin 1994, Bratton promoted Maple\nfrom lieutenant to Deputy Chief\n▪\nMaple and Bratton institute new\nCOMPuterized STATistics\nprogram\n▪\nCompStat required personnel\nfrom each of city's 77 precincts\nand other units to submit weekly\nreport on complaints, arrests,\nsummons, open crimes, etc.\n▪\nNYPD CompStat system\nproduced regular reports\nshowing weekly, monthly, annual\ntrends\nhttps://www.innovations.harvard.edu/c\nompstat-crime-reduction-management-\ntool\n(c) Harvard. All rights reserved. This content is excluded\nfrom our Creative Commons license. For more information,\nsee https://ocw.mit.edu/help/faq-fair-use/\n\nCompStat in Practice\n▪\nSystems of regular meetings with\nleading NYPD officials and\nprecinct/unit commanders\nenabled sharing of data,\ndiscussion of crime control\nstrategies, and oversight of units\n▪\nOne key objective of CompStat\nincluding improving accountability\nand professionalism of local force\nwhile giving more responsibility to\nlocal commanders\n▪\nAlso sought to address problems\nof inadequate police attention in\ncertain areas: e.g. major crimes in\npoor, predominantly Black and\nLatinx areas outside Manhattan\ncore went routinely unsolved\nhttps://www.innovations.harvard.edu/c\nompstat-crime-reduction-management-\ntool\n(c) Harvard. All rights reserved. This content is excluded\nfrom our Creative Commons license. For more information,\nsee https://ocw.mit.edu/help/faq-fair-use/\n\nThe \"Marvel\" of CompStat\n▪\nInstitution of CompStat coincided\nwith notable decline in crime in\nNew York City - inc. stark\ndecline in murders, from record\n2,245 in 1990 to 673 in 2000 (and\n289 in 2018)\n▪\nBratton publicly targeted 10%+\nreductions in crime; achieved\n12% in first CompStat years\n▪\nNYT called results under Bratton\n\"marvel of modern law\nenforcement\"; \"simply\nbreathtaking\"\n▪\nBut debate over role of CompStat\nin decline in crime (decline\nbegan in 1990, before CompStat,\nand occurred across major\ncities)\n(c) TIME. All rights reserved. This content is excluded from\nour Creative Commons license. For more information, see\nhttps://ocw.mit.edu/help/faq-fair-use/\n\nThe \"Marvel\" of CompStat\n▪\nApparent successes of CompStat\nin New York led to widespread\nuptake of data-driven methods\nacross other US police\ndepartments over early 2000s,\ninc. Philadelphia, Miami,\nChicago, Baltimore, DC, San\nFrancisco, etc.\n▪\n2002: Bratton recruited to lead\nLos Angeles PD; wracked by\nlongstanding abuses, poor\ncommunity relations, poor\nmorale, and major corruption\nscandal in anti-gang unit\n(\"Rampart Scandal\")\n▪\nBratton instituted CompStat in LA\n(c) TIME. All rights reserved. This content is excluded from\nour Creative Commons license. For more information, see\nhttps://ocw.mit.edu/help/faq-fair-use/\n\nThe \"Marvel\" of CompStat\n▪\nFor opposing perspectives on\nthe role of CompStat in crime\ndecline:\nLauren-Brooke Eisen, Oliver\nRoeder, and Julia Bowling, \"What\nCaused the Crime Decline?\" The\nBrennan Center for Justice (Feb. 12,\n2015)\nSteven D. Levitt, \"Understanding\nWhy Crime Fell in the 1990s: Four\nFactors that Explain the Decline and\nSix That Do Not,\" Journal of\nEconomic Perspectives 18, no. 1\n(Winter 2004): 163-190.\n(c) TIME. All rights reserved. This content is excluded from\nour Creative Commons license. For more information, see\nhttps://ocw.mit.edu/help/faq-fair-use/\n\n\"Juking the Stats\": Critiques of CompStat\n▪\nIntroduction of CompStat had\nmajor effects on practice and\nculture of policing\n▪\nIncreasing political, managerial\nemphasis on reducing CompStat\nnumbers created pressure on\ncommanders and officers to make\nit appear crime was falling\n▪\nEmphasis on measurable stats\ndistracted from public safety\ngoals, community relationships\n▪\n\"Juking the Stats\": statistical\nmanipulation designed to make\nCompStat figures appear better:\ne.g. through reclassifying crimes\ninto lesser categories (aggravated\nassaults assaults)\nMayor Rudolph W. Giuliani, right, and\nPolice Commissioner William Bratton at a\n1995 news conference reporting a decline\nin crime statistics.James Estrin for The New\nYork Times.\nhttps://archive.nytimes.com/www.nytimes.\ncom/interactive/2013/12/06/nyregion/bratt\non-on-the-issues.html - /\n(c) James Estrin/The New York Times. All rights\nreserved. This content is excluded from our Creative\nCommons license. For more information, see\nhttps://ocw.mit.edu/help/faq-fair-use/\n\n\"Juking the Stats\": Critiques of CompStat\n▪\nRewarding measurable indicators of\npolice activity - e.g. arrests and\ntickets - incentivized officers to\nincrease punishment for minor\noffenses (e.g. transit fare evasion,\nvandalism, loitering)\n▪\nEspecially combined with \"broken\nwindows\" theory (as in Bratton in the\n90s): theory that rigorously policing\nminor \"anti-social\" crimes creates\nenvironment of order, lawfulness that\nprevents more serious crime\n▪\nBlack and Latino citizens dis-\nproportionately targets of minor-\ncrime enforcement: 2001-2013, Blacks\nand Latinos in NY (57% of population)\nwere 80% of misdemeanor arrests\nand summonses\n(c) James Estrin/The New York Times. All rights\nreserved. This content is excluded from our Creative\nCommons license. For more information, see\nhttps://ocw.mit.edu/help/faq-fair-use/\n\n\"Juking the Stats\"\nThe Wire, Season 4, Episode 9\n(2006).\n\nThe Rise of Big Data Policing in the 2000s\n▪\nBratton returned as NYPD\nchief Jan. 1, 2014 - in wake of\nwidespread anger about\n\"stop-and-frisk\" and legal\nruling declaring it\nunconstitutional\n▪\nBratton oversees\nconstruction of real-time\ncrime-command center in\nManhattan; orders tens of\nthousands of crime mapping\ntablet computers\n▪\n\"Intelligence-led policing\"\npurported to go beyond\n\"hunches,\" offer alternative\nto stop and frisk\nNYPD Joint Operations Center (City Journal)\n(c) Victor Milsoslvsky/NYPD. All rights reserved. This content\nis excluded from our Creative Commons license. For more\ninformation, see https://ocw.mit.edu/help/faq-fair-use/\n\nData & the Who/Where/When/How of Policing\n▪\nWhom...\n▪\nIn 2012, Kansas City PD used\nsocial-network analysis to\nidentify 884 people deemed\nlikely to commit homicides \"focused deterrence\"\n▪\nChicago developed\nalgorithmic \"heat list\" to\nidentify likely perpetrators and\nvictims of gum violence\n▪\nWhere...\n▪\nJeff Brantingham (UCLA) uses\nearthquake-prediction\ntechniques to develop PredPol\nalgorithm for identifying likely\nsites of crime implemented\nby LAPD in 2011 (25%\nreduction in burglaries)\n\nData & the Who/Where/When/How of Policing\n▪\nWhen...\n▪\nNetworks of surveillance\ndevices (cameras, license\nplate readers, etc.) used for\nreal-time tracking and alerts;\ne.g. NYPD-Microsoft \"Domain\nAwareness system\" monitoring\nsouthern Manhattan\n▪\nHow...\n▪\nData mining to search\n\"cellular, digital, and\nbiological data trails\"\n▪\nFacial recognition\n▪\nNotably, much of this done in\nconcert with private for-profit\ncompanies - as in Palantir and\nLAPD Real-Time Analysis Critical\nResponse section\n\nThe Future of Big Data and Policing?\n▪\nAndrew Guthrie Ferguson\nproposes five-point checklist for\nsafe application of big data\ntechniques:\n1.\nCan you identify the risks your\ntechnology is trying to address?\n2.\nCan you defend the inputs into\nthe system?\n3.\nCan you defend the outputs\n(how they will impact policing\npractice/community)?\n4.\nCan you test the technology\n(transparency/accountability)?\n5.\nIs police use of the technology\nrespectful of the autonomy of the\npeople it will impact?\n▪\nOr, abolish big data? (Data for\nBlack Lives)\n(c) Data for Black Lives. All rights reserved. This content\nis excluded from our Creative Commons license. For\nmore information, see https://ocw.mit.edu/help/faq-fair-\nuse/\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\nRES.TLL-008 Social and Ethical Responsibilities of Computing (SERC)\nFall 2021\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms"
    },
    {
      "category": "Resource",
      "title": "RES.TLL-008 Social and Ethical Responsibilities of Computing (SERC), 17.64 The Road to Crisis",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/res-tll-008-social-and-ethical-responsibilities-of-computing-serc/mitres_tll008_17-64_crisis2.pdf",
      "content": "The Road to Crisis\nDuring a press conference in mid-December 2021, President Biden announced plans to provide Taiwan with\nadditional Patriot air defense systems, two-dozen new F-16 fighter jets, eight surplus P-3 maritime patrol\naircraft, and five naval destroyers equipped with Aegis Combat Systems. Biden explained that the arms deal--\none of the largest in Taiwan's history--was intended to bolster Taiwan's ability to defend itself and its\ndemocratic way of life. In response to questions from reporters, President Biden also reiterated a pledge that\nhe had made in October: \"If China attacks Taiwan, the United States will take steps to defend Taiwan.\"\nThat evening, China's Foreign Minister Wang Yi issued an official statement criticizing the arms deal and\naccused the United States of \"meddling in regional affairs\" and \"dangerously and unnecessarily escalating\ntensions.\"\nIn the days following Biden's press conference, the People's Liberation Army (PLA) significantly increased\nmilitary flights through Taiwan's Air Defense Identification Zone. In a 72-hour period from December 20\nDecember 23, the PLA Air Force (PLAAF) and PLA Navy (PLAN) flew more than 180 aircraft in the airspace\nsurrounding Taiwan. Taiwan's government responded by scrambling fighter jets to intercept many of these\nPLAAF and PLAN aircraft.\nOn December 24, a PLAAF Su-27 fighter jet collided with a Taiwan Air Force F-16 fighter jet, leading to the\ndeaths of both pilots. The domestic public in China takes to the streets demanding harsh action against Taiwan\nto avenge the death of the PLAAF pilot.\nPresident Biden and Secretary of State Blinken urge calm, but also warn China--both privately and publicly--\nto not attempt to forcefully change the status of Taiwan.\nOn December 25, Christmas celebrations in the Taiwanese cities of Taipei and Kaoshiung are interrupted by\nextensive blackouts. More than a million people are left without power, and 279 Taiwanese citizens die as a\nresult of the power outages (e.g., life support failures, etc.).\nRecorded Futures, the Somerville, Massachusetts-based company that identified the Chinese malware behind\npower outages that plagued Indian cities during the Sino-Indian conflict of 2020, make a similar discovery in\nthis case: the Taiwan backouts are almost certainly triggered by Chinese malware. The discovery was made\npossible by advances in machine learning that allowed Recorded Futures to find common patterns between the\ntimings of sequential cyber-intrusion attacks in India and Taiwan. Recorded Futures identified a record of\nattempts to connect to the same infrastructure registered to Tsinghua University that was implicated in the\nIndian outages. In the China-India incident, analysts believed China was signaling its ability to cause significant\ndamage if India escalated the border conflict. The U.S. intelligence community has yet to confirm that the\nblackout is the result of a Chinese cyberattack, and some AI/ML scholars have raised doubts about the accuracy\nof the Recorded Futures machine learning algorithms.\nPresident Biden schedules an emergency National Security Council Principals Committee meeting for this\nafternoon. You've been called into the office to help your organization prepare for this meeting. You open\nyour email to find President Biden's strategic objectives for dealing with the crisis:\n1. Maintain status quo (i.e., no change to the status of Taiwan).\n2. Protect U.S. citizens and interests in the People's Republic of China (PRC) and Taiwan.\n3. Prevent further escalation between the PRC and Taiwan.\n4. Should the PRC and Taiwan escalate, minimize direct U.S. combat involvement in conflict.\n\nMove 1:\nDecember 26, 2021\n(30 minutes followed by 15 minute \"report back\")\nAs the death toll in Taipei and Kaoshiung continues to climb, your teams begin formulating the initial U.S.\nresponse. The FBI and NSA also reports increased evidence of Chinese intelligence collection in the United\nStates. Specifically, Chinese \"consular\" officials have been started taking photos of U.S. military and port\nfacilities in Hawaii, Alaska, California, and Washington, and there have been increased phishing attempts against\nsenior U.S. military officers.\nThe list below includes tasks for each team.\nDepartment of State:\n-\nWhat actions, if any, should the United States take to protect American citizens and interests in\nChina/Taiwan?\n-\nWhat coordination, if any, should the United States take with allies and partners within the Asia-Pacific\nregion and beyond?\n-\nPrepare talking points for the Secretary of State that he can use to offer brief comments on the situation\nif asked by reporters. Ensure these are aligned with the whole of government position.\nDepartment of Defense:\n-\nWhat military measures, if any, should the United States take at this point? These measures could\ninclude mobilization/deployment of forces, kinetic/non-kinetic action, etc.\n-\nPrepare talking points for the Secretary of Defense and Chairman of the Joint Chiefs that they can use\nto offer brief comments on the situation if asked by reporters. Ensure these are aligned with the whole\nof government position.\nOffice of the Director of National Intelligence:\n-\nWhat additional information does your team (and the other Executive Branch agencies) need?\n-\nHow will you obtain this information (i.e., which intelligence disciplines are best suited to collect this)?\nDepartment of Homeland Security:\n-\nWhat steps should the United States take to protect the U.S. homeland from kinetic and non-kinetic\nattacks?\nDepartment of Justice:\n-\nWhat actions should the Department of Justice take to mitigate the risk of espionage against the United\nStates during this period of heightened tensions? Which organizations will DOJ need to coordinate\nwith?\nWhen formulating your recommendations, ensure you respond to the defined tasks/questions and ensure your recommendations are\nin line with President Biden's objections. You are encouraged to coordinate with the other Executive branch agencies when developing\nyour response.\n\nMove 2:\nDecember 28, 2021\n(35 minutes followed by 15 minute \"report back\")\nOn December 27th, Taiwan's President Tsai Ing-Wen declares a state of emergency in Taipei and Kaoshiung,\nwhere power still remains out. She also orders a limited mobilization of Taiwan's reserve forces (including 3000\ninfantry personnel) and puts 40 civilian fishing vessels and 8 civilian Boeing airliners from China Airlines under\nthe operational control of the Ministry of Defense. Tsai publicly states these measures are to \"support\nhumanitarian relief operations,\" but also makes a secret call to President Biden in which she expresses fear that\nChina may attempt to use military force to seize Taiwan in the coming weeks.\nAlthough large numbers of PLA ground, naval, and air forces continue to flow into China's Eastern Theater\nCommand, U.S. intelligence has no specific indication of an impending attack. China's defense minister,\nhowever, issues the warning that \"outside nations should not meddle in China's internal affairs. Unnecessary\nmeddling will risk a significant heightening of tensions.\"\nIn the early morning hours of December 28th, Guam--a U.S. territory that is home to Anderson Air Force\nBase and several key U.S. naval facilities--suffers a significant cyberattack that significantly degrades operations\nat Anderson and kills 3 Americans at Guam Medical Center in the city of Tamuning. Intelligence assessments\nsuggest with high confidence that China's military is behind the data breach and cyberattack on Guam\nAt the same time, ransomware locks down systems at sea and airport facilities in Long Beach, Los Angeles,\nOakland, San Francisco, and Seattle--all facilities that would be used to deploy material into the Pacific Theater.\nAn unknown actor demands $500 million to unlock the systems. Security analysis identifies the attack as Conti\nransomware deployed via a spearphishing attack that compromised employee accounts lacking multi-factor\nauthentication. The Conti Ransomware Gang is known to perform ruthless attacks on life-critical systems, but\nin this case, the NSA and DHS are unable to attribute the ransomware attack's initiator.\nEvents also continue to unfold in Asia. The identities of U.S. diplomatic and intelligence personnel stationed\nat diplomatic posts throughout Asia are posted on Chinese social media sites, which urge \"loyal Chinese\npatriots\" to track down and hold these individuals accountable for \"aggression against China.\" Intelligence\nanalysis of Chinese operations reveals that information about these personnel were likely obtained through the\nSolarWinds leak in early 2020.\nOn top of actions in the cyber domain, China has detained four U.S. citizens working for Ford in Shanghai,\naccusing them of espionage.\nIn this move, teams do not have specific tasks. Instead, determine what actions you believe your agency is responsible for and develop\na set of policy recommendations. Again, ensure the recommendations are in line with the president's objectives and are coordinated\nwith the other agencies. President Biden, however, has tasked the NSC to address three specific points (ensure, however, that you\nconsider all events that have transpired):\n-\nThe president seeks advice on retaliation for the cyberattack on Guam. Specifically, he asks for legal\nand military/intelligence guidance on 1) the legality of a retaliatory cyberattack and 2) an assessment\nof the risks of spillover effects that impact non-military actors in China (he is concerned about the\nlegal, political, and ethical implications of harming civilians)\n-\nHow to address the ransomware incident?\n-\nWhat actions can the United States take to deter further aggression against the U.S. homeland and\nTaiwan without significantly escalating tensions?\n\nMove 3:\nJanuary 5, 2021\n(40 minutes, followed by 20 minute brief)\nIn the days following the cyberattack on Guam, PLA forces continued to flow into the mainland areas near\nTaiwan. In response, Taiwan ordered a full mobilization of its reserve forces and heightened its military alert\nlevel on December 29th. That evening, President Biden issued a public statement again urging calm in the\nTaiwan Strait Crisis of 2021, and reiterated Washington's support for Taiwan's democratic system.\nEfforts to remove the ransomware have been largely ineffective and the port facilities remain closed. The port\nclosure has had several follow-on effects. First, the inability to load/un-load ships has led to a back-up of\nshipping vessels both off the western U.S. coast and in key chokepoints, including the Panama Canal. Shipping\nanalysts have described the port closures as having the potential to generate a larger impact on global trade than\nthe 2021 Ever Given incident. The U.S. Chief of Naval Operations has voiced concerns that delays at the\nPanama Canal could make it difficult to reposition naval vessels in the event of conflict. Closer to home, fears\nthat the port closure will exacerbate global supply chain issues has led to Americans to begin stockpiling\nhousehold goods. In Los Angeles, large scale protests erupt as port workers take to the streets criticizing the\nU.S. government of its inability to resolve the ransomware incidents. Other actors take advantage of the protests\nto loot homes and businesses around the city. Amid the chaos, protestors set the Chinese Consulate in Los\nAngeles ablaze, resulting in the death of two Chinese consular officials. The governor of California activates\nthe National Guard to restore calm. Governors in several other states including Washington, Texas, Florida,\nand New York follow suit as a preemptive measure.\nChina's foreign minister condemns \"the violent attack\" on its Los Angeles Consulate and publicly lambasts the\nUnited States for failing to uphold its responsibilities under the Vienna Convention on Consular Relations. As\nprotests outside of U.S. diplomatic and consular facilities in China mount, the Chinese foreign ministry\nannounces they are no longer able to ensure the security of U.S. consulates in China and orders the immediate\nclosure of U.S. consulates in Shanghai, Nanjing, and Guangzhou. These facilities support some of the largest\npopulations of American citizens in China.\nU.S. intelligence indicates that a U.S.- based Taiwan-activist group is taking advantage of the protests to\ndeliberately target Chinese diplomatic facilities and may be planning to attack Chinese diplomats and consular\nofficials in major U.S. cities. While some officials in the DHS and DOJ push for search warrants (and forced\nnondisclosure, to keep the search under wraps) to inspect electronic communications of protest attendees, they\nface pushback from internal groups that believe the warrant would grossly violate the privacy of innocent\ncitizens exercising their protest rights.\nOn January 3rd, a U.S. Air Force RQ-4 unmanned reconnaissance aircraft flying 50 miles north of Taiwan\ncrashes into the East China Sea after U.S. operators lose contact with the aircraft. Initial reports suggest that\nChinese disturbance signals jammed the drone signal and disrupted communication with its operators. A frigate\nfrom Taiwan's Navy sailing to the crash site to help recover wreckage suffers an explosion, killing 17 Taiwanese\nsailors. Although it is too soon to assess the cause of the explosion, members of Taiwan's public are calling for\nmilitary retaliation against China.\nAt home, American pundits and politicians are calling on President Biden to resolve the situation. Hawks are\ncalling for action to punish China for causing the incident; some doves have demanded that Biden cut back\nelements of the arms deal as an olive branch to China; while others simply hope the U.S. stays out of the rapidly\nescalating conflict in Taiwan.\nDetermine how your agency can best respond to the events that have transpired in this move and develop a set of policy\nrecommendations. What are the most important issues that your agency must wrestle with? Again, ensure your recommendations\nare in line with the president's objectives and are coordinated with the other agencies.\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\nRES.TLL-008 Social and Ethical Responsibilities of Computing (SERC)\nFall 2022\nFor information about citing these materials or our Terms of Use, visit:\nhttps://ocw.mit.edu/terms"
    },
    {
      "category": "Resource",
      "title": "RES.TLL-008 Social and Ethical Responsibilities of Computing (SERC), 6.031 Moral Lenses",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/res-tll-008-social-and-ethical-responsibilities-of-computing-serc/mit_restll008_6-031_moral.pdf",
      "content": "Moral Lenses\nAbby Everett Jaques\nMIT\nWhen you make something, your efforts may go well or badly in many ways.\nThings may go well in that you may benefit yourself, by furthering your career, or\nenjoying the feeling of using your skills, or creating something people admire. You\nmay benefit others--your company, your family, your users, or even society at\nlarge. Or things may go badly, so that your project is a stain on your career or\nyour reputation, a harm to others, even a danger to the world. Often, things will\ngo well in some ways, and less well in others. Sometimes there are tradeoffs, even\npainful ones.\nEvaluating your project ethically is about understanding all the ways it goes well\nand badly. It's about tallying up all the things your project does--not just in the\nnarrow sense in which you might conceive it at first, but in as much richness and\ndimension as you possibly can--and then thinking through the ways in which\nwhat it does is good and bad (sometimes both at once!), and for whom.\nTo assess your project ethically, you'll use four moral lenses, each of which offers\nyou a way of looking at a project in order to see what's good or bad about it.\nThe lenses complement each other: each one gives you a different perspective.\nSome change the scale at which you're considering the project, as a microscope or\ntelescope does. Some make particular features visible and obscure others, as\nlenses that filter certain wavelengths do. The lenses provide goals and guardrails:\nthings to aim for and things to avoid.\nSometimes the lenses will agree; other times something that seems fine when\nviewed with one lens will seem worrying or even egregious with another. When\nthat happens, you need to think about how the people affected would weigh\nvarious harms and benefits--and remember that others may weigh things\ndifferently than you do.\n\nA Process for Ethical Engineering\nTo use the lenses, you first need to think about everything that will be different if\nyour project exists and operates. When you make things, you change things; the\nworld is altered. In what ways? Some are small: you may check something off\nyour to-do list; your boss may add something to your list of accomplishments for\nyour performance review; users may gain a new feature in a familiar app. But\nothers are larger: you may get funding for your startup; users may change how\nthey perform an important activity in their lives; old ways of doing things may\ndie off, so that some people lose their jobs, economies both regional and national\nsuffer or thrive; and so on.\nOnce you've thought of as many ways a project will and may change things as\nyou can, notice all the different people and groups who are affected, and how the\neffects are similar or different depending on who you're talking about.\nNext, use the lenses to get clear about the ways in which particular effects on\nparticular groups are good and bad. The same thing may be good for one group\nbut bad for another, or good in one way and bad in another way for a single\ngroup, and so on.\nFinally, revisit your project's design: How can you maximize the good and\nminimize the bad features you've identified? How will you justify your choices to\nthe people and groups affected by them? Maybe your project needs to be quite\ndifferent. Maybe you shouldn't pursue it at all, because something else would be\nbetter.\nYou can think of this process as involving four steps:\n1.Differences: Think through all the things your project does, all the ways\nthe world is different with your project in it.\n2.Players: Catalog the people and groups who are affected by those\nchanges.\n3.Values: Use the lenses to understand how the differences your project\nmakes for each person or group are good and bad.\n4.Design: Think about which of your design choices affects the good and\nbad aspects of your project overall. How can your decisions shape the\nbalance and distribution of harms and benefits? Iterate your project in\nlight of steps 1-3 and your new understanding of how your engineering\nchoices are also ethical choices. Then repeat this process with the new\nMoral Lenses\nJaques\n\nproject, until you arrive at a version that seems to achieve the best\nbalance of benefits and harms for all the affected groups.\nStep 1: Finding Differences\nYou make things because you want to change things. You want to provide a\nbetter way to do something, or enable something never possible before. You can\nthink of the changes your project makes in layers of nested systems:\n- Layer 1: changes in the system that includes you, your team, your\norganization\n- Layer 2: changes in the systems that contain your users, your\ncompetitors, the activities your software performs/replaces/changes\n- Layer 3+: changes in the systems that enclose the first 2 layers: the\nlarger business or institution that contains the activities from layer 2, the\nindustry of which that business or institution is a part; the larger\neconomy of which that industry is a part; and so on.\nIn each layer, think of as many changes, or potential changes, as you can. Make a\nlist, and when you think of a change in one layer, ask yourself how it would affect\nthe others. The idea is to understand all the changes that will or may happen--\nbig or small; good, bad, or in between--as a result of the existence and operation\nof your project.\nOne way to tackle this step is to work forward, starting from what you expect\nyour project to do and imagining how those things will cause further effects.\nAnother way is to work backward: look at similar projects that you or others\nhave created, where you know what (some) of their effects were, and see if or how\nthose effects map to your project, given its similarities and differences compared\nto the previous one.\nYou can also consult the work of experts in other fields: each layer involves\nsystems, from companies and other organizations to the health care system, the\ngovernment, and the economy. Social scientists know a lot about how those\nsystems work, and have important insights to offer. Depending on the specifics of\nyour project, there may be various kinds of experts who've already developed the\ninsights you need. Don't hesitate to seek them out.\nA combination of these approaches is often the best bet.\nMoral Lenses\nJaques\n\nExample: Suppose you make a new app that can perform the tasks of a\nroutine medical checkup. Layer 1 changes may include completing a\nproject you've been assigned by your boss; your organization's being able\nto go public; etc. Layer 2 changes may include enabling people without\neasy access to medical care to get checkups outside of doctors' offices or\nenabling nurses to administer checkups without MDs (one or both of those\nmay have been a design goal from the start, but one may not have been\nthe original plan). Layer 3 changes may include medical practices reducing\ntheir number of primary care physicians; higher up we may see insurers\nrequiring the use of the app instead of in-person appointments; medical\nstudents shifting away from primary care specialties; changes to the\nfederal budget because of cost savings on Medicare and other federally\nfunded programs, unemployment and/or retraining needs among primary\ncare physicians, etc.\nStep 2: Identifying Players\nImagine all the changes you identified in Step 1 were parts of a story, a movie.\nWho would be in the cast? Notice all the people and groups you've identified--\nyou and your boss, your users and your competitors, and so on. Don't just think\nabout who'd have starring roles; remember that the extras matter too: sometimes\nvery important ethical effects are those that are small at the individual level but\nmatter because they involve so many people, even if those people might initially\nseem far from the center of the action.\nNotice too that sometimes you'll need to subdivide groups: your software may\nwork differently for some subsets of users; it may affect some non-users more than\nothers, etc. Again you can think in layers: at each layer from Step 1, who is\naffected? Remember to capture secondary effects, too: if some parents are directly\naffected, there may be important indirect effects on their children, for example.\nOr if primary care doctors are directly affected, the nurses and other employees in\ntheir practices may be indirectly affected.\nAdd the relevant people and groups, subdivided as needed, to each change on\nyour list from Step 1.\nExample: Keep thinking about the medical checkup app. Lots of people\nand groups came up in describing the changes in each layer: you, people in\nyour company, patients, doctors, medical students, hospital\nMoral Lenses\nJaques\n\nadministrators, insurers, and more. And some of those groups will need to\nbe subdivided: we imagined patients being required to use the app instead\nof in-person appointments, but that might be true only for less affluent\npatients; people with very high-end insurance might not be subject to the\nrequirement, for example.\nStep 3: Using the Four Lenses\nNow that you know how your project makes a difference, and for whom, it's time\nto get clear on which of those differences are good and bad, and in what ways.\n(Some differences will be good in one way, and bad in another.) That's what the\nlenses are for.\nI. The Outcomes Lens: When we make something, the state of the world is\naltered. What changes when your project is created/used/maintained? In what\nway(s) do things turn out better or worse vs the starting state?\n‣ Ask: What good or bad thing, tangible or intangible, does each person or\ngroup have more or less of? (health, wealth, power, freedom, security,\ntime, burritos?)\n‣ This lens is about costs and benefits.\nExample: Users of the checkup app may save time and money by using it:\nthose are outcome benefits to them. (Though if the app is less good than\na doctor at detecting some medical conditions, your users may also lose\nhealth by using it. This would be an outcome harm.) Given the problems\nin the US health care system, an app like yours might be very valuable:\nyou and your company might well make a lot of money. That would be an\noutcome benefit. On the other hand, some primary care doctors might\nlose their jobs; that would be an outcome harm.\nII. The Process Lens: it's not just what happens, but how. Even if the\noutcome is good, it can still be that something has gone wrong. How is each\nperson or group treated by, and in, this process? Are rules followed? Rights\nrespected? Duties fulfilled?\n‣ Ask: Did people have a chance to consent or refuse? (Note that EULAs\nthat are too long to read and too full of jargon to understand do not yield\nmeaningful consent.) Were they deceived (which undermines their ability\nto meaningfully consent)? Was someone used in ways they might object\nMoral Lenses\nJaques\n\nto? Was their privacy violated? Did people have the kinds of control they\nare entitled to, or were important things out of their hands? Were\nprocedures/rules/etc. followed as people reasonably expect?\n‣ This lens is about the means by which outcomes are produced.\nExample: Think about our checkup app again. If many people would\nprefer to talk to a human doctor rather than using the app, but their\ninsurer won't allow it, then the existence of the app reduces those people's\ncontrol of how they receive medical care. This is a process harm to those\npeople, even though to other people the additional option may be a\nprocess benefit.\nNow imagine the app can monitor people's health without their knowing\nit (thanks to some fancy hardware/peripherals that check vital signs at a\ndistance using radio waves, plus some data collection about people's\nactivities from their phone accelerometers, calendars, etc, plus more data\ncollection from the Alexas in people's homes that hear what they talk\nabout, their tone of voice, whether they sneeze and cough...).\nEven if people can gain important health information this way--an\noutcome benefit--it is nonetheless a process harm. Individuals are\nsupposed to get to decide what medical care they get, generally speaking,\nbecause control of what happens to your own body is important. Having\nthis app collect data about everyone could also provide important\noutcome benefits to the population as a whole--say, by supporting\nmedical research, enabling early intervention with outbreaks of infectious\ndiseases, and so on. But again, if people do not have the opportunity to\nconsent or deny consent, there is a process harm. And of course, if you\nwere monetizing all this health data, you or your company might gain\nthat outcome benefit. But that does not negate the process harm.\nIII. The Structure Lens: how are outcomes distributed among people and\ngroups? what are the differences in how people and groups are treated in the\nprocess? what are the patterns of harm and benefit?\n‣ Ask: Is everyone treated equally? If not, what is the basis for the\ninequality? Do the patterns of harm and benefit track historical patterns\nof advantage and disadvantage, for example by privileging people of a\ncertain race or gender, or do they mitigate historical patterns? Does the\ndistribution of harms and benefits look fair, or unfair?\nMoral Lenses\nJaques\n\n‣ Remember to consider both outcomes and process when you're thinking\nabout the distribution of harms and benefits: in other words, you want to\npay attention not only to the patterns in who ends up better and worse\noff, but also the patterns in who was treated well or badly as a means to\nthose outcomes.\n‣ This lens is about things like patterns, distribution, fairness, and bias.\nExample: Recall the insurers forcing people to use the app instead of\nseeing a doctor. This may only happen to people who are poor, with\ninexpensive insurance. The wealthiest people, who have excellent\ninsurance or don't need insurance at all, may have more options. This\npattern, where the app gives additional flexibility to people who are\nalready the best off, and limits the control of people who are already\ndisadvantaged, is a structural harm.\nWhat's more, if the app is better at diagnosing medical problems for some\npeople than others, especially if those differences map to important\ncategories like race or gender, there will be a structural problem even if\nthe app is better than a doctor for many people.\nIV. The Character Lens: what kind of 'person' is this project? does it\nmanifest virtue or vice? would a good person create, use, and/or support this\nproject, or not?\n‣ Ask: What are the character traits of this project? Does the\nproject (its development, use, operation) manifest virtues like\ncourage, kindness, impartiality, consideration, generosity, and\naltruism, or vices like cowardice, greed, bias, and selfishness?\n‣ This lens is a bit different from the others. But sometimes it's the\nmost intuitive way to understand ways in which a project can be\ngood or bad.\nExample: What is the character of the checkup app, and those who\nwould create, support, or use it? We can imagine that its\ndevelopers' goal was to increase access to medical care for those\nwho need it; that would be generous. Even so, if the app is\ndeployed by insurers just to cut costs, without benefiting patients,\nthat's greedy. If the app only works well for certain groups, then\nit's biased. Sometimes virtuous efforts are exploited by actors\noperating from vice; sometimes a project can itself seem to\nMoral Lenses\nJaques\n\nmanifest both virtues and vices. Thinking about how your project\ncan support virtuous uses and resist vicious ones can be a good\nway of working through its ethical dimensions.\nStep 4: Make it Ethical by Design\nYou now know a lot more about what your project is and does, and to and for\nwhom, and the ways in which that's good and bad. Your final step is to think\nabout which features of your project make a difference to the balance and\ndistribution of benefits and harms. What design choices maximize benefits,\nminimize harms, and do the best job of making sure both are distributed fairly?\nAt this stage, it's a good idea to think about how you would justify your choices\nto the people and groups affected by them--especially when there are significant\ntradeoffs. If one of your design choices benefits some people at others' expense,\nwhat would you say to those who are bearing the burden? What would they say\nin reply? One very good way to work through this stage--and the earlier ones,\ntoo!--is to talk to as many people from the relevant groups as you can. You don't\nneed to guess; you can ask.\nOnce you've mapped the changes your project produces to particular design\nchoices, and thought through which way to go with those choices by thinking\nabout what you can justify to those affected, you may find you need to rethink\nyour project. Do that, then work through the process again with the new version;\nkeep going till you have a version that doesn't seem to call for more changes.\n(And of course, the version that turns out to be best could be the one that means\nabandoning the project: you always need to be able to explain why your project\nis better than the alternatives, where those alternatives include the status quo.)\nExample: One important set of choices for the checkup app has to\ndo with what role actual doctors play in the process. Is the app\ndesigned to replace in-person checkups, or is it designed to speed\nup the checkup process without eliminating the in-person\ncomponent? If it's the latter, doctors may be in favor of your app;\nif it's the latter; expect them to object--because the former looks\nlike an outcome benefit to them, since it saves them time and thus\nallows them either to fit more appointments into their workday or\nto spend more time communicating with their patients, but the\nlatter is an outcome harm to them, threatening their income and\nMoral Lenses\nJaques\n\neven jobs. Of course, insurers will see different benefits and harms,\nand so deciding which way to design the app will involve balancing\nthe needs of each--along with patients and everyone else from\nStep 2.\nPractice Exercises\n1. Think of a piece of software you'd like to create. Work through the four steps,\nusing the moral lenses, and think about what the ethical issues are for your\nproject.\n‣ What are the main benefits it will or may provide, and to whom?\n‣ What are the main harms it will or may cause, and to whom?\n‣ How could you maximize the benefits and minimize the harms, and ensure\nthat they are distributed fairly?\n2. You've been practicing evaluating the software you create in terms of three\nimportant properties: correctness, clarity, and changeability. Correctness is about\nensuring that your code does what it's supposed to do. Clarity is about ensuring\nthat those who work with your code understand what they're getting, what\nthey're doing if they use it. And changeability is about ensuring that as\ncircumstances evolve, your code is able to adapt--so that it continues to do what\nit's supposed to do, and what people expect.\nAll of these properties are important to writing good software, and they often\nreinforce each other. Working on clarity can help with correctness; ensuring\ncorrectness can contribute to changeability; and so on. These properties can also\naffect the ethical import of a project: that is, failures of correctness, clarity, or\nchangeability can also be failures of outcomes, process, structure, or character.\nThis is because the 3 Cs affect what your project does, whether it does what\nothers expect, and so on.\n‣ How can a failure of correctness become an ethical problem?\nUse the moral lenses to answer.\n‣ Then do the same for failures of clarity and changeability.\nMoral Lenses\nJaques\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\nRES.TLL-008 Social and Ethical Responsibilities of Computing (SERC)\nFall 2022\nFor information about citing these materials or our Terms of Use, visit: https://\nocw.mit.edu/terms"
    },
    {
      "category": "Resource",
      "title": "RES.TLL-008 Social and Ethical Responsibilities of Computing (SERC), 6.031 Moral Lenses case study",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/res-tll-008-social-and-ethical-responsibilities-of-computing-serc/mit_restll008_6-031_moralslides.pdf",
      "content": "Moral Lenses case study\n\nWarmup\n- Read the problem and the proposed design change\n- With your partner, brainstorm:\n- differences that might happen as a result\n- stakeholders affected by or interested in those differences\n- Write your answers in case-study.txt\n\nMoral Lenses review\n- What are the three moral lenses?\n- let's imagine them in the context of a game show\n\nFacebook in 2017\n- Problem: people are still using FB, but more passively\n- reading posts and watching videos, but not commenting or liking as much as before\n- \"We have an ethical duty not to turn Facebook users into zombies\"\n- Proposal: rank posts by meaningful social interaction (MSI)\n- MSI = actions on a post (comment >> react-emoji/reshare >> like) made by your own friends\n- With your partner:\n- apply the moral lenses for the stakeholder group of your section of the room\n- write your answers in case-study.txt\n- Working with the other pairs in your section:\n- put your Outcomes/Process/Structure points in the slides\n- consolidate similar points\n- vote for 1-2 points per slide (e.g. important or nonobvious)\n- boldface those key points\n\nAction\n- After moral lens analysis, what do we have that we may not have had\nbefore?\n- What can we do with that new knowledge?\nFor more about this case study:\nWall Street Journal Facebook Files podcast series\n(c) WSJ. All rights reserved. This content is excluded from our Creative Commons\nlicense. For more information, see https://ocw.mit.edu/help/faq-fair-use/\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu/\nRES.TLL-008 Social and Ethical Responsibilities of Computing (SERC)\nFall 2022\nFor information about citing these materials or our Terms of Use, visit: https://\nocw.mit.edu/terms"
    },
    {
      "category": "Lecture Notes",
      "title": "RES.TLL-008 Social and Ethical Responsibilities of Computing (SERC), 6.170 Ethics Protocol Lecture",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/res-tll-008-social-and-ethical-responsibilities-of-computing-serc/9a221dbe4d169781cb4cd9df4fced3e8_MITRESTLL-008F21-6170lec.pdf",
      "content": "Ethics Protocol:\nA method for designing responsibly\n6.170 Fall 2020\nSerena Booth\nContent: Milo Phillips-Brown and Abby Jaques\n\nResponsibility\n\nResponsibility\nSome Choices\nA. Happy to do it\nB.\nReluctant but would do it\nC. Object to doing it and ask for an\nalternative task, but would do it if I had to\nD. Leak information to the public, but don't\nresign from my job\nE.\nKeep your job, but organize with others to\nstand up to leadership in the future.\nF.\nResign from my job rather than do it\nG. Resign from my job and leak information\nto the public\nCite: Abeba Birhane\nYou're an engineer at change.org.\nYour users have been learning that your\ncompany is for-profit, and that your petitions\nare never presented to government in an official\ncapacity. They're starting to leave your platform.\nYour manager asks you to design an alternative\nchange.org website to look and feel exactly like\nreal government petitions using their newly\npurchased change.whitehouse.org domain.\nWhat do you do?\n\nResponsibility\nSome Choices\nA. Happy to do it\nB.\nReluctant but would do it\nC. Object to doing it and ask for an\nalternative task, but would do it if I had to\nD. Leak information to the public, but don't\nresign from my job\nE.\nKeep your job, but organize with others to\nstand up to leadership in the future.\nF.\nResign from my job rather than do it\nG. Resign from my job and leak information\nto the public\nCite: Abeba Birhane\nYou're a UROP. You're interested in going to\ngrad school, and you had a hard time getting\nthis position. You're hoping for a good letter.\nYour grad student mentor works on a method\nfor explaining the decisions of autonomous\nsystems. Your grad student recently realized\ntheir system could also work for drones.\nThey task you with creating a website to help\nmilitary personnel assess UAV decisions. They\nsay, \"they're already using the drones, this will\njust increase accountability.\"\nWhat do you do?\n\nEthics: why should I care?\n\nEthics: why should I care?\nWe claim: exploring ethics and assessing your values now will\nhelp you make better decisions in the future.\nNow: less pressure, less stress, fewer sources of conflict.\nThe ethics protocol is a tool to help you with such decisions.\n\nEthics: why should I care?\nWe claim: exploring ethics and assessing your values now will\nhelp you make better decisions in the future.\nNow: less pressure, less stress, fewer sources of conflict.\nThe ethics protocol is a tool to help you with such decisions.\nYou will use the ethics protocol for your final projects.\n\nEthics Protocol Goals\n● Make more informed decisions\n● Justifying existing/past decisions\n\nEthics Protocol Goals\n● Make more informed decisions\n● Justifying existing/past decisions\n● Assess priorities, compromise\n● Search for a simple \"right\" answer\n\nEthics Protocol Goals\n● Make more informed decisions\n● Justifying existing/past decisions\n● Assess priorities, compromise\n● Search for a simple \"right\" answer\n● Avoid thoughtless blunders\n● Replacing participatory design\n\nEthics Protocol Overview\nEnvision\nPossible\nFutures\n\nEthics Protocol Overview\nEnvision\nPossible\nFutures\nIdentify\nStakeholder\ns\n\nEthics Protocol Overview\nEnvision\nPossible\nFutures\nIdentify\nStakeholder\ns\nIdentify\nValues at\nPlay\n\nEthics Protocol Overview\nEnvision\nPossible\nFutures\nIdentify\nStakeholder\ns\nIdentify\nValues at\nPlay\nIdentify\nValue-Laden\nDesign\nChoices\n\nEthics Protocol Overview\nEnvision\nPossible\nFutures\nIdentify\nStakeholder\ns\nIdentify\nValues at\nPlay\nIdentify\nValue-Laden\nDesign\nChoices\nChoose &\nJustify\n\nEthics Protocol Overview\nEnvision\nPossible\nFutures\nIdentify\nStakeholder\ns\nIdentify\nValues at\nPlay\nIdentify\nValue-Laden\nDesign\nChoices\nChoose &\nJustify\nBuild\n\ncw: COVID-19\n\nRunning Example: Digital Contact Tracing\nTwo main features:\n1. Contact Identification\npeople who have been exposed are identified\n1. Contact Notification\npeople are notified of their potential exposure\n\nPreliminary design choices\n1.Is contact tracing always \"on,\" or is it just used\nat certain establishments (e.g., restaurants)?\n2.Does the app use phone-to-phone\ncommunication, or do we add additional\nhardware beacons?\n3.Do we use bluetooth or GPS or neither?\n4.How is the app distributed?\n5....\n\nEthics Protocol Overview\nEnvision\nPossible\nFutures\n\nContact Tracing Imagined Futures\nThe government releases a contact tracing app.\nWithin two months, there were zero COVID-19\ncases in the country. Hundreds of thousands of\nlives were saved. Schools reopened, businesses\nflourished, and the roaring twenties kicked off.\nThe government preemptively decided to stop\ncollecting data from users, but maintained the\napp for in case of future pandemics.\n\nContact Tracing Imagined Futures\n< Room X: Add your imagined futures>\n\nContact Tracing Imagined Futures\n5 minutes\n\nContact Tracing Imagined Futures\nPOSITIVE\n-\nFaster\npandemic\nNEGATIVE\nrecovery\n-\nTrack certain\ngroups movements\nthrough the app\n(e.g. criminals)\n-\nOverreach for\nother examples\nthat don't\nrequire...\n-\nMake assumptions about\nmovement of certain groups\nNEUTRAL\n-\nWhat happens to data\nafter contact tracing is\nknow longer needed?\n-\nIncreased Legislation for\nreusing the app\n-\nData used for future\nresearch\n\nContact Tracing Imagined Futures\n-\nSurveillance state\n-\nDisproportionately harms marginalized communities\n-\nProtestors/whistleblowers at risk (one person traced can lead to\ntracking others)\n-\nBuggy App\n-\nLoses User's Trust, causes mass panic, doesn't prevent spread\n-\nApp is hacked/compromised\n-\nCan be used for ransom/stalking/blackmail\n\nContact Tracing Imagined Futures\n-\nPrivacy issues: creators of the app have access to other users'\nlocations and may use users' information for financial gain (e.g.\nselling to companies), could be used in turn for individual\nmarketing\n-\nOverconfidence issue: users' behavior becomes more risky as\nthey underestimate exposure and reduce testing frequency\n-\nGovernment abuse: using the app to track groups of people /\nhow they interact, potentially voter suppression\n\nContact Tracing Imagined Futures\n< Room 4: Add your imagined futures>\nGood:\n● Limited only for pandemic\nBad:\n● Using for other domains\n● Collected data unintentionally leaks sensitive information or is\nmisused/sold\n\nContact Tracing Imagined Futures\nSocial media could be transformed if this contact\ntracing app takes off. Something like proximity-\nbased socialization and connecting to others.\nSurveillance from government and corporations\nincreases. What if our location data is all sold?\n\nEthics Protocol Overview\nEnvision\nPossible\nFutures\nIdentify\nStakeholder\ns\n\nWhat is a stakeholder?\n\nWhat is a stakeholder?\nA stakeholder is anyone or any thing that\ncan affect or be affected by your project.\n\nStakeholders are not (just):\nYou & your institution\nFinancial backers (shareholders)\nUsers\n\nWhy define stakeholder so broadly?\n\nWhy define stakeholder so broadly?\nThere are no ethical externalities.\n\nThat doesn't mean you're responsible for\neverything.\n\nBut, to make things ethically,\nyou need to know\nwhat all the ethical elements are!\n\nStakeholder subgroups matter.\n\nContact Tracing Stakeholders\nSmartphone users\nNot-smartphone users\n\nContact Tracing Stakeholders\nSmartphone users\nNot-smartphone users\nBlack people\nHispanic or Latino people\n\nContact Tracing Stakeholders\nTask: Brainstorm as many stakeholders as you can\n5 minutes\n\nContact Tracing Stakeholders\n● Coronavirus(?)\n● Low income communities\n● Developers\n● Governments\n● Different Age Groups\n● People in areas with worse connectivity\n● People who are benefiting from the\npandemic.\n\nContact Tracing Stakeholders\n< Room 2: Add your stakeholders>\n-\nHealthcare workers\n-\nEssential workers\n-\nBusinesses/potential hubs for\ntransmission\n-\nMaker of app\n\nContact Tracing Stakeholders\n● Homeless & low-income\n● Healthcare workers\n● BIPOC\n● Non-smartphone owners\n● Elderly\n● Disabled\n● Children\n● Essential workers\n● Public transportation users\n● Government (all levels)\n\nContact Tracing Stakeholders\n● Users\n● Non-Users: Elderly (non-smartphone users)\n● Government\n● Hospitals\n● Testing Centers\n● Academia\n● Big pharma\n● Inter-Country Tracing Systems\n\nContact Tracing Stakeholders\n< Room 5: Add your stakeholders>\n● Lower-income, anyone without a phone or areas with\npoor connectivity\n● Rural vs. urban?\n○ Proximity to other people (tracing you through\nother people's devices)\n● Older vs younger\n○ People\n○ Tech\n■ New tech - less hackable but built in\nhardware\n● BIPOC\n\nEthics Protocol Overview\nEnvision\nPossible\nFutures\nIdentify\nStakeholder\ns\nIdentify\nValues at\nPlay\n\nMoral Lenses\nDifferent ways of looking at effects\non stakeholders that reveal different\nkinds of ethical significance.\n\nOutcome Lens\nIn what ways does what you're\nmaking turn out better or worse\nfor your stakeholders?\n\nProcess Lens\nHow did the process treat\nstakeholders?\nThink: autonomy, consent,\ntransparency, participation, etc.\n\nStructure Lens\nHow are the outcomes distributed\namong different stakeholders? What\nare the differences in how different\nstakeholders were treated by the\nprocess?\nCould be called 'Justice Lens'\n\nOutcome, Process, Structure\nWhat's missing?\nWhat are your values?\n\nEthics Protocol Overview\nEnvision\nPossible\nFutures\nIdentify\nStakeholder\ns\nIdentify\nValues at\nPlay\nIdentify\nValue-Laden\nDesign\nChoices\n\nTwo ways to identify value-\nladen design choices\n\nTwo ways to identify value-\nladen design choices\n1. Work forward:\nTake a choice you know you'd have to make and\ntrace out the value-laden implications\n\nPreliminary design choices\n1. How are COVID-19 cases identified?\n\nValues promoted\nValues demoted\nPossible Choice\n(and for whom?)\n(and for whom?)\nOption A\nOption B\nOption C\n\nValues promoted\nValues demoted\nPossible Choice\n(and for whom?)\n(and for whom?)\nUsers post their COVID-19\nstatus without proof\nOption B\nOption C\n\nValues promoted\nValues demoted\nPossible Choice\n(and for whom?)\n(and for whom?)\nUsers post their COVID-19\nstatus without proof\nUsers post their COVID-19\nstatus with doctor's note\nOption C\n\nPossible Choice\nValues promoted\n(and for whom?)\nValues demoted\n(and for whom?)\nUsers post their COVID-19\nstatus without proof\nUsers post their COVID-19\nstatus with doctor's note\nWe identify COVID-19\nstatus by monitoring vocal\npatterns [src]\n\nPossible Choice\nUsers post their COVID-19\nstatus without proof\nUsers post their COVID-19\nstatus with doctor's note\nWe identify COVID-19\nstatus by monitoring vocal\npatterns [src]\nValues promoted\n(and for whom?)\nStructure Lens: users don't\nhave to see a doctor\nProcess Lens: the process is\nentirely transparent\nValues demoted\n(and for whom?)\nOutcome Lens: bad actors\ncan prank the system\n\nPossible Choice\nUsers post their COVID-19\nstatus without proof\nUsers post their COVID-19\nstatus with doctor's note\nWe identify COVID-19\nstatus by monitoring vocal\nValues promoted\n(and for whom?)\nStructure Lens: users don't\nhave to see a doctor\nProcess Lens: the process is\nentirely transparent\nOutcome Lens: the least\nfalse positives\nOutcome Lens: we're able\nto identify the most cases\nValues demoted\n(and for whom?)\nOutcome Lens: bad actors\ncan prank the system\nStructure Lens: high\nbarrier to use\nProcess Lens: compromises\nprivacy\nProcess Lens: users didn't\nconsent to this data\ncollection\nStructure Lens: the model\npatterns [src]\nusing this technology\nonly uses English data.\n\nTwo ways to identify value-\nladen design choices\n1. Work forward:\nTake a choice you know you'd have to make and\ntrace out the value-laden implications\n2. Work backward:\nYou've identified futures and their ethical\ndimensions. Which choices result in which\noutcomes?\n\nWorking backward\nOne envisioned future is that there are so many\nfalse positives, the system is incredibly ineffective\nand we give up using it.\nOne contributing design decision could be this\nquestion of how positive cases are communicated.\n\nPreliminary design choices\n1. How are COVID-19 cases identified?\n2. GPS vs Phone-to-Phone Bluetooth\n3. Opt-in vs opt-out?\n4. Distribution mechanism?\n5. Always on, or only used in certain locations?\n6. ...\n\nPossible Choice\nGPS\nBluetooth\nValues promoted\n(and for whom?)\nOutcomes: we can remove\noutdoors\nJustice: works anywhere in\nthe world\nOutcomes: we're more\nconfident you were in close\nproximity\nValues demoted\n(and for whom?)\nOutcomes: generally worse\nprotocol\nProcess: collecting a lot\nmore data\nOption C\nRoom 1\n\nValues promoted\nValues demoted\nPossible Choice\n(and for whom?)\n(and for whom?)\nOption A\nOption B\nOption C\nRoom 2\n\nEthics Protocol Overview\nEnvision\nPossible\nFutures\nIdentify\nStakeholder\ns\nIdentify\nValues at\nPlay\nIdentify\nValue-Laden\nDesign\nChoices\nChoose &\nJustify\n\n1. How are COVID-19 cases identified?\nChoice: Users post their COVID-19 Status by acquiring\nan authorization code from their doctor.\n● This prevents bad actors from manipulating\nthe system, forcing unnecessary self-isolation,\nunlike without requiring authorization codes.\n● Users consent, unlike with the voice\nmonitoring solution.\n● Fewer users report, since this requires the\nfinancial means/feelings of security needed to\nsee a doctor in the US.\n● Privacy is compromised since users can be\nassociated with a specific doctor's visit.\n\nContact Tracing Choose & Justify\n5 minutes\n\n1. Question?\nChoice\nJustification\nRoom 1\n\nEthics Protocol Overview\nEnvision\nPossible\nFutures\nIdentify\nStakeholder\ns\nIdentify\nValues at\nPlay\nIdentify\nValue-Laden\nDesign\nChoices\nChoose &\nJustify\nBuild\n\nChoose &\nJustify\nBuild\n\"Minor\" technical\ndecisions can have\nethical consequences.\n\nChoose &\nJustify\nBuild\nImmediate\nNotifications?\n\nDon't forget to ask:\n\"Should I build this?\"\nFin!\nReminder: You'll use the ethics protocol\nin your final projects.\n\nLearn More Ethics!\nClasses (Spring `21):\n● 24.191 Being, Thinking, Doing (or not): Ethics in Your Life\n● 24.03 Good Food: The Ethics and Politics of Food\n● 24.231 Ethics: Systematic study of central theories in ethics\n● 24.237(J) Feminist Thought\nOther:\n● PKG Center - internships, colloquia, funding for your ideas, lots of\nopportunities!\n● AI Ethics Reading Group, AI Alignment Reading Group, & more\n\nQ&A\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\nRES.TLL-008 Social and Ethical Responsibilities of Computing (SERC)\nFall 2021\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms"
    },
    {
      "category": "Resource",
      "title": "Design Decisions",
      "type": "DOCX",
      "source_url": "https://ocw.mit.edu/courses/res-tll-008-social-and-ethical-responsibilities-of-computing-serc/b89d2884415283f892633d8ab97dd456_MITRESTLL-008F21-6170designReflection.docx",
      "content": "Design Decisions\n\n1. Insert your short and compelling design decision title phrase\n\nBegin your design decision discussion with introducing the decision and the rationale behind why you chose it but be sure to discuss any limitations this choice still has.\n\nAlternatives Considered: Then go on to listing alternative design choices you may have considered and discuss why you didn't choose them, comparing them to the design you did choose.\n\n2. Insert your short and compelling design decision title phrase\n\nBegin your design decision discussion with introducing the decision and the rationale behind why you chose it but be sure to discuss any limitations this choice still has.\n\nAlternatives Considered: Then go on to listing alternative design choices you may have considered and discuss why you didn't choose them, comparing them to the design you did choose.\n\n3. Insert your short and compelling design decision title phrase\n\nBegin your design decision discussion with introducing the decision and the rationale behind why you chose it but be sure to discuss any limitations this choice still has.\n\nAlternatives Considered: Then go on to listing alternative design choices you may have considered and discuss why you didn't choose them, comparing them to the design you did choose.\n\n4. Insert your short and compelling design decision title phrase\n\nBegin your design decision discussion with introducing the decision and the rationale behind why you chose it but be sure to discuss any limitations this choice still has.\n\nAlternatives Considered: Then go on to listing alternative design choices you may have considered and discuss why you didn't choose them, comparing them to the design you did choose.\n\nEthical / Social Reflection\n\nDescribe how conducting the A4 reflection informed your design process in this assignment. In particular, has your interface design changed as a result - how, or why not? Also, are there other social/ethical implications that you encountered when translating your wireframes into a working implementation?\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\n\nRES.TLL-008 Social and Ethical Responsibilities of Computing (SERC)\nFall 2021\n\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms"
    },
    {
      "category": "Resource",
      "title": "Ethical Implications",
      "type": "DOCX",
      "source_url": "https://ocw.mit.edu/courses/res-tll-008-social-and-ethical-responsibilities-of-computing-serc/d9fd91777252a2cc082f4ff820c42b6b_MITRESTLL-008F21-6170ethical.docx",
      "content": "Ethical Implications\n\nAnswer the following questions. In your answers, please distinguish which implications follow from your conceptual design and which follow from your UI design.\n\nDid you make cultural or other assumptions about your users that affect how they interact with Fritter?\n\nWould an effective use of design heuristics to maximize engagement with Fritter be manipulative?\n\nHow would you adjust your design if your only goal were to: get children addicted to Fritter? or make it hard for older people to use Fritter? or stop fake news spreading? or prevent harassment? How, if at all, do your answers to these questions inform how you would actually design Fritter?\n\nYou have the option to allow users to see which other users have upvoted a Freet. What forms of engagement between users (positive or negative) would be encouraged by allowing this?\n\nIn A3, we asked about stakeholders who aren't your immediate users. Identify a design choice you faced that would benefit or harm such a stakeholder, and explain how.\n\nWhat are the accessibility implications of your design for people with different abilities?\n\nOne of the heuristics is to \"speak the user's language.\" In retrospect, assuming you followed this, can you identify what kind of user you had in mind?\nMIT OpenCourseWare\nhttps://ocw.mit.edu\n\nRES.TLL-008 Social and Ethical Responsibilities of Computing (SERC)\nFall 2021\n\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms"
    },
    {
      "category": "Resource",
      "title": "Fritter User Test",
      "type": "DOCX",
      "source_url": "https://ocw.mit.edu/courses/res-tll-008-social-and-ethical-responsibilities-of-computing-serc/16a11f2babb9f1c77c67da33a4a14054_MITRESTLL-008F21-6170user.docx",
      "content": "Fritter User Test\n\nSpecify Tasks for the User completed for your user test\nTask 1: User upvotes another user's freet, then removes their upvote\nTask 2: User follows another user, then checks their feed\n....\nTask n: User refreets another user's freet\n\nSummary of Observations\n\nDiscuss your observations you had as you observed your user go through the tasks you provided them.\n\nChanges in Responses to UI\n\nNote any changes you will make to your UI in response to what you observed from your user test.\nMIT OpenCourseWare\nhttps://ocw.mit.edu\n\nRES.TLL-008 Social and Ethical Responsibilities of Computing (SERC)\nFall 2021\n\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms"
    },
    {
      "category": "Resource",
      "title": "Heuristic Evaluation",
      "type": "DOCX",
      "source_url": "https://ocw.mit.edu/courses/res-tll-008-social-and-ethical-responsibilities-of-computing-serc/b91f260be72dba5c48c53d9bab5b5f61_MITRES-TLL-008F21-6170Heuristic.docx",
      "content": "Heuristic Evaluation\n\nFor each heuristic, you should cite one example in your wireframe either illustrating how the heuristic suggests an improvement, or pointing to a design decision you made that supports the heuristic.\n\nFitt's Law\n\nSpeak the User's Language\n\nConsistent Naming & Icons\n\nInformation Scent\n\nFollow Conventions\n\nShow Location & Structure\n\nAccelerators\n\nKeep Paths Short\n\nUndo & Cancel\n\nPerceptual Fusion\n\nGestalt Principle of Grouping\n\nRecognition vs. Recall\n\nAnticipation & Context\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\n\nRES.TLL-008 Social and Ethical Responsibilities of Computing (SERC)\nFall 2021\n\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms"
    },
    {
      "category": "Resource",
      "title": "Module: Big Data and Personal Privacy",
      "type": "DOCX",
      "source_url": "https://ocw.mit.edu/courses/res-tll-008-social-and-ethical-responsibilities-of-computing-serc/8283d95f3ec08827137334de3d3959ca_MITRES-TLL008F21-STS-012module.docx",
      "content": "Module: Big Data and Personal Privacy\n\nReadings:\n\nSarah Valentine, Impoverished Algorithms: Misguided Governments, Flawed Technologies, and Social Control. (2019). 46 Fordham Urb. L.J. 364.\n\nBoyd, Danah, and Kate Crawford. 2012. \"Critical Questions for Big Data.\" Information, Communication & Society 15(5): 662-679.\n\nAt home exercise:\n(Voluntary)\n\nLearn more about your data rights.\nhttps://www.dataprotection.ie/en/individuals/know-your-rights/right-access-information\nhttps://tapmydata.com/features/#superpower\nAccess your data from three websites/services you frequently use (Examples: Facebook, Twitter, Instagram, Google etc.)\nTip: Tapmydata is an application that makes it easy to send these requests. (Remember however that after a certain point in the process, they might ask you to use your data in a particular way.)\nWrite and post a short 200-word reflection on what you found and whether what you found surprised you. Think reflection should incorporate insights from the two readings for this week, particularly the sections on data triangulation and commercialization.\nRead your classmates posts.\n\nIn class:\n\nDiscussion of the key points of the articles and of the student responses.\n\nAims:\n\nTo find overlaps and differences in the experience of students learning about their right to privacy\nTo discuss whether they believe existing rights to be adequate\nTo examine whether current ethical standards (such as those instituted by the GDPR) sufficiently protect their rights (as they exist or as they believe should exist).\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\n\nRES.TLL-008 Social and Ethical Responsibilities of Computing (SERC)\nFall 2021\n\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms"
    },
    {
      "category": "Resource",
      "title": "Social / Ethical Implications",
      "type": "DOCX",
      "source_url": "https://ocw.mit.edu/courses/res-tll-008-social-and-ethical-responsibilities-of-computing-serc/6798d7403276605c3f41b5a84eb2e433_MITRESTLL-008F21-6170social.docx",
      "content": "Social / Ethical Implications\n\n1. Insert your short and compelling social / ethical implication title phrase\n\nYou should explain why the decision you made has particular implications, and, if those are negative, how they might be mitigated.\n\n2. Insert your short and compelling social / ethical implication title phrase\n\nYou should explain why the decision you made has particular implications, and, if those are negative, how they might be mitigated.\n\n3. Insert your short and compelling social / ethical implication title phrase\n\nYou should explain why the decision you made has particular implications, and, if those are negative, how they might be mitigated.\nMIT OpenCourseWare\nhttps://ocw.mit.edu\n\nRES.TLL-008 Social and Ethical Responsibilities of Computing (SERC)\nFall 2021\n\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms"
    },
    {
      "category": "Assignment",
      "title": "Assignment Part 0",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/res-tll-008-social-and-ethical-responsibilities-of-computing-serc/62162d4f97741c381b492697930242ed_MITRES-TLL008F21_6864pt0.pdf",
      "content": "Assignment Part 0:\nFirst read the assignment background & overview. Then, consider the following scenarios, and\nbriefly describe any problem(s) you think could arise (~1 paragraph or a few bullet points).\n1. Your friend works in the admissions office of a nearby university. They mention that\nthere's a proposal to build an ML model to help filter applications, using features like\nthe applicant's extracurricular activities and test scores. They're planning to train the\nmodel on data from past students at the school. To label this data, they propose using\nthese past students' college GPA -- if the GPA is above 2.75, the label will be positive\n(i.e., should be admitted) and if not, the label will be negative (i.e., should not be\nadmitted).\n2. The company you work for is prototyping a model to sift resumes and recommend\nwhich applicants to follow up with for interviews. Over a period of a few months, they\npull out the text from all the applications that come in, and have employees across the\ncompany annotate whether they are qualified candidates. Now, they want to use this as\nthe dataset to train a model to predict whether a new candidate is qualified (and if so,\nextend an interview).\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\nRES.TLL-008 Social and Ethical Responsibilities of Computing (SERC)\nFall 2021\nFor information about citing these materials or our Terms of Use, visit:\nhttps://ocw.mit.edu/terms"
    },
    {
      "category": "Resource",
      "title": "A1 Problem Statement",
      "type": "DOCX",
      "source_url": "https://ocw.mit.edu/courses/res-tll-008-social-and-ethical-responsibilities-of-computing-serc/bfc14b2cbbe688c89a9901034e027e52_MITRESTLL-008F21-6170hw1.docx",
      "content": "A1 Problem Statement\nOverview & Objectives\nThe Game. In this assignment, you'll build a browser-based version of John Conway's Game of Life, a cellular automaton that simulates the evolution of an organism using a simple deterministic rule.\nWriting code in JavaScript. The main purpose of the assignment is to give you practice writing high-quality code in JavaScript. This includes not only the superficial aspects of coding (such as neat formatting, judicious commenting, having functions of reasonable size, and so on) but also the more subtle aspects that have a major impact on how easy the code is to understand and modify, and which tend to require more sophisticated techniques.\nIdioms. In particular, you should use the idioms you've learned in class, notably abstracting iteration with functionals and using closures to control access to state.\nLocalizing design decisions and avoiding repetition. A good check that your code is well structured is to consider whether each of the key design decisions (such as the shape of the board, or the rules for playing the game) is expressed at a single point in the code. Also, you should avoid repetition and redundancy so that changes even to small features (such as the dimensions of the board) can be made in just one place.\nDesign Reflection. Although this assignment is focused on coding, the theme of the class as a whole is design. Each assignment will therefore involve conducting some design reflection, and this assignment will give you your first experience doing this.\nSpecification\nYour pair's (or individually) task is to build a browser-based version of John Conway's Game of Life. Users should be able to select one of a collection of preset starting states, or create an arbitrary starting configuration, and start and stop an instance of the animation while it is running.\nProvided code. To spare you the effort of implementing a user interface (which we will cover later in the class), we are providing you with some starter code that sets up the visual board and controls for you. Your task is to write the code that maintains the internal representation of the game, applies the rules, and sends updates to the visual board. Implementing this code involves providing the bodies of some functions in a given file. Of course, you should not constrain your code to be entirely within those functions; they will likely make calls to other functions that you will declare. To open & manually test your implementation in the browser in Chrome go to File > Open File... > Select & open index.html from finder and this will show you the game of life UI.\nClient side code only. Your implementation will be loaded as a web page, and run without a server. This project requires client-side code only. You should only be writing JavaScript that runs in a web browser, and there is no need to provide any server-side code to generate these pages.\nCommenting and testing. Your code should include succinct specifications of functions and classes, should be commented appropriately. Testing graphical behavior is hard, and we don't expect you to do this automatically -- eyeballing the output is enough.\nDesign Reflection. (max 1000 words) In your design reflection, you & your partner should describe:\nThe key design decisions you made, and how you achieved localization and avoided repetition.\nHow you exploited functionals in your code, and why they improved the design.\nSome alternatives you considered to your design and why they were not chosen.\nSome limitations of your design and how they might be addressed.\nSome comments on the ethical implications of the project (see hints below).\nDeliverables\n\nThe entire code of your project, comprising the starter code with your code inserted in the file internal.js (which provides several skeletal functions that you should complete).\nA file called reflection.md, in the top-level directory of the repo, that contains the design, ethical reflections. Give each section a header and in the header, put the partner responsible for that section in parenthesis\nIf you worked with a partner, each partner must fill out the prompts of the Assignment repo's critiques.md file.\nIf you worked individually, fill out the sections for Partner 1 in critiques.md except the Partner Critique & Authorship sections.\nCollaboration Policy for Partner Assignments\nPlease review and follow the collaboration policy for partner assignments on the course syllabus.\n\nRemember that both partner's should engage with all parts of the assignment (code implementation, design, and reflections) and divide the work equally.\nGrading\nSee the accompanying rubric.\n\nHints\nDesign Reflection. Keep your discussion succinct, clear and to the point. Including irrelevant comments or repeating yourself will lead to a lower grade. Some design decisions to consider (also called \"dimensions\" or \"axes\" of a design) include: what data structures you used to represent the game board; how you chose to iterate over cells; how the board was updated or replaced at each step; how presets were represented and loaded.\nEthical Implications. The last part of the design reflection asks you to comment on some of the ethical implications of your project. You are free to consider any moral or ethical issue that you think is relevant, so long as what you write is coherent, thoughtful and to the point. Recognizing that the Game of Life has been taken by many computer scientists as a metaphor for biological and evolutionary processes, or even for population control, you might consider how this metaphor influences, positively or negatively the way we view the real world and our role in it. Or you might examine to what extent you just implemented the rules without considering their meaning, and whether this is typical of how programmers operate in corporate settings.\nDocumentation of Public Interfaces: You are not required to use any particular JavaScript annotation tool (if you'd like to, JSDoc is a popular tool), nor any particular styling of comments. Recall from 6.031 that to document your interfaces, you wrote brief, stylized comments for each function and, for each module, a very brief summary of what the module provides.\nUse of Functionals: This assignment provides many opportunities to use functionals, as taught in lecture, to eliminate duplication in the code and to make it more succinct and more elegant. In particular, you may want to think about how you iterate over the neighbors of a cell, and whether this can be abstracted. One of the former 6.170 TAs (Harihar Subramanyam) made a guide about common misuses of functionals. It's highly recommended that you read it before starting the pset.\nAdditional References: The Wikipedia article on Game of Life; an implementation using an external graphics library, with simple source code (but you can do better!); a video of Conway talking about the game; a longer discussion of the game, its properties, as well as different objects and their properties (including stationary, oscillating, and gliding objects).\nEdge Behavior: When live cells reach the edge of the grid, there are a number of ways they could behave, including: cells off the board could simply all be \"dead\" cells, or \"live\" cells could wrap around the edge of the board. Any behavior is acceptable, so long as your implementation is consistent and reasonable.\nMarkdown: When writing your reflection.md file, check out this cheat sheet for information on how to style markdown.\nTesting: Although you will not be assessed on writing tests (graders will not run them), if you choose to write tests, we suggest using Jest.\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\n\nRES.TLL-008 Social and Ethical Responsibilities of Computing (SERC)\nFall 2021\n\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms"
    },
    {
      "category": "Resource",
      "title": "A1 Rubric",
      "type": "DOCX",
      "source_url": "https://ocw.mit.edu/courses/res-tll-008-social-and-ethical-responsibilities-of-computing-serc/c37d9a4ef3bc3c3c6b6b06612fe2ba3e_MITRESTLL-008F21-6170hw1rubric.docx",
      "content": "A1 Rubric\n(50 points) Functionality\n30 points for correct rule implementation\n10 points for creating a collection of preset starting states (at least 3)\n10 points for being able to create an arbitrary starting configuration\n\n(5 points) Presentation\n5 points for presenting code neatly, well formatted and judiciously documented.\n\n(45 points) Design reflection (max 1000 words)\n15 points for describing key design decisions:\n2 points for describing what design decisions were identified.\n5 points for describing how the decisions were resolved, and localized.\n3 points for describing why those decisions were made.\n5 points for describing what alternatives were considered and why they were not taken.\n10 points for describing functionals:\n5 points for describing how functionals were used (point to places in the code).\n5 points for describing why these functionals were used (that is, what was gained).\n10 points for analyzing limitations:\n5 points for describing design limitations (not bugs in the implementation).\n5 points for describing how they may be addressed in the future.\n10 points for discussing ethical implications in a compelling and coherent way.\nMIT OpenCourseWare\nhttps://ocw.mit.edu\n\nRES.TLL-008 Social and Ethical Responsibilities of Computing (SERC)\nFall 2021\n\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms"
    },
    {
      "category": "Resource",
      "title": "Part 1 HW2",
      "type": "DOCX",
      "source_url": "https://ocw.mit.edu/courses/res-tll-008-social-and-ethical-responsibilities-of-computing-serc/4008487bbeb088b18e99a15727f1dec5_MITRES-TLL008F21-6864pt1.docx",
      "content": "Part 1:\n\nThis part of HW2 is a group assignment. Look through the Task A and Task B descriptions, and then discuss & submit answers for the following questions with your group. Only one group member needs to submit answers but you should work collaboratively (e.g., maybe draft answers together in a google doc).\n\nCome up with a labeling scheme. How many labels do you want to have? Are they binary, or multi-class? It might help to think about / decide how you want to use the resulting model. Write a few sentences on how you came to your decision.\n\nYou have a budget to hire people to annotate the comments according to your labeling scheme. Write a set of instructions to give to the annotators.\nThe format of your instructions is flexible, but as a guide you can consider the following parts:\nBrief task description including what they will see & be asked to do (~1 paragraph)\nStep-by-step instructions for how to label each example\nTips for reading the examples (~1 paragraph): For example, are there specific factors they should consider/look out for? Should they go with their first reaction or look up additional information?\nYour labeling scheme (~1-2 paragraphs or several bullet points): Make sure you describe your labeling scheme precisely--you don't want people to be labeling examples with different terms, since that will make it hard to reconcile the labels from different annotators. Define terms that are not clear, and maybe include guidelines for what people should do if they're not sure (Should they go with their best guess? Or are you going to include a \"Not Sure\" label in your scheme?).\nSample labeled examples according to your labeling scheme (e.g. use the examples in your task description doc)\n\nWrite a few sentences about how you might integrate the annotations into the dataset. Will you average labels of multiple annotators for each example or use some other aggregation? What do you do with examples where there's disagreement among annotators? It's okay if you're not sure, just try to write about what the tradeoffs might be.\n\nAre there concerns you have about using technology to address this problem?\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\n\nRES.TLL-008 Social and Ethical Responsibilities of Computing (SERC)\nFall 2021\n\nFor information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms"
    },
    {
      "category": "Assignment",
      "title": "RES.TLL-008 Social and Ethical Responsibilities of Computing (SERC), 17.806 Problem Set 1 Questions",
      "type": "PDF",
      "source_url": "https://ocw.mit.edu/courses/res-tll-008-social-and-ethical-responsibilities-of-computing-serc/mit_restll008_17-806_pset1.pdf",
      "content": "17.806: Problem Set 1\nProfessor: In Song Kim\nPlease submit both your write-up and your code electronically to the Learning Modules.1 This should\nbe completed before class begins at 3 pm (late submissions will not be accepted).\nAnalyzing the impact of police stopping on politcal behavior\nIn the lecture, we have learned that an increase in the availability of (unstructured) data would advance\nempirical analysis in political science. In this problem set, you will explore how/whether policing against\ncitizens and against racial minorities a ects political behavior of citizens by leveraging a variety of data\nsources online. In recent years, micro-level administrative data on policing is readily available, which\nallows us to conduct more reliable analysis from observational data. This problem set particularly focuses\non the stop-question-and-frisk (SQF) by the New York Police Department (NYPD).\nNYPD discloses geo-located data on all SQF, which o ers us a unique opportunity to study the\nrelationship between policing and voting behavior at the ne-grained level. Some critics have argued\nthat SQF is a racially discriminatory policy because people being stopped are overwhelmingly Black\nand Latino.2 In particular, more than 50% of SQF are conducted against black people while they only\naccount for a quarter of the population in NYC. Since policy toward policing has been one of the salient\nissues in recent elections, this problem set will examine how/whether SQF in a community a ects voting\nbehavior. Speci cally, we will analyze the impact of police stopping on the electoral outcomes using the\nNYPD SQF data and election data from the 2016 and 2020 presidential elections. For the purpose of\nthis course, these problems will help us practice various skills to collect new data and make use of regex.\n1. As the rst step, we will practice automatically downloading data and structuring the downloaded\ndata. Although the number of les that we download in this question does not require us to develop\na pipeline to download the data automatically, researchers often encounter websites with thousands\nor millions of target data that makes it impossible to download manually. Therefore, this exercise\nwill get you started on this process while you think about your own data collection e orts.\nThe NYPD discloses the SQF data at their website (https://www1.nyc.gov/site/nypd/stats/\nreports-analysis/stopfrisk.page) from years 2003 to 2019.\nWrite codes to automatically\ndownload the SQF data from the website. In your codes, create a directory named data rst,\nthen create a subdirectory named nypd_stop_data inside data, and store the downloaded data\ninto nypd_stop_data (i.e., write a script to automatically create the folders and subfolders and\nstore the downloaded data rather than manually do so).\nPlease follow these steps:\n1 Site is unavailable to OCW users.\n2 Milner, Adrienne N., Brandon J. George, and David B. Allison. 2016. Black and Hispanic men perceived to be large\nare at increased risk for police frisk, search, and force. PloS One 11.1.\n\n‹ Identify the URL that contains data\n‹ Analyze the html by extracting tags and attributes that contain data\n‹ Create folders/directories to store data\n‹ Download data (Make sure to wait a bit between downloads because too much tra°c may\ncause a website to crash, and/or the website could identify you as a bot and block you from\naccessing it. To do so, try using the Sys.sleep function.)\nThe directory to contain the data should look like this.\nPset1\npset1_solution.Rmd\ndata\nnypd_stop_data\nsqf-2019.xlsx\n...\nHint\n‹ Use the rvest package to analyze html\n‹ Use download.file function in the base R to download les\n‹ Use regex to identify les to download. Closely examine the html le of the website and make\nsure not to download irrelevant les. You can check the source code with the web browser\n(e.g., go to View/Developer/View Source in Google Chrome).\n2. The downloaded SQF data span multiple years and contain more than one hundred variables that\nmay not be relevant to our analysis. The natural next step is to clean and structure our data.\nIn this problem, we will practice cleaning data programmatically, while the tools we learn can\nbe applied to many settings. The goal is to construct one standard data frame nypd_data that\ncontains four variables year, race, xcoord, and ycoord from years 2014 to 2019. This data frame\nwill then be used to identify election districts for our empirical analysis.\nHint: Use regex to identify targeted years and unzip corresponding les. For further information\nabout the dataset, refer to the code books available at the NYPD website (https://www1.nyc.\ngov/site/nypd/stats/reports-analysis/stopfrisk.page).\n3. Extra Credit. Follow the hint below to map the location of each SQF to corresponding election\ndistrict based on xcoord and ycoord. 3 Since cleaning this data requires some knowledge in GIS\nsystem, we provide the cleaned version of the data (nypd_sqf_2014_2019.csv) for later analysis\non the Canvas website.\nHint\n‹ NYC publicizes GIS data of election district, which is also available on Canvas.\n‹ The geographic coordination system used in the SQF data is not based on longitude and\nlatitude.\nproject function in the proj4 package will be useful to convert its geographic\ncoordination system to longitude/latitude rst. You may nd the following website helpful:\nhttps://spatialreference.org/ref/epsg/nad83-new-york-long-island-ftus/proj4/.\n3 Note that election district is an administrative border created within each electoral district.\n\n‹ To match the election district with each SQF location, st_intersects function in the sf\npackage would be useful.\n4. In this question, we will analyze the impact of SQF on the electoral outcomes using the collected\nNYPD data (nypd_sqf_2014_2019.csv on Canvas).\nWe apply the Di erence-in-Di erences strategy to estimate the e ect of the changes in SQF on the\nchanges in the vote share for the Democratic candidate (We will learn more about the Di erence\nin-Di erences strategy later in the course). In our regression analysis, the outcome variable is the\nproportion of votes for the Democratic candidate in the 2016 and 2020 presidential elections, Yit,\nwhere i denotes the election district and t denotes one of the two time periods. The explanatory\nvariable, Dit, is the average number of SQF in 20142016 and 20172019. We de ne Tt as the\nbinary indicator that will be equal to one for the second period and zero for the rst period. We\nwill also include a vector of Xit as our control variables. Formally, we estimate the regression\nmodel:\nYit = β0 + β1Dit + β2Tt + β3DitTt + γ0Xit + εit\nLoad the election result data from the 2016 and 2020 presidential election (pres_res.csv). The\ndata is measured at election district level, which is much more granular than any other adminis\ntrative district.4\nFollowing variables are contained in the data:\n‹ year: year of election, either 2016 or 2020\n‹ election_type: type of election\n‹ district: electoral district\n‹ elect_dist: election district\n‹ vote_dem: the proportion of votes for the Democratic candidate received in the election district\nThe election district control variables are available in demographic_df.csv on Canvas.\nThose\ncontrol variables are total_pop, black, unemploy_rate, and median_income.\nEstimate the model with an ordinary least square regression. Plot all the estimates along with\n95% con dence intervals. In your plot, make sure to adjust for your standard error and highlight\nthe quantity of interest with a di erent color. Finally, brie y interpret the results and explain the\nrationale of this modeling strategy and necessary assumptions for causal identi cation.\n5. One potential confounder in our analysis is neighborhood safety. That is, whether the neighborhood\nis safe or not might a ect both votes toward Democrats and SQF. To address this concern, we will\ncollect crime report data in NYC while practicing using API. Follow the steps below to obtain the\nAPI token and download this dataset.\n‹ Sign up for API token at https://data.cityofnewyork.us/signup (Using App Tokens\nwill be enough).\n‹ Access crime report data at https://data.cityofnewyork.us/resource/qgea-i56i.json.\n4 You can check election districts in NYC at this website: https://vote.nyc/page/nyc-district-maps\n\n‹ Write codes to download the crime report data from years 2017 to 2019 and extract variables\nrpt_dt, law_cat_cd, latitude, longitude, x_coord_cd, y_coord_cd. You may nd the\nhttr package useful.\n‹ Limit your download per query to 5000. Note that over-tra°c can crash the server and other\npeople might not be able to use the API. $offset and $limit would be useful to control the\nnumber of query.\n‹ Construct the data frame and lter for felony and violation in the crime category.\nOnce you nish downloading the data, create a data frame to store the data. First ve rows should\nlook like this:\nrpt_dt\nlaw_cat_cd\nlatitude\nlongitude\nx_coord_cd\ny_coord_cd\n2017-01-01T00:00:00.000\nFELONY\n40.872037533\n-73.83784794\n2017-01-01T00:00:00.000\nFELONY\n40.830911443\n-73.866137497\n2017-01-01T00:00:00.000\nFELONY\n40.67109684\n-73.906209401\n2017-01-01T00:00:00.000\nFELONY\n40.837436665\n-73.944159423\n2017-01-01T00:00:00.000\nVIOLATION\n40.627248134\n-73.942627681\nAlthough you can click and download the entire data from 2006, it is an extremely huge le (larger\nthan 1GB) and would be di°cult to load in R even if you directly download the data manually\nfrom the website. Therefore, it is necessary to download just relevant observations and columns by\ncommunicating with API. The New York City API is constructed based on the Socrata Open Data\nAPI, which is widely used in governments, non-pro ts, and NGOs around the world. Once you\ncomplete this task, you will be able to deal with any datasets that use the Socrata's\nsystem at http://www.opendatanetwork.com/.\n6. Extra Credit. Now follow the same steps in Question 3 to map the crime report data to election\ndistricts. Calculate the number of crime reports from 2014 to 2016 and from 2017 to 2019 for each\nelection district. Include this additional control variable in our Di erence-in-Di erences analysis.\nAre our results robust?\n7. Another way to strengthen our analysis is to test the mechanism through which SQF a ects voting\nbehaviors. One possible mechanism is that Democratic politicians have introduced more or fewer\nbills on police reforms as a response to increasing concerns over law enforcement. To start on\nthis analysis and practice parsing PDF les, download the meeting agenda for NYC Committee\non Public Safety from years 2014 to 2019 (available on Canvas).5 Read in PDF les and apply\nregex to extract bill, bill number, committee chair, and date of introduction. For this question,\nyou should focus on bills with Int as the pre x and can approximate the date of introduction as\nthe printed date (See Figure below). Construct a dataset with the rst few rows as:\nbill\nbill number\nchair\ndate\nInt 1234-2018\n1234-2018\nDonovan J. Richards\n1/ 18/19\nInt 1261-2018\n1261-2018\nDonovan J. Richards\n1/ 18/19\nInt 1105-2018\n1105-2018\nDonovan J. Richards\n2/ 6/19\nInt 1309-2018\n1309-2018\nDonovan J. Richards\n2/ 6/19\n5 The\noriginal\nles\nare\navailable\nat\nhttps://legistar.council.nyc.gov/DepartmentDetail.aspx?ID=6913&GUID=\nBCE87221-FD8F-40B5-94D4-66C5F4F643E7\n\nWhat do you observe about the number of reform bills across two periods of study (i.e., 2014-2016\nand 2017-2019)? Given our goal, can you think of a way to improve this data collection strategy?\n(c) New York City Council. All rights reserved. This content is excluded from our Creative\nCommons license. For more information, see https://ocw.mit.edu/help/faq-fair-use/\nFigure 1: Sample Meeting Agenda for NYC Committee on Public Safety. The highlighted\nparts represent the key information we would like to extract for our analysis.\n\nMIT OpenCourseWare\nhttps://ocw.mit.edu\nRES.TLL-008 Social and Ethical Responsibilities of Computing (SERC)\nFall 2022\nFor information about citing these materials or our Terms of Use, visit: https://\nocw.mit.edu/terms"
    }
  ]
}